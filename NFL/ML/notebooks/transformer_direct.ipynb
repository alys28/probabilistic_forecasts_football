{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "print(parent_dir)\n",
    "interpolated_dir = os.path.join(parent_dir, \"dataset_interpolated_fixed\")\n",
    "features = [\"score_difference\", \"timestep\", \"type.id\", \"relative_strength\", \"home_has_possession\", \"end.down\", \"end.yardsToEndzone\", \"end.distance\", \"field_position_shift\", \"home_timeouts_left\", \"away_timeouts_left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 2022\n",
      "  Processing 271 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2022\n",
      "Loading data for 2024\n",
      "skipping  2024\n",
      "Loading data for 2023\n",
      "skipping  2023\n",
      "Loading data for .DS_Store\n",
      "Loading data for 2017\n",
      "  Processing 254 CSV files in parallel with 8 workers...\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2017/game_400951752.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2017/game_400951752.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2017/game_400951752.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2017/game_400951752.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2017/game_400951752.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2017/game_400951752.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2017/game_400951752.csv\n",
      "  Completed processing 2017\n",
      "Loading data for 2019\n",
      "  Processing 256 CSV files in parallel with 8 workers...\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127989.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127989.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127989.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127989.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127989.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127963.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127963.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127963.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127963.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127963.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127963.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2019/game_401127963.csv\n",
      "  Completed processing 2019\n",
      "Loading data for 2021\n",
      "  Processing 272 CSV files in parallel with 8 workers...\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326405.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326405.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326405.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326405.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326405.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326412.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326412.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326412.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326412.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326412.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326412.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326412.csv\n",
      "  Completed processing 2021\n",
      "Loading data for 2020\n",
      "  Processing 255 CSV files in parallel with 8 workers...\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
      "  Completed processing 2020\n",
      "Loading data for 2018\n",
      "  Processing 255 CSV files in parallel with 8 workers...\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030954.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030954.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030954.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030954.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030954.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030954.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030954.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030954.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030954.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030831.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030831.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030831.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030831.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030831.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030831.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030831.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030856.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030856.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030856.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030856.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030856.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030931.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030931.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030931.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030931.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2018/game_401030931.csv\n",
      "  Completed processing 2018\n",
      "Loading data for 2016\n",
      "  Processing 254 CSV files in parallel with 8 workers...\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2016/game_400874612.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2016/game_400874612.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2016/game_400874612.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2016/game_400874612.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2016/game_400874612.csv\n",
      "  Completed processing 2016\n",
      "Loading data for 2022\n",
      "skipping  2022\n",
      "Loading data for 2024\n",
      "  Processing 272 CSV files in parallel with 8 workers...\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
      "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
      "  Completed processing 2024\n",
      "Loading data for 2023\n",
      "  Processing 272 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2023\n",
      "Loading data for .DS_Store\n",
      "Loading data for 2017\n",
      "skipping  2017\n",
      "Loading data for 2019\n",
      "skipping  2019\n",
      "Loading data for 2021\n",
      "skipping  2021\n",
      "Loading data for 2020\n",
      "skipping  2020\n",
      "Loading data for 2018\n",
      "skipping  2018\n",
      "Loading data for 2016\n",
      "skipping  2016\n"
     ]
    }
   ],
   "source": [
    "# Reset the modules\n",
    "modules_to_reload = [\n",
    "    'process_data',\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "import process_data\n",
    "\n",
    "training_data = process_data.load_data(interpolated_dir, \n",
    "                                       years = [2016, 2017,2018, 2019, 2020, 2021, 2022], \n",
    "                                       history_length = 4, \n",
    "                                       features = features, \n",
    "                                       label_feature = \"home_win\",\n",
    "                                       train = True\n",
    "                                       )\n",
    "\n",
    "test_data = process_data.load_data(interpolated_dir, \n",
    "                                       years = [2023, 2024],\n",
    "                                       history_length = 4, \n",
    "                                       features = features, \n",
    "                                       label_feature = \"home_win\",\n",
    "                                       train = False\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep: 0.0, number of instances: 3244\n",
      "timestep: 0.005, number of instances: 1142\n",
      "timestep: 0.01, number of instances: 2157\n",
      "timestep: 0.015, number of instances: 1805\n",
      "timestep: 0.02, number of instances: 2016\n",
      "timestep: 0.025, number of instances: 2086\n",
      "timestep: 0.03, number of instances: 1976\n",
      "timestep: 0.035, number of instances: 2157\n",
      "timestep: 0.04, number of instances: 2047\n",
      "timestep: 0.045, number of instances: 2177\n",
      "timestep: 0.05, number of instances: 2126\n",
      "timestep: 0.055, number of instances: 2038\n",
      "timestep: 0.06, number of instances: 2220\n",
      "timestep: 0.065, number of instances: 2157\n",
      "timestep: 0.07, number of instances: 2181\n",
      "timestep: 0.075, number of instances: 2135\n",
      "timestep: 0.08, number of instances: 2193\n",
      "timestep: 0.085, number of instances: 2211\n",
      "timestep: 0.09, number of instances: 2122\n",
      "timestep: 0.095, number of instances: 2207\n",
      "timestep: 0.1, number of instances: 2178\n",
      "timestep: 0.105, number of instances: 2161\n",
      "timestep: 0.11, number of instances: 2234\n",
      "timestep: 0.115, number of instances: 2122\n",
      "timestep: 0.12, number of instances: 2214\n",
      "timestep: 0.125, number of instances: 2242\n",
      "timestep: 0.13, number of instances: 2206\n",
      "timestep: 0.135, number of instances: 2136\n",
      "timestep: 0.14, number of instances: 2126\n",
      "timestep: 0.145, number of instances: 2157\n",
      "timestep: 0.15, number of instances: 2235\n",
      "timestep: 0.155, number of instances: 2058\n",
      "timestep: 0.16, number of instances: 2275\n",
      "timestep: 0.165, number of instances: 2094\n",
      "timestep: 0.17, number of instances: 2173\n",
      "timestep: 0.175, number of instances: 2219\n",
      "timestep: 0.18, number of instances: 2109\n",
      "timestep: 0.185, number of instances: 2175\n",
      "timestep: 0.19, number of instances: 2125\n",
      "timestep: 0.195, number of instances: 2194\n",
      "timestep: 0.2, number of instances: 2113\n",
      "timestep: 0.205, number of instances: 2171\n",
      "timestep: 0.21, number of instances: 2316\n",
      "timestep: 0.215, number of instances: 2068\n",
      "timestep: 0.22, number of instances: 2188\n",
      "timestep: 0.225, number of instances: 2208\n",
      "timestep: 0.23, number of instances: 2101\n",
      "timestep: 0.235, number of instances: 2225\n",
      "timestep: 0.24, number of instances: 2098\n",
      "timestep: 0.245, number of instances: 1971\n",
      "timestep: 0.25, number of instances: 6480\n",
      "timestep: 0.255, number of instances: 1263\n",
      "timestep: 0.26, number of instances: 1683\n",
      "timestep: 0.265, number of instances: 2280\n",
      "timestep: 0.27, number of instances: 2018\n",
      "timestep: 0.275, number of instances: 2331\n",
      "timestep: 0.28, number of instances: 2000\n",
      "timestep: 0.285, number of instances: 2340\n",
      "timestep: 0.29, number of instances: 2121\n",
      "timestep: 0.295, number of instances: 2185\n",
      "timestep: 0.3, number of instances: 2199\n",
      "timestep: 0.305, number of instances: 2097\n",
      "timestep: 0.31, number of instances: 2225\n",
      "timestep: 0.315, number of instances: 2165\n",
      "timestep: 0.32, number of instances: 2223\n",
      "timestep: 0.325, number of instances: 2108\n",
      "timestep: 0.33, number of instances: 2192\n",
      "timestep: 0.335, number of instances: 2217\n",
      "timestep: 0.34, number of instances: 2166\n",
      "timestep: 0.345, number of instances: 2276\n",
      "timestep: 0.35, number of instances: 2188\n",
      "timestep: 0.355, number of instances: 2218\n",
      "timestep: 0.36, number of instances: 2142\n",
      "timestep: 0.365, number of instances: 2245\n",
      "timestep: 0.37, number of instances: 2142\n",
      "timestep: 0.375, number of instances: 2218\n",
      "timestep: 0.38, number of instances: 2153\n",
      "timestep: 0.385, number of instances: 2159\n",
      "timestep: 0.39, number of instances: 2175\n",
      "timestep: 0.395, number of instances: 2218\n",
      "timestep: 0.4, number of instances: 2161\n",
      "timestep: 0.405, number of instances: 2072\n",
      "timestep: 0.41, number of instances: 2255\n",
      "timestep: 0.415, number of instances: 2162\n",
      "timestep: 0.42, number of instances: 2239\n",
      "timestep: 0.425, number of instances: 2202\n",
      "timestep: 0.43, number of instances: 2166\n",
      "timestep: 0.435, number of instances: 2251\n",
      "timestep: 0.44, number of instances: 2171\n",
      "timestep: 0.445, number of instances: 2237\n",
      "timestep: 0.45, number of instances: 2203\n",
      "timestep: 0.455, number of instances: 2194\n",
      "timestep: 0.46, number of instances: 2283\n",
      "timestep: 0.465, number of instances: 2086\n",
      "timestep: 0.47, number of instances: 6070\n",
      "timestep: 0.475, number of instances: 3056\n",
      "timestep: 0.48, number of instances: 3289\n",
      "timestep: 0.485, number of instances: 3773\n",
      "timestep: 0.49, number of instances: 4531\n",
      "timestep: 0.495, number of instances: 5561\n",
      "timestep: 0.5, number of instances: 9928\n",
      "timestep: 0.505, number of instances: 1271\n",
      "timestep: 0.51, number of instances: 2074\n",
      "timestep: 0.515, number of instances: 1816\n",
      "timestep: 0.52, number of instances: 2039\n",
      "timestep: 0.525, number of instances: 2173\n",
      "timestep: 0.53, number of instances: 2025\n",
      "timestep: 0.535, number of instances: 2175\n",
      "timestep: 0.54, number of instances: 2090\n",
      "timestep: 0.545, number of instances: 2063\n",
      "timestep: 0.55, number of instances: 2144\n",
      "timestep: 0.555, number of instances: 2109\n",
      "timestep: 0.56, number of instances: 2177\n",
      "timestep: 0.565, number of instances: 2164\n",
      "timestep: 0.57, number of instances: 2220\n",
      "timestep: 0.575, number of instances: 2218\n",
      "timestep: 0.58, number of instances: 2120\n",
      "timestep: 0.585, number of instances: 2174\n",
      "timestep: 0.59, number of instances: 2256\n",
      "timestep: 0.595, number of instances: 2199\n",
      "timestep: 0.6, number of instances: 2191\n",
      "timestep: 0.605, number of instances: 2226\n",
      "timestep: 0.61, number of instances: 2236\n",
      "timestep: 0.615, number of instances: 2210\n",
      "timestep: 0.62, number of instances: 2164\n",
      "timestep: 0.625, number of instances: 2235\n",
      "timestep: 0.63, number of instances: 2206\n",
      "timestep: 0.635, number of instances: 2208\n",
      "timestep: 0.64, number of instances: 2077\n",
      "timestep: 0.645, number of instances: 2272\n",
      "timestep: 0.65, number of instances: 2182\n",
      "timestep: 0.655, number of instances: 2250\n",
      "timestep: 0.66, number of instances: 2221\n",
      "timestep: 0.665, number of instances: 2183\n",
      "timestep: 0.67, number of instances: 2162\n",
      "timestep: 0.675, number of instances: 2182\n",
      "timestep: 0.68, number of instances: 2160\n",
      "timestep: 0.685, number of instances: 2270\n",
      "timestep: 0.69, number of instances: 2198\n",
      "timestep: 0.695, number of instances: 2179\n",
      "timestep: 0.7, number of instances: 2224\n",
      "timestep: 0.705, number of instances: 2144\n",
      "timestep: 0.71, number of instances: 2126\n",
      "timestep: 0.715, number of instances: 2230\n",
      "timestep: 0.72, number of instances: 2200\n",
      "timestep: 0.725, number of instances: 2231\n",
      "timestep: 0.73, number of instances: 2236\n",
      "timestep: 0.735, number of instances: 2186\n",
      "timestep: 0.74, number of instances: 2049\n",
      "timestep: 0.745, number of instances: 1950\n",
      "timestep: 0.75, number of instances: 6306\n",
      "timestep: 0.755, number of instances: 1301\n",
      "timestep: 0.76, number of instances: 1701\n",
      "timestep: 0.765, number of instances: 2287\n",
      "timestep: 0.77, number of instances: 1979\n",
      "timestep: 0.775, number of instances: 2431\n",
      "timestep: 0.78, number of instances: 2049\n",
      "timestep: 0.785, number of instances: 2274\n",
      "timestep: 0.79, number of instances: 2127\n",
      "timestep: 0.795, number of instances: 2105\n",
      "timestep: 0.8, number of instances: 2334\n",
      "timestep: 0.805, number of instances: 2229\n",
      "timestep: 0.81, number of instances: 2231\n",
      "timestep: 0.815, number of instances: 2195\n",
      "timestep: 0.82, number of instances: 2277\n",
      "timestep: 0.825, number of instances: 2130\n",
      "timestep: 0.83, number of instances: 2196\n",
      "timestep: 0.835, number of instances: 2198\n",
      "timestep: 0.84, number of instances: 2219\n",
      "timestep: 0.845, number of instances: 2229\n",
      "timestep: 0.85, number of instances: 2207\n",
      "timestep: 0.855, number of instances: 2181\n",
      "timestep: 0.86, number of instances: 2228\n",
      "timestep: 0.865, number of instances: 2203\n",
      "timestep: 0.87, number of instances: 2187\n",
      "timestep: 0.875, number of instances: 2265\n",
      "timestep: 0.88, number of instances: 2219\n",
      "timestep: 0.885, number of instances: 2257\n",
      "timestep: 0.89, number of instances: 2237\n",
      "timestep: 0.895, number of instances: 2287\n",
      "timestep: 0.9, number of instances: 2253\n",
      "timestep: 0.905, number of instances: 2256\n",
      "timestep: 0.91, number of instances: 2320\n",
      "timestep: 0.915, number of instances: 2289\n",
      "timestep: 0.92, number of instances: 2430\n",
      "timestep: 0.925, number of instances: 2559\n",
      "timestep: 0.93, number of instances: 2509\n",
      "timestep: 0.935, number of instances: 2646\n",
      "timestep: 0.94, number of instances: 2844\n",
      "timestep: 0.945, number of instances: 2856\n",
      "timestep: 0.95, number of instances: 2934\n",
      "timestep: 0.955, number of instances: 2796\n",
      "timestep: 0.96, number of instances: 2935\n",
      "timestep: 0.965, number of instances: 2685\n",
      "timestep: 0.97, number of instances: 6245\n",
      "timestep: 0.975, number of instances: 2893\n",
      "timestep: 0.98, number of instances: 3039\n",
      "timestep: 0.985, number of instances: 2991\n",
      "timestep: 0.99, number of instances: 2993\n",
      "timestep: 0.995, number of instances: 2981\n",
      "timestep: 1.0, number of instances: 3686\n"
     ]
    }
   ],
   "source": [
    "# Get information about the data\n",
    "for timestep in training_data:\n",
    "    print(f\"timestep: {timestep}, number of instances: {len(training_data[timestep])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features to be scaled: ['homeScore', 'awayScore', 'start.down', 'start.distance', 'start.yardLine', 'end.down', 'end.distance', 'end.yardLine']\n",
      "Features to passthrough: ['relative_strength', 'scoringPlay', 'home_has_possession', 'home_timeouts_left', 'away_timeouts_left']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Define which features to scale vs. passthrough\n",
    "numeric_features = [\n",
    "    \"homeScore\", \"awayScore\", \"start.down\", \"start.distance\", \"start.yardLine\",\n",
    "    \"end.down\", \"end.distance\", \"end.yardLine\",\n",
    "]\n",
    "other_features = [\"relative_strength\", \"scoringPlay\", \"home_has_possession\", \"home_timeouts_left\", \"away_timeouts_left\"] # for timestep in training_data.keys():\n",
    "\n",
    "\n",
    "numeric_feature_indices = [\n",
    "    0,  # score_difference\n",
    "    1,  # relative_strength  \n",
    "    4,  # end.down\n",
    "    5,  # end.yardsToEndzone\n",
    "    6,  # end.distance\n",
    "    7,  # field_position_shift\n",
    "]\n",
    "\n",
    "# Features that should NOT be scaled (categorical/binary/discrete)\n",
    "other_feature_indices = [\n",
    "    2,  # type.id (categorical)\n",
    "    3,  # home_has_possession (binary)\n",
    "    8,  # home_timeouts_left (discrete 0-3)\n",
    "    9,  # away_timeouts_left (discrete 0-3)\n",
    "]\n",
    "\n",
    "print(\"Features to be scaled:\", numeric_features)\n",
    "print(\"Features to passthrough:\", other_features)\n",
    "\n",
    "# Scale the data pipeline (using column indices for numpy arrays)\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", StandardScaler(), numeric_feature_indices),\n",
    "    (\"passthrough\", \"passthrough\", other_feature_indices)\n",
    "])\n",
    "\n",
    "# No scaling pipeline (for comparison)\n",
    "preprocessor_no_scaling = ColumnTransformer(transformers=[\n",
    "    (\"passthrough\", \"passthrough\", list(range(len(features))))\n",
    "])\n",
    "# TO DO:\n",
    "# - Rounding for end games\n",
    "# - Only keep home_has_possession + timeouts_left + everything I had before - DONE\n",
    "# - Kernel based methods\n",
    "#   - At least 10 data points to do an estimation\n",
    "#   - Score difference - make it categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 11)\n"
     ]
    }
   ],
   "source": [
    "print(training_data[0.0][0][\"rows\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training direct prediction transformer model for timestep range [0.0, 0.005]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 13\n",
      "Best epoch: 3, Train Acc: 0.5447, Train Loss: 0.6885, Val Acc: 0.5341, Val Loss: 0.6928\n",
      "Restored transformer model from best epoch 3 with val_loss: 0.692763\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.0-0.005_ep3_valAcc0.5341_valLoss0.6928.pth\n",
      "NFL transformer model 1/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.005, 0.01]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 12\n",
      "Best epoch: 2, Train Acc: 0.5149, Train Loss: 0.6956, Val Acc: 0.5345, Val Loss: 0.6894\n",
      "Restored transformer model from best epoch 2 with val_loss: 0.689417\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.005-0.01_ep2_valAcc0.5345_valLoss0.6894.pth\n",
      "NFL transformer model 2/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.01, 0.015]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 20\n",
      "Best epoch: 10, Train Acc: 0.5633, Train Loss: 0.6850, Val Acc: 0.5564, Val Loss: 0.6836\n",
      "Restored transformer model from best epoch 10 with val_loss: 0.683579\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.01-0.015_ep10_valAcc0.5564_valLoss0.6836.pth\n",
      "NFL transformer model 3/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.015, 0.02]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 18\n",
      "Best epoch: 8, Train Acc: 0.5551, Train Loss: 0.6847, Val Acc: 0.5208, Val Loss: 0.6942\n",
      "Restored transformer model from best epoch 8 with val_loss: 0.694234\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.015-0.02_ep8_valAcc0.5208_valLoss0.6942.pth\n",
      "NFL transformer model 4/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.02, 0.025]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 14\n",
      "Best epoch: 4, Train Acc: 0.5347, Train Loss: 0.6897, Val Acc: 0.5590, Val Loss: 0.6865\n",
      "Restored transformer model from best epoch 4 with val_loss: 0.686524\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.02-0.025_ep4_valAcc0.5590_valLoss0.6865.pth\n",
      "NFL transformer model 5/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.025, 0.03]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 18\n",
      "Best epoch: 8, Train Acc: 0.5475, Train Loss: 0.6874, Val Acc: 0.5251, Val Loss: 0.6907\n",
      "Restored transformer model from best epoch 8 with val_loss: 0.690701\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.025-0.03_ep8_valAcc0.5251_valLoss0.6907.pth\n",
      "NFL transformer model 6/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.03, 0.035]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 12\n",
      "Best epoch: 2, Train Acc: 0.5455, Train Loss: 0.6933, Val Acc: 0.5350, Val Loss: 0.6895\n",
      "Restored transformer model from best epoch 2 with val_loss: 0.689517\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.03-0.035_ep2_valAcc0.5350_valLoss0.6895.pth\n",
      "NFL transformer model 7/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.035, 0.04]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 13\n",
      "Best epoch: 3, Train Acc: 0.5392, Train Loss: 0.6940, Val Acc: 0.5580, Val Loss: 0.6882\n",
      "Restored transformer model from best epoch 3 with val_loss: 0.688173\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.035-0.04_ep3_valAcc0.5580_valLoss0.6882.pth\n",
      "NFL transformer model 8/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.04, 0.045]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 11\n",
      "Best epoch: 1, Train Acc: 0.4880, Train Loss: 0.7104, Val Acc: 0.5297, Val Loss: 0.6878\n",
      "Restored transformer model from best epoch 1 with val_loss: 0.687754\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.04-0.045_ep1_valAcc0.5297_valLoss0.6878.pth\n",
      "NFL transformer model 9/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.045, 0.05]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 29\n",
      "Best epoch: 19, Train Acc: 0.5535, Train Loss: 0.6905, Val Acc: 0.5346, Val Loss: 0.6847\n",
      "Restored transformer model from best epoch 19 with val_loss: 0.684684\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.045-0.05_ep19_valAcc0.5346_valLoss0.6847.pth\n",
      "NFL transformer model 10/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.05, 0.055]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 25\n",
      "Best epoch: 15, Train Acc: 0.5583, Train Loss: 0.6839, Val Acc: 0.5406, Val Loss: 0.6918\n",
      "Restored transformer model from best epoch 15 with val_loss: 0.691778\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.05-0.055_ep15_valAcc0.5406_valLoss0.6918.pth\n",
      "NFL transformer model 11/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.055, 0.06]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 26\n",
      "Best epoch: 16, Train Acc: 0.5662, Train Loss: 0.6801, Val Acc: 0.5569, Val Loss: 0.6843\n",
      "Restored transformer model from best epoch 16 with val_loss: 0.684317\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.055-0.06_ep16_valAcc0.5569_valLoss0.6843.pth\n",
      "NFL transformer model 12/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.06, 0.065]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 22\n",
      "Best epoch: 12, Train Acc: 0.5626, Train Loss: 0.6818, Val Acc: 0.5421, Val Loss: 0.6911\n",
      "Restored transformer model from best epoch 12 with val_loss: 0.691062\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.06-0.065_ep12_valAcc0.5421_valLoss0.6911.pth\n",
      "NFL transformer model 13/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.065, 0.07]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 30\n",
      "Best epoch: 20, Train Acc: 0.5614, Train Loss: 0.6773, Val Acc: 0.5646, Val Loss: 0.6758\n",
      "Restored transformer model from best epoch 20 with val_loss: 0.675822\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.065-0.07_ep20_valAcc0.5646_valLoss0.6758.pth\n",
      "NFL transformer model 14/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.07, 0.075]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 27\n",
      "Best epoch: 17, Train Acc: 0.5910, Train Loss: 0.6696, Val Acc: 0.5831, Val Loss: 0.6758\n",
      "Restored transformer model from best epoch 17 with val_loss: 0.675751\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.07-0.075_ep17_valAcc0.5831_valLoss0.6758.pth\n",
      "NFL transformer model 15/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.075, 0.08]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 22\n",
      "Best epoch: 12, Train Acc: 0.5794, Train Loss: 0.6789, Val Acc: 0.5647, Val Loss: 0.6736\n",
      "Restored transformer model from best epoch 12 with val_loss: 0.673579\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.075-0.08_ep12_valAcc0.5647_valLoss0.6736.pth\n",
      "NFL transformer model 16/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.08, 0.085]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 32\n",
      "Best epoch: 22, Train Acc: 0.5709, Train Loss: 0.6713, Val Acc: 0.5772, Val Loss: 0.6787\n",
      "Restored transformer model from best epoch 22 with val_loss: 0.678715\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.08-0.085_ep22_valAcc0.5772_valLoss0.6787.pth\n",
      "NFL transformer model 17/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.085, 0.09]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 29\n",
      "Best epoch: 19, Train Acc: 0.6201, Train Loss: 0.6560, Val Acc: 0.5815, Val Loss: 0.6666\n",
      "Restored transformer model from best epoch 19 with val_loss: 0.666553\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.085-0.09_ep19_valAcc0.5815_valLoss0.6666.pth\n",
      "NFL transformer model 18/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.09, 0.095]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 21\n",
      "Best epoch: 11, Train Acc: 0.5759, Train Loss: 0.6779, Val Acc: 0.5859, Val Loss: 0.6782\n",
      "Restored transformer model from best epoch 11 with val_loss: 0.678222\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.09-0.095_ep11_valAcc0.5859_valLoss0.6782.pth\n",
      "NFL transformer model 19/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.095, 0.1]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 23\n",
      "Best epoch: 13, Train Acc: 0.5868, Train Loss: 0.6738, Val Acc: 0.6007, Val Loss: 0.6711\n",
      "Restored transformer model from best epoch 13 with val_loss: 0.671141\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.095-0.1_ep13_valAcc0.6007_valLoss0.6711.pth\n",
      "NFL transformer model 20/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.1, 0.105]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 28\n",
      "Best epoch: 18, Train Acc: 0.6047, Train Loss: 0.6681, Val Acc: 0.6019, Val Loss: 0.6635\n",
      "Restored transformer model from best epoch 18 with val_loss: 0.663489\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.1-0.105_ep18_valAcc0.6019_valLoss0.6635.pth\n",
      "NFL transformer model 21/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.105, 0.11]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 18\n",
      "Best epoch: 8, Train Acc: 0.5895, Train Loss: 0.6699, Val Acc: 0.5944, Val Loss: 0.6614\n",
      "Restored transformer model from best epoch 8 with val_loss: 0.661422\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.105-0.11_ep8_valAcc0.5944_valLoss0.6614.pth\n",
      "NFL transformer model 22/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.11, 0.115]\n",
      "Starting transformer training on device: cpu\n",
      "Early stopping at epoch 19\n",
      "Best epoch: 9, Train Acc: 0.5801, Train Loss: 0.6758, Val Acc: 0.6012, Val Loss: 0.6649\n",
      "Restored transformer model from best epoch 9 with val_loss: 0.664884\n",
      "Direct prediction transformer model saved: saved_models_transformer/nfl_transformer_model_transformer_0.11-0.115_ep9_valAcc0.6012_valLoss0.6649.pth\n",
      "NFL transformer model 23/201 completed\n",
      "\n",
      "Training direct prediction transformer model for timestep range [0.115, 0.12]\n",
      "Starting transformer training on device: cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[module_name]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdirect_prediction_network_transformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_direct_transformer_models\n\u001b[0;32m---> 13\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43msetup_direct_transformer_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m201\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/notebooks/models/direct_prediction_network_transformer.py:513\u001b[0m, in \u001b[0;36msetup_direct_transformer_models\u001b[0;34m(training_data, test_data, num_models, epochs, lr, batch_size, d_model, nhead, num_layers, use_scaler)\u001b[0m\n\u001b[1;32m    510\u001b[0m classifier \u001b[38;5;241m=\u001b[39m DirectTransformerClassifier(transformer_network, epochs, optimizer, criterion, device, scheduler, use_scaler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# Train the model (scaler is handled internally)\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m    516\u001b[0m model_save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models_transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/notebooks/models/direct_prediction_network_transformer.py:202\u001b[0m, in \u001b[0;36mDirectTransformerClassifier.fit\u001b[0;34m(self, X, y, val_X, val_y, batch_size)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    201\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 202\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Remove only the last dimension\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    205\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output, y)\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/notebooks/models/direct_prediction_network_transformer.py:118\u001b[0m, in \u001b[0;36mDirectPredictionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    115\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [batch, d_model]\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Final classification\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, 1]\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m(\u001b[38;5;28minput\u001b[39m, p, training)\n\u001b[1;32m   1426\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL_env/lib/python3.9/site-packages/torch/_VF.py:27\u001b[0m, in \u001b[0;36mVFModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_VariableFunctions\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf, name)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modules_to_reload = [\n",
    "    'models.direct_prediction_network',\n",
    "    'models.direct_prediction_network_transformer',\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "from models.direct_prediction_network_transformer import setup_direct_transformer_models\n",
    "\n",
    "\n",
    "models = setup_direct_transformer_models(training_data, test_data, num_models = 201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'models' (namespace)>\n"
     ]
    }
   ],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[module_name]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m direct_prediction_network_transformer\n\u001b[0;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# process_data.plot_accuracy(models, test_data, \"Logistic Regression\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/notebooks/process_data.py:285\u001b[0m, in \u001b[0;36mplot_loss\u001b[0;34m(models, test_data, title)\u001b[0m\n\u001b[1;32m    283\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_key, rows \u001b[38;5;129;01min\u001b[39;00m rows_by_model\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 285\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_key\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# KeyError if missing  intentional (no fallbacks)\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(rows)\n\u001b[1;32m    287\u001b[0m     labels\u001b[38;5;241m.\u001b[39mextend(labels_by_model[model_key])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# # Test accuracy of model for each timestep on test data and plot\n",
    "# accuracies = []\n",
    "# timesteps = []\n",
    "import process_data\n",
    "modules_to_reload = [\n",
    "    'process_data',\n",
    "    'models.direct_prediction_network_transformer'\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "from models import direct_prediction_network_transformer\n",
    "\n",
    "x = process_data.plot_loss(models, test_data, \"Transformer\")\n",
    "# process_data.plot_accuracy(models, test_data, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 2024\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[module_name]\n\u001b[1;32m     14\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mwrite_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolated_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2024\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_nan_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphat_b\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformer_phat_b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/notebooks/process_data.py:370\u001b[0m, in \u001b[0;36mwrite_predictions\u001b[0;34m(models, interpolated_dir, years, history_length, features, replace_nan_val, phat_b)\u001b[0m\n\u001b[1;32m    368\u001b[0m     model \u001b[38;5;241m=\u001b[39m models[model_assigned]\n\u001b[1;32m    369\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(final_rows_for_timestep, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 370\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    371\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[idx, phat_b] \u001b[38;5;241m=\u001b[39m pred\n\u001b[1;32m    372\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/notebooks/models/direct_prediction_network_transformer.py:328\u001b[0m, in \u001b[0;36mDirectTransformerClassifier.predict_proba\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    Return prediction probabilities (same as predict for this model)\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m pred, pred]]\n",
      "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/notebooks/models/direct_prediction_network_transformer.py:316\u001b[0m, in \u001b[0;36mDirectTransformerClassifier.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    314\u001b[0m     x_scaled \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Reshape to (samples, seq_len, input_dim)\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m x_scaled \u001b[38;5;241m=\u001b[39m x_scaled\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from process_data import write_predictions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Reload the modules\n",
    "modules_to_reload = [\n",
    "    'process_data',\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "write_predictions(models, interpolated_dir, [2024], 0, features, replace_nan_val = 0, phat_b = \"transformer_phat_b\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
