{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensemble training (2 years of testing, 1 year of validation, the rest is training)\n",
        "    # Learned weights on validation data (Constrained optimization)\n",
        "    # Meta-learning using an other ML model\n",
        "\n",
        "# Models used:\n",
        "# - XGBoost\n",
        "# - Neural Network\n",
        "# - Logistic Regression\n",
        "# - LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML\n"
          ]
        }
      ],
      "source": [
        "# Set up paths and load data\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "sys.path.append(parent_dir)\n",
        "print(parent_dir)\n",
        "\n",
        "interpolated_dir = os.path.join(parent_dir, \"dataset_interpolated_with_overtime\")\n",
        "features = [\"score_difference\", \"timestep\", \"type.id\", \"relative_strength\", \"home_has_possession\", \"end.down\", \"end.yardsToEndzone\", \"end.distance\", \"field_position_shift\", \"home_timeouts_left\", \"away_timeouts_left\"]\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.metrics import brier_score_loss, accuracy_score, log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.optimize import minimize\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for 2015\n",
            "skipping  2015\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951752.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951752.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951632.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951627.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951590.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951783.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951582.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951780.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951730.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951647.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951735.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951710.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951699.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951648.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951562.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951560.csv\n",
            "Loading data for 2019\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127989.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127963.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127963.csv\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220161.csv\n",
            "Loading data for 2018\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030856.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030931.csv\n",
            "Loading data for 2016\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874505.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874489.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874676.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874604.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874565.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874612.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874570.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874561.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874629.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874555.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874621.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874690.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874734.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874508.csv\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for 2015\n",
            "skipping  2015\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326405.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326412.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326412.csv\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "Loading data for 2015\n",
            "skipping  2015\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2024/game_401671770.csv\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for 2015\n",
            "skipping  2015\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for 2015\n",
            "skipping  2015\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951752.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951752.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951752.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951752.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951752.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951752.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951752.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951632.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951627.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951590.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951783.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951582.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951780.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951730.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951647.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951735.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951710.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951699.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951648.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951562.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2017/game_400951560.csv\n",
            "Loading data for 2019\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127989.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127989.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127989.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127989.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127989.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127963.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127963.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127963.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127963.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127963.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127963.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2019/game_401127963.csv\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2020/game_401220161.csv\n",
            "Loading data for 2018\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030954.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030831.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030856.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030856.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030856.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030856.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030856.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030931.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030931.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030931.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030931.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2018/game_401030931.csv\n",
            "Loading data for 2016\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874505.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874489.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874676.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874604.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874565.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874612.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874612.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874612.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874612.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874612.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874570.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874561.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874629.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874555.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874621.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874690.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874734.csv\n",
            "  NaN Label found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2016/game_400874508.csv\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for 2015\n",
            "skipping  2015\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326405.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326405.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326405.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326405.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326405.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326412.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326412.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326412.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326412.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326412.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326412.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2021/game_401326412.csv\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "Loading data for 2015\n",
            "skipping  2015\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/evalRTPF/R/NFL/ML/dataset_interpolated_with_overtime/2024/game_401671770.csv\n",
            "Loading data for 2023\n",
            "Loading data for 2015\n",
            "skipping  2015\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n"
          ]
        }
      ],
      "source": [
        "# Load data for ensemble training\n",
        "import process_data\n",
        "training_data = process_data.load_data(interpolated_dir, \n",
        "                                       years = [2016, 2017, 2018, 2019, 2020], \n",
        "                                       history_length = 0, \n",
        "                                       features = features, \n",
        "                                       label_feature = \"home_win\")\n",
        "\n",
        "validation_data = process_data.load_data(interpolated_dir, \n",
        "                                       years = [2021], \n",
        "                                       history_length = 0, \n",
        "                                       features = features, \n",
        "                                       label_feature = \"home_win\")\n",
        "\n",
        "ensemble_data = process_data.load_data(interpolated_dir, \n",
        "                                         years = [2022, 2023], \n",
        "                                         history_length = 0, \n",
        "                                         features = features, \n",
        "                                         label_feature = \"home_win\")\n",
        "\n",
        "test_data = process_data.load_data(interpolated_dir, \n",
        "                                   years = [2024],\n",
        "                                   history_length = 0, \n",
        "                                   features = features, \n",
        "                                   label_feature = \"home_win\")\n",
        "\n",
        "training_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                       years = [2016, 2017, 2018, 2019, 2020], \n",
        "                                       history_length = 4, \n",
        "                                       features = features, \n",
        "                                       label_feature = \"home_win\")\n",
        "\n",
        "validation_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                         years = [2021], \n",
        "                                         history_length = 4, \n",
        "                                         features = features, \n",
        "                                         label_feature = \"home_win\")\n",
        "\n",
        "ensemble_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                         years = [2022, 2023], \n",
        "                                         history_length = 4, \n",
        "                                         features = features, \n",
        "                                         label_feature = \"home_win\")\n",
        "\n",
        "test_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                   years = [2023, 2024],\n",
        "                                   history_length = 4, \n",
        "                                   features = features, \n",
        "                                   label_feature = \"home_win\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "class EnsemblePredictor:\n",
        "    \"\"\"\n",
        "    Ensemble predictor class, one per timestep\n",
        "    \"\"\"\n",
        "    def __init__(self, all_models, all_models_order, strategy='meta_model', meta_model=None):\n",
        "        self.all_models = all_models\n",
        "        self.all_models_order = all_models_order\n",
        "        self.strategy = strategy\n",
        "        if self.strategy != 'meta_model' and self.strategy != 'weighted_average':\n",
        "            raise ValueError(\"Invalid strategy\")\n",
        "        if meta_model is None and self.strategy == 'meta_model':\n",
        "            raise ValueError(\"Meta model is required for meta_model strategy\")\n",
        "        self.meta_model = meta_model\n",
        "        self.ensemble_weights = None # Will be a 1D array of shape (n_models,) once trained\n",
        " \n",
        "    def train_ensemble(self, x_train, y_train, objective='brier'):\n",
        "        \"\"\"\n",
        "        Train the ensemble for a single timestep using validation data.\n",
        "        \"\"\"\n",
        "        print(f\"Training ensemble for this timestep...\")\n",
        "        if self.strategy == 'weighted_average':\n",
        "            self.optimize_ensemble_weights(x_train, y_train, objective)\n",
        "        elif self.strategy == 'meta_model':\n",
        "            self.train_meta_model(x_train, y_train)\n",
        "\n",
        "    def optimize_ensemble_weights(self, x_train, y_train, objective='brier'):\n",
        "        \"\"\"\n",
        "        Optimize ensemble weights for a single timestep using validation data.\n",
        "        \"\"\"\n",
        "        print(f\"Optimizing ensemble weights for this timestep...\")\n",
        "\n",
        "        n_models = x_train.shape[1]\n",
        "\n",
        "        def objective_function(weights):\n",
        "            weights = weights / np.sum(weights)  # Normalize weights\n",
        "            ensemble_preds = np.dot(x_train, weights)\n",
        "\n",
        "            if objective == 'brier':\n",
        "                return brier_score_loss(y_train, ensemble_preds)\n",
        "            elif objective == 'logloss':\n",
        "                # Clip predictions to avoid log(0)\n",
        "                ensemble_preds = np.clip(ensemble_preds, 1e-15, 1-1e-15)\n",
        "                return log_loss(y_train, ensemble_preds)\n",
        "            elif objective == 'accuracy':\n",
        "                return -accuracy_score(y_train, ensemble_preds > 0.5)  # Negative for minimization\n",
        "\n",
        "        # Constraints: weights sum to 1 and are non-negative\n",
        "        constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
        "        bounds = [(0, 1) for _ in range(n_models)]\n",
        "\n",
        "        # Initialize with equal weights\n",
        "        initial_weights = np.ones(n_models) / n_models\n",
        "\n",
        "        result = minimize(objective_function, initial_weights,\n",
        "                          method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "\n",
        "        if result.success:\n",
        "            self.ensemble_weights = result.x\n",
        "            print(f\"  Optimized weights: {dict(zip(self.all_models_order, result.x.round(4)))} (score: {result.fun:.6f})\")\n",
        "        else:\n",
        "            print(f\"  Optimization failed, using equal weights\")\n",
        "            self.ensemble_weights = initial_weights\n",
        "\n",
        "        return self.ensemble_weights\n",
        "\n",
        "    def train_meta_model(self, x_train, y_train):\n",
        "        \"\"\"\n",
        "        Train a meta-model for a single timestep to predict based on base model outputs.\n",
        "        \"\"\"\n",
        "        X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "        # Train meta-model: input=base_model_predictions, output=final_prediction\n",
        "        self.meta_model.fit(X_train, y_train.reshape(-1, 1))\n",
        "\n",
        "        # Test the meta-model's prediction capability\n",
        "        meta_predictions = self.meta_model.predict_proba(X_val)[:, 1]\n",
        "        meta_accuracy = accuracy_score(y_val, meta_predictions > 0.5)\n",
        "        meta_brier = brier_score_loss(y_val, meta_predictions)\n",
        "\n",
        "        print(f\"  Meta-model trained on {len(X_train)} samples\")\n",
        "        print(f\"    Validation Meta-model accuracy: {meta_accuracy:.4f}, Validation Brier score: {meta_brier:.4f}\")\n",
        "\n",
        "        return self.meta_model\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probability of the positive class for a given input\n",
        "        \"\"\"\n",
        "        # Generate predictions from each individual model\n",
        "        # X is a 3D array of shape (n_samples, n_history, n_features)\n",
        "        predictions = [] # Will be a 2D array of shape (n_samples, n_models)\n",
        "        for i, model_name in enumerate(self.all_models_order):\n",
        "            model = self.all_models[model_name]\n",
        "            if model_name == \"lstm\":\n",
        "                predictions.append(model.predict_proba(X)[:, 1]) # Will be a 1D array of shape (n_samples,) for each model\n",
        "            else:\n",
        "                x = np.array([X[i][-1] for i in range(X.shape[0])])\n",
        "                predictions.append(model.predict_proba(x)[:, 1]) # Will be a 1D array of shape (n_samples,) for each model\n",
        "        predictions = np.array(predictions) # Will be a 2D array of shape (n_models, n_samples)\n",
        "        predictions = predictions.T # Reshape to be a 2D array of shape (n_samples, n_models)\n",
        "        if self.strategy == 'weighted_average':\n",
        "            return np.dot(predictions, self.ensemble_weights)\n",
        "        elif self.strategy == 'meta_model':\n",
        "            return self.meta_model.predict_proba(predictions)[:, 1]\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probability of the positive class for a given input\n",
        "        \"\"\"\n",
        "        pred = self.predict(X).flatten()\n",
        "        return np.column_stack([1 - pred, pred])\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        Score the ensemble for a given input\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "        y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "        return np.mean(y_pred_labels == y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload modules\n",
        "modules_to_reload = [\n",
        "    'models.xg_boost',\n",
        "    'models.direct_prediction_network_lstm',\n",
        "    'models.direct_prediction_network',\n",
        "    'models.logistic_regression',\n",
        "]\n",
        "\n",
        "for module_name in modules_to_reload:\n",
        "    if module_name in sys.modules:\n",
        "        del sys.modules[module_name]\n",
        "from models.xg_boost import setup_xgboost_models\n",
        "from models.direct_prediction_network_lstm import setup_direct_lstm_models\n",
        "from models.direct_prediction_network import setup_direct_models\n",
        "from models.logistic_regression import setup_logistic_regression_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training individual models...\n",
            "Using provided test data as validation: 1949 train, 412 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.0, 0.005]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1949, 5, 11)\n",
            "Flattened training data shape: (1949, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.6444, Train Loss: 0.2191, Val Acc: 0.6044, Val Loss: 0.2315\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.231451\n",
            "NFL LSTM model 1/201 completed\n",
            "Using provided test data as validation: 1448 train, 308 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.005, 0.01]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1448, 5, 11)\n",
            "Flattened training data shape: (1448, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.6609, Train Loss: 0.2160, Val Acc: 0.6396, Val Loss: 0.2317\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.231728\n",
            "NFL LSTM model 2/201 completed\n",
            "Using provided test data as validation: 1303 train, 282 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.01, 0.015]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1303, 5, 11)\n",
            "Flattened training data shape: (1303, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6477, Train Loss: 0.2218, Val Acc: 0.6206, Val Loss: 0.2316\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.231560\n",
            "NFL LSTM model 3/201 completed\n",
            "Using provided test data as validation: 1411 train, 310 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.015, 0.02]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1411, 5, 11)\n",
            "Flattened training data shape: (1411, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6471, Train Loss: 0.2194, Val Acc: 0.6194, Val Loss: 0.2322\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.232226\n",
            "NFL LSTM model 4/201 completed\n",
            "Using provided test data as validation: 1337 train, 297 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.02, 0.025]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1337, 5, 11)\n",
            "Flattened training data shape: (1337, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.6619, Train Loss: 0.2119, Val Acc: 0.6330, Val Loss: 0.2258\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.225751\n",
            "NFL LSTM model 5/201 completed\n",
            "Using provided test data as validation: 1464 train, 306 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.025, 0.03]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1464, 5, 11)\n",
            "Flattened training data shape: (1464, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.6633, Train Loss: 0.2134, Val Acc: 0.6078, Val Loss: 0.2292\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.229172\n",
            "NFL LSTM model 6/201 completed\n",
            "Using provided test data as validation: 1429 train, 307 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.03, 0.035]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1429, 5, 11)\n",
            "Flattened training data shape: (1429, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6340, Train Loss: 0.2249, Val Acc: 0.6059, Val Loss: 0.2245\n",
            "Restored LSTM model from best epoch 3 with val_loss: 0.224522\n",
            "NFL LSTM model 7/201 completed\n",
            "Using provided test data as validation: 1423 train, 315 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.035, 0.04]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1423, 5, 11)\n",
            "Flattened training data shape: (1423, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6479, Train Loss: 0.2238, Val Acc: 0.5968, Val Loss: 0.2362\n",
            "Restored LSTM model from best epoch 3 with val_loss: 0.236229\n",
            "NFL LSTM model 8/201 completed\n",
            "Using provided test data as validation: 1444 train, 321 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.04, 0.045]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1444, 5, 11)\n",
            "Flattened training data shape: (1444, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6697, Train Loss: 0.2111, Val Acc: 0.6137, Val Loss: 0.2405\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.240512\n",
            "NFL LSTM model 9/201 completed\n",
            "Using provided test data as validation: 1451 train, 320 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.045, 0.05]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1451, 5, 11)\n",
            "Flattened training data shape: (1451, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6340, Train Loss: 0.2212, Val Acc: 0.6031, Val Loss: 0.2316\n",
            "Restored LSTM model from best epoch 3 with val_loss: 0.231631\n",
            "NFL LSTM model 10/201 completed\n",
            "Using provided test data as validation: 1456 train, 314 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.05, 0.055]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1456, 5, 11)\n",
            "Flattened training data shape: (1456, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6346, Train Loss: 0.2251, Val Acc: 0.6369, Val Loss: 0.2315\n",
            "Restored LSTM model from best epoch 3 with val_loss: 0.231548\n",
            "NFL LSTM model 11/201 completed\n",
            "Using provided test data as validation: 1488 train, 334 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.055, 0.06]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1488, 5, 11)\n",
            "Flattened training data shape: (1488, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.6660, Train Loss: 0.2197, Val Acc: 0.6198, Val Loss: 0.2245\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.224465\n",
            "NFL LSTM model 12/201 completed\n",
            "Using provided test data as validation: 1465 train, 317 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.06, 0.065]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1465, 5, 11)\n",
            "Flattened training data shape: (1465, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.6792, Train Loss: 0.2119, Val Acc: 0.6246, Val Loss: 0.2327\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.232688\n",
            "NFL LSTM model 13/201 completed\n",
            "Using provided test data as validation: 1501 train, 322 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.065, 0.07]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1501, 5, 11)\n",
            "Flattened training data shape: (1501, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6629, Train Loss: 0.2177, Val Acc: 0.6056, Val Loss: 0.2396\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.239566\n",
            "NFL LSTM model 14/201 completed\n",
            "Using provided test data as validation: 1471 train, 339 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.07, 0.075]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1471, 5, 11)\n",
            "Flattened training data shape: (1471, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6587, Train Loss: 0.2215, Val Acc: 0.6165, Val Loss: 0.2278\n",
            "Restored LSTM model from best epoch 3 with val_loss: 0.227791\n",
            "NFL LSTM model 15/201 completed\n",
            "Using provided test data as validation: 1507 train, 323 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.075, 0.08]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1507, 5, 11)\n",
            "Flattened training data shape: (1507, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6576, Train Loss: 0.2201, Val Acc: 0.6037, Val Loss: 0.2286\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.228626\n",
            "NFL LSTM model 16/201 completed\n",
            "Using provided test data as validation: 1512 train, 314 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.08, 0.085]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1512, 5, 11)\n",
            "Flattened training data shape: (1512, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6700, Train Loss: 0.2128, Val Acc: 0.6210, Val Loss: 0.2323\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.232285\n",
            "NFL LSTM model 17/201 completed\n",
            "Using provided test data as validation: 1458 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.085, 0.09]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1458, 5, 11)\n",
            "Flattened training data shape: (1458, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.6735, Train Loss: 0.2136, Val Acc: 0.6258, Val Loss: 0.2292\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.229162\n",
            "NFL LSTM model 18/201 completed\n",
            "Using provided test data as validation: 1541 train, 330 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.09, 0.095]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1541, 5, 11)\n",
            "Flattened training data shape: (1541, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6554, Train Loss: 0.2156, Val Acc: 0.6061, Val Loss: 0.2253\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.225337\n",
            "NFL LSTM model 19/201 completed\n",
            "Using provided test data as validation: 1512 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.095, 0.1]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1512, 5, 11)\n",
            "Flattened training data shape: (1512, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.6865, Train Loss: 0.2098, Val Acc: 0.6226, Val Loss: 0.2336\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.233562\n",
            "NFL LSTM model 20/201 completed\n",
            "Using provided test data as validation: 1557 train, 320 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.1, 0.105]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1557, 5, 11)\n",
            "Flattened training data shape: (1557, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6705, Train Loss: 0.2109, Val Acc: 0.6062, Val Loss: 0.2326\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.232601\n",
            "NFL LSTM model 21/201 completed\n",
            "Using provided test data as validation: 1521 train, 309 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.105, 0.11]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1521, 5, 11)\n",
            "Flattened training data shape: (1521, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6588, Train Loss: 0.2124, Val Acc: 0.5987, Val Loss: 0.2216\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.221617\n",
            "NFL LSTM model 22/201 completed\n",
            "Using provided test data as validation: 1487 train, 337 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.11, 0.115]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1487, 5, 11)\n",
            "Flattened training data shape: (1487, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6564, Train Loss: 0.2167, Val Acc: 0.6231, Val Loss: 0.2242\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.224151\n",
            "NFL LSTM model 23/201 completed\n",
            "Using provided test data as validation: 1521 train, 342 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.115, 0.12]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1521, 5, 11)\n",
            "Flattened training data shape: (1521, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6805, Train Loss: 0.2120, Val Acc: 0.6345, Val Loss: 0.2189\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.218882\n",
            "NFL LSTM model 24/201 completed\n",
            "Using provided test data as validation: 1468 train, 313 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.12, 0.125]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1468, 5, 11)\n",
            "Flattened training data shape: (1468, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6846, Train Loss: 0.2082, Val Acc: 0.6677, Val Loss: 0.2185\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.218457\n",
            "NFL LSTM model 25/201 completed\n",
            "Using provided test data as validation: 1481 train, 331 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.125, 0.13]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1481, 5, 11)\n",
            "Flattened training data shape: (1481, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6739, Train Loss: 0.2120, Val Acc: 0.6526, Val Loss: 0.2190\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.219012\n",
            "NFL LSTM model 26/201 completed\n",
            "Using provided test data as validation: 1516 train, 310 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.13, 0.135]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1516, 5, 11)\n",
            "Flattened training data shape: (1516, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6827, Train Loss: 0.2028, Val Acc: 0.6484, Val Loss: 0.2184\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.218370\n",
            "NFL LSTM model 27/201 completed\n",
            "Using provided test data as validation: 1495 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.135, 0.14]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 5, 11)\n",
            "Flattened training data shape: (1495, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.6997, Train Loss: 0.2044, Val Acc: 0.6509, Val Loss: 0.2170\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.216997\n",
            "NFL LSTM model 28/201 completed\n",
            "Using provided test data as validation: 1473 train, 321 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.14, 0.145]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1473, 5, 11)\n",
            "Flattened training data shape: (1473, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7122, Train Loss: 0.2067, Val Acc: 0.6386, Val Loss: 0.2224\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.222386\n",
            "NFL LSTM model 29/201 completed\n",
            "Using provided test data as validation: 1477 train, 310 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.145, 0.15]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1477, 5, 11)\n",
            "Flattened training data shape: (1477, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.7062, Train Loss: 0.2002, Val Acc: 0.6742, Val Loss: 0.2105\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.210503\n",
            "NFL LSTM model 30/201 completed\n",
            "Using provided test data as validation: 1524 train, 349 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.15, 0.155]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1524, 5, 11)\n",
            "Flattened training data shape: (1524, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6929, Train Loss: 0.2066, Val Acc: 0.6361, Val Loss: 0.2218\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.221812\n",
            "NFL LSTM model 31/201 completed\n",
            "Using provided test data as validation: 1495 train, 316 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.155, 0.16]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 5, 11)\n",
            "Flattened training data shape: (1495, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7164, Train Loss: 0.1921, Val Acc: 0.6582, Val Loss: 0.2100\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.210028\n",
            "NFL LSTM model 32/201 completed\n",
            "Using provided test data as validation: 1479 train, 309 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.16, 0.165]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1479, 5, 11)\n",
            "Flattened training data shape: (1479, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6978, Train Loss: 0.2012, Val Acc: 0.6472, Val Loss: 0.2191\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.219119\n",
            "NFL LSTM model 33/201 completed\n",
            "Using provided test data as validation: 1525 train, 339 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.165, 0.17]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1525, 5, 11)\n",
            "Flattened training data shape: (1525, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6807, Train Loss: 0.2030, Val Acc: 0.6195, Val Loss: 0.2150\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.215041\n",
            "NFL LSTM model 34/201 completed\n",
            "Using provided test data as validation: 1500 train, 309 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.17, 0.175]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1500, 5, 11)\n",
            "Flattened training data shape: (1500, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7173, Train Loss: 0.1946, Val Acc: 0.6537, Val Loss: 0.2103\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.210301\n",
            "NFL LSTM model 35/201 completed\n",
            "Using provided test data as validation: 1523 train, 321 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.175, 0.18]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1523, 5, 11)\n",
            "Flattened training data shape: (1523, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6934, Train Loss: 0.2032, Val Acc: 0.6698, Val Loss: 0.2202\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.220224\n",
            "NFL LSTM model 36/201 completed\n",
            "Using provided test data as validation: 1506 train, 330 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.18, 0.185]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1506, 5, 11)\n",
            "Flattened training data shape: (1506, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.6999, Train Loss: 0.1948, Val Acc: 0.6182, Val Loss: 0.2139\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.213935\n",
            "NFL LSTM model 37/201 completed\n",
            "Using provided test data as validation: 1476 train, 320 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.185, 0.19]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1476, 5, 11)\n",
            "Flattened training data shape: (1476, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7026, Train Loss: 0.1994, Val Acc: 0.6531, Val Loss: 0.2185\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.218546\n",
            "NFL LSTM model 38/201 completed\n",
            "Using provided test data as validation: 1508 train, 329 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.19, 0.195]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1508, 5, 11)\n",
            "Flattened training data shape: (1508, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6751, Train Loss: 0.2153, Val Acc: 0.6170, Val Loss: 0.2267\n",
            "Restored LSTM model from best epoch 3 with val_loss: 0.226682\n",
            "NFL LSTM model 39/201 completed\n",
            "Using provided test data as validation: 1437 train, 320 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.195, 0.2]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1437, 5, 11)\n",
            "Flattened training data shape: (1437, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7126, Train Loss: 0.1976, Val Acc: 0.6687, Val Loss: 0.2113\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.211293\n",
            "NFL LSTM model 40/201 completed\n",
            "Using provided test data as validation: 1522 train, 343 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.2, 0.205]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1522, 5, 11)\n",
            "Flattened training data shape: (1522, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7037, Train Loss: 0.1910, Val Acc: 0.6618, Val Loss: 0.2097\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.209711\n",
            "NFL LSTM model 41/201 completed\n",
            "Using provided test data as validation: 1483 train, 348 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.205, 0.21]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1483, 5, 11)\n",
            "Flattened training data shape: (1483, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7020, Train Loss: 0.2011, Val Acc: 0.6638, Val Loss: 0.2104\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.210435\n",
            "NFL LSTM model 42/201 completed\n",
            "Using provided test data as validation: 1495 train, 323 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.21, 0.215]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 5, 11)\n",
            "Flattened training data shape: (1495, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6876, Train Loss: 0.2016, Val Acc: 0.6563, Val Loss: 0.2073\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.207277\n",
            "NFL LSTM model 43/201 completed\n",
            "Using provided test data as validation: 1519 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.215, 0.22]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1519, 5, 11)\n",
            "Flattened training data shape: (1519, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7097, Train Loss: 0.1976, Val Acc: 0.6667, Val Loss: 0.2097\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.209675\n",
            "NFL LSTM model 44/201 completed\n",
            "Using provided test data as validation: 1481 train, 322 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.22, 0.225]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1481, 5, 11)\n",
            "Flattened training data shape: (1481, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7232, Train Loss: 0.1913, Val Acc: 0.6677, Val Loss: 0.1995\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.199541\n",
            "NFL LSTM model 45/201 completed\n",
            "Using provided test data as validation: 1559 train, 333 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.225, 0.23]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1559, 5, 11)\n",
            "Flattened training data shape: (1559, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7184, Train Loss: 0.1921, Val Acc: 0.6757, Val Loss: 0.2039\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.203920\n",
            "NFL LSTM model 46/201 completed\n",
            "Using provided test data as validation: 1488 train, 316 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.23, 0.235]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1488, 5, 11)\n",
            "Flattened training data shape: (1488, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7272, Train Loss: 0.1949, Val Acc: 0.6772, Val Loss: 0.2077\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.207707\n",
            "NFL LSTM model 47/201 completed\n",
            "Using provided test data as validation: 1470 train, 309 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.235, 0.24]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1470, 5, 11)\n",
            "Flattened training data shape: (1470, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7136, Train Loss: 0.1938, Val Acc: 0.6893, Val Loss: 0.1996\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.199550\n",
            "NFL LSTM model 48/201 completed\n",
            "Using provided test data as validation: 1563 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.24, 0.245]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1563, 5, 11)\n",
            "Flattened training data shape: (1563, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7012, Train Loss: 0.1976, Val Acc: 0.6883, Val Loss: 0.1954\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.195430\n",
            "NFL LSTM model 49/201 completed\n",
            "Using provided test data as validation: 1510 train, 319 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.245, 0.25]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1510, 5, 11)\n",
            "Flattened training data shape: (1510, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7152, Train Loss: 0.1910, Val Acc: 0.6552, Val Loss: 0.2092\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.209213\n",
            "NFL LSTM model 50/201 completed\n",
            "Using provided test data as validation: 3315 train, 657 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.25, 0.255]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3315, 5, 11)\n",
            "Flattened training data shape: (3315, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 7\n",
            "Best epoch: 2, Train Acc: 0.7092, Train Loss: 0.1949, Val Acc: 0.6728, Val Loss: 0.2114\n",
            "Restored LSTM model from best epoch 2 with val_loss: 0.211409\n",
            "NFL LSTM model 51/201 completed\n",
            "Using provided test data as validation: 1671 train, 356 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.255, 0.26]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1671, 5, 11)\n",
            "Flattened training data shape: (1671, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7181, Train Loss: 0.1868, Val Acc: 0.7051, Val Loss: 0.1911\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.191081\n",
            "NFL LSTM model 52/201 completed\n",
            "Using provided test data as validation: 1333 train, 283 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.26, 0.265]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1333, 5, 11)\n",
            "Flattened training data shape: (1333, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7082, Train Loss: 0.1930, Val Acc: 0.6820, Val Loss: 0.2015\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.201471\n",
            "NFL LSTM model 53/201 completed\n",
            "Using provided test data as validation: 1647 train, 358 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.265, 0.27]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1647, 5, 11)\n",
            "Flattened training data shape: (1647, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7158, Train Loss: 0.1912, Val Acc: 0.6983, Val Loss: 0.1990\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.199011\n",
            "NFL LSTM model 54/201 completed\n",
            "Using provided test data as validation: 1439 train, 303 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.27, 0.275]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1439, 5, 11)\n",
            "Flattened training data shape: (1439, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7130, Train Loss: 0.1950, Val Acc: 0.6667, Val Loss: 0.2036\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.203622\n",
            "NFL LSTM model 55/201 completed\n",
            "Using provided test data as validation: 1514 train, 327 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.275, 0.28]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1514, 5, 11)\n",
            "Flattened training data shape: (1514, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7299, Train Loss: 0.1857, Val Acc: 0.7003, Val Loss: 0.1883\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.188323\n",
            "NFL LSTM model 56/201 completed\n",
            "Using provided test data as validation: 1470 train, 341 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.28, 0.285]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1470, 5, 11)\n",
            "Flattened training data shape: (1470, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7170, Train Loss: 0.1887, Val Acc: 0.7009, Val Loss: 0.1979\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.197893\n",
            "NFL LSTM model 57/201 completed\n",
            "Using provided test data as validation: 1495 train, 325 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.285, 0.29]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 5, 11)\n",
            "Flattened training data shape: (1495, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7378, Train Loss: 0.1815, Val Acc: 0.6923, Val Loss: 0.2014\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.201367\n",
            "NFL LSTM model 58/201 completed\n",
            "Using provided test data as validation: 1510 train, 333 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.29, 0.295]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1510, 5, 11)\n",
            "Flattened training data shape: (1510, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7093, Train Loss: 0.1916, Val Acc: 0.6667, Val Loss: 0.2029\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.202890\n",
            "NFL LSTM model 59/201 completed\n",
            "Using provided test data as validation: 1461 train, 319 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.295, 0.3]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1461, 5, 11)\n",
            "Flattened training data shape: (1461, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7303, Train Loss: 0.1815, Val Acc: 0.6708, Val Loss: 0.2100\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.210030\n",
            "NFL LSTM model 60/201 completed\n",
            "Using provided test data as validation: 1529 train, 310 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.3, 0.305]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1529, 5, 11)\n",
            "Flattened training data shape: (1529, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7214, Train Loss: 0.1869, Val Acc: 0.7129, Val Loss: 0.1953\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.195274\n",
            "NFL LSTM model 61/201 completed\n",
            "Using provided test data as validation: 1533 train, 321 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.305, 0.31]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1533, 5, 11)\n",
            "Flattened training data shape: (1533, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7228, Train Loss: 0.1866, Val Acc: 0.6885, Val Loss: 0.1940\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.194041\n",
            "NFL LSTM model 62/201 completed\n",
            "Using provided test data as validation: 1477 train, 319 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.31, 0.315]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1477, 5, 11)\n",
            "Flattened training data shape: (1477, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7332, Train Loss: 0.1773, Val Acc: 0.6740, Val Loss: 0.2132\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.213194\n",
            "NFL LSTM model 63/201 completed\n",
            "Using provided test data as validation: 1559 train, 350 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.315, 0.32]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1559, 5, 11)\n",
            "Flattened training data shape: (1559, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6947, Train Loss: 0.1946, Val Acc: 0.6743, Val Loss: 0.2119\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.211851\n",
            "NFL LSTM model 64/201 completed\n",
            "Using provided test data as validation: 1472 train, 332 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.32, 0.325]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1472, 5, 11)\n",
            "Flattened training data shape: (1472, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7480, Train Loss: 0.1777, Val Acc: 0.7108, Val Loss: 0.1873\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.187294\n",
            "NFL LSTM model 65/201 completed\n",
            "Using provided test data as validation: 1520 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.325, 0.33]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1520, 5, 11)\n",
            "Flattened training data shape: (1520, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.7447, Train Loss: 0.1767, Val Acc: 0.7160, Val Loss: 0.1942\n",
            "Restored LSTM model from best epoch 13 with val_loss: 0.194152\n",
            "NFL LSTM model 66/201 completed\n",
            "Using provided test data as validation: 1508 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.33, 0.335]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1508, 5, 11)\n",
            "Flattened training data shape: (1508, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7308, Train Loss: 0.1834, Val Acc: 0.6950, Val Loss: 0.2004\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.200403\n",
            "NFL LSTM model 67/201 completed\n",
            "Using provided test data as validation: 1492 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.335, 0.34]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1492, 5, 11)\n",
            "Flattened training data shape: (1492, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.7487, Train Loss: 0.1729, Val Acc: 0.7315, Val Loss: 0.1757\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.175698\n",
            "NFL LSTM model 68/201 completed\n",
            "Using provided test data as validation: 1504 train, 339 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.34, 0.345]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1504, 5, 11)\n",
            "Flattened training data shape: (1504, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.7566, Train Loss: 0.1674, Val Acc: 0.7493, Val Loss: 0.1725\n",
            "Restored LSTM model from best epoch 13 with val_loss: 0.172455\n",
            "NFL LSTM model 69/201 completed\n",
            "Using provided test data as validation: 1522 train, 316 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.345, 0.35]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1522, 5, 11)\n",
            "Flattened training data shape: (1522, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.7569, Train Loss: 0.1664, Val Acc: 0.7373, Val Loss: 0.1816\n",
            "Restored LSTM model from best epoch 14 with val_loss: 0.181561\n",
            "NFL LSTM model 70/201 completed\n",
            "Using provided test data as validation: 1553 train, 336 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.35, 0.355]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1553, 5, 11)\n",
            "Flattened training data shape: (1553, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7521, Train Loss: 0.1656, Val Acc: 0.7232, Val Loss: 0.1879\n",
            "Restored LSTM model from best epoch 12 with val_loss: 0.187941\n",
            "NFL LSTM model 71/201 completed\n",
            "Using provided test data as validation: 1534 train, 337 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.355, 0.36]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1534, 5, 11)\n",
            "Flattened training data shape: (1534, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.7392, Train Loss: 0.1736, Val Acc: 0.7300, Val Loss: 0.1934\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.193447\n",
            "NFL LSTM model 72/201 completed\n",
            "Using provided test data as validation: 1470 train, 329 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.36, 0.365]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1470, 5, 11)\n",
            "Flattened training data shape: (1470, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7401, Train Loss: 0.1754, Val Acc: 0.7082, Val Loss: 0.1926\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.192622\n",
            "NFL LSTM model 73/201 completed\n",
            "Using provided test data as validation: 1520 train, 335 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.365, 0.37]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1520, 5, 11)\n",
            "Flattened training data shape: (1520, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.7704, Train Loss: 0.1650, Val Acc: 0.7373, Val Loss: 0.1760\n",
            "Restored LSTM model from best epoch 16 with val_loss: 0.175964\n",
            "NFL LSTM model 74/201 completed\n",
            "Using provided test data as validation: 1478 train, 314 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.37, 0.375]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1478, 5, 11)\n",
            "Flattened training data shape: (1478, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7463, Train Loss: 0.1794, Val Acc: 0.7229, Val Loss: 0.1886\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.188558\n",
            "NFL LSTM model 75/201 completed\n",
            "Using provided test data as validation: 1518 train, 335 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.375, 0.38]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1518, 5, 11)\n",
            "Flattened training data shape: (1518, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7549, Train Loss: 0.1704, Val Acc: 0.7493, Val Loss: 0.1704\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.170439\n",
            "NFL LSTM model 76/201 completed\n",
            "Using provided test data as validation: 1509 train, 313 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.38, 0.385]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1509, 5, 11)\n",
            "Flattened training data shape: (1509, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7588, Train Loss: 0.1689, Val Acc: 0.7316, Val Loss: 0.1760\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.175982\n",
            "NFL LSTM model 77/201 completed\n",
            "Using provided test data as validation: 1500 train, 332 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.385, 0.39]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1500, 5, 11)\n",
            "Flattened training data shape: (1500, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7487, Train Loss: 0.1692, Val Acc: 0.7530, Val Loss: 0.1749\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.174945\n",
            "NFL LSTM model 78/201 completed\n",
            "Using provided test data as validation: 1500 train, 317 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.39, 0.395]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1500, 5, 11)\n",
            "Flattened training data shape: (1500, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7507, Train Loss: 0.1690, Val Acc: 0.7129, Val Loss: 0.1833\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.183288\n",
            "NFL LSTM model 79/201 completed\n",
            "Using provided test data as validation: 1526 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.395, 0.4]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1526, 5, 11)\n",
            "Flattened training data shape: (1526, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7575, Train Loss: 0.1718, Val Acc: 0.7075, Val Loss: 0.1879\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.187918\n",
            "NFL LSTM model 80/201 completed\n",
            "Using provided test data as validation: 1494 train, 344 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.4, 0.405]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1494, 5, 11)\n",
            "Flattened training data shape: (1494, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.7691, Train Loss: 0.1628, Val Acc: 0.7442, Val Loss: 0.1663\n",
            "Restored LSTM model from best epoch 21 with val_loss: 0.166336\n",
            "NFL LSTM model 81/201 completed\n",
            "Using provided test data as validation: 1516 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.405, 0.41]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1516, 5, 11)\n",
            "Flattened training data shape: (1516, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7619, Train Loss: 0.1696, Val Acc: 0.7296, Val Loss: 0.1802\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.180195\n",
            "NFL LSTM model 82/201 completed\n",
            "Using provided test data as validation: 1493 train, 332 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.41, 0.415]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1493, 5, 11)\n",
            "Flattened training data shape: (1493, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "NFL LSTM model 83/201 completed\n",
            "Using provided test data as validation: 1539 train, 308 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.415, 0.42]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1539, 5, 11)\n",
            "Flattened training data shape: (1539, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7628, Train Loss: 0.1672, Val Acc: 0.7110, Val Loss: 0.1895\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.189532\n",
            "NFL LSTM model 84/201 completed\n",
            "Using provided test data as validation: 1499 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.42, 0.425]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1499, 5, 11)\n",
            "Flattened training data shape: (1499, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7578, Train Loss: 0.1642, Val Acc: 0.7264, Val Loss: 0.1826\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.182591\n",
            "NFL LSTM model 85/201 completed\n",
            "Using provided test data as validation: 1523 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.425, 0.43]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1523, 5, 11)\n",
            "Flattened training data shape: (1523, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7420, Train Loss: 0.1768, Val Acc: 0.7296, Val Loss: 0.1903\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.190253\n",
            "NFL LSTM model 86/201 completed\n",
            "Using provided test data as validation: 1549 train, 346 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.43, 0.435]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1549, 5, 11)\n",
            "Flattened training data shape: (1549, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7669, Train Loss: 0.1632, Val Acc: 0.7428, Val Loss: 0.1793\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.179284\n",
            "NFL LSTM model 87/201 completed\n",
            "Using provided test data as validation: 1497 train, 317 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.435, 0.44]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1497, 5, 11)\n",
            "Flattened training data shape: (1497, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.7649, Train Loss: 0.1578, Val Acc: 0.7729, Val Loss: 0.1658\n",
            "Restored LSTM model from best epoch 16 with val_loss: 0.165836\n",
            "NFL LSTM model 88/201 completed\n",
            "Using provided test data as validation: 1526 train, 329 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.44, 0.445]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1526, 5, 11)\n",
            "Flattened training data shape: (1526, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7772, Train Loss: 0.1555, Val Acc: 0.7477, Val Loss: 0.1703\n",
            "Restored LSTM model from best epoch 12 with val_loss: 0.170314\n",
            "NFL LSTM model 89/201 completed\n",
            "Using provided test data as validation: 1483 train, 337 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.445, 0.45]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1483, 5, 11)\n",
            "Flattened training data shape: (1483, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.7815, Train Loss: 0.1583, Val Acc: 0.7359, Val Loss: 0.1697\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.169712\n",
            "NFL LSTM model 90/201 completed\n",
            "Using provided test data as validation: 1555 train, 349 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.45, 0.455]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1555, 5, 11)\n",
            "Flattened training data shape: (1555, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.7653, Train Loss: 0.1630, Val Acc: 0.7564, Val Loss: 0.1716\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.171629\n",
            "NFL LSTM model 91/201 completed\n",
            "Using provided test data as validation: 1527 train, 317 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.455, 0.46]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1527, 5, 11)\n",
            "Flattened training data shape: (1527, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7656, Train Loss: 0.1646, Val Acc: 0.7445, Val Loss: 0.1683\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.168269\n",
            "NFL LSTM model 92/201 completed\n",
            "Using provided test data as validation: 1588 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.46, 0.465]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1588, 5, 11)\n",
            "Flattened training data shape: (1588, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7676, Train Loss: 0.1647, Val Acc: 0.7390, Val Loss: 0.1673\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.167319\n",
            "NFL LSTM model 93/201 completed\n",
            "Using provided test data as validation: 1627 train, 346 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.465, 0.47]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1627, 5, 11)\n",
            "Flattened training data shape: (1627, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.7966, Train Loss: 0.1452, Val Acc: 0.7572, Val Loss: 0.1696\n",
            "Restored LSTM model from best epoch 14 with val_loss: 0.169566\n",
            "NFL LSTM model 94/201 completed\n",
            "Using provided test data as validation: 3876 train, 880 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.47, 0.475]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3876, 5, 11)\n",
            "Flattened training data shape: (3876, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7851, Train Loss: 0.1520, Val Acc: 0.7648, Val Loss: 0.1673\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.167322\n",
            "NFL LSTM model 95/201 completed\n",
            "Using provided test data as validation: 2135 train, 503 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.475, 0.48]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2135, 5, 11)\n",
            "Flattened training data shape: (2135, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8131, Train Loss: 0.1359, Val Acc: 0.7773, Val Loss: 0.1581\n",
            "Restored LSTM model from best epoch 17 with val_loss: 0.158124\n",
            "NFL LSTM model 96/201 completed\n",
            "Using provided test data as validation: 2200 train, 454 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.48, 0.485]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2200, 5, 11)\n",
            "Flattened training data shape: (2200, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7973, Train Loss: 0.1479, Val Acc: 0.7930, Val Loss: 0.1535\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.153517\n",
            "NFL LSTM model 97/201 completed\n",
            "Using provided test data as validation: 2591 train, 649 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.485, 0.49]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2591, 5, 11)\n",
            "Flattened training data shape: (2591, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.7754, Train Loss: 0.1654, Val Acc: 0.7026, Val Loss: 0.1900\n",
            "Restored LSTM model from best epoch 3 with val_loss: 0.190014\n",
            "NFL LSTM model 98/201 completed\n",
            "Using provided test data as validation: 3061 train, 634 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.49, 0.495]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3061, 5, 11)\n",
            "Flattened training data shape: (3061, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.7844, Train Loss: 0.1554, Val Acc: 0.7713, Val Loss: 0.1652\n",
            "Restored LSTM model from best epoch 3 with val_loss: 0.165169\n",
            "NFL LSTM model 99/201 completed\n",
            "Using provided test data as validation: 3610 train, 872 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.495, 0.5]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3610, 5, 11)\n",
            "Flattened training data shape: (3610, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8075, Train Loss: 0.1384, Val Acc: 0.7592, Val Loss: 0.1630\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.163044\n",
            "NFL LSTM model 100/201 completed\n",
            "Using provided test data as validation: 6787 train, 1483 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.5, 0.505]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (6787, 5, 11)\n",
            "Flattened training data shape: (6787, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 6\n",
            "Best epoch: 1, Train Acc: 0.7520, Train Loss: 0.1719, Val Acc: 0.7707, Val Loss: 0.1604\n",
            "Restored LSTM model from best epoch 1 with val_loss: 0.160409\n",
            "NFL LSTM model 101/201 completed\n",
            "Using provided test data as validation: 1443 train, 313 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.505, 0.51]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1443, 5, 11)\n",
            "Flattened training data shape: (1443, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8226, Train Loss: 0.1333, Val Acc: 0.7923, Val Loss: 0.1427\n",
            "Restored LSTM model from best epoch 17 with val_loss: 0.142680\n",
            "NFL LSTM model 102/201 completed\n",
            "Using provided test data as validation: 1298 train, 280 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.51, 0.515]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1298, 5, 11)\n",
            "Flattened training data shape: (1298, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8059, Train Loss: 0.1406, Val Acc: 0.7821, Val Loss: 0.1460\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.146007\n",
            "NFL LSTM model 103/201 completed\n",
            "Using provided test data as validation: 1449 train, 311 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.515, 0.52]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1449, 5, 11)\n",
            "Flattened training data shape: (1449, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8150, Train Loss: 0.1418, Val Acc: 0.7942, Val Loss: 0.1427\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.142740\n",
            "NFL LSTM model 104/201 completed\n",
            "Using provided test data as validation: 1367 train, 306 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.52, 0.525]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1367, 5, 11)\n",
            "Flattened training data shape: (1367, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8061, Train Loss: 0.1375, Val Acc: 0.7941, Val Loss: 0.1461\n",
            "Restored LSTM model from best epoch 15 with val_loss: 0.146111\n",
            "NFL LSTM model 105/201 completed\n",
            "Using provided test data as validation: 1452 train, 308 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.525, 0.53]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1452, 5, 11)\n",
            "Flattened training data shape: (1452, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8154, Train Loss: 0.1376, Val Acc: 0.7760, Val Loss: 0.1531\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.153066\n",
            "NFL LSTM model 106/201 completed\n",
            "Using provided test data as validation: 1456 train, 300 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.53, 0.535]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1456, 5, 11)\n",
            "Flattened training data shape: (1456, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8077, Train Loss: 0.1427, Val Acc: 0.7567, Val Loss: 0.1593\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.159278\n",
            "NFL LSTM model 107/201 completed\n",
            "Using provided test data as validation: 1449 train, 306 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.535, 0.54]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1449, 5, 11)\n",
            "Flattened training data shape: (1449, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8199, Train Loss: 0.1361, Val Acc: 0.7974, Val Loss: 0.1480\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.147975\n",
            "NFL LSTM model 108/201 completed\n",
            "Using provided test data as validation: 1437 train, 316 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.54, 0.545]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1437, 5, 11)\n",
            "Flattened training data shape: (1437, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8100, Train Loss: 0.1400, Val Acc: 0.7911, Val Loss: 0.1454\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.145399\n",
            "NFL LSTM model 109/201 completed\n",
            "Using provided test data as validation: 1487 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.545, 0.55]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1487, 5, 11)\n",
            "Flattened training data shape: (1487, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7996, Train Loss: 0.1465, Val Acc: 0.7840, Val Loss: 0.1473\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.147275\n",
            "NFL LSTM model 110/201 completed\n",
            "Using provided test data as validation: 1461 train, 319 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.55, 0.555]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1461, 5, 11)\n",
            "Flattened training data shape: (1461, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8220, Train Loss: 0.1355, Val Acc: 0.8119, Val Loss: 0.1412\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.141198\n",
            "NFL LSTM model 111/201 completed\n",
            "Using provided test data as validation: 1476 train, 325 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.555, 0.56]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1476, 5, 11)\n",
            "Flattened training data shape: (1476, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.8252, Train Loss: 0.1289, Val Acc: 0.8215, Val Loss: 0.1347\n",
            "Restored LSTM model from best epoch 25 with val_loss: 0.134741\n",
            "NFL LSTM model 112/201 completed\n",
            "Using provided test data as validation: 1498 train, 305 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.56, 0.565]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1498, 5, 11)\n",
            "Flattened training data shape: (1498, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8144, Train Loss: 0.1340, Val Acc: 0.8066, Val Loss: 0.1411\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.141096\n",
            "NFL LSTM model 113/201 completed\n",
            "Using provided test data as validation: 1498 train, 334 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.565, 0.57]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1498, 5, 11)\n",
            "Flattened training data shape: (1498, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8244, Train Loss: 0.1312, Val Acc: 0.8114, Val Loss: 0.1401\n",
            "Restored LSTM model from best epoch 15 with val_loss: 0.140068\n",
            "NFL LSTM model 114/201 completed\n",
            "Using provided test data as validation: 1492 train, 331 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.57, 0.575]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1492, 5, 11)\n",
            "Flattened training data shape: (1492, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.8210, Train Loss: 0.1337, Val Acc: 0.8248, Val Loss: 0.1325\n",
            "Restored LSTM model from best epoch 16 with val_loss: 0.132530\n",
            "NFL LSTM model 115/201 completed\n",
            "Using provided test data as validation: 1495 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.575, 0.58]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 5, 11)\n",
            "Flattened training data shape: (1495, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8127, Train Loss: 0.1337, Val Acc: 0.7893, Val Loss: 0.1494\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.149403\n",
            "NFL LSTM model 116/201 completed\n",
            "Using provided test data as validation: 1469 train, 309 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.58, 0.585]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1469, 5, 11)\n",
            "Flattened training data shape: (1469, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8108, Train Loss: 0.1398, Val Acc: 0.8091, Val Loss: 0.1457\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.145740\n",
            "NFL LSTM model 117/201 completed\n",
            "Using provided test data as validation: 1528 train, 312 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.585, 0.59]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1528, 5, 11)\n",
            "Flattened training data shape: (1528, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8168, Train Loss: 0.1359, Val Acc: 0.8205, Val Loss: 0.1297\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.129672\n",
            "NFL LSTM model 118/201 completed\n",
            "Using provided test data as validation: 1545 train, 336 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.59, 0.595]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1545, 5, 11)\n",
            "Flattened training data shape: (1545, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8259, Train Loss: 0.1305, Val Acc: 0.8393, Val Loss: 0.1211\n",
            "Restored LSTM model from best epoch 17 with val_loss: 0.121054\n",
            "NFL LSTM model 119/201 completed\n",
            "Using provided test data as validation: 1500 train, 339 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.595, 0.6]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1500, 5, 11)\n",
            "Flattened training data shape: (1500, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8233, Train Loss: 0.1287, Val Acc: 0.8142, Val Loss: 0.1283\n",
            "Restored LSTM model from best epoch 22 with val_loss: 0.128294\n",
            "NFL LSTM model 120/201 completed\n",
            "Using provided test data as validation: 1541 train, 331 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.6, 0.605]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1541, 5, 11)\n",
            "Flattened training data shape: (1541, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8215, Train Loss: 0.1356, Val Acc: 0.8248, Val Loss: 0.1316\n",
            "Restored LSTM model from best epoch 12 with val_loss: 0.131609\n",
            "NFL LSTM model 121/201 completed\n",
            "Using provided test data as validation: 1514 train, 319 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.605, 0.61]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1514, 5, 11)\n",
            "Flattened training data shape: (1514, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8203, Train Loss: 0.1314, Val Acc: 0.8056, Val Loss: 0.1387\n",
            "Restored LSTM model from best epoch 12 with val_loss: 0.138726\n",
            "NFL LSTM model 122/201 completed\n",
            "Using provided test data as validation: 1522 train, 334 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.61, 0.615]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1522, 5, 11)\n",
            "Flattened training data shape: (1522, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8193, Train Loss: 0.1321, Val Acc: 0.7844, Val Loss: 0.1499\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.149857\n",
            "NFL LSTM model 123/201 completed\n",
            "Using provided test data as validation: 1547 train, 323 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.615, 0.62]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1547, 5, 11)\n",
            "Flattened training data shape: (1547, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8132, Train Loss: 0.1341, Val Acc: 0.8142, Val Loss: 0.1300\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.129959\n",
            "NFL LSTM model 124/201 completed\n",
            "Using provided test data as validation: 1499 train, 336 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.62, 0.625]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1499, 5, 11)\n",
            "Flattened training data shape: (1499, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.8132, Train Loss: 0.1281, Val Acc: 0.8125, Val Loss: 0.1357\n",
            "Restored LSTM model from best epoch 13 with val_loss: 0.135686\n",
            "NFL LSTM model 125/201 completed\n",
            "Using provided test data as validation: 1573 train, 320 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.625, 0.63]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1573, 5, 11)\n",
            "Flattened training data shape: (1573, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8258, Train Loss: 0.1330, Val Acc: 0.8219, Val Loss: 0.1308\n",
            "Restored LSTM model from best epoch 22 with val_loss: 0.130800\n",
            "NFL LSTM model 126/201 completed\n",
            "Using provided test data as validation: 1486 train, 327 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.63, 0.635]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1486, 5, 11)\n",
            "Flattened training data shape: (1486, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8089, Train Loss: 0.1348, Val Acc: 0.8012, Val Loss: 0.1347\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.134732\n",
            "NFL LSTM model 127/201 completed\n",
            "Using provided test data as validation: 1531 train, 332 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.635, 0.64]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1531, 5, 11)\n",
            "Flattened training data shape: (1531, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8374, Train Loss: 0.1218, Val Acc: 0.8343, Val Loss: 0.1206\n",
            "Restored LSTM model from best epoch 17 with val_loss: 0.120560\n",
            "NFL LSTM model 128/201 completed\n",
            "Using provided test data as validation: 1498 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.64, 0.645]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1498, 5, 11)\n",
            "Flattened training data shape: (1498, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.8291, Train Loss: 0.1239, Val Acc: 0.8364, Val Loss: 0.1182\n",
            "Restored LSTM model from best epoch 19 with val_loss: 0.118194\n",
            "NFL LSTM model 129/201 completed\n",
            "Using provided test data as validation: 1504 train, 352 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.645, 0.65]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1504, 5, 11)\n",
            "Flattened training data shape: (1504, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8431, Train Loss: 0.1200, Val Acc: 0.8267, Val Loss: 0.1294\n",
            "Restored LSTM model from best epoch 22 with val_loss: 0.129418\n",
            "NFL LSTM model 130/201 completed\n",
            "Using provided test data as validation: 1496 train, 321 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.65, 0.655]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1496, 5, 11)\n",
            "Flattened training data shape: (1496, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8369, Train Loss: 0.1228, Val Acc: 0.8224, Val Loss: 0.1219\n",
            "Restored LSTM model from best epoch 21 with val_loss: 0.121918\n",
            "NFL LSTM model 131/201 completed\n",
            "Using provided test data as validation: 1527 train, 346 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.655, 0.66]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1527, 5, 11)\n",
            "Flattened training data shape: (1527, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.8402, Train Loss: 0.1218, Val Acc: 0.8353, Val Loss: 0.1201\n",
            "Restored LSTM model from best epoch 19 with val_loss: 0.120149\n",
            "NFL LSTM model 132/201 completed\n",
            "Using provided test data as validation: 1576 train, 318 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.66, 0.665]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1576, 5, 11)\n",
            "Flattened training data shape: (1576, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8261, Train Loss: 0.1270, Val Acc: 0.8145, Val Loss: 0.1270\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.126970\n",
            "NFL LSTM model 133/201 completed\n",
            "Using provided test data as validation: 1497 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.665, 0.67]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1497, 5, 11)\n",
            "Flattened training data shape: (1497, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8377, Train Loss: 0.1263, Val Acc: 0.8210, Val Loss: 0.1163\n",
            "Restored LSTM model from best epoch 12 with val_loss: 0.116311\n",
            "NFL LSTM model 134/201 completed\n",
            "Using provided test data as validation: 1539 train, 326 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.67, 0.675]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1539, 5, 11)\n",
            "Flattened training data shape: (1539, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8454, Train Loss: 0.1213, Val Acc: 0.8098, Val Loss: 0.1258\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.125775\n",
            "NFL LSTM model 135/201 completed\n",
            "Using provided test data as validation: 1493 train, 334 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.675, 0.68]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1493, 5, 11)\n",
            "Flattened training data shape: (1493, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "NFL LSTM model 136/201 completed\n",
            "Using provided test data as validation: 1517 train, 320 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.68, 0.685]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1517, 5, 11)\n",
            "Flattened training data shape: (1517, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8260, Train Loss: 0.1290, Val Acc: 0.8313, Val Loss: 0.1235\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.123485\n",
            "NFL LSTM model 137/201 completed\n",
            "Using provided test data as validation: 1509 train, 320 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.685, 0.69]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1509, 5, 11)\n",
            "Flattened training data shape: (1509, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8443, Train Loss: 0.1214, Val Acc: 0.8375, Val Loss: 0.1110\n",
            "Restored LSTM model from best epoch 14 with val_loss: 0.110977\n",
            "NFL LSTM model 138/201 completed\n",
            "Using provided test data as validation: 1525 train, 331 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.69, 0.695]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1525, 5, 11)\n",
            "Flattened training data shape: (1525, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8407, Train Loss: 0.1220, Val Acc: 0.8459, Val Loss: 0.1041\n",
            "Restored LSTM model from best epoch 15 with val_loss: 0.104101\n",
            "NFL LSTM model 139/201 completed\n",
            "Using provided test data as validation: 1504 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.695, 0.7]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1504, 5, 11)\n",
            "Flattened training data shape: (1504, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8477, Train Loss: 0.1162, Val Acc: 0.8364, Val Loss: 0.1119\n",
            "Restored LSTM model from best epoch 17 with val_loss: 0.111949\n",
            "NFL LSTM model 140/201 completed\n",
            "Using provided test data as validation: 1502 train, 314 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.7, 0.705]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1502, 5, 11)\n",
            "Flattened training data shape: (1502, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.8502, Train Loss: 0.1143, Val Acc: 0.8248, Val Loss: 0.1281\n",
            "Restored LSTM model from best epoch 16 with val_loss: 0.128149\n",
            "NFL LSTM model 141/201 completed\n",
            "Using provided test data as validation: 1502 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.705, 0.71]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1502, 5, 11)\n",
            "Flattened training data shape: (1502, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8296, Train Loss: 0.1209, Val Acc: 0.8272, Val Loss: 0.1084\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.108383\n",
            "NFL LSTM model 142/201 completed\n",
            "Using provided test data as validation: 1496 train, 332 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.71, 0.715]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1496, 5, 11)\n",
            "Flattened training data shape: (1496, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.8596, Train Loss: 0.1053, Val Acc: 0.8404, Val Loss: 0.1110\n",
            "Restored LSTM model from best epoch 25 with val_loss: 0.110992\n",
            "NFL LSTM model 143/201 completed\n",
            "Using provided test data as validation: 1544 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.715, 0.72]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1544, 5, 11)\n",
            "Flattened training data shape: (1544, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8556, Train Loss: 0.1072, Val Acc: 0.8302, Val Loss: 0.1089\n",
            "Restored LSTM model from best epoch 21 with val_loss: 0.108929\n",
            "NFL LSTM model 144/201 completed\n",
            "Using provided test data as validation: 1530 train, 322 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.72, 0.725]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1530, 5, 11)\n",
            "Flattened training data shape: (1530, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8412, Train Loss: 0.1165, Val Acc: 0.8385, Val Loss: 0.1101\n",
            "Restored LSTM model from best epoch 15 with val_loss: 0.110052\n",
            "NFL LSTM model 145/201 completed\n",
            "Using provided test data as validation: 1535 train, 336 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.725, 0.73]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1535, 5, 11)\n",
            "Flattened training data shape: (1535, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.8476, Train Loss: 0.1132, Val Acc: 0.8333, Val Loss: 0.1111\n",
            "Restored LSTM model from best epoch 18 with val_loss: 0.111106\n",
            "NFL LSTM model 146/201 completed\n",
            "Using provided test data as validation: 1525 train, 334 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.73, 0.735]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1525, 5, 11)\n",
            "Flattened training data shape: (1525, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8590, Train Loss: 0.1127, Val Acc: 0.8683, Val Loss: 0.1053\n",
            "Restored LSTM model from best epoch 12 with val_loss: 0.105322\n",
            "NFL LSTM model 147/201 completed\n",
            "Using provided test data as validation: 1502 train, 328 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.735, 0.74]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1502, 5, 11)\n",
            "Flattened training data shape: (1502, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.8555, Train Loss: 0.1057, Val Acc: 0.8628, Val Loss: 0.1085\n",
            "Restored LSTM model from best epoch 18 with val_loss: 0.108524\n",
            "NFL LSTM model 148/201 completed\n",
            "Using provided test data as validation: 1504 train, 352 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.74, 0.745]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1504, 5, 11)\n",
            "Flattened training data shape: (1504, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.8491, Train Loss: 0.1109, Val Acc: 0.8608, Val Loss: 0.1030\n",
            "Restored LSTM model from best epoch 13 with val_loss: 0.102988\n",
            "NFL LSTM model 149/201 completed\n",
            "Using provided test data as validation: 1479 train, 325 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.745, 0.75]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1479, 5, 11)\n",
            "Flattened training data shape: (1479, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8580, Train Loss: 0.1108, Val Acc: 0.8185, Val Loss: 0.1218\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.121843\n",
            "NFL LSTM model 150/201 completed\n",
            "Using provided test data as validation: 3141 train, 691 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.75, 0.755]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3141, 5, 11)\n",
            "Flattened training data shape: (3141, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8647, Train Loss: 0.1023, Val Acc: 0.8365, Val Loss: 0.1152\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.115169\n",
            "NFL LSTM model 151/201 completed\n",
            "Using provided test data as validation: 1680 train, 351 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.755, 0.76]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1680, 5, 11)\n",
            "Flattened training data shape: (1680, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8601, Train Loss: 0.1073, Val Acc: 0.8632, Val Loss: 0.1040\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.104028\n",
            "NFL LSTM model 152/201 completed\n",
            "Using provided test data as validation: 1343 train, 295 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.76, 0.765]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1343, 5, 11)\n",
            "Flattened training data shape: (1343, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8652, Train Loss: 0.1044, Val Acc: 0.8610, Val Loss: 0.0988\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.098761\n",
            "NFL LSTM model 153/201 completed\n",
            "Using provided test data as validation: 1642 train, 349 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.765, 0.77]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1642, 5, 11)\n",
            "Flattened training data shape: (1642, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8581, Train Loss: 0.1075, Val Acc: 0.8481, Val Loss: 0.1082\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.108178\n",
            "NFL LSTM model 154/201 completed\n",
            "Using provided test data as validation: 1418 train, 303 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.77, 0.775]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1418, 5, 11)\n",
            "Flattened training data shape: (1418, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8597, Train Loss: 0.1109, Val Acc: 0.8614, Val Loss: 0.1050\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.105018\n",
            "NFL LSTM model 155/201 completed\n",
            "Using provided test data as validation: 1573 train, 331 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.775, 0.78]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1573, 5, 11)\n",
            "Flattened training data shape: (1573, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8684, Train Loss: 0.1043, Val Acc: 0.8278, Val Loss: 0.1084\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.108418\n",
            "NFL LSTM model 156/201 completed\n",
            "Using provided test data as validation: 1463 train, 336 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.78, 0.785]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1463, 5, 11)\n",
            "Flattened training data shape: (1463, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8694, Train Loss: 0.1062, Val Acc: 0.8482, Val Loss: 0.1041\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.104089\n",
            "NFL LSTM model 157/201 completed\n",
            "Using provided test data as validation: 1494 train, 329 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.785, 0.79]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1494, 5, 11)\n",
            "Flattened training data shape: (1494, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8608, Train Loss: 0.1058, Val Acc: 0.8511, Val Loss: 0.1015\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.101544\n",
            "NFL LSTM model 158/201 completed\n",
            "Using provided test data as validation: 1526 train, 329 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.79, 0.795]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1526, 5, 11)\n",
            "Flattened training data shape: (1526, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8742, Train Loss: 0.1005, Val Acc: 0.8480, Val Loss: 0.0988\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.098793\n",
            "NFL LSTM model 159/201 completed\n",
            "Using provided test data as validation: 1520 train, 312 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.795, 0.8]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1520, 5, 11)\n",
            "Flattened training data shape: (1520, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.8711, Train Loss: 0.1007, Val Acc: 0.8269, Val Loss: 0.1110\n",
            "Restored LSTM model from best epoch 16 with val_loss: 0.110956\n",
            "NFL LSTM model 160/201 completed\n",
            "Using provided test data as validation: 1577 train, 341 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.8, 0.805]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1577, 5, 11)\n",
            "Flattened training data shape: (1577, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8592, Train Loss: 0.1058, Val Acc: 0.8182, Val Loss: 0.1171\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.117080\n",
            "NFL LSTM model 161/201 completed\n",
            "Using provided test data as validation: 1538 train, 326 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.805, 0.81]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1538, 5, 11)\n",
            "Flattened training data shape: (1538, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8667, Train Loss: 0.1091, Val Acc: 0.8620, Val Loss: 0.0888\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.088801\n",
            "NFL LSTM model 162/201 completed\n",
            "Using provided test data as validation: 1485 train, 335 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.81, 0.815]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1485, 5, 11)\n",
            "Flattened training data shape: (1485, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8673, Train Loss: 0.1001, Val Acc: 0.8627, Val Loss: 0.0941\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.094062\n",
            "NFL LSTM model 163/201 completed\n",
            "Using provided test data as validation: 1538 train, 341 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.815, 0.82]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1538, 5, 11)\n",
            "Flattened training data shape: (1538, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8752, Train Loss: 0.0946, Val Acc: 0.8475, Val Loss: 0.1031\n",
            "Restored LSTM model from best epoch 10 with val_loss: 0.103081\n",
            "NFL LSTM model 164/201 completed\n",
            "Using provided test data as validation: 1516 train, 345 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.82, 0.825]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1516, 5, 11)\n",
            "Flattened training data shape: (1516, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8720, Train Loss: 0.0954, Val Acc: 0.8551, Val Loss: 0.0942\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.094232\n",
            "NFL LSTM model 165/201 completed\n",
            "Using provided test data as validation: 1496 train, 341 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.825, 0.83]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1496, 5, 11)\n",
            "Flattened training data shape: (1496, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8777, Train Loss: 0.0976, Val Acc: 0.8534, Val Loss: 0.0947\n",
            "Restored LSTM model from best epoch 11 with val_loss: 0.094658\n",
            "NFL LSTM model 166/201 completed\n",
            "Using provided test data as validation: 1529 train, 331 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.83, 0.835]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1529, 5, 11)\n",
            "Flattened training data shape: (1529, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8738, Train Loss: 0.1017, Val Acc: 0.8640, Val Loss: 0.0934\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.093370\n",
            "NFL LSTM model 167/201 completed\n",
            "Using provided test data as validation: 1502 train, 329 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.835, 0.84]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1502, 5, 11)\n",
            "Flattened training data shape: (1502, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.8708, Train Loss: 0.1016, Val Acc: 0.8450, Val Loss: 0.1016\n",
            "Restored LSTM model from best epoch 5 with val_loss: 0.101592\n",
            "NFL LSTM model 168/201 completed\n",
            "Using provided test data as validation: 1499 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.84, 0.845]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1499, 5, 11)\n",
            "Flattened training data shape: (1499, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8766, Train Loss: 0.0938, Val Acc: 0.8395, Val Loss: 0.0935\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.093507\n",
            "NFL LSTM model 169/201 completed\n",
            "Using provided test data as validation: 1538 train, 330 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.845, 0.85]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1538, 5, 11)\n",
            "Flattened training data shape: (1538, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8771, Train Loss: 0.0919, Val Acc: 0.8606, Val Loss: 0.0890\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.088997\n",
            "NFL LSTM model 170/201 completed\n",
            "Using provided test data as validation: 1527 train, 335 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.85, 0.855]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1527, 5, 11)\n",
            "Flattened training data shape: (1527, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8756, Train Loss: 0.0940, Val Acc: 0.8776, Val Loss: 0.0871\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.087123\n",
            "NFL LSTM model 171/201 completed\n",
            "Using provided test data as validation: 1515 train, 337 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.855, 0.86]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1515, 5, 11)\n",
            "Flattened training data shape: (1515, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8785, Train Loss: 0.0984, Val Acc: 0.8843, Val Loss: 0.0893\n",
            "Restored LSTM model from best epoch 6 with val_loss: 0.089321\n",
            "NFL LSTM model 172/201 completed\n",
            "Using provided test data as validation: 1552 train, 322 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.86, 0.865]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1552, 5, 11)\n",
            "Flattened training data shape: (1552, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8827, Train Loss: 0.0873, Val Acc: 0.8789, Val Loss: 0.0804\n",
            "Restored LSTM model from best epoch 15 with val_loss: 0.080432\n",
            "NFL LSTM model 173/201 completed\n",
            "Using provided test data as validation: 1512 train, 346 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.865, 0.87]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1512, 5, 11)\n",
            "Flattened training data shape: (1512, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8869, Train Loss: 0.0880, Val Acc: 0.8931, Val Loss: 0.0775\n",
            "Restored LSTM model from best epoch 15 with val_loss: 0.077498\n",
            "NFL LSTM model 174/201 completed\n",
            "Using provided test data as validation: 1491 train, 326 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.87, 0.875]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1491, 5, 11)\n",
            "Flattened training data shape: (1491, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8873, Train Loss: 0.0859, Val Acc: 0.8834, Val Loss: 0.0793\n",
            "Restored LSTM model from best epoch 14 with val_loss: 0.079271\n",
            "NFL LSTM model 175/201 completed\n",
            "Using provided test data as validation: 1537 train, 338 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.875, 0.88]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1537, 5, 11)\n",
            "Flattened training data shape: (1537, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8953, Train Loss: 0.0797, Val Acc: 0.8787, Val Loss: 0.0808\n",
            "Restored LSTM model from best epoch 15 with val_loss: 0.080825\n",
            "NFL LSTM model 176/201 completed\n",
            "Using provided test data as validation: 1539 train, 343 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.88, 0.885]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1539, 5, 11)\n",
            "Flattened training data shape: (1539, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.8902, Train Loss: 0.0818, Val Acc: 0.8746, Val Loss: 0.0877\n",
            "Restored LSTM model from best epoch 18 with val_loss: 0.087717\n",
            "NFL LSTM model 177/201 completed\n",
            "Using provided test data as validation: 1536 train, 330 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.885, 0.89]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1536, 5, 11)\n",
            "Flattened training data shape: (1536, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8815, Train Loss: 0.0837, Val Acc: 0.9000, Val Loss: 0.0702\n",
            "Restored LSTM model from best epoch 14 with val_loss: 0.070191\n",
            "NFL LSTM model 178/201 completed\n",
            "Using provided test data as validation: 1584 train, 335 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.89, 0.895]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1584, 5, 11)\n",
            "Flattened training data shape: (1584, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8782, Train Loss: 0.0918, Val Acc: 0.8806, Val Loss: 0.0854\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.085408\n",
            "NFL LSTM model 179/201 completed\n",
            "Using provided test data as validation: 1562 train, 340 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.895, 0.9]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1562, 5, 11)\n",
            "Flattened training data shape: (1562, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8905, Train Loss: 0.0879, Val Acc: 0.8912, Val Loss: 0.0756\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.075579\n",
            "NFL LSTM model 180/201 completed\n",
            "Using provided test data as validation: 1553 train, 331 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.9, 0.905]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1553, 5, 11)\n",
            "Flattened training data shape: (1553, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.8577, Train Loss: 0.1067, Val Acc: 0.8520, Val Loss: 0.0955\n",
            "Restored LSTM model from best epoch 4 with val_loss: 0.095543\n",
            "NFL LSTM model 181/201 completed\n",
            "Using provided test data as validation: 1564 train, 330 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.905, 0.91]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1564, 5, 11)\n",
            "Flattened training data shape: (1564, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8817, Train Loss: 0.0887, Val Acc: 0.8667, Val Loss: 0.0831\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.083051\n",
            "NFL LSTM model 182/201 completed\n",
            "Using provided test data as validation: 1572 train, 346 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.91, 0.915]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1572, 5, 11)\n",
            "Flattened training data shape: (1572, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8849, Train Loss: 0.0889, Val Acc: 0.8613, Val Loss: 0.0891\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.089079\n",
            "NFL LSTM model 183/201 completed\n",
            "Using provided test data as validation: 1593 train, 352 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.915, 0.92]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1593, 5, 11)\n",
            "Flattened training data shape: (1593, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8895, Train Loss: 0.0841, Val Acc: 0.8920, Val Loss: 0.0762\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.076180\n",
            "NFL LSTM model 184/201 completed\n",
            "Using provided test data as validation: 1678 train, 363 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.92, 0.925]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1678, 5, 11)\n",
            "Flattened training data shape: (1678, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8903, Train Loss: 0.0858, Val Acc: 0.8898, Val Loss: 0.0751\n",
            "Restored LSTM model from best epoch 8 with val_loss: 0.075122\n",
            "NFL LSTM model 185/201 completed\n",
            "Using provided test data as validation: 1704 train, 396 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.925, 0.93]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1704, 5, 11)\n",
            "Flattened training data shape: (1704, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.9131, Train Loss: 0.0667, Val Acc: 0.8864, Val Loss: 0.0719\n",
            "Restored LSTM model from best epoch 24 with val_loss: 0.071927\n",
            "NFL LSTM model 186/201 completed\n",
            "Using provided test data as validation: 1747 train, 413 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.93, 0.935]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1747, 5, 11)\n",
            "Flattened training data shape: (1747, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.9084, Train Loss: 0.0687, Val Acc: 0.8862, Val Loss: 0.0816\n",
            "Restored LSTM model from best epoch 13 with val_loss: 0.081588\n",
            "NFL LSTM model 187/201 completed\n",
            "Using provided test data as validation: 1864 train, 363 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.935, 0.94]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1864, 5, 11)\n",
            "Flattened training data shape: (1864, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.9018, Train Loss: 0.0786, Val Acc: 0.8926, Val Loss: 0.0747\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.074654\n",
            "NFL LSTM model 188/201 completed\n",
            "Using provided test data as validation: 1941 train, 437 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.94, 0.945]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1941, 5, 11)\n",
            "Flattened training data shape: (1941, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.9083, Train Loss: 0.0697, Val Acc: 0.9153, Val Loss: 0.0685\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.068471\n",
            "NFL LSTM model 189/201 completed\n",
            "Using provided test data as validation: 1972 train, 446 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.945, 0.95]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1972, 5, 11)\n",
            "Flattened training data shape: (1972, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.9189, Train Loss: 0.0666, Val Acc: 0.9126, Val Loss: 0.0610\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.060952\n",
            "NFL LSTM model 190/201 completed\n",
            "Using provided test data as validation: 2011 train, 434 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.95, 0.955]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2011, 5, 11)\n",
            "Flattened training data shape: (2011, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.9170, Train Loss: 0.0652, Val Acc: 0.8779, Val Loss: 0.0766\n",
            "Restored LSTM model from best epoch 19 with val_loss: 0.076588\n",
            "NFL LSTM model 191/201 completed\n",
            "Using provided test data as validation: 1968 train, 413 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.955, 0.96]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1968, 5, 11)\n",
            "Flattened training data shape: (1968, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.9131, Train Loss: 0.0660, Val Acc: 0.9201, Val Loss: 0.0618\n",
            "Restored LSTM model from best epoch 19 with val_loss: 0.061840\n",
            "NFL LSTM model 192/201 completed\n",
            "Using provided test data as validation: 2040 train, 480 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.96, 0.965]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2040, 5, 11)\n",
            "Flattened training data shape: (2040, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.9162, Train Loss: 0.0629, Val Acc: 0.9104, Val Loss: 0.0622\n",
            "Restored LSTM model from best epoch 21 with val_loss: 0.062245\n",
            "NFL LSTM model 193/201 completed\n",
            "Using provided test data as validation: 2016 train, 439 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.965, 0.97]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2016, 5, 11)\n",
            "Flattened training data shape: (2016, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.9236, Train Loss: 0.0597, Val Acc: 0.8998, Val Loss: 0.0713\n",
            "Restored LSTM model from best epoch 14 with val_loss: 0.071264\n",
            "NFL LSTM model 194/201 completed\n",
            "Using provided test data as validation: 4127 train, 885 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.97, 0.975]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (4127, 5, 11)\n",
            "Flattened training data shape: (4127, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.9232, Train Loss: 0.0594, Val Acc: 0.9096, Val Loss: 0.0678\n",
            "Restored LSTM model from best epoch 19 with val_loss: 0.067805\n",
            "NFL LSTM model 195/201 completed\n",
            "Using provided test data as validation: 2114 train, 414 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.975, 0.98]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2114, 5, 11)\n",
            "Flattened training data shape: (2114, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.9314, Train Loss: 0.0572, Val Acc: 0.8986, Val Loss: 0.0768\n",
            "Restored LSTM model from best epoch 19 with val_loss: 0.076833\n",
            "NFL LSTM model 196/201 completed\n",
            "Using provided test data as validation: 1954 train, 441 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.98, 0.985]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1954, 5, 11)\n",
            "Flattened training data shape: (1954, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.9263, Train Loss: 0.0586, Val Acc: 0.8889, Val Loss: 0.0728\n",
            "Restored LSTM model from best epoch 17 with val_loss: 0.072756\n",
            "NFL LSTM model 197/201 completed\n",
            "Using provided test data as validation: 2042 train, 491 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.985, 0.99]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2042, 5, 11)\n",
            "Flattened training data shape: (2042, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.9265, Train Loss: 0.0559, Val Acc: 0.9206, Val Loss: 0.0591\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.059059\n",
            "NFL LSTM model 198/201 completed\n",
            "Using provided test data as validation: 1982 train, 447 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.99, 0.995]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1982, 5, 11)\n",
            "Flattened training data shape: (1982, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.9334, Train Loss: 0.0521, Val Acc: 0.9060, Val Loss: 0.0719\n",
            "Restored LSTM model from best epoch 18 with val_loss: 0.071911\n",
            "NFL LSTM model 199/201 completed\n",
            "Using provided test data as validation: 2120 train, 519 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.995, 1.0]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2120, 5, 11)\n",
            "Flattened training data shape: (2120, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.9297, Train Loss: 0.0566, Val Acc: 0.8863, Val Loss: 0.0758\n",
            "Restored LSTM model from best epoch 9 with val_loss: 0.075822\n",
            "NFL LSTM model 200/201 completed\n",
            "Using provided test data as validation: 2697 train, 576 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [1.0, 1.005]\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2697, 5, 11)\n",
            "Flattened training data shape: (2697, 55)\n",
            "Scaler fitted with 55 features\n",
            "Starting LSTM training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.9429, Train Loss: 0.0479, Val Acc: 0.8993, Val Loss: 0.0676\n",
            "Restored LSTM model from best epoch 7 with val_loss: 0.067609\n",
            "NFL LSTM model 201/201 completed\n",
            "Original data shape: (1949, 11)\n",
            "Flattened data shape: (1949, 11)\n",
            "Using provided test data as validation: 1949 train, 412 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.0, 0.005]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1949, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6609, Train Loss: 0.2153, Val Acc: 0.6214, Val Loss: 0.2282\n",
            "Restored model from best epoch 6 with val_loss: 0.228191\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.0-0.005_ep6_valAcc0.6214_valLoss0.2282.pth\n",
            "NFL direct model 1/201 completed\n",
            "Original data shape: (1448, 11)\n",
            "Flattened data shape: (1448, 11)\n",
            "Using provided test data as validation: 1448 train, 308 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.005, 0.01]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1448, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6609, Train Loss: 0.2180, Val Acc: 0.5747, Val Loss: 0.2390\n",
            "Restored model from best epoch 6 with val_loss: 0.238972\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.005-0.01_ep6_valAcc0.5747_valLoss0.2390.pth\n",
            "NFL direct model 2/201 completed\n",
            "Original data shape: (1303, 11)\n",
            "Flattened data shape: (1303, 11)\n",
            "Using provided test data as validation: 1303 train, 282 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.01, 0.015]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1303, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6332, Train Loss: 0.2230, Val Acc: 0.6099, Val Loss: 0.2279\n",
            "Restored model from best epoch 4 with val_loss: 0.227914\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.01-0.015_ep4_valAcc0.6099_valLoss0.2279.pth\n",
            "NFL direct model 3/201 completed\n",
            "Original data shape: (1411, 11)\n",
            "Flattened data shape: (1411, 11)\n",
            "Using provided test data as validation: 1411 train, 310 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.015, 0.02]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1411, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.6208, Train Loss: 0.2281, Val Acc: 0.5871, Val Loss: 0.2343\n",
            "Restored model from best epoch 2 with val_loss: 0.234344\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.015-0.02_ep2_valAcc0.5871_valLoss0.2343.pth\n",
            "NFL direct model 4/201 completed\n",
            "Original data shape: (1337, 11)\n",
            "Flattened data shape: (1337, 11)\n",
            "Using provided test data as validation: 1337 train, 297 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.02, 0.025]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1337, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.6619, Train Loss: 0.2171, Val Acc: 0.6094, Val Loss: 0.2295\n",
            "Restored model from best epoch 5 with val_loss: 0.229457\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.02-0.025_ep5_valAcc0.6094_valLoss0.2295.pth\n",
            "NFL direct model 5/201 completed\n",
            "Original data shape: (1464, 11)\n",
            "Flattened data shape: (1464, 11)\n",
            "Using provided test data as validation: 1464 train, 306 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.025, 0.03]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1464, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6544, Train Loss: 0.2221, Val Acc: 0.6209, Val Loss: 0.2249\n",
            "Restored model from best epoch 4 with val_loss: 0.224930\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.025-0.03_ep4_valAcc0.6209_valLoss0.2249.pth\n",
            "NFL direct model 6/201 completed\n",
            "Original data shape: (1429, 11)\n",
            "Flattened data shape: (1429, 11)\n",
            "Using provided test data as validation: 1429 train, 307 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.03, 0.035]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1429, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6627, Train Loss: 0.2177, Val Acc: 0.6026, Val Loss: 0.2293\n",
            "Restored model from best epoch 3 with val_loss: 0.229251\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.03-0.035_ep3_valAcc0.6026_valLoss0.2293.pth\n",
            "NFL direct model 7/201 completed\n",
            "Original data shape: (1423, 11)\n",
            "Flattened data shape: (1423, 11)\n",
            "Using provided test data as validation: 1423 train, 315 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.035, 0.04]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1423, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.6739, Train Loss: 0.2140, Val Acc: 0.5937, Val Loss: 0.2395\n",
            "Restored model from best epoch 12 with val_loss: 0.239519\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.035-0.04_ep12_valAcc0.5937_valLoss0.2395.pth\n",
            "NFL direct model 8/201 completed\n",
            "Original data shape: (1444, 11)\n",
            "Flattened data shape: (1444, 11)\n",
            "Using provided test data as validation: 1444 train, 321 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.04, 0.045]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1444, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.6738, Train Loss: 0.2155, Val Acc: 0.6106, Val Loss: 0.2374\n",
            "Restored model from best epoch 8 with val_loss: 0.237429\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.04-0.045_ep8_valAcc0.6106_valLoss0.2374.pth\n",
            "NFL direct model 9/201 completed\n",
            "Original data shape: (1451, 11)\n",
            "Flattened data shape: (1451, 11)\n",
            "Using provided test data as validation: 1451 train, 320 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.045, 0.05]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1451, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6657, Train Loss: 0.2152, Val Acc: 0.6188, Val Loss: 0.2336\n",
            "Restored model from best epoch 7 with val_loss: 0.233634\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.045-0.05_ep7_valAcc0.6188_valLoss0.2336.pth\n",
            "NFL direct model 10/201 completed\n",
            "Original data shape: (1456, 11)\n",
            "Flattened data shape: (1456, 11)\n",
            "Using provided test data as validation: 1456 train, 314 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.05, 0.055]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1456, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.6820, Train Loss: 0.2119, Val Acc: 0.6306, Val Loss: 0.2280\n",
            "Restored model from best epoch 8 with val_loss: 0.228023\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.05-0.055_ep8_valAcc0.6306_valLoss0.2280.pth\n",
            "NFL direct model 11/201 completed\n",
            "Original data shape: (1488, 11)\n",
            "Flattened data shape: (1488, 11)\n",
            "Using provided test data as validation: 1488 train, 334 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.055, 0.06]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1488, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6653, Train Loss: 0.2186, Val Acc: 0.6407, Val Loss: 0.2132\n",
            "Restored model from best epoch 6 with val_loss: 0.213199\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.055-0.06_ep6_valAcc0.6407_valLoss0.2132.pth\n",
            "NFL direct model 12/201 completed\n",
            "Original data shape: (1465, 11)\n",
            "Flattened data shape: (1465, 11)\n",
            "Using provided test data as validation: 1465 train, 317 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.06, 0.065]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1465, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6840, Train Loss: 0.2091, Val Acc: 0.6183, Val Loss: 0.2326\n",
            "Restored model from best epoch 7 with val_loss: 0.232633\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.06-0.065_ep7_valAcc0.6183_valLoss0.2326.pth\n",
            "NFL direct model 13/201 completed\n",
            "Original data shape: (1501, 11)\n",
            "Flattened data shape: (1501, 11)\n",
            "Using provided test data as validation: 1501 train, 322 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.065, 0.07]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1501, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.5803, Train Loss: 0.2388, Val Acc: 0.5621, Val Loss: 0.2485\n",
            "Restored model from best epoch 1 with val_loss: 0.248483\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.065-0.07_ep1_valAcc0.5621_valLoss0.2485.pth\n",
            "NFL direct model 14/201 completed\n",
            "Original data shape: (1471, 11)\n",
            "Flattened data shape: (1471, 11)\n",
            "Using provided test data as validation: 1471 train, 339 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.07, 0.075]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1471, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6900, Train Loss: 0.2094, Val Acc: 0.6136, Val Loss: 0.2265\n",
            "Restored model from best epoch 6 with val_loss: 0.226532\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.07-0.075_ep6_valAcc0.6136_valLoss0.2265.pth\n",
            "NFL direct model 15/201 completed\n",
            "Original data shape: (1507, 11)\n",
            "Flattened data shape: (1507, 11)\n",
            "Using provided test data as validation: 1507 train, 323 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.075, 0.08]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1507, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6603, Train Loss: 0.2235, Val Acc: 0.6285, Val Loss: 0.2223\n",
            "Restored model from best epoch 4 with val_loss: 0.222309\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.075-0.08_ep4_valAcc0.6285_valLoss0.2223.pth\n",
            "NFL direct model 16/201 completed\n",
            "Original data shape: (1512, 11)\n",
            "Flattened data shape: (1512, 11)\n",
            "Using provided test data as validation: 1512 train, 314 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.08, 0.085]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1512, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6739, Train Loss: 0.2204, Val Acc: 0.6115, Val Loss: 0.2311\n",
            "Restored model from best epoch 4 with val_loss: 0.231065\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.08-0.085_ep4_valAcc0.6115_valLoss0.2311.pth\n",
            "NFL direct model 17/201 completed\n",
            "Original data shape: (1458, 11)\n",
            "Flattened data shape: (1458, 11)\n",
            "Using provided test data as validation: 1458 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.085, 0.09]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1458, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.6310, Train Loss: 0.2353, Val Acc: 0.6132, Val Loss: 0.2350\n",
            "Restored model from best epoch 2 with val_loss: 0.235018\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.085-0.09_ep2_valAcc0.6132_valLoss0.2350.pth\n",
            "NFL direct model 18/201 completed\n",
            "Original data shape: (1541, 11)\n",
            "Flattened data shape: (1541, 11)\n",
            "Using provided test data as validation: 1541 train, 330 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.09, 0.095]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1541, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.6801, Train Loss: 0.2099, Val Acc: 0.6182, Val Loss: 0.2233\n",
            "Restored model from best epoch 8 with val_loss: 0.223324\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.09-0.095_ep8_valAcc0.6182_valLoss0.2233.pth\n",
            "NFL direct model 19/201 completed\n",
            "Original data shape: (1512, 11)\n",
            "Flattened data shape: (1512, 11)\n",
            "Using provided test data as validation: 1512 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.095, 0.1]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1512, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6925, Train Loss: 0.2077, Val Acc: 0.6321, Val Loss: 0.2323\n",
            "Restored model from best epoch 7 with val_loss: 0.232345\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.095-0.1_ep7_valAcc0.6321_valLoss0.2323.pth\n",
            "NFL direct model 20/201 completed\n",
            "Original data shape: (1557, 11)\n",
            "Flattened data shape: (1557, 11)\n",
            "Using provided test data as validation: 1557 train, 320 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.1, 0.105]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1557, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6776, Train Loss: 0.2165, Val Acc: 0.6344, Val Loss: 0.2310\n",
            "Restored model from best epoch 4 with val_loss: 0.231002\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.1-0.105_ep4_valAcc0.6344_valLoss0.2310.pth\n",
            "NFL direct model 21/201 completed\n",
            "Original data shape: (1521, 11)\n",
            "Flattened data shape: (1521, 11)\n",
            "Using provided test data as validation: 1521 train, 309 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.105, 0.11]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1521, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6726, Train Loss: 0.2063, Val Acc: 0.6570, Val Loss: 0.2180\n",
            "Restored model from best epoch 4 with val_loss: 0.218022\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.105-0.11_ep4_valAcc0.6570_valLoss0.2180.pth\n",
            "NFL direct model 22/201 completed\n",
            "Original data shape: (1487, 11)\n",
            "Flattened data shape: (1487, 11)\n",
            "Using provided test data as validation: 1487 train, 337 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.11, 0.115]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1487, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6617, Train Loss: 0.2247, Val Acc: 0.6142, Val Loss: 0.2290\n",
            "Restored model from best epoch 3 with val_loss: 0.229044\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.11-0.115_ep3_valAcc0.6142_valLoss0.2290.pth\n",
            "NFL direct model 23/201 completed\n",
            "Original data shape: (1521, 11)\n",
            "Flattened data shape: (1521, 11)\n",
            "Using provided test data as validation: 1521 train, 342 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.115, 0.12]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1521, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6634, Train Loss: 0.2170, Val Acc: 0.6345, Val Loss: 0.2140\n",
            "Restored model from best epoch 3 with val_loss: 0.213997\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.115-0.12_ep3_valAcc0.6345_valLoss0.2140.pth\n",
            "NFL direct model 24/201 completed\n",
            "Original data shape: (1468, 11)\n",
            "Flattened data shape: (1468, 11)\n",
            "Using provided test data as validation: 1468 train, 313 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.12, 0.125]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1468, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6751, Train Loss: 0.2137, Val Acc: 0.6613, Val Loss: 0.2175\n",
            "Restored model from best epoch 3 with val_loss: 0.217517\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.12-0.125_ep3_valAcc0.6613_valLoss0.2175.pth\n",
            "NFL direct model 25/201 completed\n",
            "Original data shape: (1481, 11)\n",
            "Flattened data shape: (1481, 11)\n",
            "Using provided test data as validation: 1481 train, 331 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.125, 0.13]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1481, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.6604, Train Loss: 0.2116, Val Acc: 0.6375, Val Loss: 0.2150\n",
            "Restored model from best epoch 2 with val_loss: 0.214993\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.125-0.13_ep2_valAcc0.6375_valLoss0.2150.pth\n",
            "NFL direct model 26/201 completed\n",
            "Original data shape: (1516, 11)\n",
            "Flattened data shape: (1516, 11)\n",
            "Using provided test data as validation: 1516 train, 310 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.13, 0.135]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1516, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.6979, Train Loss: 0.1968, Val Acc: 0.6516, Val Loss: 0.2189\n",
            "Restored model from best epoch 14 with val_loss: 0.218923\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.13-0.135_ep14_valAcc0.6516_valLoss0.2189.pth\n",
            "NFL direct model 27/201 completed\n",
            "Original data shape: (1495, 11)\n",
            "Flattened data shape: (1495, 11)\n",
            "Using provided test data as validation: 1495 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.135, 0.14]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7130, Train Loss: 0.1979, Val Acc: 0.6509, Val Loss: 0.2193\n",
            "Restored model from best epoch 12 with val_loss: 0.219318\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.135-0.14_ep12_valAcc0.6509_valLoss0.2193.pth\n",
            "NFL direct model 28/201 completed\n",
            "Original data shape: (1473, 11)\n",
            "Flattened data shape: (1473, 11)\n",
            "Using provided test data as validation: 1473 train, 321 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.14, 0.145]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1473, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.7074, Train Loss: 0.1858, Val Acc: 0.6480, Val Loss: 0.1996\n",
            "Restored model from best epoch 13 with val_loss: 0.199588\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.14-0.145_ep13_valAcc0.6480_valLoss0.1996.pth\n",
            "NFL direct model 29/201 completed\n",
            "Original data shape: (1477, 11)\n",
            "Flattened data shape: (1477, 11)\n",
            "Using provided test data as validation: 1477 train, 310 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.145, 0.15]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1477, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7346, Train Loss: 0.1871, Val Acc: 0.6742, Val Loss: 0.2149\n",
            "Restored model from best epoch 11 with val_loss: 0.214912\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.145-0.15_ep11_valAcc0.6742_valLoss0.2149.pth\n",
            "NFL direct model 30/201 completed\n",
            "Original data shape: (1524, 11)\n",
            "Flattened data shape: (1524, 11)\n",
            "Using provided test data as validation: 1524 train, 349 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.15, 0.155]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1524, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6929, Train Loss: 0.2095, Val Acc: 0.6418, Val Loss: 0.2188\n",
            "Restored model from best epoch 4 with val_loss: 0.218762\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.15-0.155_ep4_valAcc0.6418_valLoss0.2188.pth\n",
            "NFL direct model 31/201 completed\n",
            "Original data shape: (1495, 11)\n",
            "Flattened data shape: (1495, 11)\n",
            "Using provided test data as validation: 1495 train, 316 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.155, 0.16]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7050, Train Loss: 0.1945, Val Acc: 0.6487, Val Loss: 0.2189\n",
            "Restored model from best epoch 7 with val_loss: 0.218893\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.155-0.16_ep7_valAcc0.6487_valLoss0.2189.pth\n",
            "NFL direct model 32/201 completed\n",
            "Original data shape: (1479, 11)\n",
            "Flattened data shape: (1479, 11)\n",
            "Using provided test data as validation: 1479 train, 309 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.16, 0.165]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1479, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6856, Train Loss: 0.2067, Val Acc: 0.6408, Val Loss: 0.2260\n",
            "Restored model from best epoch 3 with val_loss: 0.226043\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.16-0.165_ep3_valAcc0.6408_valLoss0.2260.pth\n",
            "NFL direct model 33/201 completed\n",
            "Original data shape: (1525, 11)\n",
            "Flattened data shape: (1525, 11)\n",
            "Using provided test data as validation: 1525 train, 339 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.165, 0.17]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1525, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6695, Train Loss: 0.2154, Val Acc: 0.6431, Val Loss: 0.2104\n",
            "Restored model from best epoch 3 with val_loss: 0.210435\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.165-0.17_ep3_valAcc0.6431_valLoss0.2104.pth\n",
            "NFL direct model 34/201 completed\n",
            "Original data shape: (1500, 11)\n",
            "Flattened data shape: (1500, 11)\n",
            "Using provided test data as validation: 1500 train, 309 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.17, 0.175]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1500, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7307, Train Loss: 0.1860, Val Acc: 0.6764, Val Loss: 0.2106\n",
            "Restored model from best epoch 17 with val_loss: 0.210572\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.17-0.175_ep17_valAcc0.6764_valLoss0.2106.pth\n",
            "NFL direct model 35/201 completed\n",
            "Original data shape: (1523, 11)\n",
            "Flattened data shape: (1523, 11)\n",
            "Using provided test data as validation: 1523 train, 321 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.175, 0.18]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1523, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6671, Train Loss: 0.2145, Val Acc: 0.6667, Val Loss: 0.2189\n",
            "Restored model from best epoch 3 with val_loss: 0.218916\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.175-0.18_ep3_valAcc0.6667_valLoss0.2189.pth\n",
            "NFL direct model 36/201 completed\n",
            "Original data shape: (1506, 11)\n",
            "Flattened data shape: (1506, 11)\n",
            "Using provided test data as validation: 1506 train, 330 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.18, 0.185]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1506, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6992, Train Loss: 0.2029, Val Acc: 0.6303, Val Loss: 0.2125\n",
            "Restored model from best epoch 6 with val_loss: 0.212546\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.18-0.185_ep6_valAcc0.6303_valLoss0.2125.pth\n",
            "NFL direct model 37/201 completed\n",
            "Original data shape: (1476, 11)\n",
            "Flattened data shape: (1476, 11)\n",
            "Using provided test data as validation: 1476 train, 320 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.185, 0.19]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1476, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7236, Train Loss: 0.1859, Val Acc: 0.6562, Val Loss: 0.2179\n",
            "Restored model from best epoch 7 with val_loss: 0.217856\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.185-0.19_ep7_valAcc0.6562_valLoss0.2179.pth\n",
            "NFL direct model 38/201 completed\n",
            "Original data shape: (1508, 11)\n",
            "Flattened data shape: (1508, 11)\n",
            "Using provided test data as validation: 1508 train, 329 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.19, 0.195]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1508, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6837, Train Loss: 0.2041, Val Acc: 0.6261, Val Loss: 0.2268\n",
            "Restored model from best epoch 7 with val_loss: 0.226832\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.19-0.195_ep7_valAcc0.6261_valLoss0.2268.pth\n",
            "NFL direct model 39/201 completed\n",
            "Original data shape: (1437, 11)\n",
            "Flattened data shape: (1437, 11)\n",
            "Using provided test data as validation: 1437 train, 320 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.195, 0.2]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1437, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7015, Train Loss: 0.1943, Val Acc: 0.6813, Val Loss: 0.2046\n",
            "Restored model from best epoch 5 with val_loss: 0.204563\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.195-0.2_ep5_valAcc0.6813_valLoss0.2046.pth\n",
            "NFL direct model 40/201 completed\n",
            "Original data shape: (1522, 11)\n",
            "Flattened data shape: (1522, 11)\n",
            "Using provided test data as validation: 1522 train, 343 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.2, 0.205]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1522, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7096, Train Loss: 0.1972, Val Acc: 0.6851, Val Loss: 0.1995\n",
            "Restored model from best epoch 5 with val_loss: 0.199511\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.2-0.205_ep5_valAcc0.6851_valLoss0.1995.pth\n",
            "NFL direct model 41/201 completed\n",
            "Original data shape: (1483, 11)\n",
            "Flattened data shape: (1483, 11)\n",
            "Using provided test data as validation: 1483 train, 348 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.205, 0.21]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1483, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6891, Train Loss: 0.1972, Val Acc: 0.6897, Val Loss: 0.2014\n",
            "Restored model from best epoch 3 with val_loss: 0.201404\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.205-0.21_ep3_valAcc0.6897_valLoss0.2014.pth\n",
            "NFL direct model 42/201 completed\n",
            "Original data shape: (1495, 11)\n",
            "Flattened data shape: (1495, 11)\n",
            "Using provided test data as validation: 1495 train, 323 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.21, 0.215]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7151, Train Loss: 0.1947, Val Acc: 0.6718, Val Loss: 0.1929\n",
            "Restored model from best epoch 9 with val_loss: 0.192907\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.21-0.215_ep9_valAcc0.6718_valLoss0.1929.pth\n",
            "NFL direct model 43/201 completed\n",
            "Original data shape: (1519, 11)\n",
            "Flattened data shape: (1519, 11)\n",
            "Using provided test data as validation: 1519 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.215, 0.22]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1519, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7110, Train Loss: 0.1928, Val Acc: 0.6792, Val Loss: 0.2059\n",
            "Restored model from best epoch 5 with val_loss: 0.205893\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.215-0.22_ep5_valAcc0.6792_valLoss0.2059.pth\n",
            "NFL direct model 44/201 completed\n",
            "Original data shape: (1481, 11)\n",
            "Flattened data shape: (1481, 11)\n",
            "Using provided test data as validation: 1481 train, 322 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.22, 0.225]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1481, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7191, Train Loss: 0.1968, Val Acc: 0.6801, Val Loss: 0.1918\n",
            "Restored model from best epoch 5 with val_loss: 0.191799\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.22-0.225_ep5_valAcc0.6801_valLoss0.1918.pth\n",
            "NFL direct model 45/201 completed\n",
            "Original data shape: (1559, 11)\n",
            "Flattened data shape: (1559, 11)\n",
            "Using provided test data as validation: 1559 train, 333 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.225, 0.23]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1559, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7197, Train Loss: 0.1925, Val Acc: 0.7027, Val Loss: 0.1948\n",
            "Restored model from best epoch 5 with val_loss: 0.194797\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.225-0.23_ep5_valAcc0.7027_valLoss0.1948.pth\n",
            "NFL direct model 46/201 completed\n",
            "Original data shape: (1488, 11)\n",
            "Flattened data shape: (1488, 11)\n",
            "Using provided test data as validation: 1488 train, 316 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.23, 0.235]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1488, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7097, Train Loss: 0.1897, Val Acc: 0.6835, Val Loss: 0.2128\n",
            "Restored model from best epoch 5 with val_loss: 0.212797\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.23-0.235_ep5_valAcc0.6835_valLoss0.2128.pth\n",
            "NFL direct model 47/201 completed\n",
            "Original data shape: (1470, 11)\n",
            "Flattened data shape: (1470, 11)\n",
            "Using provided test data as validation: 1470 train, 309 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.235, 0.24]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1470, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7252, Train Loss: 0.1929, Val Acc: 0.6828, Val Loss: 0.1977\n",
            "Restored model from best epoch 4 with val_loss: 0.197734\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.235-0.24_ep4_valAcc0.6828_valLoss0.1977.pth\n",
            "NFL direct model 48/201 completed\n",
            "Original data shape: (1563, 11)\n",
            "Flattened data shape: (1563, 11)\n",
            "Using provided test data as validation: 1563 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.24, 0.245]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1563, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.7364, Train Loss: 0.1816, Val Acc: 0.6667, Val Loss: 0.1923\n",
            "Restored model from best epoch 15 with val_loss: 0.192299\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.24-0.245_ep15_valAcc0.6667_valLoss0.1923.pth\n",
            "NFL direct model 49/201 completed\n",
            "Original data shape: (1510, 11)\n",
            "Flattened data shape: (1510, 11)\n",
            "Using provided test data as validation: 1510 train, 319 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.245, 0.25]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1510, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6927, Train Loss: 0.2006, Val Acc: 0.6834, Val Loss: 0.2023\n",
            "Restored model from best epoch 3 with val_loss: 0.202268\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.245-0.25_ep3_valAcc0.6834_valLoss0.2023.pth\n",
            "NFL direct model 50/201 completed\n",
            "Original data shape: (3315, 11)\n",
            "Flattened data shape: (3315, 11)\n",
            "Using provided test data as validation: 3315 train, 657 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.25, 0.255]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3315, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.6217, Train Loss: 0.2280, Val Acc: 0.6773, Val Loss: 0.2039\n",
            "Restored model from best epoch 1 with val_loss: 0.203884\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.25-0.255_ep1_valAcc0.6773_valLoss0.2039.pth\n",
            "NFL direct model 51/201 completed\n",
            "Original data shape: (1671, 11)\n",
            "Flattened data shape: (1671, 11)\n",
            "Using provided test data as validation: 1671 train, 356 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.255, 0.26]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1671, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7062, Train Loss: 0.1931, Val Acc: 0.6994, Val Loss: 0.1874\n",
            "Restored model from best epoch 5 with val_loss: 0.187398\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.255-0.26_ep5_valAcc0.6994_valLoss0.1874.pth\n",
            "NFL direct model 52/201 completed\n",
            "Original data shape: (1333, 11)\n",
            "Flattened data shape: (1333, 11)\n",
            "Using provided test data as validation: 1333 train, 283 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.26, 0.265]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1333, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7112, Train Loss: 0.1950, Val Acc: 0.6926, Val Loss: 0.1937\n",
            "Restored model from best epoch 6 with val_loss: 0.193700\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.26-0.265_ep6_valAcc0.6926_valLoss0.1937.pth\n",
            "NFL direct model 53/201 completed\n",
            "Original data shape: (1647, 11)\n",
            "Flattened data shape: (1647, 11)\n",
            "Using provided test data as validation: 1647 train, 358 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.265, 0.27]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1647, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7049, Train Loss: 0.1927, Val Acc: 0.6844, Val Loss: 0.1964\n",
            "Restored model from best epoch 3 with val_loss: 0.196385\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.265-0.27_ep3_valAcc0.6844_valLoss0.1964.pth\n",
            "NFL direct model 54/201 completed\n",
            "Original data shape: (1439, 11)\n",
            "Flattened data shape: (1439, 11)\n",
            "Using provided test data as validation: 1439 train, 303 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.27, 0.275]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1439, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7345, Train Loss: 0.1855, Val Acc: 0.6832, Val Loss: 0.2064\n",
            "Restored model from best epoch 7 with val_loss: 0.206446\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.27-0.275_ep7_valAcc0.6832_valLoss0.2064.pth\n",
            "NFL direct model 55/201 completed\n",
            "Original data shape: (1514, 11)\n",
            "Flattened data shape: (1514, 11)\n",
            "Using provided test data as validation: 1514 train, 327 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.275, 0.28]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1514, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7272, Train Loss: 0.1826, Val Acc: 0.6850, Val Loss: 0.1904\n",
            "Restored model from best epoch 7 with val_loss: 0.190448\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.275-0.28_ep7_valAcc0.6850_valLoss0.1904.pth\n",
            "NFL direct model 56/201 completed\n",
            "Original data shape: (1470, 11)\n",
            "Flattened data shape: (1470, 11)\n",
            "Using provided test data as validation: 1470 train, 341 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.28, 0.285]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1470, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7238, Train Loss: 0.1873, Val Acc: 0.6716, Val Loss: 0.1872\n",
            "Restored model from best epoch 7 with val_loss: 0.187186\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.28-0.285_ep7_valAcc0.6716_valLoss0.1872.pth\n",
            "NFL direct model 57/201 completed\n",
            "Original data shape: (1495, 11)\n",
            "Flattened data shape: (1495, 11)\n",
            "Using provided test data as validation: 1495 train, 325 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.285, 0.29]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7338, Train Loss: 0.1850, Val Acc: 0.6892, Val Loss: 0.1923\n",
            "Restored model from best epoch 5 with val_loss: 0.192297\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.285-0.29_ep5_valAcc0.6892_valLoss0.1923.pth\n",
            "NFL direct model 58/201 completed\n",
            "Original data shape: (1510, 11)\n",
            "Flattened data shape: (1510, 11)\n",
            "Using provided test data as validation: 1510 train, 333 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.29, 0.295]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1510, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7146, Train Loss: 0.1894, Val Acc: 0.6637, Val Loss: 0.2055\n",
            "Restored model from best epoch 4 with val_loss: 0.205543\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.29-0.295_ep4_valAcc0.6637_valLoss0.2055.pth\n",
            "NFL direct model 59/201 completed\n",
            "Original data shape: (1461, 11)\n",
            "Flattened data shape: (1461, 11)\n",
            "Using provided test data as validation: 1461 train, 319 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.295, 0.3]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1461, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7262, Train Loss: 0.1909, Val Acc: 0.6771, Val Loss: 0.2026\n",
            "Restored model from best epoch 4 with val_loss: 0.202650\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.295-0.3_ep4_valAcc0.6771_valLoss0.2026.pth\n",
            "NFL direct model 60/201 completed\n",
            "Original data shape: (1529, 11)\n",
            "Flattened data shape: (1529, 11)\n",
            "Using provided test data as validation: 1529 train, 310 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.3, 0.305]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1529, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7103, Train Loss: 0.1917, Val Acc: 0.7290, Val Loss: 0.1890\n",
            "Restored model from best epoch 4 with val_loss: 0.189026\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.3-0.305_ep4_valAcc0.7290_valLoss0.1890.pth\n",
            "NFL direct model 61/201 completed\n",
            "Original data shape: (1533, 11)\n",
            "Flattened data shape: (1533, 11)\n",
            "Using provided test data as validation: 1533 train, 321 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.305, 0.31]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1533, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7117, Train Loss: 0.1918, Val Acc: 0.6916, Val Loss: 0.1924\n",
            "Restored model from best epoch 4 with val_loss: 0.192424\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.305-0.31_ep4_valAcc0.6916_valLoss0.1924.pth\n",
            "NFL direct model 62/201 completed\n",
            "Original data shape: (1477, 11)\n",
            "Flattened data shape: (1477, 11)\n",
            "Using provided test data as validation: 1477 train, 319 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.31, 0.315]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1477, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7360, Train Loss: 0.1869, Val Acc: 0.6771, Val Loss: 0.2113\n",
            "Restored model from best epoch 4 with val_loss: 0.211252\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.31-0.315_ep4_valAcc0.6771_valLoss0.2113.pth\n",
            "NFL direct model 63/201 completed\n",
            "Original data shape: (1559, 11)\n",
            "Flattened data shape: (1559, 11)\n",
            "Using provided test data as validation: 1559 train, 350 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.315, 0.32]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1559, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6979, Train Loss: 0.2007, Val Acc: 0.6629, Val Loss: 0.2016\n",
            "Restored model from best epoch 3 with val_loss: 0.201646\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.315-0.32_ep3_valAcc0.6629_valLoss0.2016.pth\n",
            "NFL direct model 64/201 completed\n",
            "Original data shape: (1472, 11)\n",
            "Flattened data shape: (1472, 11)\n",
            "Using provided test data as validation: 1472 train, 332 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.32, 0.325]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1472, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7303, Train Loss: 0.1823, Val Acc: 0.7349, Val Loss: 0.1730\n",
            "Restored model from best epoch 3 with val_loss: 0.173038\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.32-0.325_ep3_valAcc0.7349_valLoss0.1730.pth\n",
            "NFL direct model 65/201 completed\n",
            "Original data shape: (1520, 11)\n",
            "Flattened data shape: (1520, 11)\n",
            "Using provided test data as validation: 1520 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.325, 0.33]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1520, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7428, Train Loss: 0.1820, Val Acc: 0.7284, Val Loss: 0.1836\n",
            "Restored model from best epoch 4 with val_loss: 0.183606\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.325-0.33_ep4_valAcc0.7284_valLoss0.1836.pth\n",
            "NFL direct model 66/201 completed\n",
            "Original data shape: (1508, 11)\n",
            "Flattened data shape: (1508, 11)\n",
            "Using provided test data as validation: 1508 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.33, 0.335]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1508, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7573, Train Loss: 0.1702, Val Acc: 0.7138, Val Loss: 0.1937\n",
            "Restored model from best epoch 9 with val_loss: 0.193730\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.33-0.335_ep9_valAcc0.7138_valLoss0.1937.pth\n",
            "NFL direct model 67/201 completed\n",
            "Original data shape: (1492, 11)\n",
            "Flattened data shape: (1492, 11)\n",
            "Using provided test data as validation: 1492 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.335, 0.34]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1492, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7460, Train Loss: 0.1821, Val Acc: 0.7654, Val Loss: 0.1534\n",
            "Restored model from best epoch 5 with val_loss: 0.153364\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.335-0.34_ep5_valAcc0.7654_valLoss0.1534.pth\n",
            "NFL direct model 68/201 completed\n",
            "Original data shape: (1504, 11)\n",
            "Flattened data shape: (1504, 11)\n",
            "Using provided test data as validation: 1504 train, 339 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.34, 0.345]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1504, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7473, Train Loss: 0.1737, Val Acc: 0.7788, Val Loss: 0.1589\n",
            "Restored model from best epoch 4 with val_loss: 0.158935\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.34-0.345_ep4_valAcc0.7788_valLoss0.1589.pth\n",
            "NFL direct model 69/201 completed\n",
            "Original data shape: (1522, 11)\n",
            "Flattened data shape: (1522, 11)\n",
            "Using provided test data as validation: 1522 train, 316 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.345, 0.35]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1522, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7576, Train Loss: 0.1679, Val Acc: 0.7152, Val Loss: 0.1850\n",
            "Restored model from best epoch 9 with val_loss: 0.185013\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.345-0.35_ep9_valAcc0.7152_valLoss0.1850.pth\n",
            "NFL direct model 70/201 completed\n",
            "Original data shape: (1553, 11)\n",
            "Flattened data shape: (1553, 11)\n",
            "Using provided test data as validation: 1553 train, 336 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.35, 0.355]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1553, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7572, Train Loss: 0.1666, Val Acc: 0.7649, Val Loss: 0.1709\n",
            "Restored model from best epoch 9 with val_loss: 0.170856\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.35-0.355_ep9_valAcc0.7649_valLoss0.1709.pth\n",
            "NFL direct model 71/201 completed\n",
            "Original data shape: (1534, 11)\n",
            "Flattened data shape: (1534, 11)\n",
            "Using provided test data as validation: 1534 train, 337 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.355, 0.36]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1534, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7295, Train Loss: 0.1795, Val Acc: 0.7181, Val Loss: 0.1862\n",
            "Restored model from best epoch 5 with val_loss: 0.186241\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.355-0.36_ep5_valAcc0.7181_valLoss0.1862.pth\n",
            "NFL direct model 72/201 completed\n",
            "Original data shape: (1470, 11)\n",
            "Flattened data shape: (1470, 11)\n",
            "Using provided test data as validation: 1470 train, 329 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.36, 0.365]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1470, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7279, Train Loss: 0.1811, Val Acc: 0.7234, Val Loss: 0.1866\n",
            "Restored model from best epoch 5 with val_loss: 0.186579\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.36-0.365_ep5_valAcc0.7234_valLoss0.1866.pth\n",
            "NFL direct model 73/201 completed\n",
            "Original data shape: (1520, 11)\n",
            "Flattened data shape: (1520, 11)\n",
            "Using provided test data as validation: 1520 train, 335 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.365, 0.37]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1520, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7520, Train Loss: 0.1724, Val Acc: 0.7313, Val Loss: 0.1642\n",
            "Restored model from best epoch 6 with val_loss: 0.164181\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.365-0.37_ep6_valAcc0.7313_valLoss0.1642.pth\n",
            "NFL direct model 74/201 completed\n",
            "Original data shape: (1478, 11)\n",
            "Flattened data shape: (1478, 11)\n",
            "Using provided test data as validation: 1478 train, 314 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.37, 0.375]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1478, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.7720, Train Loss: 0.1758, Val Acc: 0.7325, Val Loss: 0.1910\n",
            "Restored model from best epoch 20 with val_loss: 0.191040\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.37-0.375_ep20_valAcc0.7325_valLoss0.1910.pth\n",
            "NFL direct model 75/201 completed\n",
            "Original data shape: (1518, 11)\n",
            "Flattened data shape: (1518, 11)\n",
            "Using provided test data as validation: 1518 train, 335 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.375, 0.38]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1518, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7292, Train Loss: 0.1829, Val Acc: 0.7612, Val Loss: 0.1634\n",
            "Restored model from best epoch 4 with val_loss: 0.163377\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.375-0.38_ep4_valAcc0.7612_valLoss0.1634.pth\n",
            "NFL direct model 76/201 completed\n",
            "Original data shape: (1509, 11)\n",
            "Flattened data shape: (1509, 11)\n",
            "Using provided test data as validation: 1509 train, 313 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.38, 0.385]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1509, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7495, Train Loss: 0.1719, Val Acc: 0.7444, Val Loss: 0.1755\n",
            "Restored model from best epoch 6 with val_loss: 0.175520\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.38-0.385_ep6_valAcc0.7444_valLoss0.1755.pth\n",
            "NFL direct model 77/201 completed\n",
            "Original data shape: (1500, 11)\n",
            "Flattened data shape: (1500, 11)\n",
            "Using provided test data as validation: 1500 train, 332 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.385, 0.39]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1500, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7400, Train Loss: 0.1768, Val Acc: 0.7108, Val Loss: 0.1755\n",
            "Restored model from best epoch 5 with val_loss: 0.175548\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.385-0.39_ep5_valAcc0.7108_valLoss0.1755.pth\n",
            "NFL direct model 78/201 completed\n",
            "Original data shape: (1500, 11)\n",
            "Flattened data shape: (1500, 11)\n",
            "Using provided test data as validation: 1500 train, 317 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.39, 0.395]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1500, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7487, Train Loss: 0.1732, Val Acc: 0.7066, Val Loss: 0.1970\n",
            "Restored model from best epoch 9 with val_loss: 0.197020\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.39-0.395_ep9_valAcc0.7066_valLoss0.1970.pth\n",
            "NFL direct model 79/201 completed\n",
            "Original data shape: (1526, 11)\n",
            "Flattened data shape: (1526, 11)\n",
            "Using provided test data as validation: 1526 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.395, 0.4]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1526, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7549, Train Loss: 0.1710, Val Acc: 0.7107, Val Loss: 0.1893\n",
            "Restored model from best epoch 7 with val_loss: 0.189341\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.395-0.4_ep7_valAcc0.7107_valLoss0.1893.pth\n",
            "NFL direct model 80/201 completed\n",
            "Original data shape: (1494, 11)\n",
            "Flattened data shape: (1494, 11)\n",
            "Using provided test data as validation: 1494 train, 344 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.4, 0.405]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1494, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7577, Train Loss: 0.1677, Val Acc: 0.7500, Val Loss: 0.1620\n",
            "Restored model from best epoch 9 with val_loss: 0.162045\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.4-0.405_ep9_valAcc0.7500_valLoss0.1620.pth\n",
            "NFL direct model 81/201 completed\n",
            "Original data shape: (1516, 11)\n",
            "Flattened data shape: (1516, 11)\n",
            "Using provided test data as validation: 1516 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.405, 0.41]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1516, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7269, Train Loss: 0.1766, Val Acc: 0.7390, Val Loss: 0.1760\n",
            "Restored model from best epoch 4 with val_loss: 0.175969\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.405-0.41_ep4_valAcc0.7390_valLoss0.1760.pth\n",
            "NFL direct model 82/201 completed\n",
            "Original data shape: (1493, 11)\n",
            "Flattened data shape: (1493, 11)\n",
            "Using provided test data as validation: 1493 train, 332 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.41, 0.415]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1493, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7749, Train Loss: 0.1561, Val Acc: 0.7470, Val Loss: 0.1699\n",
            "Restored model from best epoch 11 with val_loss: 0.169921\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.41-0.415_ep11_valAcc0.7470_valLoss0.1699.pth\n",
            "NFL direct model 83/201 completed\n",
            "Original data shape: (1539, 11)\n",
            "Flattened data shape: (1539, 11)\n",
            "Using provided test data as validation: 1539 train, 308 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.415, 0.42]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1539, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7719, Train Loss: 0.1594, Val Acc: 0.7013, Val Loss: 0.1984\n",
            "Restored model from best epoch 12 with val_loss: 0.198379\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.415-0.42_ep12_valAcc0.7013_valLoss0.1984.pth\n",
            "NFL direct model 84/201 completed\n",
            "Original data shape: (1499, 11)\n",
            "Flattened data shape: (1499, 11)\n",
            "Using provided test data as validation: 1499 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.42, 0.425]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1499, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7058, Train Loss: 0.2038, Val Acc: 0.7044, Val Loss: 0.1829\n",
            "Restored model from best epoch 2 with val_loss: 0.182883\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.42-0.425_ep2_valAcc0.7044_valLoss0.1829.pth\n",
            "NFL direct model 85/201 completed\n",
            "Original data shape: (1523, 11)\n",
            "Flattened data shape: (1523, 11)\n",
            "Using provided test data as validation: 1523 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.425, 0.43]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1523, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7557, Train Loss: 0.1697, Val Acc: 0.7516, Val Loss: 0.1822\n",
            "Restored model from best epoch 5 with val_loss: 0.182214\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.425-0.43_ep5_valAcc0.7516_valLoss0.1822.pth\n",
            "NFL direct model 86/201 completed\n",
            "Original data shape: (1549, 11)\n",
            "Flattened data shape: (1549, 11)\n",
            "Using provided test data as validation: 1549 train, 346 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.43, 0.435]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1549, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7644, Train Loss: 0.1665, Val Acc: 0.7601, Val Loss: 0.1656\n",
            "Restored model from best epoch 7 with val_loss: 0.165618\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.43-0.435_ep7_valAcc0.7601_valLoss0.1656.pth\n",
            "NFL direct model 87/201 completed\n",
            "Original data shape: (1497, 11)\n",
            "Flattened data shape: (1497, 11)\n",
            "Using provided test data as validation: 1497 train, 317 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.435, 0.44]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1497, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7649, Train Loss: 0.1621, Val Acc: 0.7508, Val Loss: 0.1659\n",
            "Restored model from best epoch 11 with val_loss: 0.165888\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.435-0.44_ep11_valAcc0.7508_valLoss0.1659.pth\n",
            "NFL direct model 88/201 completed\n",
            "Original data shape: (1526, 11)\n",
            "Flattened data shape: (1526, 11)\n",
            "Using provided test data as validation: 1526 train, 329 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.44, 0.445]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1526, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7733, Train Loss: 0.1577, Val Acc: 0.7477, Val Loss: 0.1655\n",
            "Restored model from best epoch 9 with val_loss: 0.165481\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.44-0.445_ep9_valAcc0.7477_valLoss0.1655.pth\n",
            "NFL direct model 89/201 completed\n",
            "Original data shape: (1483, 11)\n",
            "Flattened data shape: (1483, 11)\n",
            "Using provided test data as validation: 1483 train, 337 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.445, 0.45]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1483, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 40\n",
            "Best epoch: 30, Train Acc: 0.7910, Train Loss: 0.1451, Val Acc: 0.7418, Val Loss: 0.1682\n",
            "Restored model from best epoch 30 with val_loss: 0.168250\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.445-0.45_ep30_valAcc0.7418_valLoss0.1682.pth\n",
            "NFL direct model 90/201 completed\n",
            "Original data shape: (1555, 11)\n",
            "Flattened data shape: (1555, 11)\n",
            "Using provided test data as validation: 1555 train, 349 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.45, 0.455]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1555, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7833, Train Loss: 0.1534, Val Acc: 0.7450, Val Loss: 0.1649\n",
            "Restored model from best epoch 16 with val_loss: 0.164914\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.45-0.455_ep16_valAcc0.7450_valLoss0.1649.pth\n",
            "NFL direct model 91/201 completed\n",
            "Original data shape: (1527, 11)\n",
            "Flattened data shape: (1527, 11)\n",
            "Using provided test data as validation: 1527 train, 317 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.455, 0.46]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1527, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7636, Train Loss: 0.1682, Val Acc: 0.7476, Val Loss: 0.1700\n",
            "Restored model from best epoch 5 with val_loss: 0.169968\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.455-0.46_ep5_valAcc0.7476_valLoss0.1700.pth\n",
            "NFL direct model 92/201 completed\n",
            "Original data shape: (1588, 11)\n",
            "Flattened data shape: (1588, 11)\n",
            "Using provided test data as validation: 1588 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.46, 0.465]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1588, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7777, Train Loss: 0.1528, Val Acc: 0.7579, Val Loss: 0.1704\n",
            "Restored model from best epoch 9 with val_loss: 0.170381\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.46-0.465_ep9_valAcc0.7579_valLoss0.1704.pth\n",
            "NFL direct model 93/201 completed\n",
            "Original data shape: (1627, 11)\n",
            "Flattened data shape: (1627, 11)\n",
            "Using provided test data as validation: 1627 train, 346 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.465, 0.47]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1627, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7861, Train Loss: 0.1539, Val Acc: 0.7486, Val Loss: 0.1691\n",
            "Restored model from best epoch 6 with val_loss: 0.169092\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.465-0.47_ep6_valAcc0.7486_valLoss0.1691.pth\n",
            "NFL direct model 94/201 completed\n",
            "Original data shape: (3876, 11)\n",
            "Flattened data shape: (3876, 11)\n",
            "Using provided test data as validation: 3876 train, 880 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.47, 0.475]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3876, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7536, Train Loss: 0.1670, Val Acc: 0.7602, Val Loss: 0.1619\n",
            "Restored model from best epoch 2 with val_loss: 0.161942\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.47-0.475_ep2_valAcc0.7602_valLoss0.1619.pth\n",
            "NFL direct model 95/201 completed\n",
            "Original data shape: (2135, 11)\n",
            "Flattened data shape: (2135, 11)\n",
            "Using provided test data as validation: 2135 train, 503 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.475, 0.48]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2135, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8014, Train Loss: 0.1436, Val Acc: 0.7654, Val Loss: 0.1568\n",
            "Restored model from best epoch 10 with val_loss: 0.156807\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.475-0.48_ep10_valAcc0.7654_valLoss0.1568.pth\n",
            "NFL direct model 96/201 completed\n",
            "Original data shape: (2200, 11)\n",
            "Flattened data shape: (2200, 11)\n",
            "Using provided test data as validation: 2200 train, 454 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.48, 0.485]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2200, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7895, Train Loss: 0.1487, Val Acc: 0.7643, Val Loss: 0.1579\n",
            "Restored model from best epoch 9 with val_loss: 0.157918\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.48-0.485_ep9_valAcc0.7643_valLoss0.1579.pth\n",
            "NFL direct model 97/201 completed\n",
            "Original data shape: (2591, 11)\n",
            "Flattened data shape: (2591, 11)\n",
            "Using provided test data as validation: 2591 train, 649 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.485, 0.49]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2591, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7954, Train Loss: 0.1455, Val Acc: 0.6980, Val Loss: 0.1762\n",
            "Restored model from best epoch 9 with val_loss: 0.176231\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.485-0.49_ep9_valAcc0.6980_valLoss0.1762.pth\n",
            "NFL direct model 98/201 completed\n",
            "Original data shape: (3061, 11)\n",
            "Flattened data shape: (3061, 11)\n",
            "Using provided test data as validation: 3061 train, 634 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.49, 0.495]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3061, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7984, Train Loss: 0.1458, Val Acc: 0.7902, Val Loss: 0.1588\n",
            "Restored model from best epoch 7 with val_loss: 0.158848\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.49-0.495_ep7_valAcc0.7902_valLoss0.1588.pth\n",
            "NFL direct model 99/201 completed\n",
            "Original data shape: (3610, 11)\n",
            "Flattened data shape: (3610, 11)\n",
            "Using provided test data as validation: 3610 train, 872 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.495, 0.5]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3610, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7925, Train Loss: 0.1513, Val Acc: 0.7718, Val Loss: 0.1598\n",
            "Restored model from best epoch 3 with val_loss: 0.159825\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.495-0.5_ep3_valAcc0.7718_valLoss0.1598.pth\n",
            "NFL direct model 100/201 completed\n",
            "Original data shape: (6787, 11)\n",
            "Flattened data shape: (6787, 11)\n",
            "Using provided test data as validation: 6787 train, 1483 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.5, 0.505]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (6787, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8118, Train Loss: 0.1436, Val Acc: 0.7822, Val Loss: 0.1580\n",
            "Restored model from best epoch 4 with val_loss: 0.158000\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.5-0.505_ep4_valAcc0.7822_valLoss0.1580.pth\n",
            "NFL direct model 101/201 completed\n",
            "Original data shape: (1443, 11)\n",
            "Flattened data shape: (1443, 11)\n",
            "Using provided test data as validation: 1443 train, 313 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.505, 0.51]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1443, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8018, Train Loss: 0.1484, Val Acc: 0.8147, Val Loss: 0.1381\n",
            "Restored model from best epoch 6 with val_loss: 0.138111\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.505-0.51_ep6_valAcc0.8147_valLoss0.1381.pth\n",
            "NFL direct model 102/201 completed\n",
            "Original data shape: (1298, 11)\n",
            "Flattened data shape: (1298, 11)\n",
            "Using provided test data as validation: 1298 train, 280 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.51, 0.515]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1298, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8166, Train Loss: 0.1352, Val Acc: 0.8179, Val Loss: 0.1295\n",
            "Restored model from best epoch 12 with val_loss: 0.129497\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.51-0.515_ep12_valAcc0.8179_valLoss0.1295.pth\n",
            "NFL direct model 103/201 completed\n",
            "Original data shape: (1449, 11)\n",
            "Flattened data shape: (1449, 11)\n",
            "Using provided test data as validation: 1449 train, 311 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.515, 0.52]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1449, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8068, Train Loss: 0.1426, Val Acc: 0.8039, Val Loss: 0.1401\n",
            "Restored model from best epoch 8 with val_loss: 0.140084\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.515-0.52_ep8_valAcc0.8039_valLoss0.1401.pth\n",
            "NFL direct model 104/201 completed\n",
            "Original data shape: (1367, 11)\n",
            "Flattened data shape: (1367, 11)\n",
            "Using provided test data as validation: 1367 train, 306 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.52, 0.525]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1367, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.8105, Train Loss: 0.1329, Val Acc: 0.7843, Val Loss: 0.1493\n",
            "Restored model from best epoch 18 with val_loss: 0.149349\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.52-0.525_ep18_valAcc0.7843_valLoss0.1493.pth\n",
            "NFL direct model 105/201 completed\n",
            "Original data shape: (1452, 11)\n",
            "Flattened data shape: (1452, 11)\n",
            "Using provided test data as validation: 1452 train, 308 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.525, 0.53]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1452, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7927, Train Loss: 0.1479, Val Acc: 0.7792, Val Loss: 0.1486\n",
            "Restored model from best epoch 4 with val_loss: 0.148597\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.525-0.53_ep4_valAcc0.7792_valLoss0.1486.pth\n",
            "NFL direct model 106/201 completed\n",
            "Original data shape: (1456, 11)\n",
            "Flattened data shape: (1456, 11)\n",
            "Using provided test data as validation: 1456 train, 300 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.53, 0.535]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1456, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7988, Train Loss: 0.1493, Val Acc: 0.7800, Val Loss: 0.1583\n",
            "Restored model from best epoch 6 with val_loss: 0.158301\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.53-0.535_ep6_valAcc0.7800_valLoss0.1583.pth\n",
            "NFL direct model 107/201 completed\n",
            "Original data shape: (1449, 11)\n",
            "Flattened data shape: (1449, 11)\n",
            "Using provided test data as validation: 1449 train, 306 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.535, 0.54]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1449, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8157, Train Loss: 0.1390, Val Acc: 0.7876, Val Loss: 0.1448\n",
            "Restored model from best epoch 7 with val_loss: 0.144759\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.535-0.54_ep7_valAcc0.7876_valLoss0.1448.pth\n",
            "NFL direct model 108/201 completed\n",
            "Original data shape: (1437, 11)\n",
            "Flattened data shape: (1437, 11)\n",
            "Using provided test data as validation: 1437 train, 316 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.54, 0.545]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1437, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8121, Train Loss: 0.1319, Val Acc: 0.8038, Val Loss: 0.1406\n",
            "Restored model from best epoch 8 with val_loss: 0.140592\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.54-0.545_ep8_valAcc0.8038_valLoss0.1406.pth\n",
            "NFL direct model 109/201 completed\n",
            "Original data shape: (1487, 11)\n",
            "Flattened data shape: (1487, 11)\n",
            "Using provided test data as validation: 1487 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.545, 0.55]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1487, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8124, Train Loss: 0.1412, Val Acc: 0.7932, Val Loss: 0.1392\n",
            "Restored model from best epoch 7 with val_loss: 0.139237\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.545-0.55_ep7_valAcc0.7932_valLoss0.1392.pth\n",
            "NFL direct model 110/201 completed\n",
            "Original data shape: (1461, 11)\n",
            "Flattened data shape: (1461, 11)\n",
            "Using provided test data as validation: 1461 train, 319 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.55, 0.555]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1461, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8022, Train Loss: 0.1392, Val Acc: 0.8307, Val Loss: 0.1286\n",
            "Restored model from best epoch 8 with val_loss: 0.128565\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.55-0.555_ep8_valAcc0.8307_valLoss0.1286.pth\n",
            "NFL direct model 111/201 completed\n",
            "Original data shape: (1476, 11)\n",
            "Flattened data shape: (1476, 11)\n",
            "Using provided test data as validation: 1476 train, 325 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.555, 0.56]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1476, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.8205, Train Loss: 0.1302, Val Acc: 0.8246, Val Loss: 0.1323\n",
            "Restored model from best epoch 18 with val_loss: 0.132281\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.555-0.56_ep18_valAcc0.8246_valLoss0.1323.pth\n",
            "NFL direct model 112/201 completed\n",
            "Original data shape: (1498, 11)\n",
            "Flattened data shape: (1498, 11)\n",
            "Using provided test data as validation: 1498 train, 305 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.56, 0.565]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1498, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8184, Train Loss: 0.1343, Val Acc: 0.8000, Val Loss: 0.1385\n",
            "Restored model from best epoch 8 with val_loss: 0.138468\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.56-0.565_ep8_valAcc0.8000_valLoss0.1385.pth\n",
            "NFL direct model 113/201 completed\n",
            "Original data shape: (1498, 11)\n",
            "Flattened data shape: (1498, 11)\n",
            "Using provided test data as validation: 1498 train, 334 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.565, 0.57]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1498, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8191, Train Loss: 0.1325, Val Acc: 0.8383, Val Loss: 0.1323\n",
            "Restored model from best epoch 11 with val_loss: 0.132285\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.565-0.57_ep11_valAcc0.8383_valLoss0.1323.pth\n",
            "NFL direct model 114/201 completed\n",
            "Original data shape: (1492, 11)\n",
            "Flattened data shape: (1492, 11)\n",
            "Using provided test data as validation: 1492 train, 331 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.57, 0.575]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1492, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7714, Train Loss: 0.1574, Val Acc: 0.8066, Val Loss: 0.1408\n",
            "Restored model from best epoch 3 with val_loss: 0.140812\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.57-0.575_ep3_valAcc0.8066_valLoss0.1408.pth\n",
            "NFL direct model 115/201 completed\n",
            "Original data shape: (1495, 11)\n",
            "Flattened data shape: (1495, 11)\n",
            "Using provided test data as validation: 1495 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.575, 0.58]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1495, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8201, Train Loss: 0.1310, Val Acc: 0.7956, Val Loss: 0.1492\n",
            "Restored model from best epoch 14 with val_loss: 0.149163\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.575-0.58_ep14_valAcc0.7956_valLoss0.1492.pth\n",
            "NFL direct model 116/201 completed\n",
            "Original data shape: (1469, 11)\n",
            "Flattened data shape: (1469, 11)\n",
            "Using provided test data as validation: 1469 train, 309 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.58, 0.585]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1469, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8305, Train Loss: 0.1310, Val Acc: 0.8123, Val Loss: 0.1346\n",
            "Restored model from best epoch 8 with val_loss: 0.134643\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.58-0.585_ep8_valAcc0.8123_valLoss0.1346.pth\n",
            "NFL direct model 117/201 completed\n",
            "Original data shape: (1528, 11)\n",
            "Flattened data shape: (1528, 11)\n",
            "Using provided test data as validation: 1528 train, 312 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.585, 0.59]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1528, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8135, Train Loss: 0.1358, Val Acc: 0.8141, Val Loss: 0.1280\n",
            "Restored model from best epoch 7 with val_loss: 0.127980\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.585-0.59_ep7_valAcc0.8141_valLoss0.1280.pth\n",
            "NFL direct model 118/201 completed\n",
            "Original data shape: (1545, 11)\n",
            "Flattened data shape: (1545, 11)\n",
            "Using provided test data as validation: 1545 train, 336 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.59, 0.595]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1545, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8168, Train Loss: 0.1379, Val Acc: 0.8363, Val Loss: 0.1191\n",
            "Restored model from best epoch 10 with val_loss: 0.119090\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.59-0.595_ep10_valAcc0.8363_valLoss0.1191.pth\n",
            "NFL direct model 119/201 completed\n",
            "Original data shape: (1500, 11)\n",
            "Flattened data shape: (1500, 11)\n",
            "Using provided test data as validation: 1500 train, 339 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.595, 0.6]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1500, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8140, Train Loss: 0.1404, Val Acc: 0.8112, Val Loss: 0.1333\n",
            "Restored model from best epoch 8 with val_loss: 0.133347\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.595-0.6_ep8_valAcc0.8112_valLoss0.1333.pth\n",
            "NFL direct model 120/201 completed\n",
            "Original data shape: (1541, 11)\n",
            "Flattened data shape: (1541, 11)\n",
            "Using provided test data as validation: 1541 train, 331 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.6, 0.605]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1541, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8215, Train Loss: 0.1381, Val Acc: 0.8187, Val Loss: 0.1326\n",
            "Restored model from best epoch 12 with val_loss: 0.132561\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.6-0.605_ep12_valAcc0.8187_valLoss0.1326.pth\n",
            "NFL direct model 121/201 completed\n",
            "Original data shape: (1514, 11)\n",
            "Flattened data shape: (1514, 11)\n",
            "Using provided test data as validation: 1514 train, 319 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.605, 0.61]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1514, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8098, Train Loss: 0.1395, Val Acc: 0.8119, Val Loss: 0.1364\n",
            "Restored model from best epoch 6 with val_loss: 0.136413\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.605-0.61_ep6_valAcc0.8119_valLoss0.1364.pth\n",
            "NFL direct model 122/201 completed\n",
            "Original data shape: (1522, 11)\n",
            "Flattened data shape: (1522, 11)\n",
            "Using provided test data as validation: 1522 train, 334 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.61, 0.615]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1522, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8101, Train Loss: 0.1348, Val Acc: 0.8024, Val Loss: 0.1388\n",
            "Restored model from best epoch 5 with val_loss: 0.138756\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.61-0.615_ep5_valAcc0.8024_valLoss0.1388.pth\n",
            "NFL direct model 123/201 completed\n",
            "Original data shape: (1547, 11)\n",
            "Flattened data shape: (1547, 11)\n",
            "Using provided test data as validation: 1547 train, 323 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.615, 0.62]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1547, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8035, Train Loss: 0.1459, Val Acc: 0.8142, Val Loss: 0.1165\n",
            "Restored model from best epoch 4 with val_loss: 0.116464\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.615-0.62_ep4_valAcc0.8142_valLoss0.1165.pth\n",
            "NFL direct model 124/201 completed\n",
            "Original data shape: (1499, 11)\n",
            "Flattened data shape: (1499, 11)\n",
            "Using provided test data as validation: 1499 train, 336 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.62, 0.625]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1499, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8266, Train Loss: 0.1248, Val Acc: 0.8214, Val Loss: 0.1265\n",
            "Restored model from best epoch 17 with val_loss: 0.126509\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.62-0.625_ep17_valAcc0.8214_valLoss0.1265.pth\n",
            "NFL direct model 125/201 completed\n",
            "Original data shape: (1573, 11)\n",
            "Flattened data shape: (1573, 11)\n",
            "Using provided test data as validation: 1573 train, 320 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.625, 0.63]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1573, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8252, Train Loss: 0.1285, Val Acc: 0.8469, Val Loss: 0.1311\n",
            "Restored model from best epoch 14 with val_loss: 0.131077\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.625-0.63_ep14_valAcc0.8469_valLoss0.1311.pth\n",
            "NFL direct model 126/201 completed\n",
            "Original data shape: (1486, 11)\n",
            "Flattened data shape: (1486, 11)\n",
            "Using provided test data as validation: 1486 train, 327 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.63, 0.635]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1486, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 38\n",
            "Best epoch: 28, Train Acc: 0.8432, Train Loss: 0.1201, Val Acc: 0.8226, Val Loss: 0.1218\n",
            "Restored model from best epoch 28 with val_loss: 0.121791\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.63-0.635_ep28_valAcc0.8226_valLoss0.1218.pth\n",
            "NFL direct model 127/201 completed\n",
            "Original data shape: (1531, 11)\n",
            "Flattened data shape: (1531, 11)\n",
            "Using provided test data as validation: 1531 train, 332 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.635, 0.64]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1531, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.8491, Train Loss: 0.1180, Val Acc: 0.8343, Val Loss: 0.1098\n",
            "Restored model from best epoch 18 with val_loss: 0.109835\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.635-0.64_ep18_valAcc0.8343_valLoss0.1098.pth\n",
            "NFL direct model 128/201 completed\n",
            "Original data shape: (1498, 11)\n",
            "Flattened data shape: (1498, 11)\n",
            "Using provided test data as validation: 1498 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.64, 0.645]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1498, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7997, Train Loss: 0.1464, Val Acc: 0.8241, Val Loss: 0.1122\n",
            "Restored model from best epoch 3 with val_loss: 0.112191\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.64-0.645_ep3_valAcc0.8241_valLoss0.1122.pth\n",
            "NFL direct model 129/201 completed\n",
            "Original data shape: (1504, 11)\n",
            "Flattened data shape: (1504, 11)\n",
            "Using provided test data as validation: 1504 train, 352 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.645, 0.65]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1504, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8391, Train Loss: 0.1210, Val Acc: 0.8239, Val Loss: 0.1188\n",
            "Restored model from best epoch 16 with val_loss: 0.118750\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.645-0.65_ep16_valAcc0.8239_valLoss0.1188.pth\n",
            "NFL direct model 130/201 completed\n",
            "Original data shape: (1496, 11)\n",
            "Flattened data shape: (1496, 11)\n",
            "Using provided test data as validation: 1496 train, 321 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.65, 0.655]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1496, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8329, Train Loss: 0.1211, Val Acc: 0.8287, Val Loss: 0.1130\n",
            "Restored model from best epoch 7 with val_loss: 0.113034\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.65-0.655_ep7_valAcc0.8287_valLoss0.1130.pth\n",
            "NFL direct model 131/201 completed\n",
            "Original data shape: (1527, 11)\n",
            "Flattened data shape: (1527, 11)\n",
            "Using provided test data as validation: 1527 train, 346 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.655, 0.66]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1527, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 31\n",
            "Best epoch: 21, Train Acc: 0.8448, Train Loss: 0.1186, Val Acc: 0.8353, Val Loss: 0.1171\n",
            "Restored model from best epoch 21 with val_loss: 0.117052\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.655-0.66_ep21_valAcc0.8353_valLoss0.1171.pth\n",
            "NFL direct model 132/201 completed\n",
            "Original data shape: (1576, 11)\n",
            "Flattened data shape: (1576, 11)\n",
            "Using provided test data as validation: 1576 train, 318 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.66, 0.665]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1576, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8052, Train Loss: 0.1516, Val Acc: 0.8239, Val Loss: 0.1239\n",
            "Restored model from best epoch 3 with val_loss: 0.123858\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.66-0.665_ep3_valAcc0.8239_valLoss0.1239.pth\n",
            "NFL direct model 133/201 completed\n",
            "Original data shape: (1497, 11)\n",
            "Flattened data shape: (1497, 11)\n",
            "Using provided test data as validation: 1497 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.665, 0.67]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1497, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8216, Train Loss: 0.1311, Val Acc: 0.8302, Val Loss: 0.1072\n",
            "Restored model from best epoch 6 with val_loss: 0.107205\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.665-0.67_ep6_valAcc0.8302_valLoss0.1072.pth\n",
            "NFL direct model 134/201 completed\n",
            "Original data shape: (1539, 11)\n",
            "Flattened data shape: (1539, 11)\n",
            "Using provided test data as validation: 1539 train, 326 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.67, 0.675]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1539, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8291, Train Loss: 0.1232, Val Acc: 0.8374, Val Loss: 0.1042\n",
            "Restored model from best epoch 8 with val_loss: 0.104225\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.67-0.675_ep8_valAcc0.8374_valLoss0.1042.pth\n",
            "NFL direct model 135/201 completed\n",
            "Original data shape: (1493, 11)\n",
            "Flattened data shape: (1493, 11)\n",
            "Using provided test data as validation: 1493 train, 334 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.675, 0.68]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1493, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8125, Train Loss: 0.1311, Val Acc: 0.8563, Val Loss: 0.1055\n",
            "Restored model from best epoch 8 with val_loss: 0.105464\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.675-0.68_ep8_valAcc0.8563_valLoss0.1055.pth\n",
            "NFL direct model 136/201 completed\n",
            "Original data shape: (1517, 11)\n",
            "Flattened data shape: (1517, 11)\n",
            "Using provided test data as validation: 1517 train, 320 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.68, 0.685]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1517, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8042, Train Loss: 0.1373, Val Acc: 0.8469, Val Loss: 0.1193\n",
            "Restored model from best epoch 4 with val_loss: 0.119250\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.68-0.685_ep4_valAcc0.8469_valLoss0.1193.pth\n",
            "NFL direct model 137/201 completed\n",
            "Original data shape: (1509, 11)\n",
            "Flattened data shape: (1509, 11)\n",
            "Using provided test data as validation: 1509 train, 320 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.685, 0.69]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1509, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8383, Train Loss: 0.1225, Val Acc: 0.8562, Val Loss: 0.1045\n",
            "Restored model from best epoch 11 with val_loss: 0.104528\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.685-0.69_ep11_valAcc0.8562_valLoss0.1045.pth\n",
            "NFL direct model 138/201 completed\n",
            "Original data shape: (1525, 11)\n",
            "Flattened data shape: (1525, 11)\n",
            "Using provided test data as validation: 1525 train, 331 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.69, 0.695]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1525, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8223, Train Loss: 0.1298, Val Acc: 0.8459, Val Loss: 0.1046\n",
            "Restored model from best epoch 9 with val_loss: 0.104591\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.69-0.695_ep9_valAcc0.8459_valLoss0.1046.pth\n",
            "NFL direct model 139/201 completed\n",
            "Original data shape: (1504, 11)\n",
            "Flattened data shape: (1504, 11)\n",
            "Using provided test data as validation: 1504 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.695, 0.7]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1504, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8531, Train Loss: 0.1098, Val Acc: 0.8117, Val Loss: 0.1200\n",
            "Restored model from best epoch 16 with val_loss: 0.120048\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.695-0.7_ep16_valAcc0.8117_valLoss0.1200.pth\n",
            "NFL direct model 140/201 completed\n",
            "Original data shape: (1502, 11)\n",
            "Flattened data shape: (1502, 11)\n",
            "Using provided test data as validation: 1502 train, 314 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.7, 0.705]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1502, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8469, Train Loss: 0.1168, Val Acc: 0.8217, Val Loss: 0.1310\n",
            "Restored model from best epoch 11 with val_loss: 0.130991\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.7-0.705_ep11_valAcc0.8217_valLoss0.1310.pth\n",
            "NFL direct model 141/201 completed\n",
            "Original data shape: (1502, 11)\n",
            "Flattened data shape: (1502, 11)\n",
            "Using provided test data as validation: 1502 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.705, 0.71]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1502, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8302, Train Loss: 0.1287, Val Acc: 0.8457, Val Loss: 0.0945\n",
            "Restored model from best epoch 6 with val_loss: 0.094525\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.705-0.71_ep6_valAcc0.8457_valLoss0.0945.pth\n",
            "NFL direct model 142/201 completed\n",
            "Original data shape: (1496, 11)\n",
            "Flattened data shape: (1496, 11)\n",
            "Using provided test data as validation: 1496 train, 332 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.71, 0.715]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1496, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8416, Train Loss: 0.1192, Val Acc: 0.8404, Val Loss: 0.1027\n",
            "Restored model from best epoch 7 with val_loss: 0.102703\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.71-0.715_ep7_valAcc0.8404_valLoss0.1027.pth\n",
            "NFL direct model 143/201 completed\n",
            "Original data shape: (1544, 11)\n",
            "Flattened data shape: (1544, 11)\n",
            "Using provided test data as validation: 1544 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.715, 0.72]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1544, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8478, Train Loss: 0.1162, Val Acc: 0.8457, Val Loss: 0.0961\n",
            "Restored model from best epoch 10 with val_loss: 0.096074\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.715-0.72_ep10_valAcc0.8457_valLoss0.0961.pth\n",
            "NFL direct model 144/201 completed\n",
            "Original data shape: (1530, 11)\n",
            "Flattened data shape: (1530, 11)\n",
            "Using provided test data as validation: 1530 train, 322 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.72, 0.725]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1530, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8510, Train Loss: 0.1150, Val Acc: 0.8509, Val Loss: 0.0930\n",
            "Restored model from best epoch 10 with val_loss: 0.093011\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.72-0.725_ep10_valAcc0.8509_valLoss0.0930.pth\n",
            "NFL direct model 145/201 completed\n",
            "Original data shape: (1535, 11)\n",
            "Flattened data shape: (1535, 11)\n",
            "Using provided test data as validation: 1535 train, 336 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.725, 0.73]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1535, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.8599, Train Loss: 0.1042, Val Acc: 0.8452, Val Loss: 0.1060\n",
            "Restored model from best epoch 26 with val_loss: 0.106023\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.725-0.73_ep26_valAcc0.8452_valLoss0.1060.pth\n",
            "NFL direct model 146/201 completed\n",
            "Original data shape: (1525, 11)\n",
            "Flattened data shape: (1525, 11)\n",
            "Using provided test data as validation: 1525 train, 334 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.73, 0.735]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1525, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8367, Train Loss: 0.1167, Val Acc: 0.8413, Val Loss: 0.1117\n",
            "Restored model from best epoch 7 with val_loss: 0.111696\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.73-0.735_ep7_valAcc0.8413_valLoss0.1117.pth\n",
            "NFL direct model 147/201 completed\n",
            "Original data shape: (1502, 11)\n",
            "Flattened data shape: (1502, 11)\n",
            "Using provided test data as validation: 1502 train, 328 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.735, 0.74]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1502, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8409, Train Loss: 0.1245, Val Acc: 0.8445, Val Loss: 0.1120\n",
            "Restored model from best epoch 5 with val_loss: 0.111994\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.735-0.74_ep5_valAcc0.8445_valLoss0.1120.pth\n",
            "NFL direct model 148/201 completed\n",
            "Original data shape: (1504, 11)\n",
            "Flattened data shape: (1504, 11)\n",
            "Using provided test data as validation: 1504 train, 352 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.74, 0.745]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1504, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8431, Train Loss: 0.1128, Val Acc: 0.8267, Val Loss: 0.1022\n",
            "Restored model from best epoch 8 with val_loss: 0.102213\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.74-0.745_ep8_valAcc0.8267_valLoss0.1022.pth\n",
            "NFL direct model 149/201 completed\n",
            "Original data shape: (1479, 11)\n",
            "Flattened data shape: (1479, 11)\n",
            "Using provided test data as validation: 1479 train, 325 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.745, 0.75]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1479, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.8343, Train Loss: 0.1057, Val Acc: 0.8400, Val Loss: 0.1046\n",
            "Restored model from best epoch 18 with val_loss: 0.104612\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.745-0.75_ep18_valAcc0.8400_valLoss0.1046.pth\n",
            "NFL direct model 150/201 completed\n",
            "Original data shape: (3141, 11)\n",
            "Flattened data shape: (3141, 11)\n",
            "Using provided test data as validation: 3141 train, 691 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.75, 0.755]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (3141, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.8322, Train Loss: 0.1257, Val Acc: 0.8495, Val Loss: 0.1092\n",
            "Restored model from best epoch 2 with val_loss: 0.109175\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.75-0.755_ep2_valAcc0.8495_valLoss0.1092.pth\n",
            "NFL direct model 151/201 completed\n",
            "Original data shape: (1680, 11)\n",
            "Flattened data shape: (1680, 11)\n",
            "Using provided test data as validation: 1680 train, 351 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.755, 0.76]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1680, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8750, Train Loss: 0.1071, Val Acc: 0.8632, Val Loss: 0.0998\n",
            "Restored model from best epoch 13 with val_loss: 0.099784\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.755-0.76_ep13_valAcc0.8632_valLoss0.0998.pth\n",
            "NFL direct model 152/201 completed\n",
            "Original data shape: (1343, 11)\n",
            "Flattened data shape: (1343, 11)\n",
            "Using provided test data as validation: 1343 train, 295 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.76, 0.765]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1343, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8697, Train Loss: 0.1013, Val Acc: 0.8305, Val Loss: 0.1113\n",
            "Restored model from best epoch 9 with val_loss: 0.111333\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.76-0.765_ep9_valAcc0.8305_valLoss0.1113.pth\n",
            "NFL direct model 153/201 completed\n",
            "Original data shape: (1642, 11)\n",
            "Flattened data shape: (1642, 11)\n",
            "Using provided test data as validation: 1642 train, 349 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.765, 0.77]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1642, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8435, Train Loss: 0.1181, Val Acc: 0.8481, Val Loss: 0.1016\n",
            "Restored model from best epoch 6 with val_loss: 0.101582\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.765-0.77_ep6_valAcc0.8481_valLoss0.1016.pth\n",
            "NFL direct model 154/201 completed\n",
            "Original data shape: (1418, 11)\n",
            "Flattened data shape: (1418, 11)\n",
            "Using provided test data as validation: 1418 train, 303 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.77, 0.775]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1418, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8420, Train Loss: 0.1121, Val Acc: 0.8449, Val Loss: 0.1094\n",
            "Restored model from best epoch 9 with val_loss: 0.109370\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.77-0.775_ep9_valAcc0.8449_valLoss0.1094.pth\n",
            "NFL direct model 155/201 completed\n",
            "Original data shape: (1573, 11)\n",
            "Flattened data shape: (1573, 11)\n",
            "Using provided test data as validation: 1573 train, 331 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.775, 0.78]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1573, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8722, Train Loss: 0.1003, Val Acc: 0.8429, Val Loss: 0.0955\n",
            "Restored model from best epoch 15 with val_loss: 0.095492\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.775-0.78_ep15_valAcc0.8429_valLoss0.0955.pth\n",
            "NFL direct model 156/201 completed\n",
            "Original data shape: (1463, 11)\n",
            "Flattened data shape: (1463, 11)\n",
            "Using provided test data as validation: 1463 train, 336 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.78, 0.785]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1463, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8708, Train Loss: 0.0990, Val Acc: 0.8601, Val Loss: 0.0906\n",
            "Restored model from best epoch 15 with val_loss: 0.090641\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.78-0.785_ep15_valAcc0.8601_valLoss0.0906.pth\n",
            "NFL direct model 157/201 completed\n",
            "Original data shape: (1494, 11)\n",
            "Flattened data shape: (1494, 11)\n",
            "Using provided test data as validation: 1494 train, 329 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.785, 0.79]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1494, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8788, Train Loss: 0.0985, Val Acc: 0.8511, Val Loss: 0.1026\n",
            "Restored model from best epoch 12 with val_loss: 0.102642\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.785-0.79_ep12_valAcc0.8511_valLoss0.1026.pth\n",
            "NFL direct model 158/201 completed\n",
            "Original data shape: (1526, 11)\n",
            "Flattened data shape: (1526, 11)\n",
            "Using provided test data as validation: 1526 train, 329 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.79, 0.795]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1526, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8290, Train Loss: 0.1210, Val Acc: 0.8663, Val Loss: 0.0893\n",
            "Restored model from best epoch 4 with val_loss: 0.089281\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.79-0.795_ep4_valAcc0.8663_valLoss0.0893.pth\n",
            "NFL direct model 159/201 completed\n",
            "Original data shape: (1520, 11)\n",
            "Flattened data shape: (1520, 11)\n",
            "Using provided test data as validation: 1520 train, 312 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.795, 0.8]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1520, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8697, Train Loss: 0.0985, Val Acc: 0.8526, Val Loss: 0.1068\n",
            "Restored model from best epoch 10 with val_loss: 0.106847\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.795-0.8_ep10_valAcc0.8526_valLoss0.1068.pth\n",
            "NFL direct model 160/201 completed\n",
            "Original data shape: (1577, 11)\n",
            "Flattened data shape: (1577, 11)\n",
            "Using provided test data as validation: 1577 train, 341 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.8, 0.805]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1577, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8656, Train Loss: 0.1059, Val Acc: 0.8416, Val Loss: 0.1116\n",
            "Restored model from best epoch 8 with val_loss: 0.111631\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.8-0.805_ep8_valAcc0.8416_valLoss0.1116.pth\n",
            "NFL direct model 161/201 completed\n",
            "Original data shape: (1538, 11)\n",
            "Flattened data shape: (1538, 11)\n",
            "Using provided test data as validation: 1538 train, 326 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.805, 0.81]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1538, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8602, Train Loss: 0.1048, Val Acc: 0.8650, Val Loss: 0.0891\n",
            "Restored model from best epoch 7 with val_loss: 0.089065\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.805-0.81_ep7_valAcc0.8650_valLoss0.0891.pth\n",
            "NFL direct model 162/201 completed\n",
            "Original data shape: (1485, 11)\n",
            "Flattened data shape: (1485, 11)\n",
            "Using provided test data as validation: 1485 train, 335 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.81, 0.815]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1485, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8532, Train Loss: 0.1119, Val Acc: 0.8627, Val Loss: 0.0862\n",
            "Restored model from best epoch 4 with val_loss: 0.086170\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.81-0.815_ep4_valAcc0.8627_valLoss0.0862.pth\n",
            "NFL direct model 163/201 completed\n",
            "Original data shape: (1538, 11)\n",
            "Flattened data shape: (1538, 11)\n",
            "Using provided test data as validation: 1538 train, 341 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.815, 0.82]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1538, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8771, Train Loss: 0.0946, Val Acc: 0.8768, Val Loss: 0.0889\n",
            "Restored model from best epoch 17 with val_loss: 0.088906\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.815-0.82_ep17_valAcc0.8768_valLoss0.0889.pth\n",
            "NFL direct model 164/201 completed\n",
            "Original data shape: (1516, 11)\n",
            "Flattened data shape: (1516, 11)\n",
            "Using provided test data as validation: 1516 train, 345 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.82, 0.825]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1516, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8694, Train Loss: 0.0964, Val Acc: 0.8812, Val Loss: 0.0812\n",
            "Restored model from best epoch 12 with val_loss: 0.081173\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.82-0.825_ep12_valAcc0.8812_valLoss0.0812.pth\n",
            "NFL direct model 165/201 completed\n",
            "Original data shape: (1496, 11)\n",
            "Flattened data shape: (1496, 11)\n",
            "Using provided test data as validation: 1496 train, 341 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.825, 0.83]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1496, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8369, Train Loss: 0.1274, Val Acc: 0.8504, Val Loss: 0.0971\n",
            "Restored model from best epoch 3 with val_loss: 0.097143\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.825-0.83_ep3_valAcc0.8504_valLoss0.0971.pth\n",
            "NFL direct model 166/201 completed\n",
            "Original data shape: (1529, 11)\n",
            "Flattened data shape: (1529, 11)\n",
            "Using provided test data as validation: 1529 train, 331 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.83, 0.835]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1529, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8777, Train Loss: 0.1031, Val Acc: 0.8520, Val Loss: 0.0932\n",
            "Restored model from best epoch 10 with val_loss: 0.093185\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.83-0.835_ep10_valAcc0.8520_valLoss0.0932.pth\n",
            "NFL direct model 167/201 completed\n",
            "Original data shape: (1502, 11)\n",
            "Flattened data shape: (1502, 11)\n",
            "Using provided test data as validation: 1502 train, 329 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.835, 0.84]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1502, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8655, Train Loss: 0.1011, Val Acc: 0.8632, Val Loss: 0.0870\n",
            "Restored model from best epoch 4 with val_loss: 0.087009\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.835-0.84_ep4_valAcc0.8632_valLoss0.0870.pth\n",
            "NFL direct model 168/201 completed\n",
            "Original data shape: (1499, 11)\n",
            "Flattened data shape: (1499, 11)\n",
            "Using provided test data as validation: 1499 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.84, 0.845]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1499, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8719, Train Loss: 0.0938, Val Acc: 0.8673, Val Loss: 0.0814\n",
            "Restored model from best epoch 9 with val_loss: 0.081392\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.84-0.845_ep9_valAcc0.8673_valLoss0.0814.pth\n",
            "NFL direct model 169/201 completed\n",
            "Original data shape: (1538, 11)\n",
            "Flattened data shape: (1538, 11)\n",
            "Using provided test data as validation: 1538 train, 330 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.845, 0.85]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1538, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8388, Train Loss: 0.1188, Val Acc: 0.8788, Val Loss: 0.0830\n",
            "Restored model from best epoch 3 with val_loss: 0.082995\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.845-0.85_ep3_valAcc0.8788_valLoss0.0830.pth\n",
            "NFL direct model 170/201 completed\n",
            "Original data shape: (1527, 11)\n",
            "Flattened data shape: (1527, 11)\n",
            "Using provided test data as validation: 1527 train, 335 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.85, 0.855]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1527, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8657, Train Loss: 0.1057, Val Acc: 0.8716, Val Loss: 0.0795\n",
            "Restored model from best epoch 5 with val_loss: 0.079497\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.85-0.855_ep5_valAcc0.8716_valLoss0.0795.pth\n",
            "NFL direct model 171/201 completed\n",
            "Original data shape: (1515, 11)\n",
            "Flattened data shape: (1515, 11)\n",
            "Using provided test data as validation: 1515 train, 337 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.855, 0.86]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1515, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8614, Train Loss: 0.1106, Val Acc: 0.8754, Val Loss: 0.0833\n",
            "Restored model from best epoch 4 with val_loss: 0.083279\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.855-0.86_ep4_valAcc0.8754_valLoss0.0833.pth\n",
            "NFL direct model 172/201 completed\n",
            "Original data shape: (1552, 11)\n",
            "Flattened data shape: (1552, 11)\n",
            "Using provided test data as validation: 1552 train, 322 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.86, 0.865]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1552, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8789, Train Loss: 0.0890, Val Acc: 0.8789, Val Loss: 0.0723\n",
            "Restored model from best epoch 15 with val_loss: 0.072280\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.86-0.865_ep15_valAcc0.8789_valLoss0.0723.pth\n",
            "NFL direct model 173/201 completed\n",
            "Original data shape: (1512, 11)\n",
            "Flattened data shape: (1512, 11)\n",
            "Using provided test data as validation: 1512 train, 346 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.865, 0.87]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1512, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8862, Train Loss: 0.0917, Val Acc: 0.9133, Val Loss: 0.0650\n",
            "Restored model from best epoch 10 with val_loss: 0.064954\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.865-0.87_ep10_valAcc0.9133_valLoss0.0650.pth\n",
            "NFL direct model 174/201 completed\n",
            "Original data shape: (1491, 11)\n",
            "Flattened data shape: (1491, 11)\n",
            "Using provided test data as validation: 1491 train, 326 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.87, 0.875]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1491, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 50\n",
            "Best epoch: 40, Train Acc: 0.8981, Train Loss: 0.0728, Val Acc: 0.8957, Val Loss: 0.0654\n",
            "Restored model from best epoch 40 with val_loss: 0.065392\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.87-0.875_ep40_valAcc0.8957_valLoss0.0654.pth\n",
            "NFL direct model 175/201 completed\n",
            "Original data shape: (1537, 11)\n",
            "Flattened data shape: (1537, 11)\n",
            "Using provided test data as validation: 1537 train, 338 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.875, 0.88]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1537, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8887, Train Loss: 0.0819, Val Acc: 0.8876, Val Loss: 0.0715\n",
            "Restored model from best epoch 13 with val_loss: 0.071468\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.875-0.88_ep13_valAcc0.8876_valLoss0.0715.pth\n",
            "NFL direct model 176/201 completed\n",
            "Original data shape: (1539, 11)\n",
            "Flattened data shape: (1539, 11)\n",
            "Using provided test data as validation: 1539 train, 343 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.88, 0.885]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1539, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8720, Train Loss: 0.1020, Val Acc: 0.8717, Val Loss: 0.0860\n",
            "Restored model from best epoch 5 with val_loss: 0.085979\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.88-0.885_ep5_valAcc0.8717_valLoss0.0860.pth\n",
            "NFL direct model 177/201 completed\n",
            "Original data shape: (1536, 11)\n",
            "Flattened data shape: (1536, 11)\n",
            "Using provided test data as validation: 1536 train, 330 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.885, 0.89]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1536, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8906, Train Loss: 0.0811, Val Acc: 0.8848, Val Loss: 0.0697\n",
            "Restored model from best epoch 17 with val_loss: 0.069727\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.885-0.89_ep17_valAcc0.8848_valLoss0.0697.pth\n",
            "NFL direct model 178/201 completed\n",
            "Original data shape: (1584, 11)\n",
            "Flattened data shape: (1584, 11)\n",
            "Using provided test data as validation: 1584 train, 335 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.89, 0.895]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1584, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8636, Train Loss: 0.1049, Val Acc: 0.8896, Val Loss: 0.0740\n",
            "Restored model from best epoch 5 with val_loss: 0.073999\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.89-0.895_ep5_valAcc0.8896_valLoss0.0740.pth\n",
            "NFL direct model 179/201 completed\n",
            "Original data shape: (1562, 11)\n",
            "Flattened data shape: (1562, 11)\n",
            "Using provided test data as validation: 1562 train, 340 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.895, 0.9]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1562, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8816, Train Loss: 0.0927, Val Acc: 0.8912, Val Loss: 0.0747\n",
            "Restored model from best epoch 6 with val_loss: 0.074666\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.895-0.9_ep6_valAcc0.8912_valLoss0.0747.pth\n",
            "NFL direct model 180/201 completed\n",
            "Original data shape: (1553, 11)\n",
            "Flattened data shape: (1553, 11)\n",
            "Using provided test data as validation: 1553 train, 331 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.9, 0.905]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1553, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 31\n",
            "Best epoch: 21, Train Acc: 0.9008, Train Loss: 0.0769, Val Acc: 0.8610, Val Loss: 0.0923\n",
            "Restored model from best epoch 21 with val_loss: 0.092319\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.9-0.905_ep21_valAcc0.8610_valLoss0.0923.pth\n",
            "NFL direct model 181/201 completed\n",
            "Original data shape: (1564, 11)\n",
            "Flattened data shape: (1564, 11)\n",
            "Using provided test data as validation: 1564 train, 330 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.905, 0.91]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1564, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 51\n",
            "Best epoch: 41, Train Acc: 0.9118, Train Loss: 0.0646, Val Acc: 0.8818, Val Loss: 0.0721\n",
            "Restored model from best epoch 41 with val_loss: 0.072095\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.905-0.91_ep41_valAcc0.8818_valLoss0.0721.pth\n",
            "NFL direct model 182/201 completed\n",
            "Original data shape: (1572, 11)\n",
            "Flattened data shape: (1572, 11)\n",
            "Using provided test data as validation: 1572 train, 346 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.91, 0.915]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1572, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.9008, Train Loss: 0.0732, Val Acc: 0.8960, Val Loss: 0.0724\n",
            "Restored model from best epoch 13 with val_loss: 0.072372\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.91-0.915_ep13_valAcc0.8960_valLoss0.0724.pth\n",
            "NFL direct model 183/201 completed\n",
            "Original data shape: (1593, 11)\n",
            "Flattened data shape: (1593, 11)\n",
            "Using provided test data as validation: 1593 train, 352 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.915, 0.92]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1593, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8977, Train Loss: 0.0834, Val Acc: 0.9148, Val Loss: 0.0615\n",
            "Restored model from best epoch 6 with val_loss: 0.061475\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.915-0.92_ep6_valAcc0.9148_valLoss0.0615.pth\n",
            "NFL direct model 184/201 completed\n",
            "Original data shape: (1678, 11)\n",
            "Flattened data shape: (1678, 11)\n",
            "Using provided test data as validation: 1678 train, 363 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.92, 0.925]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1678, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8814, Train Loss: 0.0936, Val Acc: 0.8981, Val Loss: 0.0823\n",
            "Restored model from best epoch 6 with val_loss: 0.082295\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.92-0.925_ep6_valAcc0.8981_valLoss0.0823.pth\n",
            "NFL direct model 185/201 completed\n",
            "Original data shape: (1704, 11)\n",
            "Flattened data shape: (1704, 11)\n",
            "Using provided test data as validation: 1704 train, 396 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.925, 0.93]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1704, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8979, Train Loss: 0.0793, Val Acc: 0.8889, Val Loss: 0.0737\n",
            "Restored model from best epoch 9 with val_loss: 0.073670\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.925-0.93_ep9_valAcc0.8889_valLoss0.0737.pth\n",
            "NFL direct model 186/201 completed\n",
            "Original data shape: (1747, 11)\n",
            "Flattened data shape: (1747, 11)\n",
            "Using provided test data as validation: 1747 train, 413 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.93, 0.935]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1747, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.9136, Train Loss: 0.0653, Val Acc: 0.8983, Val Loss: 0.0740\n",
            "Restored model from best epoch 20 with val_loss: 0.074040\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.93-0.935_ep20_valAcc0.8983_valLoss0.0740.pth\n",
            "NFL direct model 187/201 completed\n",
            "Original data shape: (1864, 11)\n",
            "Flattened data shape: (1864, 11)\n",
            "Using provided test data as validation: 1864 train, 363 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.935, 0.94]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1864, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8948, Train Loss: 0.0861, Val Acc: 0.9174, Val Loss: 0.0693\n",
            "Restored model from best epoch 7 with val_loss: 0.069280\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.935-0.94_ep7_valAcc0.9174_valLoss0.0693.pth\n",
            "NFL direct model 188/201 completed\n",
            "Original data shape: (1941, 11)\n",
            "Flattened data shape: (1941, 11)\n",
            "Using provided test data as validation: 1941 train, 437 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.94, 0.945]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1941, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.9119, Train Loss: 0.0736, Val Acc: 0.8970, Val Loss: 0.0674\n",
            "Restored model from best epoch 14 with val_loss: 0.067388\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.94-0.945_ep14_valAcc0.8970_valLoss0.0674.pth\n",
            "NFL direct model 189/201 completed\n",
            "Original data shape: (1972, 11)\n",
            "Flattened data shape: (1972, 11)\n",
            "Using provided test data as validation: 1972 train, 446 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.945, 0.95]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1972, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.9204, Train Loss: 0.0613, Val Acc: 0.9215, Val Loss: 0.0610\n",
            "Restored model from best epoch 14 with val_loss: 0.061042\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.945-0.95_ep14_valAcc0.9215_valLoss0.0610.pth\n",
            "NFL direct model 190/201 completed\n",
            "Original data shape: (2011, 11)\n",
            "Flattened data shape: (2011, 11)\n",
            "Using provided test data as validation: 2011 train, 434 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.95, 0.955]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2011, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8866, Train Loss: 0.0851, Val Acc: 0.8917, Val Loss: 0.0739\n",
            "Restored model from best epoch 5 with val_loss: 0.073943\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.95-0.955_ep5_valAcc0.8917_valLoss0.0739.pth\n",
            "NFL direct model 191/201 completed\n",
            "Original data shape: (1968, 11)\n",
            "Flattened data shape: (1968, 11)\n",
            "Using provided test data as validation: 1968 train, 413 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.955, 0.96]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1968, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8968, Train Loss: 0.0760, Val Acc: 0.9031, Val Loss: 0.0589\n",
            "Restored model from best epoch 10 with val_loss: 0.058918\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.955-0.96_ep10_valAcc0.9031_valLoss0.0589.pth\n",
            "NFL direct model 192/201 completed\n",
            "Original data shape: (2040, 11)\n",
            "Flattened data shape: (2040, 11)\n",
            "Using provided test data as validation: 2040 train, 480 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.96, 0.965]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2040, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.9078, Train Loss: 0.0739, Val Acc: 0.9146, Val Loss: 0.0584\n",
            "Restored model from best epoch 18 with val_loss: 0.058422\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.96-0.965_ep18_valAcc0.9146_valLoss0.0584.pth\n",
            "NFL direct model 193/201 completed\n",
            "Original data shape: (2016, 11)\n",
            "Flattened data shape: (2016, 11)\n",
            "Using provided test data as validation: 2016 train, 439 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.965, 0.97]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2016, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.9276, Train Loss: 0.0564, Val Acc: 0.9043, Val Loss: 0.0759\n",
            "Restored model from best epoch 18 with val_loss: 0.075867\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.965-0.97_ep18_valAcc0.9043_valLoss0.0759.pth\n",
            "NFL direct model 194/201 completed\n",
            "Original data shape: (4127, 11)\n",
            "Flattened data shape: (4127, 11)\n",
            "Using provided test data as validation: 4127 train, 885 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.97, 0.975]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (4127, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.9106, Train Loss: 0.0689, Val Acc: 0.9096, Val Loss: 0.0707\n",
            "Restored model from best epoch 7 with val_loss: 0.070681\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.97-0.975_ep7_valAcc0.9096_valLoss0.0707.pth\n",
            "NFL direct model 195/201 completed\n",
            "Original data shape: (2114, 11)\n",
            "Flattened data shape: (2114, 11)\n",
            "Using provided test data as validation: 2114 train, 414 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.975, 0.98]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2114, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 46\n",
            "Best epoch: 36, Train Acc: 0.9376, Train Loss: 0.0541, Val Acc: 0.8986, Val Loss: 0.0777\n",
            "Restored model from best epoch 36 with val_loss: 0.077726\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.975-0.98_ep36_valAcc0.8986_valLoss0.0777.pth\n",
            "NFL direct model 196/201 completed\n",
            "Original data shape: (1954, 11)\n",
            "Flattened data shape: (1954, 11)\n",
            "Using provided test data as validation: 1954 train, 441 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.98, 0.985]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1954, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.9237, Train Loss: 0.0591, Val Acc: 0.9093, Val Loss: 0.0688\n",
            "Restored model from best epoch 9 with val_loss: 0.068767\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.98-0.985_ep9_valAcc0.9093_valLoss0.0688.pth\n",
            "NFL direct model 197/201 completed\n",
            "Original data shape: (2042, 11)\n",
            "Flattened data shape: (2042, 11)\n",
            "Using provided test data as validation: 2042 train, 491 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.985, 0.99]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2042, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.9295, Train Loss: 0.0492, Val Acc: 0.9226, Val Loss: 0.0558\n",
            "Restored model from best epoch 12 with val_loss: 0.055817\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.985-0.99_ep12_valAcc0.9226_valLoss0.0558.pth\n",
            "NFL direct model 198/201 completed\n",
            "Original data shape: (1982, 11)\n",
            "Flattened data shape: (1982, 11)\n",
            "Using provided test data as validation: 1982 train, 447 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.99, 0.995]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (1982, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.9339, Train Loss: 0.0516, Val Acc: 0.8881, Val Loss: 0.0809\n",
            "Restored model from best epoch 20 with val_loss: 0.080902\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.99-0.995_ep20_valAcc0.8881_valLoss0.0809.pth\n",
            "NFL direct model 199/201 completed\n",
            "Original data shape: (2120, 11)\n",
            "Flattened data shape: (2120, 11)\n",
            "Using provided test data as validation: 2120 train, 519 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.995, 1.0]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2120, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.9373, Train Loss: 0.0478, Val Acc: 0.8921, Val Loss: 0.0695\n",
            "Restored model from best epoch 10 with val_loss: 0.069537\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_0.995-1.0_ep10_valAcc0.8921_valLoss0.0695.pth\n",
            "NFL direct model 200/201 completed\n",
            "Original data shape: (2697, 11)\n",
            "Flattened data shape: (2697, 11)\n",
            "Using provided test data as validation: 2697 train, 576 validation\n",
            "\n",
            "Training direct prediction model for timestep range [1.0, 1.005]\n",
            "Created neural network with input_dim=11, hidden_dim=128\n",
            "Fitting scaler on training data...\n",
            "Training data shape: (2697, 11)\n",
            "Scaler fitted with 11 features\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.9574, Train Loss: 0.0363, Val Acc: 0.9115, Val Loss: 0.0603\n",
            "Restored model from best epoch 10 with val_loss: 0.060254\n",
            "Direct prediction model saved: saved_models/nfl_direct_model_direct_1.0-1.005_ep10_valAcc0.9115_valLoss0.0603.pth\n",
            "NFL direct model 201/201 completed\n",
            "Processing timestep: 0.0\n",
            "  Timestep 0.00%: Train Loss=0.6114, Acc=0.6598 | Test Loss=0.6612, Acc=0.5995\n",
            "Processing timestep: 0.005\n",
            "  Timestep 0.50%: Train Loss=0.6057, Acc=0.6699 | Test Loss=0.6751, Acc=0.5974\n",
            "Processing timestep: 0.01\n",
            "  Timestep 1.00%: Train Loss=0.6104, Acc=0.6662 | Test Loss=0.6618, Acc=0.6241\n",
            "Processing timestep: 0.015\n",
            "  Timestep 1.50%: Train Loss=0.6036, Acc=0.6740 | Test Loss=0.6686, Acc=0.6194\n",
            "Processing timestep: 0.02\n",
            "  Timestep 2.00%: Train Loss=0.6094, Acc=0.6746 | Test Loss=0.6511, Acc=0.6229\n",
            "Processing timestep: 0.025\n",
            "  Timestep 2.50%: Train Loss=0.6164, Acc=0.6564 | Test Loss=0.6532, Acc=0.6111\n",
            "Processing timestep: 0.03\n",
            "  Timestep 3.00%: Train Loss=0.6029, Acc=0.6774 | Test Loss=0.6551, Acc=0.6091\n",
            "Processing timestep: 0.035\n",
            "  Timestep 3.50%: Train Loss=0.6089, Acc=0.6683 | Test Loss=0.6643, Acc=0.5937\n",
            "Processing timestep: 0.04\n",
            "  Timestep 4.00%: Train Loss=0.5994, Acc=0.6752 | Test Loss=0.6371, Acc=0.6449\n",
            "Processing timestep: 0.045\n",
            "  Timestep 4.50%: Train Loss=0.6088, Acc=0.6678 | Test Loss=0.6605, Acc=0.6250\n",
            "Processing timestep: 0.05\n",
            "  Timestep 5.00%: Train Loss=0.6004, Acc=0.6703 | Test Loss=0.6530, Acc=0.6242\n",
            "Processing timestep: 0.055\n",
            "  Timestep 5.50%: Train Loss=0.6166, Acc=0.6647 | Test Loss=0.6263, Acc=0.6497\n",
            "Processing timestep: 0.06\n",
            "  Timestep 6.00%: Train Loss=0.6012, Acc=0.6744 | Test Loss=0.6569, Acc=0.6151\n",
            "Processing timestep: 0.065\n",
            "  Timestep 6.50%: Train Loss=0.6017, Acc=0.6822 | Test Loss=0.6784, Acc=0.6056\n",
            "Processing timestep: 0.07\n",
            "  Timestep 7.00%: Train Loss=0.5937, Acc=0.6975 | Test Loss=0.6551, Acc=0.6224\n",
            "Processing timestep: 0.075\n",
            "  Timestep 7.50%: Train Loss=0.6008, Acc=0.6768 | Test Loss=0.6420, Acc=0.6316\n",
            "Processing timestep: 0.08\n",
            "  Timestep 8.00%: Train Loss=0.5937, Acc=0.6938 | Test Loss=0.6559, Acc=0.6083\n",
            "Processing timestep: 0.085\n",
            "  Timestep 8.50%: Train Loss=0.5910, Acc=0.6934 | Test Loss=0.6587, Acc=0.6038\n",
            "Processing timestep: 0.09\n",
            "  Timestep 9.00%: Train Loss=0.5957, Acc=0.6859 | Test Loss=0.6542, Acc=0.6394\n",
            "Processing timestep: 0.095\n",
            "  Timestep 9.50%: Train Loss=0.5963, Acc=0.6772 | Test Loss=0.6563, Acc=0.6164\n",
            "Processing timestep: 0.1\n",
            "  Timestep 10.00%: Train Loss=0.5902, Acc=0.6898 | Test Loss=0.6453, Acc=0.6281\n",
            "Processing timestep: 0.105\n",
            "  Timestep 10.50%: Train Loss=0.5712, Acc=0.6969 | Test Loss=0.6325, Acc=0.6472\n",
            "Processing timestep: 0.11\n",
            "  Timestep 11.00%: Train Loss=0.5940, Acc=0.6886 | Test Loss=0.6572, Acc=0.6172\n",
            "Processing timestep: 0.115\n",
            "  Timestep 11.50%: Train Loss=0.5828, Acc=0.6930 | Test Loss=0.6376, Acc=0.6374\n",
            "Processing timestep: 0.12\n",
            "  Timestep 12.00%: Train Loss=0.5763, Acc=0.6975 | Test Loss=0.6231, Acc=0.6454\n",
            "Processing timestep: 0.125\n",
            "  Timestep 12.50%: Train Loss=0.5713, Acc=0.6975 | Test Loss=0.6652, Acc=0.6375\n",
            "Processing timestep: 0.13\n",
            "  Timestep 13.00%: Train Loss=0.5777, Acc=0.6939 | Test Loss=0.6365, Acc=0.6581\n",
            "Processing timestep: 0.135\n",
            "  Timestep 13.50%: Train Loss=0.5818, Acc=0.6916 | Test Loss=0.6277, Acc=0.6478\n",
            "Processing timestep: 0.14\n",
            "  Timestep 14.00%: Train Loss=0.5728, Acc=0.7026 | Test Loss=0.6422, Acc=0.6355\n",
            "Processing timestep: 0.145\n",
            "  Timestep 14.50%: Train Loss=0.5654, Acc=0.7109 | Test Loss=0.6143, Acc=0.6613\n",
            "Processing timestep: 0.15\n",
            "  Timestep 15.00%: Train Loss=0.5817, Acc=0.7060 | Test Loss=0.6431, Acc=0.6390\n",
            "Processing timestep: 0.155\n",
            "  Timestep 15.50%: Train Loss=0.5622, Acc=0.7217 | Test Loss=0.6231, Acc=0.6551\n",
            "Processing timestep: 0.16\n",
            "  Timestep 16.00%: Train Loss=0.5641, Acc=0.7093 | Test Loss=0.6426, Acc=0.6278\n",
            "Processing timestep: 0.165\n",
            "  Timestep 16.50%: Train Loss=0.5739, Acc=0.7003 | Test Loss=0.6269, Acc=0.6254\n",
            "Processing timestep: 0.17\n",
            "  Timestep 17.00%: Train Loss=0.5630, Acc=0.7120 | Test Loss=0.6216, Acc=0.6570\n",
            "Processing timestep: 0.175\n",
            "  Timestep 17.50%: Train Loss=0.5684, Acc=0.7085 | Test Loss=0.6140, Acc=0.6636\n",
            "Processing timestep: 0.18\n",
            "  Timestep 18.00%: Train Loss=0.5710, Acc=0.7005 | Test Loss=0.6198, Acc=0.6364\n",
            "Processing timestep: 0.185\n",
            "  Timestep 18.50%: Train Loss=0.5526, Acc=0.7229 | Test Loss=0.6315, Acc=0.6562\n",
            "Processing timestep: 0.19\n",
            "  Timestep 19.00%: Train Loss=0.5536, Acc=0.7188 | Test Loss=0.6732, Acc=0.6201\n",
            "Processing timestep: 0.195\n",
            "  Timestep 19.50%: Train Loss=0.5508, Acc=0.7216 | Test Loss=0.6003, Acc=0.6844\n",
            "Processing timestep: 0.2\n",
            "  Timestep 20.00%: Train Loss=0.5581, Acc=0.7135 | Test Loss=0.6008, Acc=0.6793\n",
            "Processing timestep: 0.205\n",
            "  Timestep 20.50%: Train Loss=0.5481, Acc=0.7229 | Test Loss=0.6033, Acc=0.6925\n",
            "Processing timestep: 0.21\n",
            "  Timestep 21.00%: Train Loss=0.5520, Acc=0.7211 | Test Loss=0.5987, Acc=0.6687\n",
            "Processing timestep: 0.215\n",
            "  Timestep 21.50%: Train Loss=0.5527, Acc=0.7136 | Test Loss=0.5876, Acc=0.6855\n",
            "Processing timestep: 0.22\n",
            "  Timestep 22.00%: Train Loss=0.5467, Acc=0.7198 | Test Loss=0.5932, Acc=0.6677\n",
            "Processing timestep: 0.225\n",
            "  Timestep 22.50%: Train Loss=0.5380, Acc=0.7300 | Test Loss=0.6009, Acc=0.6907\n",
            "Processing timestep: 0.23\n",
            "  Timestep 23.00%: Train Loss=0.5410, Acc=0.7278 | Test Loss=0.6084, Acc=0.6867\n",
            "Processing timestep: 0.235\n",
            "  Timestep 23.50%: Train Loss=0.5448, Acc=0.7190 | Test Loss=0.5833, Acc=0.6893\n",
            "Processing timestep: 0.24\n",
            "  Timestep 24.00%: Train Loss=0.5509, Acc=0.7127 | Test Loss=0.5894, Acc=0.6914\n",
            "Processing timestep: 0.245\n",
            "  Timestep 24.50%: Train Loss=0.5310, Acc=0.7358 | Test Loss=0.5904, Acc=0.6865\n",
            "Processing timestep: 0.25\n",
            "  Timestep 25.00%: Train Loss=0.5342, Acc=0.7279 | Test Loss=0.6014, Acc=0.6849\n",
            "Processing timestep: 0.255\n",
            "  Timestep 25.50%: Train Loss=0.5430, Acc=0.7163 | Test Loss=0.5715, Acc=0.6882\n",
            "Processing timestep: 0.26\n",
            "  Timestep 26.00%: Train Loss=0.5453, Acc=0.7172 | Test Loss=0.5760, Acc=0.6961\n",
            "Processing timestep: 0.265\n",
            "  Timestep 26.50%: Train Loss=0.5293, Acc=0.7274 | Test Loss=0.5725, Acc=0.6899\n",
            "Processing timestep: 0.27\n",
            "  Timestep 27.00%: Train Loss=0.5347, Acc=0.7262 | Test Loss=0.5988, Acc=0.6799\n",
            "Processing timestep: 0.275\n",
            "  Timestep 27.50%: Train Loss=0.5271, Acc=0.7285 | Test Loss=0.5763, Acc=0.6758\n",
            "Processing timestep: 0.28\n",
            "  Timestep 28.00%: Train Loss=0.5443, Acc=0.7231 | Test Loss=0.5654, Acc=0.6921\n",
            "Processing timestep: 0.285\n",
            "  Timestep 28.50%: Train Loss=0.5154, Acc=0.7512 | Test Loss=0.6014, Acc=0.6923\n",
            "Processing timestep: 0.29\n",
            "  Timestep 29.00%: Train Loss=0.5222, Acc=0.7278 | Test Loss=0.5994, Acc=0.6637\n",
            "Processing timestep: 0.295\n",
            "  Timestep 29.50%: Train Loss=0.5258, Acc=0.7276 | Test Loss=0.5879, Acc=0.6865\n",
            "Processing timestep: 0.3\n",
            "  Timestep 30.00%: Train Loss=0.5350, Acc=0.7240 | Test Loss=0.5655, Acc=0.7000\n",
            "Processing timestep: 0.305\n",
            "  Timestep 30.50%: Train Loss=0.5273, Acc=0.7254 | Test Loss=0.5746, Acc=0.6947\n",
            "Processing timestep: 0.31\n",
            "  Timestep 31.00%: Train Loss=0.5129, Acc=0.7373 | Test Loss=0.6053, Acc=0.6708\n",
            "Processing timestep: 0.315\n",
            "  Timestep 31.50%: Train Loss=0.5308, Acc=0.7197 | Test Loss=0.6130, Acc=0.6543\n",
            "Processing timestep: 0.32\n",
            "  Timestep 32.00%: Train Loss=0.5092, Acc=0.7303 | Test Loss=0.5572, Acc=0.7259\n",
            "Processing timestep: 0.325\n",
            "  Timestep 32.50%: Train Loss=0.5220, Acc=0.7230 | Test Loss=0.5589, Acc=0.7222\n",
            "Processing timestep: 0.33\n",
            "  Timestep 33.00%: Train Loss=0.5034, Acc=0.7321 | Test Loss=0.5815, Acc=0.7170\n",
            "Processing timestep: 0.335\n",
            "  Timestep 33.50%: Train Loss=0.5070, Acc=0.7373 | Test Loss=0.5202, Acc=0.7315\n",
            "Processing timestep: 0.34\n",
            "  Timestep 34.00%: Train Loss=0.4908, Acc=0.7473 | Test Loss=0.5238, Acc=0.7640\n",
            "Processing timestep: 0.345\n",
            "  Timestep 34.50%: Train Loss=0.4922, Acc=0.7490 | Test Loss=0.5444, Acc=0.7405\n",
            "Processing timestep: 0.35\n",
            "  Timestep 35.00%: Train Loss=0.5006, Acc=0.7437 | Test Loss=0.5605, Acc=0.7321\n",
            "Processing timestep: 0.355\n",
            "  Timestep 35.50%: Train Loss=0.5022, Acc=0.7373 | Test Loss=0.5872, Acc=0.7122\n",
            "Processing timestep: 0.36\n",
            "  Timestep 36.00%: Train Loss=0.5081, Acc=0.7449 | Test Loss=0.5830, Acc=0.7234\n",
            "Processing timestep: 0.365\n",
            "  Timestep 36.50%: Train Loss=0.4962, Acc=0.7533 | Test Loss=0.5214, Acc=0.7493\n",
            "Processing timestep: 0.37\n",
            "  Timestep 37.00%: Train Loss=0.5071, Acc=0.7490 | Test Loss=0.5687, Acc=0.7070\n",
            "Processing timestep: 0.375\n",
            "  Timestep 37.50%: Train Loss=0.4961, Acc=0.7477 | Test Loss=0.5176, Acc=0.7493\n",
            "Processing timestep: 0.38\n",
            "  Timestep 38.00%: Train Loss=0.5005, Acc=0.7508 | Test Loss=0.5288, Acc=0.7316\n",
            "Processing timestep: 0.385\n",
            "  Timestep 38.50%: Train Loss=0.4977, Acc=0.7473 | Test Loss=0.5311, Acc=0.7380\n",
            "Processing timestep: 0.39\n",
            "  Timestep 39.00%: Train Loss=0.4920, Acc=0.7507 | Test Loss=0.5590, Acc=0.7066\n",
            "Processing timestep: 0.395\n",
            "  Timestep 39.50%: Train Loss=0.4865, Acc=0.7575 | Test Loss=0.5584, Acc=0.7138\n",
            "Processing timestep: 0.4\n",
            "  Timestep 40.00%: Train Loss=0.4967, Acc=0.7470 | Test Loss=0.5020, Acc=0.7529\n",
            "Processing timestep: 0.405\n",
            "  Timestep 40.50%: Train Loss=0.4897, Acc=0.7592 | Test Loss=0.5348, Acc=0.7264\n",
            "Processing timestep: 0.41\n",
            "  Timestep 41.00%: Train Loss=0.4818, Acc=0.7616 | Test Loss=0.5470, Acc=0.7380\n",
            "Processing timestep: 0.415\n",
            "  Timestep 41.50%: Train Loss=0.4784, Acc=0.7667 | Test Loss=0.5628, Acc=0.7175\n",
            "Processing timestep: 0.42\n",
            "  Timestep 42.00%: Train Loss=0.4962, Acc=0.7465 | Test Loss=0.5396, Acc=0.7296\n",
            "Processing timestep: 0.425\n",
            "  Timestep 42.50%: Train Loss=0.4869, Acc=0.7518 | Test Loss=0.5615, Acc=0.7233\n",
            "Processing timestep: 0.43\n",
            "  Timestep 43.00%: Train Loss=0.4840, Acc=0.7521 | Test Loss=0.5207, Acc=0.7572\n",
            "Processing timestep: 0.435\n",
            "  Timestep 43.50%: Train Loss=0.4792, Acc=0.7635 | Test Loss=0.5013, Acc=0.7603\n",
            "Processing timestep: 0.44\n",
            "  Timestep 44.00%: Train Loss=0.4733, Acc=0.7602 | Test Loss=0.5268, Acc=0.7356\n",
            "Processing timestep: 0.445\n",
            "  Timestep 44.50%: Train Loss=0.4827, Acc=0.7552 | Test Loss=0.5209, Acc=0.7507\n",
            "Processing timestep: 0.45\n",
            "  Timestep 45.00%: Train Loss=0.4841, Acc=0.7640 | Test Loss=0.5154, Acc=0.7450\n",
            "Processing timestep: 0.455\n",
            "  Timestep 45.50%: Train Loss=0.4749, Acc=0.7695 | Test Loss=0.5010, Acc=0.7539\n",
            "Processing timestep: 0.46\n",
            "  Timestep 46.00%: Train Loss=0.4640, Acc=0.7708 | Test Loss=0.5283, Acc=0.7453\n",
            "Processing timestep: 0.465\n",
            "  Timestep 46.50%: Train Loss=0.4548, Acc=0.7873 | Test Loss=0.5209, Acc=0.7630\n",
            "Processing timestep: 0.47\n",
            "  Timestep 47.00%: Train Loss=0.4571, Acc=0.7784 | Test Loss=0.5211, Acc=0.7466\n",
            "Processing timestep: 0.475\n",
            "  Timestep 47.50%: Train Loss=0.4395, Acc=0.7883 | Test Loss=0.4970, Acc=0.7535\n",
            "Processing timestep: 0.48\n",
            "  Timestep 48.00%: Train Loss=0.4387, Acc=0.7905 | Test Loss=0.4956, Acc=0.7665\n",
            "Processing timestep: 0.485\n",
            "  Timestep 48.50%: Train Loss=0.4491, Acc=0.7897 | Test Loss=0.5313, Acc=0.7042\n",
            "Processing timestep: 0.49\n",
            "  Timestep 49.00%: Train Loss=0.4414, Acc=0.7926 | Test Loss=0.4985, Acc=0.7776\n",
            "Processing timestep: 0.495\n",
            "  Timestep 49.50%: Train Loss=0.4295, Acc=0.8069 | Test Loss=0.4984, Acc=0.7683\n",
            "Processing timestep: 0.5\n",
            "  Timestep 50.00%: Train Loss=0.4198, Acc=0.8132 | Test Loss=0.4630, Acc=0.7734\n",
            "Processing timestep: 0.505\n",
            "  Timestep 50.50%: Train Loss=0.4189, Acc=0.8046 | Test Loss=0.4339, Acc=0.7923\n",
            "Processing timestep: 0.51\n",
            "  Timestep 51.00%: Train Loss=0.4111, Acc=0.8128 | Test Loss=0.4478, Acc=0.7929\n",
            "Processing timestep: 0.515\n",
            "  Timestep 51.50%: Train Loss=0.4236, Acc=0.8102 | Test Loss=0.4362, Acc=0.7910\n",
            "Processing timestep: 0.52\n",
            "  Timestep 52.00%: Train Loss=0.4142, Acc=0.8127 | Test Loss=0.4687, Acc=0.7712\n",
            "Processing timestep: 0.525\n",
            "  Timestep 52.50%: Train Loss=0.4084, Acc=0.8147 | Test Loss=0.4418, Acc=0.7922\n",
            "Processing timestep: 0.53\n",
            "  Timestep 53.00%: Train Loss=0.4166, Acc=0.8098 | Test Loss=0.4749, Acc=0.7733\n",
            "Processing timestep: 0.535\n",
            "  Timestep 53.50%: Train Loss=0.4087, Acc=0.8233 | Test Loss=0.4375, Acc=0.7941\n",
            "Processing timestep: 0.54\n",
            "  Timestep 54.00%: Train Loss=0.3998, Acc=0.8184 | Test Loss=0.4259, Acc=0.7975\n",
            "Processing timestep: 0.545\n",
            "  Timestep 54.50%: Train Loss=0.4140, Acc=0.8171 | Test Loss=0.4494, Acc=0.7963\n",
            "Processing timestep: 0.55\n",
            "  Timestep 55.00%: Train Loss=0.4049, Acc=0.8207 | Test Loss=0.4242, Acc=0.8088\n",
            "Processing timestep: 0.555\n",
            "  Timestep 55.50%: Train Loss=0.4134, Acc=0.8137 | Test Loss=0.4206, Acc=0.8123\n",
            "Processing timestep: 0.56\n",
            "  Timestep 56.00%: Train Loss=0.4066, Acc=0.8251 | Test Loss=0.4355, Acc=0.8098\n",
            "Processing timestep: 0.565\n",
            "  Timestep 56.50%: Train Loss=0.4041, Acc=0.8191 | Test Loss=0.4375, Acc=0.8084\n",
            "Processing timestep: 0.57\n",
            "  Timestep 57.00%: Train Loss=0.3980, Acc=0.8251 | Test Loss=0.4366, Acc=0.8097\n",
            "Processing timestep: 0.575\n",
            "  Timestep 57.50%: Train Loss=0.4015, Acc=0.8161 | Test Loss=0.4384, Acc=0.7799\n",
            "Processing timestep: 0.58\n",
            "  Timestep 58.00%: Train Loss=0.4006, Acc=0.8216 | Test Loss=0.4176, Acc=0.8026\n",
            "Processing timestep: 0.585\n",
            "  Timestep 58.50%: Train Loss=0.4092, Acc=0.8135 | Test Loss=0.4062, Acc=0.8141\n",
            "Processing timestep: 0.59\n",
            "  Timestep 59.00%: Train Loss=0.4130, Acc=0.8110 | Test Loss=0.4028, Acc=0.8155\n",
            "Processing timestep: 0.595\n",
            "  Timestep 59.50%: Train Loss=0.4142, Acc=0.8127 | Test Loss=0.4168, Acc=0.7994\n",
            "Processing timestep: 0.6\n",
            "  Timestep 60.00%: Train Loss=0.4053, Acc=0.8086 | Test Loss=0.4187, Acc=0.8036\n",
            "Processing timestep: 0.605\n",
            "  Timestep 60.50%: Train Loss=0.4025, Acc=0.8098 | Test Loss=0.4127, Acc=0.8119\n",
            "Processing timestep: 0.61\n",
            "  Timestep 61.00%: Train Loss=0.3950, Acc=0.8180 | Test Loss=0.4476, Acc=0.7814\n",
            "Processing timestep: 0.615\n",
            "  Timestep 61.50%: Train Loss=0.3997, Acc=0.8112 | Test Loss=0.4025, Acc=0.8142\n",
            "Processing timestep: 0.62\n",
            "  Timestep 62.00%: Train Loss=0.3987, Acc=0.8192 | Test Loss=0.4065, Acc=0.8125\n",
            "Processing timestep: 0.625\n",
            "  Timestep 62.50%: Train Loss=0.4080, Acc=0.8195 | Test Loss=0.4043, Acc=0.8187\n",
            "Processing timestep: 0.63\n",
            "  Timestep 63.00%: Train Loss=0.3964, Acc=0.8190 | Test Loss=0.4022, Acc=0.8073\n",
            "Processing timestep: 0.635\n",
            "  Timestep 63.50%: Train Loss=0.3926, Acc=0.8250 | Test Loss=0.3939, Acc=0.8283\n",
            "Processing timestep: 0.64\n",
            "  Timestep 64.00%: Train Loss=0.3990, Acc=0.8184 | Test Loss=0.3982, Acc=0.8148\n",
            "Processing timestep: 0.645\n",
            "  Timestep 64.50%: Train Loss=0.3950, Acc=0.8178 | Test Loss=0.3756, Acc=0.8324\n",
            "Processing timestep: 0.65\n",
            "  Timestep 65.00%: Train Loss=0.3862, Acc=0.8322 | Test Loss=0.3728, Acc=0.8224\n",
            "Processing timestep: 0.655\n",
            "  Timestep 65.50%: Train Loss=0.3868, Acc=0.8291 | Test Loss=0.3662, Acc=0.8266\n",
            "Processing timestep: 0.66\n",
            "  Timestep 66.00%: Train Loss=0.3826, Acc=0.8249 | Test Loss=0.3705, Acc=0.8113\n",
            "Processing timestep: 0.665\n",
            "  Timestep 66.50%: Train Loss=0.3826, Acc=0.8176 | Test Loss=0.3647, Acc=0.8179\n",
            "Processing timestep: 0.67\n",
            "  Timestep 67.00%: Train Loss=0.3764, Acc=0.8317 | Test Loss=0.3580, Acc=0.8374\n",
            "Processing timestep: 0.675\n",
            "  Timestep 67.50%: Train Loss=0.3779, Acc=0.8259 | Test Loss=0.3643, Acc=0.8353\n",
            "Processing timestep: 0.68\n",
            "  Timestep 68.00%: Train Loss=0.3749, Acc=0.8312 | Test Loss=0.3563, Acc=0.8438\n",
            "Processing timestep: 0.685\n",
            "  Timestep 68.50%: Train Loss=0.3759, Acc=0.8304 | Test Loss=0.3274, Acc=0.8531\n",
            "Processing timestep: 0.69\n",
            "  Timestep 69.00%: Train Loss=0.3914, Acc=0.8197 | Test Loss=0.3505, Acc=0.8399\n",
            "Processing timestep: 0.695\n",
            "  Timestep 69.50%: Train Loss=0.3669, Acc=0.8364 | Test Loss=0.4100, Acc=0.8148\n",
            "Processing timestep: 0.7\n",
            "  Timestep 70.00%: Train Loss=0.3609, Acc=0.8296 | Test Loss=0.4063, Acc=0.8153\n",
            "Processing timestep: 0.705\n",
            "  Timestep 70.50%: Train Loss=0.3664, Acc=0.8302 | Test Loss=0.3498, Acc=0.8395\n",
            "Processing timestep: 0.71\n",
            "  Timestep 71.00%: Train Loss=0.3465, Acc=0.8456 | Test Loss=0.3533, Acc=0.8404\n",
            "Processing timestep: 0.715\n",
            "  Timestep 71.50%: Train Loss=0.3564, Acc=0.8413 | Test Loss=0.3535, Acc=0.8364\n",
            "Processing timestep: 0.72\n",
            "  Timestep 72.00%: Train Loss=0.3559, Acc=0.8484 | Test Loss=0.3486, Acc=0.8292\n",
            "Processing timestep: 0.725\n",
            "  Timestep 72.50%: Train Loss=0.3574, Acc=0.8365 | Test Loss=0.3589, Acc=0.8512\n",
            "Processing timestep: 0.73\n",
            "  Timestep 73.00%: Train Loss=0.3471, Acc=0.8393 | Test Loss=0.3492, Acc=0.8293\n",
            "Processing timestep: 0.735\n",
            "  Timestep 73.50%: Train Loss=0.3333, Acc=0.8489 | Test Loss=0.3340, Acc=0.8476\n",
            "Processing timestep: 0.74\n",
            "  Timestep 74.00%: Train Loss=0.3381, Acc=0.8431 | Test Loss=0.3207, Acc=0.8466\n",
            "Processing timestep: 0.745\n",
            "  Timestep 74.50%: Train Loss=0.3450, Acc=0.8492 | Test Loss=0.3612, Acc=0.8338\n",
            "Processing timestep: 0.75\n",
            "  Timestep 75.00%: Train Loss=0.3306, Acc=0.8520 | Test Loss=0.3372, Acc=0.8437\n",
            "Processing timestep: 0.755\n",
            "  Timestep 75.50%: Train Loss=0.3188, Acc=0.8619 | Test Loss=0.3336, Acc=0.8490\n",
            "Processing timestep: 0.76\n",
            "  Timestep 76.00%: Train Loss=0.3191, Acc=0.8615 | Test Loss=0.3491, Acc=0.8475\n",
            "Processing timestep: 0.765\n",
            "  Timestep 76.50%: Train Loss=0.3296, Acc=0.8569 | Test Loss=0.3461, Acc=0.8338\n",
            "Processing timestep: 0.77\n",
            "  Timestep 77.00%: Train Loss=0.3182, Acc=0.8561 | Test Loss=0.3308, Acc=0.8416\n",
            "Processing timestep: 0.775\n",
            "  Timestep 77.50%: Train Loss=0.3165, Acc=0.8576 | Test Loss=0.3205, Acc=0.8459\n",
            "Processing timestep: 0.78\n",
            "  Timestep 78.00%: Train Loss=0.3092, Acc=0.8599 | Test Loss=0.3119, Acc=0.8512\n",
            "Processing timestep: 0.785\n",
            "  Timestep 78.50%: Train Loss=0.3124, Acc=0.8621 | Test Loss=0.3389, Acc=0.8419\n",
            "Processing timestep: 0.79\n",
            "  Timestep 79.00%: Train Loss=0.2957, Acc=0.8729 | Test Loss=0.3176, Acc=0.8571\n",
            "Processing timestep: 0.795\n",
            "  Timestep 79.50%: Train Loss=0.3073, Acc=0.8651 | Test Loss=0.3405, Acc=0.8494\n",
            "Processing timestep: 0.8\n",
            "  Timestep 80.00%: Train Loss=0.3167, Acc=0.8586 | Test Loss=0.3666, Acc=0.8416\n",
            "Processing timestep: 0.805\n",
            "  Timestep 80.50%: Train Loss=0.3136, Acc=0.8635 | Test Loss=0.3061, Acc=0.8650\n",
            "Processing timestep: 0.81\n",
            "  Timestep 81.00%: Train Loss=0.3060, Acc=0.8653 | Test Loss=0.2982, Acc=0.8657\n",
            "Processing timestep: 0.815\n",
            "  Timestep 81.50%: Train Loss=0.2996, Acc=0.8745 | Test Loss=0.2996, Acc=0.8768\n",
            "Processing timestep: 0.82\n",
            "  Timestep 82.00%: Train Loss=0.2987, Acc=0.8674 | Test Loss=0.2818, Acc=0.8783\n",
            "Processing timestep: 0.825\n",
            "  Timestep 82.50%: Train Loss=0.3012, Acc=0.8643 | Test Loss=0.3009, Acc=0.8563\n",
            "Processing timestep: 0.83\n",
            "  Timestep 83.00%: Train Loss=0.2928, Acc=0.8659 | Test Loss=0.3185, Acc=0.8550\n",
            "Processing timestep: 0.835\n",
            "  Timestep 83.50%: Train Loss=0.2717, Acc=0.8842 | Test Loss=0.3059, Acc=0.8602\n",
            "Processing timestep: 0.84\n",
            "  Timestep 84.00%: Train Loss=0.2792, Acc=0.8739 | Test Loss=0.2979, Acc=0.8611\n",
            "Processing timestep: 0.845\n",
            "  Timestep 84.50%: Train Loss=0.2841, Acc=0.8726 | Test Loss=0.3012, Acc=0.8727\n",
            "Processing timestep: 0.85\n",
            "  Timestep 85.00%: Train Loss=0.2800, Acc=0.8690 | Test Loss=0.2808, Acc=0.8746\n",
            "Processing timestep: 0.855\n",
            "  Timestep 85.50%: Train Loss=0.2762, Acc=0.8739 | Test Loss=0.2754, Acc=0.8754\n",
            "Processing timestep: 0.86\n",
            "  Timestep 86.00%: Train Loss=0.2827, Acc=0.8724 | Test Loss=0.2676, Acc=0.8789\n",
            "Processing timestep: 0.865\n",
            "  Timestep 86.50%: Train Loss=0.2797, Acc=0.8710 | Test Loss=0.2526, Acc=0.8960\n",
            "Processing timestep: 0.87\n",
            "  Timestep 87.00%: Train Loss=0.2861, Acc=0.8699 | Test Loss=0.2666, Acc=0.8896\n",
            "Processing timestep: 0.875\n",
            "  Timestep 87.50%: Train Loss=0.2686, Acc=0.8829 | Test Loss=0.2503, Acc=0.8846\n",
            "Processing timestep: 0.88\n",
            "  Timestep 88.00%: Train Loss=0.2687, Acc=0.8798 | Test Loss=0.2805, Acc=0.8717\n",
            "Processing timestep: 0.885\n",
            "  Timestep 88.50%: Train Loss=0.2773, Acc=0.8704 | Test Loss=0.2359, Acc=0.8939\n",
            "Processing timestep: 0.89\n",
            "  Timestep 89.00%: Train Loss=0.2793, Acc=0.8718 | Test Loss=0.2753, Acc=0.8627\n",
            "Processing timestep: 0.895\n",
            "  Timestep 89.50%: Train Loss=0.2525, Acc=0.8860 | Test Loss=0.2363, Acc=0.8853\n",
            "Processing timestep: 0.9\n",
            "  Timestep 90.00%: Train Loss=0.2624, Acc=0.8815 | Test Loss=0.3127, Acc=0.8520\n",
            "Processing timestep: 0.905\n",
            "  Timestep 90.50%: Train Loss=0.2532, Acc=0.8843 | Test Loss=0.2605, Acc=0.8636\n",
            "Processing timestep: 0.91\n",
            "  Timestep 91.00%: Train Loss=0.2440, Acc=0.8874 | Test Loss=0.2596, Acc=0.8786\n",
            "Processing timestep: 0.915\n",
            "  Timestep 91.50%: Train Loss=0.2341, Acc=0.8977 | Test Loss=0.2382, Acc=0.8920\n",
            "Processing timestep: 0.92\n",
            "  Timestep 92.00%: Train Loss=0.2493, Acc=0.8862 | Test Loss=0.2670, Acc=0.8788\n",
            "Processing timestep: 0.925\n",
            "  Timestep 92.50%: Train Loss=0.2300, Acc=0.9032 | Test Loss=0.2603, Acc=0.8864\n",
            "Processing timestep: 0.93\n",
            "  Timestep 93.00%: Train Loss=0.2157, Acc=0.9073 | Test Loss=0.2551, Acc=0.8983\n",
            "Processing timestep: 0.935\n",
            "  Timestep 93.50%: Train Loss=0.2314, Acc=0.8975 | Test Loss=0.2411, Acc=0.8953\n",
            "Processing timestep: 0.94\n",
            "  Timestep 94.00%: Train Loss=0.2170, Acc=0.9047 | Test Loss=0.2035, Acc=0.9062\n",
            "Processing timestep: 0.945\n",
            "  Timestep 94.50%: Train Loss=0.2045, Acc=0.9138 | Test Loss=0.2108, Acc=0.9126\n",
            "Processing timestep: 0.95\n",
            "  Timestep 95.00%: Train Loss=0.2238, Acc=0.8961 | Test Loss=0.2457, Acc=0.8963\n",
            "Processing timestep: 0.955\n",
            "  Timestep 95.50%: Train Loss=0.2277, Acc=0.8938 | Test Loss=0.2138, Acc=0.9007\n",
            "Processing timestep: 0.96\n",
            "  Timestep 96.00%: Train Loss=0.2289, Acc=0.8951 | Test Loss=0.2144, Acc=0.9000\n",
            "Processing timestep: 0.965\n",
            "  Timestep 96.50%: Train Loss=0.2043, Acc=0.9082 | Test Loss=0.2278, Acc=0.8884\n",
            "Processing timestep: 0.97\n",
            "  Timestep 97.00%: Train Loss=0.2178, Acc=0.9016 | Test Loss=0.2372, Acc=0.8938\n",
            "Processing timestep: 0.975\n",
            "  Timestep 97.50%: Train Loss=0.2133, Acc=0.9040 | Test Loss=0.2611, Acc=0.8816\n",
            "Processing timestep: 0.98\n",
            "  Timestep 98.00%: Train Loss=0.1975, Acc=0.9161 | Test Loss=0.1959, Acc=0.9093\n",
            "Processing timestep: 0.985\n",
            "  Timestep 98.50%: Train Loss=0.1751, Acc=0.9256 | Test Loss=0.1996, Acc=0.9084\n",
            "Processing timestep: 0.99\n",
            "  Timestep 99.00%: Train Loss=0.2060, Acc=0.9051 | Test Loss=0.2582, Acc=0.8792\n",
            "Processing timestep: 0.995\n",
            "  Timestep 99.50%: Train Loss=0.1796, Acc=0.9349 | Test Loss=0.2544, Acc=0.8902\n",
            "Processing timestep: 1.0\n",
            "  Timestep 100.00%: Train Loss=0.1487, Acc=0.9544 | Test Loss=0.1856, Acc=0.9097\n"
          ]
        }
      ],
      "source": [
        "print(\"Training individual models...\")\n",
        "all_models = {}\n",
        "all_models[\"lstm\"] = setup_direct_lstm_models(training_data_seq, validation_data_seq, num_models=201)\n",
        "all_models[\"nn\"] = setup_direct_models(training_data, validation_data, num_models=201)\n",
        "all_models[\"logistic\"] = setup_logistic_regression_models(training_data, validation_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestep 0.00%: Training Loss = 0.2145, Accuracy = 0.6670, Validation Loss = 0.2351, Validation Accuracy = 0.6019\n",
            "Timestep 0.50%: Training Loss = 0.2129, Accuracy = 0.6630, Validation Loss = 0.2315, Validation Accuracy = 0.6136\n",
            "Timestep 1.00%: Training Loss = 0.2150, Accuracy = 0.6669, Validation Loss = 0.2328, Validation Accuracy = 0.6170\n",
            "Timestep 1.50%: Training Loss = 0.2091, Accuracy = 0.6704, Validation Loss = 0.2247, Validation Accuracy = 0.6258\n",
            "Timestep 2.00%: Training Loss = 0.2131, Accuracy = 0.6634, Validation Loss = 0.2280, Validation Accuracy = 0.6162\n",
            "Timestep 2.50%: Training Loss = 0.2155, Accuracy = 0.6728, Validation Loss = 0.2308, Validation Accuracy = 0.6013\n",
            "Timestep 3.00%: Training Loss = 0.2108, Accuracy = 0.6718, Validation Loss = 0.2294, Validation Accuracy = 0.6221\n",
            "Timestep 3.50%: Training Loss = 0.2132, Accuracy = 0.6697, Validation Loss = 0.2308, Validation Accuracy = 0.6063\n",
            "Timestep 4.00%: Training Loss = 0.2116, Accuracy = 0.6676, Validation Loss = 0.2189, Validation Accuracy = 0.6573\n",
            "Timestep 4.50%: Training Loss = 0.2139, Accuracy = 0.6733, Validation Loss = 0.2305, Validation Accuracy = 0.6250\n",
            "Timestep 5.00%: Training Loss = 0.2107, Accuracy = 0.6683, Validation Loss = 0.2273, Validation Accuracy = 0.6338\n",
            "Timestep 5.50%: Training Loss = 0.2138, Accuracy = 0.6599, Validation Loss = 0.2223, Validation Accuracy = 0.6467\n",
            "Timestep 6.00%: Training Loss = 0.2127, Accuracy = 0.6935, Validation Loss = 0.2309, Validation Accuracy = 0.6246\n",
            "Timestep 6.50%: Training Loss = 0.2123, Accuracy = 0.6722, Validation Loss = 0.2362, Validation Accuracy = 0.5963\n",
            "Timestep 7.00%: Training Loss = 0.2103, Accuracy = 0.7063, Validation Loss = 0.2327, Validation Accuracy = 0.5988\n",
            "Timestep 7.50%: Training Loss = 0.2071, Accuracy = 0.6788, Validation Loss = 0.2281, Validation Accuracy = 0.6347\n",
            "Timestep 8.00%: Training Loss = 0.2064, Accuracy = 0.7044, Validation Loss = 0.2327, Validation Accuracy = 0.6115\n",
            "Timestep 8.50%: Training Loss = 0.2110, Accuracy = 0.6914, Validation Loss = 0.2363, Validation Accuracy = 0.5849\n",
            "Timestep 9.00%: Training Loss = 0.2092, Accuracy = 0.6762, Validation Loss = 0.2293, Validation Accuracy = 0.6242\n",
            "Timestep 9.50%: Training Loss = 0.2105, Accuracy = 0.6839, Validation Loss = 0.2322, Validation Accuracy = 0.6132\n",
            "Timestep 10.00%: Training Loss = 0.2039, Accuracy = 0.6969, Validation Loss = 0.2290, Validation Accuracy = 0.6219\n",
            "Timestep 10.50%: Training Loss = 0.1977, Accuracy = 0.7107, Validation Loss = 0.2238, Validation Accuracy = 0.6440\n",
            "Timestep 11.00%: Training Loss = 0.2095, Accuracy = 0.6940, Validation Loss = 0.2313, Validation Accuracy = 0.5727\n",
            "Timestep 11.50%: Training Loss = 0.2034, Accuracy = 0.7074, Validation Loss = 0.2263, Validation Accuracy = 0.6228\n",
            "Timestep 12.00%: Training Loss = 0.2007, Accuracy = 0.7057, Validation Loss = 0.2263, Validation Accuracy = 0.6102\n",
            "Timestep 12.50%: Training Loss = 0.2079, Accuracy = 0.7063, Validation Loss = 0.2344, Validation Accuracy = 0.5921\n",
            "Timestep 13.00%: Training Loss = 0.1993, Accuracy = 0.6933, Validation Loss = 0.2264, Validation Accuracy = 0.6194\n",
            "Timestep 13.50%: Training Loss = 0.2033, Accuracy = 0.6923, Validation Loss = 0.2233, Validation Accuracy = 0.6258\n",
            "Timestep 14.00%: Training Loss = 0.2056, Accuracy = 0.6931, Validation Loss = 0.2306, Validation Accuracy = 0.6199\n",
            "Timestep 14.50%: Training Loss = 0.1913, Accuracy = 0.7183, Validation Loss = 0.2202, Validation Accuracy = 0.6516\n",
            "Timestep 15.00%: Training Loss = 0.2040, Accuracy = 0.7060, Validation Loss = 0.2273, Validation Accuracy = 0.6390\n",
            "Timestep 15.50%: Training Loss = 0.1940, Accuracy = 0.7237, Validation Loss = 0.2202, Validation Accuracy = 0.6297\n",
            "Timestep 16.00%: Training Loss = 0.1943, Accuracy = 0.7187, Validation Loss = 0.2239, Validation Accuracy = 0.6149\n",
            "Timestep 16.50%: Training Loss = 0.1973, Accuracy = 0.7016, Validation Loss = 0.2179, Validation Accuracy = 0.6254\n",
            "Timestep 17.00%: Training Loss = 0.1912, Accuracy = 0.7227, Validation Loss = 0.2120, Validation Accuracy = 0.6634\n",
            "Timestep 17.50%: Training Loss = 0.1920, Accuracy = 0.7170, Validation Loss = 0.2128, Validation Accuracy = 0.6573\n",
            "Timestep 18.00%: Training Loss = 0.1982, Accuracy = 0.6992, Validation Loss = 0.2139, Validation Accuracy = 0.6455\n",
            "Timestep 18.50%: Training Loss = 0.1909, Accuracy = 0.7317, Validation Loss = 0.2137, Validation Accuracy = 0.6500\n",
            "Timestep 19.00%: Training Loss = 0.1956, Accuracy = 0.7168, Validation Loss = 0.2282, Validation Accuracy = 0.6292\n",
            "Timestep 19.50%: Training Loss = 0.1882, Accuracy = 0.7230, Validation Loss = 0.2091, Validation Accuracy = 0.6750\n",
            "Timestep 20.00%: Training Loss = 0.1893, Accuracy = 0.7254, Validation Loss = 0.2106, Validation Accuracy = 0.6589\n",
            "Timestep 20.50%: Training Loss = 0.1881, Accuracy = 0.7195, Validation Loss = 0.2070, Validation Accuracy = 0.6868\n",
            "Timestep 21.00%: Training Loss = 0.1883, Accuracy = 0.7271, Validation Loss = 0.2151, Validation Accuracy = 0.6594\n",
            "Timestep 21.50%: Training Loss = 0.1884, Accuracy = 0.7202, Validation Loss = 0.2027, Validation Accuracy = 0.6887\n",
            "Timestep 22.00%: Training Loss = 0.1890, Accuracy = 0.7286, Validation Loss = 0.2147, Validation Accuracy = 0.6584\n",
            "Timestep 22.50%: Training Loss = 0.1835, Accuracy = 0.7415, Validation Loss = 0.2112, Validation Accuracy = 0.6637\n",
            "Timestep 23.00%: Training Loss = 0.1859, Accuracy = 0.7312, Validation Loss = 0.2120, Validation Accuracy = 0.6614\n",
            "Timestep 23.50%: Training Loss = 0.1845, Accuracy = 0.7395, Validation Loss = 0.2083, Validation Accuracy = 0.6828\n",
            "Timestep 24.00%: Training Loss = 0.1868, Accuracy = 0.7358, Validation Loss = 0.2110, Validation Accuracy = 0.6605\n",
            "Timestep 24.50%: Training Loss = 0.1822, Accuracy = 0.7430, Validation Loss = 0.2084, Validation Accuracy = 0.6834\n",
            "Completed 50/201 timesteps\n",
            "Timestep 25.00%: Training Loss = 0.1756, Accuracy = 0.7415, Validation Loss = 0.2069, Validation Accuracy = 0.6849\n",
            "Timestep 25.50%: Training Loss = 0.1823, Accuracy = 0.7301, Validation Loss = 0.2025, Validation Accuracy = 0.6685\n",
            "Timestep 26.00%: Training Loss = 0.1848, Accuracy = 0.7247, Validation Loss = 0.2035, Validation Accuracy = 0.6855\n",
            "Timestep 26.50%: Training Loss = 0.1773, Accuracy = 0.7377, Validation Loss = 0.2018, Validation Accuracy = 0.6620\n",
            "Timestep 27.00%: Training Loss = 0.1864, Accuracy = 0.7338, Validation Loss = 0.2132, Validation Accuracy = 0.6502\n",
            "Timestep 27.50%: Training Loss = 0.1794, Accuracy = 0.7365, Validation Loss = 0.2000, Validation Accuracy = 0.6697\n",
            "Timestep 28.00%: Training Loss = 0.1850, Accuracy = 0.7327, Validation Loss = 0.2018, Validation Accuracy = 0.6804\n",
            "Timestep 28.50%: Training Loss = 0.1751, Accuracy = 0.7605, Validation Loss = 0.2109, Validation Accuracy = 0.6400\n",
            "Timestep 29.00%: Training Loss = 0.1768, Accuracy = 0.7450, Validation Loss = 0.2118, Validation Accuracy = 0.6547\n",
            "Timestep 29.50%: Training Loss = 0.1780, Accuracy = 0.7385, Validation Loss = 0.2069, Validation Accuracy = 0.6740\n",
            "Timestep 30.00%: Training Loss = 0.1807, Accuracy = 0.7338, Validation Loss = 0.2051, Validation Accuracy = 0.6871\n",
            "Timestep 30.50%: Training Loss = 0.1783, Accuracy = 0.7397, Validation Loss = 0.1981, Validation Accuracy = 0.6729\n",
            "Timestep 31.00%: Training Loss = 0.1754, Accuracy = 0.7563, Validation Loss = 0.2102, Validation Accuracy = 0.6552\n",
            "Timestep 31.50%: Training Loss = 0.1802, Accuracy = 0.7300, Validation Loss = 0.2073, Validation Accuracy = 0.6686\n",
            "Timestep 32.00%: Training Loss = 0.1708, Accuracy = 0.7425, Validation Loss = 0.1902, Validation Accuracy = 0.7199\n",
            "Timestep 32.50%: Training Loss = 0.1746, Accuracy = 0.7401, Validation Loss = 0.1910, Validation Accuracy = 0.6975\n",
            "Timestep 33.00%: Training Loss = 0.1739, Accuracy = 0.7493, Validation Loss = 0.2018, Validation Accuracy = 0.6855\n",
            "Timestep 33.50%: Training Loss = 0.1719, Accuracy = 0.7480, Validation Loss = 0.1877, Validation Accuracy = 0.7130\n",
            "Timestep 34.00%: Training Loss = 0.1662, Accuracy = 0.7560, Validation Loss = 0.1854, Validation Accuracy = 0.7375\n",
            "Timestep 34.50%: Training Loss = 0.1669, Accuracy = 0.7595, Validation Loss = 0.1917, Validation Accuracy = 0.7025\n",
            "Timestep 35.00%: Training Loss = 0.1666, Accuracy = 0.7560, Validation Loss = 0.1925, Validation Accuracy = 0.6905\n",
            "Timestep 35.50%: Training Loss = 0.1675, Accuracy = 0.7608, Validation Loss = 0.2042, Validation Accuracy = 0.6914\n",
            "Timestep 36.00%: Training Loss = 0.1709, Accuracy = 0.7449, Validation Loss = 0.1993, Validation Accuracy = 0.6991\n",
            "Timestep 36.50%: Training Loss = 0.1643, Accuracy = 0.7625, Validation Loss = 0.1826, Validation Accuracy = 0.7104\n",
            "Timestep 37.00%: Training Loss = 0.1701, Accuracy = 0.7720, Validation Loss = 0.2009, Validation Accuracy = 0.6975\n",
            "Timestep 37.50%: Training Loss = 0.1672, Accuracy = 0.7628, Validation Loss = 0.1856, Validation Accuracy = 0.7194\n",
            "Timestep 38.00%: Training Loss = 0.1668, Accuracy = 0.7661, Validation Loss = 0.1883, Validation Accuracy = 0.7061\n",
            "Timestep 38.50%: Training Loss = 0.1669, Accuracy = 0.7560, Validation Loss = 0.1886, Validation Accuracy = 0.7078\n",
            "Timestep 39.00%: Training Loss = 0.1680, Accuracy = 0.7560, Validation Loss = 0.1928, Validation Accuracy = 0.7066\n",
            "Timestep 39.50%: Training Loss = 0.1634, Accuracy = 0.7713, Validation Loss = 0.1963, Validation Accuracy = 0.6761\n",
            "Timestep 40.00%: Training Loss = 0.1686, Accuracy = 0.7503, Validation Loss = 0.1774, Validation Accuracy = 0.7209\n",
            "Timestep 40.50%: Training Loss = 0.1629, Accuracy = 0.7691, Validation Loss = 0.1866, Validation Accuracy = 0.7107\n",
            "Timestep 41.00%: Training Loss = 0.1592, Accuracy = 0.7736, Validation Loss = 0.1871, Validation Accuracy = 0.7259\n",
            "Timestep 41.50%: Training Loss = 0.1587, Accuracy = 0.7791, Validation Loss = 0.1866, Validation Accuracy = 0.7175\n",
            "Timestep 42.00%: Training Loss = 0.1675, Accuracy = 0.7592, Validation Loss = 0.1855, Validation Accuracy = 0.7264\n",
            "Timestep 42.50%: Training Loss = 0.1626, Accuracy = 0.7702, Validation Loss = 0.1886, Validation Accuracy = 0.7201\n",
            "Timestep 43.00%: Training Loss = 0.1634, Accuracy = 0.7669, Validation Loss = 0.1795, Validation Accuracy = 0.7543\n",
            "Timestep 43.50%: Training Loss = 0.1597, Accuracy = 0.7756, Validation Loss = 0.1769, Validation Accuracy = 0.7508\n",
            "Timestep 44.00%: Training Loss = 0.1571, Accuracy = 0.7811, Validation Loss = 0.1832, Validation Accuracy = 0.7356\n",
            "Timestep 44.50%: Training Loss = 0.1589, Accuracy = 0.7660, Validation Loss = 0.1817, Validation Accuracy = 0.7359\n",
            "Timestep 45.00%: Training Loss = 0.1611, Accuracy = 0.7743, Validation Loss = 0.1813, Validation Accuracy = 0.7393\n",
            "Timestep 45.50%: Training Loss = 0.1584, Accuracy = 0.7787, Validation Loss = 0.1790, Validation Accuracy = 0.7319\n",
            "Timestep 46.00%: Training Loss = 0.1543, Accuracy = 0.7790, Validation Loss = 0.1848, Validation Accuracy = 0.7264\n",
            "Timestep 46.50%: Training Loss = 0.1497, Accuracy = 0.7867, Validation Loss = 0.1796, Validation Accuracy = 0.7283\n",
            "Timestep 47.00%: Training Loss = 0.1472, Accuracy = 0.7954, Validation Loss = 0.1801, Validation Accuracy = 0.7295\n",
            "Timestep 47.50%: Training Loss = 0.1435, Accuracy = 0.7963, Validation Loss = 0.1767, Validation Accuracy = 0.7336\n",
            "Timestep 48.00%: Training Loss = 0.1439, Accuracy = 0.8005, Validation Loss = 0.1716, Validation Accuracy = 0.7621\n",
            "Timestep 48.50%: Training Loss = 0.1435, Accuracy = 0.8016, Validation Loss = 0.1793, Validation Accuracy = 0.6995\n",
            "Timestep 49.00%: Training Loss = 0.1408, Accuracy = 0.8040, Validation Loss = 0.1659, Validation Accuracy = 0.7760\n",
            "Timestep 49.50%: Training Loss = 0.1332, Accuracy = 0.8144, Validation Loss = 0.1722, Validation Accuracy = 0.7523\n",
            "Completed 100/201 timesteps\n",
            "Timestep 50.00%: Training Loss = 0.1297, Accuracy = 0.8250, Validation Loss = 0.1591, Validation Accuracy = 0.7606\n",
            "Timestep 50.50%: Training Loss = 0.1392, Accuracy = 0.8101, Validation Loss = 0.1448, Validation Accuracy = 0.7891\n",
            "Timestep 51.00%: Training Loss = 0.1362, Accuracy = 0.8136, Validation Loss = 0.1508, Validation Accuracy = 0.7857\n",
            "Timestep 51.50%: Training Loss = 0.1408, Accuracy = 0.8068, Validation Loss = 0.1484, Validation Accuracy = 0.7846\n",
            "Timestep 52.00%: Training Loss = 0.1396, Accuracy = 0.8113, Validation Loss = 0.1557, Validation Accuracy = 0.7810\n",
            "Timestep 52.50%: Training Loss = 0.1358, Accuracy = 0.8140, Validation Loss = 0.1490, Validation Accuracy = 0.7955\n",
            "Timestep 53.00%: Training Loss = 0.1391, Accuracy = 0.8070, Validation Loss = 0.1621, Validation Accuracy = 0.7767\n",
            "Timestep 53.50%: Training Loss = 0.1349, Accuracy = 0.8219, Validation Loss = 0.1497, Validation Accuracy = 0.7974\n",
            "Timestep 54.00%: Training Loss = 0.1330, Accuracy = 0.8191, Validation Loss = 0.1448, Validation Accuracy = 0.8070\n",
            "Timestep 54.50%: Training Loss = 0.1385, Accuracy = 0.8090, Validation Loss = 0.1552, Validation Accuracy = 0.7870\n",
            "Timestep 55.00%: Training Loss = 0.1342, Accuracy = 0.8152, Validation Loss = 0.1434, Validation Accuracy = 0.8025\n",
            "Timestep 55.50%: Training Loss = 0.1381, Accuracy = 0.8096, Validation Loss = 0.1439, Validation Accuracy = 0.8062\n",
            "Timestep 56.00%: Training Loss = 0.1349, Accuracy = 0.8138, Validation Loss = 0.1456, Validation Accuracy = 0.8066\n",
            "Timestep 56.50%: Training Loss = 0.1366, Accuracy = 0.8117, Validation Loss = 0.1472, Validation Accuracy = 0.7964\n",
            "Timestep 57.00%: Training Loss = 0.1333, Accuracy = 0.8251, Validation Loss = 0.1495, Validation Accuracy = 0.7976\n",
            "Timestep 57.50%: Training Loss = 0.1346, Accuracy = 0.8161, Validation Loss = 0.1528, Validation Accuracy = 0.7736\n",
            "Timestep 58.00%: Training Loss = 0.1313, Accuracy = 0.8216, Validation Loss = 0.1445, Validation Accuracy = 0.7864\n",
            "Timestep 58.50%: Training Loss = 0.1354, Accuracy = 0.8128, Validation Loss = 0.1437, Validation Accuracy = 0.8013\n",
            "Timestep 59.00%: Training Loss = 0.1353, Accuracy = 0.8136, Validation Loss = 0.1349, Validation Accuracy = 0.8185\n",
            "Timestep 59.50%: Training Loss = 0.1354, Accuracy = 0.8140, Validation Loss = 0.1458, Validation Accuracy = 0.8053\n",
            "Timestep 60.00%: Training Loss = 0.1351, Accuracy = 0.8131, Validation Loss = 0.1508, Validation Accuracy = 0.7704\n",
            "Timestep 60.50%: Training Loss = 0.1331, Accuracy = 0.8091, Validation Loss = 0.1442, Validation Accuracy = 0.8088\n",
            "Timestep 61.00%: Training Loss = 0.1305, Accuracy = 0.8160, Validation Loss = 0.1564, Validation Accuracy = 0.7844\n",
            "Timestep 61.50%: Training Loss = 0.1316, Accuracy = 0.8203, Validation Loss = 0.1385, Validation Accuracy = 0.8080\n",
            "Timestep 62.00%: Training Loss = 0.1312, Accuracy = 0.8152, Validation Loss = 0.1396, Validation Accuracy = 0.8244\n",
            "Timestep 62.50%: Training Loss = 0.1343, Accuracy = 0.8182, Validation Loss = 0.1404, Validation Accuracy = 0.8313\n",
            "Timestep 63.00%: Training Loss = 0.1311, Accuracy = 0.8197, Validation Loss = 0.1407, Validation Accuracy = 0.8226\n",
            "Timestep 63.50%: Training Loss = 0.1293, Accuracy = 0.8223, Validation Loss = 0.1349, Validation Accuracy = 0.8163\n",
            "Timestep 64.00%: Training Loss = 0.1322, Accuracy = 0.8204, Validation Loss = 0.1353, Validation Accuracy = 0.8302\n",
            "Timestep 64.50%: Training Loss = 0.1290, Accuracy = 0.8198, Validation Loss = 0.1347, Validation Accuracy = 0.8267\n",
            "Timestep 65.00%: Training Loss = 0.1282, Accuracy = 0.8249, Validation Loss = 0.1296, Validation Accuracy = 0.8318\n",
            "Timestep 65.50%: Training Loss = 0.1277, Accuracy = 0.8232, Validation Loss = 0.1284, Validation Accuracy = 0.8179\n",
            "Timestep 66.00%: Training Loss = 0.1258, Accuracy = 0.8249, Validation Loss = 0.1322, Validation Accuracy = 0.8239\n",
            "Timestep 66.50%: Training Loss = 0.1261, Accuracy = 0.8250, Validation Loss = 0.1297, Validation Accuracy = 0.8148\n",
            "Timestep 67.00%: Training Loss = 0.1223, Accuracy = 0.8415, Validation Loss = 0.1253, Validation Accuracy = 0.8221\n",
            "Timestep 67.50%: Training Loss = 0.1237, Accuracy = 0.8312, Validation Loss = 0.1268, Validation Accuracy = 0.8204\n",
            "Timestep 68.00%: Training Loss = 0.1222, Accuracy = 0.8279, Validation Loss = 0.1282, Validation Accuracy = 0.8344\n",
            "Timestep 68.50%: Training Loss = 0.1233, Accuracy = 0.8376, Validation Loss = 0.1161, Validation Accuracy = 0.8406\n",
            "Timestep 69.00%: Training Loss = 0.1271, Accuracy = 0.8289, Validation Loss = 0.1219, Validation Accuracy = 0.8369\n",
            "Timestep 69.50%: Training Loss = 0.1201, Accuracy = 0.8411, Validation Loss = 0.1332, Validation Accuracy = 0.8241\n",
            "Timestep 70.00%: Training Loss = 0.1208, Accuracy = 0.8322, Validation Loss = 0.1325, Validation Accuracy = 0.8217\n",
            "Timestep 70.50%: Training Loss = 0.1219, Accuracy = 0.8349, Validation Loss = 0.1170, Validation Accuracy = 0.8519\n",
            "Timestep 71.00%: Training Loss = 0.1140, Accuracy = 0.8509, Validation Loss = 0.1129, Validation Accuracy = 0.8524\n",
            "Timestep 71.50%: Training Loss = 0.1145, Accuracy = 0.8484, Validation Loss = 0.1158, Validation Accuracy = 0.8426\n",
            "Timestep 72.00%: Training Loss = 0.1177, Accuracy = 0.8412, Validation Loss = 0.1202, Validation Accuracy = 0.8385\n",
            "Timestep 72.50%: Training Loss = 0.1189, Accuracy = 0.8371, Validation Loss = 0.1213, Validation Accuracy = 0.8244\n",
            "Timestep 73.00%: Training Loss = 0.1134, Accuracy = 0.8446, Validation Loss = 0.1157, Validation Accuracy = 0.8413\n",
            "Timestep 73.50%: Training Loss = 0.1108, Accuracy = 0.8522, Validation Loss = 0.1155, Validation Accuracy = 0.8415\n",
            "Timestep 74.00%: Training Loss = 0.1128, Accuracy = 0.8438, Validation Loss = 0.1109, Validation Accuracy = 0.8551\n",
            "Timestep 74.50%: Training Loss = 0.1139, Accuracy = 0.8513, Validation Loss = 0.1224, Validation Accuracy = 0.8462\n",
            "Completed 150/201 timesteps\n",
            "Timestep 75.00%: Training Loss = 0.1028, Accuracy = 0.8593, Validation Loss = 0.1147, Validation Accuracy = 0.8249\n",
            "Timestep 75.50%: Training Loss = 0.1028, Accuracy = 0.8696, Validation Loss = 0.1161, Validation Accuracy = 0.8405\n",
            "Timestep 76.00%: Training Loss = 0.1054, Accuracy = 0.8645, Validation Loss = 0.1185, Validation Accuracy = 0.8373\n",
            "Timestep 76.50%: Training Loss = 0.1072, Accuracy = 0.8605, Validation Loss = 0.1199, Validation Accuracy = 0.8424\n",
            "Timestep 77.00%: Training Loss = 0.1064, Accuracy = 0.8590, Validation Loss = 0.1146, Validation Accuracy = 0.8317\n",
            "Timestep 77.50%: Training Loss = 0.1033, Accuracy = 0.8589, Validation Loss = 0.1123, Validation Accuracy = 0.8399\n",
            "Timestep 78.00%: Training Loss = 0.1043, Accuracy = 0.8612, Validation Loss = 0.1088, Validation Accuracy = 0.8571\n",
            "Timestep 78.50%: Training Loss = 0.1044, Accuracy = 0.8581, Validation Loss = 0.1140, Validation Accuracy = 0.8511\n",
            "Timestep 79.00%: Training Loss = 0.0965, Accuracy = 0.8735, Validation Loss = 0.1058, Validation Accuracy = 0.8632\n",
            "Timestep 79.50%: Training Loss = 0.1021, Accuracy = 0.8684, Validation Loss = 0.1137, Validation Accuracy = 0.8558\n",
            "Timestep 80.00%: Training Loss = 0.1041, Accuracy = 0.8624, Validation Loss = 0.1158, Validation Accuracy = 0.8475\n",
            "Timestep 80.50%: Training Loss = 0.1029, Accuracy = 0.8635, Validation Loss = 0.1007, Validation Accuracy = 0.8804\n",
            "Timestep 81.00%: Training Loss = 0.0997, Accuracy = 0.8721, Validation Loss = 0.0993, Validation Accuracy = 0.8776\n",
            "Timestep 81.50%: Training Loss = 0.0986, Accuracy = 0.8739, Validation Loss = 0.0980, Validation Accuracy = 0.8944\n",
            "Timestep 82.00%: Training Loss = 0.0993, Accuracy = 0.8641, Validation Loss = 0.0926, Validation Accuracy = 0.8812\n",
            "Timestep 82.50%: Training Loss = 0.1009, Accuracy = 0.8650, Validation Loss = 0.1066, Validation Accuracy = 0.8563\n",
            "Timestep 83.00%: Training Loss = 0.0963, Accuracy = 0.8712, Validation Loss = 0.1040, Validation Accuracy = 0.8489\n",
            "Timestep 83.50%: Training Loss = 0.0901, Accuracy = 0.8782, Validation Loss = 0.1019, Validation Accuracy = 0.8602\n",
            "Timestep 84.00%: Training Loss = 0.0932, Accuracy = 0.8746, Validation Loss = 0.1063, Validation Accuracy = 0.8488\n",
            "Timestep 84.50%: Training Loss = 0.0946, Accuracy = 0.8732, Validation Loss = 0.0969, Validation Accuracy = 0.8636\n",
            "Timestep 85.00%: Training Loss = 0.0904, Accuracy = 0.8808, Validation Loss = 0.0922, Validation Accuracy = 0.8687\n",
            "Timestep 85.50%: Training Loss = 0.0917, Accuracy = 0.8772, Validation Loss = 0.0926, Validation Accuracy = 0.8783\n",
            "Timestep 86.00%: Training Loss = 0.0935, Accuracy = 0.8750, Validation Loss = 0.0895, Validation Accuracy = 0.8851\n",
            "Timestep 86.50%: Training Loss = 0.0913, Accuracy = 0.8770, Validation Loss = 0.0836, Validation Accuracy = 0.8960\n",
            "Timestep 87.00%: Training Loss = 0.0943, Accuracy = 0.8679, Validation Loss = 0.0867, Validation Accuracy = 0.8957\n",
            "Timestep 87.50%: Training Loss = 0.0877, Accuracy = 0.8790, Validation Loss = 0.0850, Validation Accuracy = 0.8994\n",
            "Timestep 88.00%: Training Loss = 0.0889, Accuracy = 0.8791, Validation Loss = 0.0880, Validation Accuracy = 0.8776\n",
            "Timestep 88.50%: Training Loss = 0.0911, Accuracy = 0.8770, Validation Loss = 0.0765, Validation Accuracy = 0.9061\n",
            "Timestep 89.00%: Training Loss = 0.0930, Accuracy = 0.8788, Validation Loss = 0.0883, Validation Accuracy = 0.8866\n",
            "Timestep 89.50%: Training Loss = 0.0846, Accuracy = 0.8860, Validation Loss = 0.0733, Validation Accuracy = 0.9059\n",
            "Timestep 90.00%: Training Loss = 0.0883, Accuracy = 0.8712, Validation Loss = 0.0943, Validation Accuracy = 0.8912\n",
            "Timestep 90.50%: Training Loss = 0.0839, Accuracy = 0.8862, Validation Loss = 0.0867, Validation Accuracy = 0.8939\n",
            "Timestep 91.00%: Training Loss = 0.0805, Accuracy = 0.8887, Validation Loss = 0.0873, Validation Accuracy = 0.8960\n",
            "Timestep 91.50%: Training Loss = 0.0785, Accuracy = 0.8939, Validation Loss = 0.0776, Validation Accuracy = 0.9006\n",
            "Timestep 92.00%: Training Loss = 0.0825, Accuracy = 0.8862, Validation Loss = 0.0843, Validation Accuracy = 0.8898\n",
            "Timestep 92.50%: Training Loss = 0.0775, Accuracy = 0.9020, Validation Loss = 0.0853, Validation Accuracy = 0.9040\n",
            "Timestep 93.00%: Training Loss = 0.0739, Accuracy = 0.9033, Validation Loss = 0.0820, Validation Accuracy = 0.9031\n",
            "Timestep 93.50%: Training Loss = 0.0772, Accuracy = 0.8954, Validation Loss = 0.0790, Validation Accuracy = 0.9063\n",
            "Timestep 94.00%: Training Loss = 0.0710, Accuracy = 0.9078, Validation Loss = 0.0682, Validation Accuracy = 0.9176\n",
            "Timestep 94.50%: Training Loss = 0.0670, Accuracy = 0.9133, Validation Loss = 0.0668, Validation Accuracy = 0.9193\n",
            "Timestep 95.00%: Training Loss = 0.0739, Accuracy = 0.9025, Validation Loss = 0.0783, Validation Accuracy = 0.8963\n",
            "Timestep 95.50%: Training Loss = 0.0756, Accuracy = 0.8928, Validation Loss = 0.0718, Validation Accuracy = 0.8983\n",
            "Timestep 96.00%: Training Loss = 0.0766, Accuracy = 0.8975, Validation Loss = 0.0688, Validation Accuracy = 0.9292\n",
            "Timestep 96.50%: Training Loss = 0.0673, Accuracy = 0.9092, Validation Loss = 0.0762, Validation Accuracy = 0.8952\n",
            "Timestep 97.00%: Training Loss = 0.0678, Accuracy = 0.9120, Validation Loss = 0.0791, Validation Accuracy = 0.8847\n",
            "Timestep 97.50%: Training Loss = 0.0681, Accuracy = 0.9153, Validation Loss = 0.0798, Validation Accuracy = 0.8961\n",
            "Timestep 98.00%: Training Loss = 0.0652, Accuracy = 0.9217, Validation Loss = 0.0637, Validation Accuracy = 0.9161\n",
            "Timestep 98.50%: Training Loss = 0.0570, Accuracy = 0.9300, Validation Loss = 0.0741, Validation Accuracy = 0.8982\n",
            "Timestep 99.00%: Training Loss = 0.0663, Accuracy = 0.9188, Validation Loss = 0.0842, Validation Accuracy = 0.8926\n",
            "Timestep 99.50%: Training Loss = 0.0561, Accuracy = 0.9363, Validation Loss = 0.0827, Validation Accuracy = 0.8863\n",
            "Completed 200/201 timesteps\n",
            "Timestep 100.00%: Training Loss = 0.0429, Accuracy = 0.9518, Validation Loss = 0.0672, Validation Accuracy = 0.9045\n",
            "Completed 201/201 timesteps\n"
          ]
        }
      ],
      "source": [
        "all_models[\"xgboost\"] = setup_xgboost_models(training_data, validation_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating predictions for timestep 0.0\n",
            "Generating predictions for timestep 0.005\n",
            "Generating predictions for timestep 0.01\n",
            "Generating predictions for timestep 0.015\n",
            "Generating predictions for timestep 0.02\n",
            "Generating predictions for timestep 0.025\n",
            "Generating predictions for timestep 0.03\n",
            "Generating predictions for timestep 0.035\n",
            "Generating predictions for timestep 0.04\n",
            "Generating predictions for timestep 0.045\n",
            "Generating predictions for timestep 0.05\n",
            "Generating predictions for timestep 0.055\n",
            "Generating predictions for timestep 0.06\n",
            "Generating predictions for timestep 0.065\n",
            "Generating predictions for timestep 0.07\n",
            "Generating predictions for timestep 0.075\n",
            "Generating predictions for timestep 0.08\n",
            "Generating predictions for timestep 0.085\n",
            "Generating predictions for timestep 0.09\n",
            "Generating predictions for timestep 0.095\n",
            "Generating predictions for timestep 0.1\n",
            "Generating predictions for timestep 0.105\n",
            "Generating predictions for timestep 0.11\n",
            "Generating predictions for timestep 0.115\n",
            "Generating predictions for timestep 0.12\n",
            "Generating predictions for timestep 0.125\n",
            "Generating predictions for timestep 0.13\n",
            "Generating predictions for timestep 0.135\n",
            "Generating predictions for timestep 0.14\n",
            "Generating predictions for timestep 0.145\n",
            "Generating predictions for timestep 0.15\n",
            "Generating predictions for timestep 0.155\n",
            "Generating predictions for timestep 0.16\n",
            "Generating predictions for timestep 0.165\n",
            "Generating predictions for timestep 0.17\n",
            "Generating predictions for timestep 0.175\n",
            "Generating predictions for timestep 0.18\n",
            "Generating predictions for timestep 0.185\n",
            "Generating predictions for timestep 0.19\n",
            "Generating predictions for timestep 0.195\n",
            "Generating predictions for timestep 0.2\n",
            "Generating predictions for timestep 0.205\n",
            "Generating predictions for timestep 0.21\n",
            "Generating predictions for timestep 0.215\n",
            "Generating predictions for timestep 0.22\n",
            "Generating predictions for timestep 0.225\n",
            "Generating predictions for timestep 0.23\n",
            "Generating predictions for timestep 0.235\n",
            "Generating predictions for timestep 0.24\n",
            "Generating predictions for timestep 0.245\n",
            "Generating predictions for timestep 0.25\n",
            "Generating predictions for timestep 0.255\n",
            "Generating predictions for timestep 0.26\n",
            "Generating predictions for timestep 0.265\n",
            "Generating predictions for timestep 0.27\n",
            "Generating predictions for timestep 0.275\n",
            "Generating predictions for timestep 0.28\n",
            "Generating predictions for timestep 0.285\n",
            "Generating predictions for timestep 0.29\n",
            "Generating predictions for timestep 0.295\n",
            "Generating predictions for timestep 0.3\n",
            "Generating predictions for timestep 0.305\n",
            "Generating predictions for timestep 0.31\n",
            "Generating predictions for timestep 0.315\n",
            "Generating predictions for timestep 0.32\n",
            "Generating predictions for timestep 0.325\n",
            "Generating predictions for timestep 0.33\n",
            "Generating predictions for timestep 0.335\n",
            "Generating predictions for timestep 0.34\n",
            "Generating predictions for timestep 0.345\n",
            "Generating predictions for timestep 0.35\n",
            "Generating predictions for timestep 0.355\n",
            "Generating predictions for timestep 0.36\n",
            "Generating predictions for timestep 0.365\n",
            "Generating predictions for timestep 0.37\n",
            "Generating predictions for timestep 0.375\n",
            "Generating predictions for timestep 0.38\n",
            "Generating predictions for timestep 0.385\n",
            "Generating predictions for timestep 0.39\n",
            "Generating predictions for timestep 0.395\n",
            "Generating predictions for timestep 0.4\n",
            "Generating predictions for timestep 0.405\n",
            "Generating predictions for timestep 0.41\n",
            "Generating predictions for timestep 0.415\n",
            "Generating predictions for timestep 0.42\n",
            "Generating predictions for timestep 0.425\n",
            "Generating predictions for timestep 0.43\n",
            "Generating predictions for timestep 0.435\n",
            "Generating predictions for timestep 0.44\n",
            "Generating predictions for timestep 0.445\n",
            "Generating predictions for timestep 0.45\n",
            "Generating predictions for timestep 0.455\n",
            "Generating predictions for timestep 0.46\n",
            "Generating predictions for timestep 0.465\n",
            "Generating predictions for timestep 0.47\n",
            "Generating predictions for timestep 0.475\n",
            "Generating predictions for timestep 0.48\n",
            "Generating predictions for timestep 0.485\n",
            "Generating predictions for timestep 0.49\n",
            "Generating predictions for timestep 0.495\n",
            "Generating predictions for timestep 0.5\n",
            "Generating predictions for timestep 0.505\n",
            "Generating predictions for timestep 0.51\n",
            "Generating predictions for timestep 0.515\n",
            "Generating predictions for timestep 0.52\n",
            "Generating predictions for timestep 0.525\n",
            "Generating predictions for timestep 0.53\n",
            "Generating predictions for timestep 0.535\n",
            "Generating predictions for timestep 0.54\n",
            "Generating predictions for timestep 0.545\n",
            "Generating predictions for timestep 0.55\n",
            "Generating predictions for timestep 0.555\n",
            "Generating predictions for timestep 0.56\n",
            "Generating predictions for timestep 0.565\n",
            "Generating predictions for timestep 0.57\n",
            "Generating predictions for timestep 0.575\n",
            "Generating predictions for timestep 0.58\n",
            "Generating predictions for timestep 0.585\n",
            "Generating predictions for timestep 0.59\n",
            "Generating predictions for timestep 0.595\n",
            "Generating predictions for timestep 0.6\n",
            "Generating predictions for timestep 0.605\n",
            "Generating predictions for timestep 0.61\n",
            "Generating predictions for timestep 0.615\n",
            "Generating predictions for timestep 0.62\n",
            "Generating predictions for timestep 0.625\n",
            "Generating predictions for timestep 0.63\n",
            "Generating predictions for timestep 0.635\n",
            "Generating predictions for timestep 0.64\n",
            "Generating predictions for timestep 0.645\n",
            "Generating predictions for timestep 0.65\n",
            "Generating predictions for timestep 0.655\n",
            "Generating predictions for timestep 0.66\n",
            "Generating predictions for timestep 0.665\n",
            "Generating predictions for timestep 0.67\n",
            "Generating predictions for timestep 0.675\n",
            "Generating predictions for timestep 0.68\n",
            "Generating predictions for timestep 0.685\n",
            "Generating predictions for timestep 0.69\n",
            "Generating predictions for timestep 0.695\n",
            "Generating predictions for timestep 0.7\n",
            "Generating predictions for timestep 0.705\n",
            "Generating predictions for timestep 0.71\n",
            "Generating predictions for timestep 0.715\n",
            "Generating predictions for timestep 0.72\n",
            "Generating predictions for timestep 0.725\n",
            "Generating predictions for timestep 0.73\n",
            "Generating predictions for timestep 0.735\n",
            "Generating predictions for timestep 0.74\n",
            "Generating predictions for timestep 0.745\n",
            "Generating predictions for timestep 0.75\n",
            "Generating predictions for timestep 0.755\n",
            "Generating predictions for timestep 0.76\n",
            "Generating predictions for timestep 0.765\n",
            "Generating predictions for timestep 0.77\n",
            "Generating predictions for timestep 0.775\n",
            "Generating predictions for timestep 0.78\n",
            "Generating predictions for timestep 0.785\n",
            "Generating predictions for timestep 0.79\n",
            "Generating predictions for timestep 0.795\n",
            "Generating predictions for timestep 0.8\n",
            "Generating predictions for timestep 0.805\n",
            "Generating predictions for timestep 0.81\n",
            "Generating predictions for timestep 0.815\n",
            "Generating predictions for timestep 0.82\n",
            "Generating predictions for timestep 0.825\n",
            "Generating predictions for timestep 0.83\n",
            "Generating predictions for timestep 0.835\n",
            "Generating predictions for timestep 0.84\n",
            "Generating predictions for timestep 0.845\n",
            "Generating predictions for timestep 0.85\n",
            "Generating predictions for timestep 0.855\n",
            "Generating predictions for timestep 0.86\n",
            "Generating predictions for timestep 0.865\n",
            "Generating predictions for timestep 0.87\n",
            "Generating predictions for timestep 0.875\n",
            "Generating predictions for timestep 0.88\n",
            "Generating predictions for timestep 0.885\n",
            "Generating predictions for timestep 0.89\n",
            "Generating predictions for timestep 0.895\n",
            "Generating predictions for timestep 0.9\n",
            "Generating predictions for timestep 0.905\n",
            "Generating predictions for timestep 0.91\n",
            "Generating predictions for timestep 0.915\n",
            "Generating predictions for timestep 0.92\n",
            "Generating predictions for timestep 0.925\n",
            "Generating predictions for timestep 0.93\n",
            "Generating predictions for timestep 0.935\n",
            "Generating predictions for timestep 0.94\n",
            "Generating predictions for timestep 0.945\n",
            "Generating predictions for timestep 0.95\n",
            "Generating predictions for timestep 0.955\n",
            "Generating predictions for timestep 0.96\n",
            "Generating predictions for timestep 0.965\n",
            "Generating predictions for timestep 0.97\n",
            "Generating predictions for timestep 0.975\n",
            "Generating predictions for timestep 0.98\n",
            "Generating predictions for timestep 0.985\n",
            "Generating predictions for timestep 0.99\n",
            "Generating predictions for timestep 0.995\n",
            "Generating predictions for timestep 1.0\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "all_models_order = [\"xgboost\", \"nn\", \"logistic\", \"lstm\"] # Strict ordering of models\n",
        "def generate_ensemble_matrix(models, all_models_order, data_dict_seq):\n",
        "    \"\"\"Generate predictions from a specific model type on given data\"\"\"\n",
        "    predictions = {}\n",
        "    # predictions:\n",
        "        # timestep:\n",
        "            # \"predictions\": [model_1_predictions, model_2_predictions, ..., model_n_predictions, \n",
        "            # model_1_oredictions_seq, model_2_oredictions_seq, ..., model_n_oredictions_seq],\n",
        "            # \"y_true\": y_true\n",
        "    for timestep in data_dict_seq:\n",
        "        print(f\"Generating predictions for timestep {timestep}\")\n",
        "        # For each entry, take the last array from the \"rows\" list and pair with its label\n",
        "        non_sequential_data_for_timestep = [{\"rows\": entry[\"rows\"][-1], \"label\": entry[\"label\"]} for entry in data_dict_seq[timestep]]\n",
        "        X = np.array([row[\"rows\"] for row in non_sequential_data_for_timestep])\n",
        "        y = np.array([row[\"label\"] for row in non_sequential_data_for_timestep])\n",
        "        X_seq = np.array([row[\"rows\"] for row in data_dict_seq[timestep]])\n",
        "        predictions[timestep] = {\"predictions\": [], \"y_true\": []}\n",
        "        for i in range(len(X)):\n",
        "            predictions[timestep][\"predictions\"].append(np.array([\n",
        "                models[model][timestep].predict_proba(np.expand_dims(X_seq[i], axis=0))[:, 1].item() if model == \"lstm\" else models[model][timestep].predict_proba(np.expand_dims(X[i], axis=0))[:, 1].item()\n",
        "                for model in all_models_order\n",
        "            ]))\n",
        "            predictions[timestep][\"y_true\"].append(y[i])\n",
        "        predictions[timestep][\"y_true\"] = np.array(predictions[timestep][\"y_true\"])\n",
        "        predictions[timestep][\"predictions\"] = np.array(predictions[timestep][\"predictions\"])\n",
        "    return predictions\n",
        "\n",
        "ensemble_matrices = generate_ensemble_matrix(all_models, all_models_order, ensemble_data_seq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LogisticRegressionMetaModel:\n",
        "    def __init__(self):\n",
        "        self.meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.meta_model.fit(X, y)\n",
        "        if X_val is not None and y_val is not None:\n",
        "            self.meta_model.fit(X_val, y_val)\n",
        "    def predict(self, X):\n",
        "        return 1 if self.meta_model.predict_proba(X)[:, 1] > 0.5 else 0\n",
        "    def predict_proba(self, X):\n",
        "        return self.meta_model.predict_proba(X)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class SimpleMetaNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleMetaNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class NeuralNetworkMetaModel(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, input_dim=None, lr=0.01, epochs=30, batch_size=32, device=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        if self.input_dim is None:\n",
        "            self.input_dim = X.shape[1]\n",
        "        self.model = SimpleMetaNN(self.input_dim).to(self.device)\n",
        "        criterion = nn.BCELoss()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(self.device)\n",
        "        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        self.model.train()\n",
        "        for epoch in range(self.epochs):\n",
        "            for xb, yb in loader:\n",
        "                optimizer.zero_grad()\n",
        "                preds = self.model(xb)\n",
        "                loss = criterion(preds, yb)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).cpu().numpy().flatten()\n",
        "        return (probs > 0.5).astype(int)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).cpu().numpy().flatten()\n",
        "        return np.column_stack([1 - probs, probs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training meta-model for timestep 0.0\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 697 samples\n",
            "    Validation Meta-model accuracy: 0.6171, Validation Brier score: 0.2372\n",
            "Training meta-model for timestep 0.005\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 489 samples\n",
            "    Validation Meta-model accuracy: 0.6260, Validation Brier score: 0.2245\n",
            "Training meta-model for timestep 0.01\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 452 samples\n",
            "    Validation Meta-model accuracy: 0.5664, Validation Brier score: 0.2445\n",
            "Training meta-model for timestep 0.015\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 508 samples\n",
            "    Validation Meta-model accuracy: 0.6142, Validation Brier score: 0.2326\n",
            "Training meta-model for timestep 0.02\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 472 samples\n",
            "    Validation Meta-model accuracy: 0.5678, Validation Brier score: 0.2290\n",
            "Training meta-model for timestep 0.025\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 502 samples\n",
            "    Validation Meta-model accuracy: 0.5952, Validation Brier score: 0.2283\n",
            "Training meta-model for timestep 0.03\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 514 samples\n",
            "    Validation Meta-model accuracy: 0.5814, Validation Brier score: 0.2445\n",
            "Training meta-model for timestep 0.035\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 500 samples\n",
            "    Validation Meta-model accuracy: 0.5794, Validation Brier score: 0.2409\n",
            "Training meta-model for timestep 0.04\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 508 samples\n",
            "    Validation Meta-model accuracy: 0.6016, Validation Brier score: 0.2311\n",
            "Training meta-model for timestep 0.045\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 486 samples\n",
            "    Validation Meta-model accuracy: 0.6967, Validation Brier score: 0.2107\n",
            "Training meta-model for timestep 0.05\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 532 samples\n",
            "    Validation Meta-model accuracy: 0.6119, Validation Brier score: 0.2229\n",
            "Training meta-model for timestep 0.055\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 493 samples\n",
            "    Validation Meta-model accuracy: 0.6048, Validation Brier score: 0.2410\n",
            "Training meta-model for timestep 0.06\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 529 samples\n",
            "    Validation Meta-model accuracy: 0.6241, Validation Brier score: 0.2257\n",
            "Training meta-model for timestep 0.065\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 529 samples\n",
            "    Validation Meta-model accuracy: 0.6090, Validation Brier score: 0.2254\n",
            "Training meta-model for timestep 0.07\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 515 samples\n",
            "    Validation Meta-model accuracy: 0.5814, Validation Brier score: 0.2384\n",
            "Training meta-model for timestep 0.075\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 531 samples\n",
            "    Validation Meta-model accuracy: 0.6466, Validation Brier score: 0.2136\n",
            "Training meta-model for timestep 0.08\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 548 samples\n",
            "    Validation Meta-model accuracy: 0.6277, Validation Brier score: 0.2370\n",
            "Training meta-model for timestep 0.085\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 511 samples\n",
            "    Validation Meta-model accuracy: 0.6016, Validation Brier score: 0.2269\n",
            "Training meta-model for timestep 0.09\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 536 samples\n",
            "    Validation Meta-model accuracy: 0.6343, Validation Brier score: 0.2196\n",
            "Training meta-model for timestep 0.095\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 547 samples\n",
            "    Validation Meta-model accuracy: 0.6423, Validation Brier score: 0.2218\n",
            "Training meta-model for timestep 0.1\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 554 samples\n",
            "    Validation Meta-model accuracy: 0.5396, Validation Brier score: 0.2535\n",
            "Training meta-model for timestep 0.105\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 540 samples\n",
            "    Validation Meta-model accuracy: 0.5852, Validation Brier score: 0.2458\n",
            "Training meta-model for timestep 0.11\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 545 samples\n",
            "    Validation Meta-model accuracy: 0.7007, Validation Brier score: 0.2045\n",
            "Training meta-model for timestep 0.115\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 531 samples\n",
            "    Validation Meta-model accuracy: 0.6692, Validation Brier score: 0.2217\n",
            "Training meta-model for timestep 0.12\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 524 samples\n",
            "    Validation Meta-model accuracy: 0.6565, Validation Brier score: 0.2137\n",
            "Training meta-model for timestep 0.125\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 532 samples\n",
            "    Validation Meta-model accuracy: 0.6119, Validation Brier score: 0.2058\n",
            "Training meta-model for timestep 0.13\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.6391, Validation Brier score: 0.2215\n",
            "Training meta-model for timestep 0.135\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 543 samples\n",
            "    Validation Meta-model accuracy: 0.6838, Validation Brier score: 0.1976\n",
            "Training meta-model for timestep 0.14\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 551 samples\n",
            "    Validation Meta-model accuracy: 0.6014, Validation Brier score: 0.2415\n",
            "Training meta-model for timestep 0.145\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 526 samples\n",
            "    Validation Meta-model accuracy: 0.6515, Validation Brier score: 0.2257\n",
            "Training meta-model for timestep 0.15\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 530 samples\n",
            "    Validation Meta-model accuracy: 0.6917, Validation Brier score: 0.2055\n",
            "Training meta-model for timestep 0.155\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 539 samples\n",
            "    Validation Meta-model accuracy: 0.7037, Validation Brier score: 0.1995\n",
            "Training meta-model for timestep 0.16\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 514 samples\n",
            "    Validation Meta-model accuracy: 0.7287, Validation Brier score: 0.2010\n",
            "Training meta-model for timestep 0.165\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.5865, Validation Brier score: 0.2340\n",
            "Training meta-model for timestep 0.17\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 519 samples\n",
            "    Validation Meta-model accuracy: 0.6692, Validation Brier score: 0.2202\n",
            "Training meta-model for timestep 0.175\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 536 samples\n",
            "    Validation Meta-model accuracy: 0.6963, Validation Brier score: 0.1989\n",
            "Training meta-model for timestep 0.18\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 530 samples\n",
            "    Validation Meta-model accuracy: 0.6090, Validation Brier score: 0.2231\n",
            "Training meta-model for timestep 0.185\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 510 samples\n",
            "    Validation Meta-model accuracy: 0.6484, Validation Brier score: 0.2124\n",
            "Training meta-model for timestep 0.19\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 533 samples\n",
            "    Validation Meta-model accuracy: 0.6343, Validation Brier score: 0.2156\n",
            "Training meta-model for timestep 0.195\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.7143, Validation Brier score: 0.1970\n",
            "Training meta-model for timestep 0.2\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 554 samples\n",
            "    Validation Meta-model accuracy: 0.6043, Validation Brier score: 0.2271\n",
            "Training meta-model for timestep 0.205\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 524 samples\n",
            "    Validation Meta-model accuracy: 0.6061, Validation Brier score: 0.2177\n",
            "Training meta-model for timestep 0.21\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 551 samples\n",
            "    Validation Meta-model accuracy: 0.6812, Validation Brier score: 0.2081\n",
            "Training meta-model for timestep 0.215\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 556 samples\n",
            "    Validation Meta-model accuracy: 0.6286, Validation Brier score: 0.2339\n",
            "Training meta-model for timestep 0.22\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 539 samples\n",
            "    Validation Meta-model accuracy: 0.7185, Validation Brier score: 0.1826\n",
            "Training meta-model for timestep 0.225\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 537 samples\n",
            "    Validation Meta-model accuracy: 0.6889, Validation Brier score: 0.2079\n",
            "Training meta-model for timestep 0.23\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 545 samples\n",
            "    Validation Meta-model accuracy: 0.6496, Validation Brier score: 0.2118\n",
            "Training meta-model for timestep 0.235\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 535 samples\n",
            "    Validation Meta-model accuracy: 0.6493, Validation Brier score: 0.2181\n",
            "Training meta-model for timestep 0.24\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 550 samples\n",
            "    Validation Meta-model accuracy: 0.6739, Validation Brier score: 0.2160\n",
            "Training meta-model for timestep 0.245\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 555 samples\n",
            "    Validation Meta-model accuracy: 0.7266, Validation Brier score: 0.1880\n",
            "Training meta-model for timestep 0.25\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 1104 samples\n",
            "    Validation Meta-model accuracy: 0.6739, Validation Brier score: 0.2077\n",
            "Training meta-model for timestep 0.255\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 576 samples\n",
            "    Validation Meta-model accuracy: 0.6806, Validation Brier score: 0.2031\n",
            "Training meta-model for timestep 0.26\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 452 samples\n",
            "    Validation Meta-model accuracy: 0.6549, Validation Brier score: 0.2103\n",
            "Training meta-model for timestep 0.265\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 607 samples\n",
            "    Validation Meta-model accuracy: 0.6316, Validation Brier score: 0.2193\n",
            "Training meta-model for timestep 0.27\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 513 samples\n",
            "    Validation Meta-model accuracy: 0.6667, Validation Brier score: 0.2171\n",
            "Training meta-model for timestep 0.275\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 556 samples\n",
            "    Validation Meta-model accuracy: 0.6906, Validation Brier score: 0.1997\n",
            "Training meta-model for timestep 0.28\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 540 samples\n",
            "    Validation Meta-model accuracy: 0.6889, Validation Brier score: 0.1990\n",
            "Training meta-model for timestep 0.285\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 555 samples\n",
            "    Validation Meta-model accuracy: 0.6835, Validation Brier score: 0.1958\n",
            "Training meta-model for timestep 0.29\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 554 samples\n",
            "    Validation Meta-model accuracy: 0.6763, Validation Brier score: 0.1982\n",
            "Training meta-model for timestep 0.295\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 520 samples\n",
            "    Validation Meta-model accuracy: 0.6154, Validation Brier score: 0.2200\n",
            "Training meta-model for timestep 0.3\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 531 samples\n",
            "    Validation Meta-model accuracy: 0.6692, Validation Brier score: 0.2129\n",
            "Training meta-model for timestep 0.305\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 564 samples\n",
            "    Validation Meta-model accuracy: 0.6809, Validation Brier score: 0.1964\n",
            "Training meta-model for timestep 0.31\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 532 samples\n",
            "    Validation Meta-model accuracy: 0.7015, Validation Brier score: 0.1993\n",
            "Training meta-model for timestep 0.315\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 530 samples\n",
            "    Validation Meta-model accuracy: 0.6842, Validation Brier score: 0.2032\n",
            "Training meta-model for timestep 0.32\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 530 samples\n",
            "    Validation Meta-model accuracy: 0.6391, Validation Brier score: 0.2324\n",
            "Training meta-model for timestep 0.325\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 549 samples\n",
            "    Validation Meta-model accuracy: 0.6957, Validation Brier score: 0.1945\n",
            "Training meta-model for timestep 0.33\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 531 samples\n",
            "    Validation Meta-model accuracy: 0.6992, Validation Brier score: 0.1928\n",
            "Training meta-model for timestep 0.335\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 532 samples\n",
            "    Validation Meta-model accuracy: 0.6493, Validation Brier score: 0.2240\n",
            "Training meta-model for timestep 0.34\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 556 samples\n",
            "    Validation Meta-model accuracy: 0.6691, Validation Brier score: 0.2055\n",
            "Training meta-model for timestep 0.345\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 539 samples\n",
            "    Validation Meta-model accuracy: 0.6667, Validation Brier score: 0.2167\n",
            "Training meta-model for timestep 0.35\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 538 samples\n",
            "    Validation Meta-model accuracy: 0.6296, Validation Brier score: 0.2308\n",
            "Training meta-model for timestep 0.355\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 553 samples\n",
            "    Validation Meta-model accuracy: 0.6906, Validation Brier score: 0.1955\n",
            "Training meta-model for timestep 0.36\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 531 samples\n",
            "    Validation Meta-model accuracy: 0.7293, Validation Brier score: 0.1798\n",
            "Training meta-model for timestep 0.365\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 532 samples\n",
            "    Validation Meta-model accuracy: 0.7744, Validation Brier score: 0.1792\n",
            "Training meta-model for timestep 0.37\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.6288, Validation Brier score: 0.2012\n",
            "Training meta-model for timestep 0.375\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 556 samples\n",
            "    Validation Meta-model accuracy: 0.6475, Validation Brier score: 0.2199\n",
            "Training meta-model for timestep 0.38\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 548 samples\n",
            "    Validation Meta-model accuracy: 0.6934, Validation Brier score: 0.1976\n",
            "Training meta-model for timestep 0.385\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 543 samples\n",
            "    Validation Meta-model accuracy: 0.7279, Validation Brier score: 0.1920\n",
            "Training meta-model for timestep 0.39\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.7143, Validation Brier score: 0.2099\n",
            "Training meta-model for timestep 0.395\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 516 samples\n",
            "    Validation Meta-model accuracy: 0.7442, Validation Brier score: 0.1935\n",
            "Training meta-model for timestep 0.4\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 527 samples\n",
            "    Validation Meta-model accuracy: 0.6515, Validation Brier score: 0.2132\n",
            "Training meta-model for timestep 0.405\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 519 samples\n",
            "    Validation Meta-model accuracy: 0.6769, Validation Brier score: 0.2130\n",
            "Training meta-model for timestep 0.41\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 538 samples\n",
            "    Validation Meta-model accuracy: 0.6296, Validation Brier score: 0.2378\n",
            "Training meta-model for timestep 0.415\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.6541, Validation Brier score: 0.2444\n",
            "Training meta-model for timestep 0.42\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 531 samples\n",
            "    Validation Meta-model accuracy: 0.7594, Validation Brier score: 0.1830\n",
            "Training meta-model for timestep 0.425\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 553 samples\n",
            "    Validation Meta-model accuracy: 0.7338, Validation Brier score: 0.1977\n",
            "Training meta-model for timestep 0.43\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 540 samples\n",
            "    Validation Meta-model accuracy: 0.7132, Validation Brier score: 0.2041\n",
            "Training meta-model for timestep 0.435\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 516 samples\n",
            "    Validation Meta-model accuracy: 0.7462, Validation Brier score: 0.1823\n",
            "Training meta-model for timestep 0.44\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 548 samples\n",
            "    Validation Meta-model accuracy: 0.6642, Validation Brier score: 0.2241\n",
            "Training meta-model for timestep 0.445\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 516 samples\n",
            "    Validation Meta-model accuracy: 0.7538, Validation Brier score: 0.1840\n",
            "Training meta-model for timestep 0.45\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 554 samples\n",
            "    Validation Meta-model accuracy: 0.6978, Validation Brier score: 0.2008\n",
            "Training meta-model for timestep 0.455\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 543 samples\n",
            "    Validation Meta-model accuracy: 0.7353, Validation Brier score: 0.1755\n",
            "Training meta-model for timestep 0.46\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 555 samples\n",
            "    Validation Meta-model accuracy: 0.6978, Validation Brier score: 0.2008\n",
            "Training meta-model for timestep 0.465\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 552 samples\n",
            "    Validation Meta-model accuracy: 0.7410, Validation Brier score: 0.1751\n",
            "Training meta-model for timestep 0.47\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 1405 samples\n",
            "    Validation Meta-model accuracy: 0.7159, Validation Brier score: 0.1901\n",
            "Training meta-model for timestep 0.475\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 804 samples\n",
            "    Validation Meta-model accuracy: 0.7079, Validation Brier score: 0.1988\n",
            "Training meta-model for timestep 0.48\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 751 samples\n",
            "    Validation Meta-model accuracy: 0.7819, Validation Brier score: 0.1595\n",
            "Training meta-model for timestep 0.485\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 892 samples\n",
            "    Validation Meta-model accuracy: 0.7366, Validation Brier score: 0.1747\n",
            "Training meta-model for timestep 0.49\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 1068 samples\n",
            "    Validation Meta-model accuracy: 0.7978, Validation Brier score: 0.1522\n",
            "Training meta-model for timestep 0.495\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 1384 samples\n",
            "    Validation Meta-model accuracy: 0.7839, Validation Brier score: 0.1603\n",
            "Training meta-model for timestep 0.5\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 2470 samples\n",
            "    Validation Meta-model accuracy: 0.7427, Validation Brier score: 0.1696\n",
            "Training meta-model for timestep 0.505\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 484 samples\n",
            "    Validation Meta-model accuracy: 0.7438, Validation Brier score: 0.1739\n",
            "Training meta-model for timestep 0.51\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 444 samples\n",
            "    Validation Meta-model accuracy: 0.7500, Validation Brier score: 0.1599\n",
            "Training meta-model for timestep 0.515\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 509 samples\n",
            "    Validation Meta-model accuracy: 0.8203, Validation Brier score: 0.1465\n",
            "Training meta-model for timestep 0.52\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 495 samples\n",
            "    Validation Meta-model accuracy: 0.7339, Validation Brier score: 0.1711\n",
            "Training meta-model for timestep 0.525\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 516 samples\n",
            "    Validation Meta-model accuracy: 0.7308, Validation Brier score: 0.1904\n",
            "Training meta-model for timestep 0.53\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 494 samples\n",
            "    Validation Meta-model accuracy: 0.7339, Validation Brier score: 0.1744\n",
            "Training meta-model for timestep 0.535\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 513 samples\n",
            "    Validation Meta-model accuracy: 0.7907, Validation Brier score: 0.1544\n",
            "Training meta-model for timestep 0.54\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 512 samples\n",
            "    Validation Meta-model accuracy: 0.7597, Validation Brier score: 0.1567\n",
            "Training meta-model for timestep 0.545\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 506 samples\n",
            "    Validation Meta-model accuracy: 0.7638, Validation Brier score: 0.1845\n",
            "Training meta-model for timestep 0.55\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 516 samples\n",
            "    Validation Meta-model accuracy: 0.7615, Validation Brier score: 0.1622\n",
            "Training meta-model for timestep 0.555\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 534 samples\n",
            "    Validation Meta-model accuracy: 0.6940, Validation Brier score: 0.1864\n",
            "Training meta-model for timestep 0.56\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.7727, Validation Brier score: 0.1761\n",
            "Training meta-model for timestep 0.565\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 524 samples\n",
            "    Validation Meta-model accuracy: 0.7710, Validation Brier score: 0.1693\n",
            "Training meta-model for timestep 0.57\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 519 samples\n",
            "    Validation Meta-model accuracy: 0.7615, Validation Brier score: 0.1681\n",
            "Training meta-model for timestep 0.575\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 552 samples\n",
            "    Validation Meta-model accuracy: 0.7101, Validation Brier score: 0.1919\n",
            "Training meta-model for timestep 0.58\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 520 samples\n",
            "    Validation Meta-model accuracy: 0.7176, Validation Brier score: 0.1836\n",
            "Training meta-model for timestep 0.585\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 566 samples\n",
            "    Validation Meta-model accuracy: 0.7535, Validation Brier score: 0.1593\n",
            "Training meta-model for timestep 0.59\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 545 samples\n",
            "    Validation Meta-model accuracy: 0.7299, Validation Brier score: 0.1802\n",
            "Training meta-model for timestep 0.595\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 548 samples\n",
            "    Validation Meta-model accuracy: 0.7101, Validation Brier score: 0.1953\n",
            "Training meta-model for timestep 0.6\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 537 samples\n",
            "    Validation Meta-model accuracy: 0.6963, Validation Brier score: 0.1823\n",
            "Training meta-model for timestep 0.605\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 539 samples\n",
            "    Validation Meta-model accuracy: 0.7333, Validation Brier score: 0.1735\n",
            "Training meta-model for timestep 0.61\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 518 samples\n",
            "    Validation Meta-model accuracy: 0.7538, Validation Brier score: 0.1645\n",
            "Training meta-model for timestep 0.615\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.7744, Validation Brier score: 0.1536\n",
            "Training meta-model for timestep 0.62\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 543 samples\n",
            "    Validation Meta-model accuracy: 0.6912, Validation Brier score: 0.1881\n",
            "Training meta-model for timestep 0.625\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 546 samples\n",
            "    Validation Meta-model accuracy: 0.7737, Validation Brier score: 0.1564\n",
            "Training meta-model for timestep 0.63\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 552 samples\n",
            "    Validation Meta-model accuracy: 0.7482, Validation Brier score: 0.1701\n",
            "Training meta-model for timestep 0.635\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 529 samples\n",
            "    Validation Meta-model accuracy: 0.7143, Validation Brier score: 0.1792\n",
            "Training meta-model for timestep 0.64\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 516 samples\n",
            "    Validation Meta-model accuracy: 0.7674, Validation Brier score: 0.1698\n",
            "Training meta-model for timestep 0.645\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 543 samples\n",
            "    Validation Meta-model accuracy: 0.7794, Validation Brier score: 0.1531\n",
            "Training meta-model for timestep 0.65\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 515 samples\n",
            "    Validation Meta-model accuracy: 0.7519, Validation Brier score: 0.1711\n",
            "Training meta-model for timestep 0.655\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 539 samples\n",
            "    Validation Meta-model accuracy: 0.8148, Validation Brier score: 0.1530\n",
            "Training meta-model for timestep 0.66\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 516 samples\n",
            "    Validation Meta-model accuracy: 0.7442, Validation Brier score: 0.1804\n",
            "Training meta-model for timestep 0.665\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 536 samples\n",
            "    Validation Meta-model accuracy: 0.7852, Validation Brier score: 0.1530\n",
            "Training meta-model for timestep 0.67\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 524 samples\n",
            "    Validation Meta-model accuracy: 0.7727, Validation Brier score: 0.1584\n",
            "Training meta-model for timestep 0.675\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 558 samples\n",
            "    Validation Meta-model accuracy: 0.8143, Validation Brier score: 0.1433\n",
            "Training meta-model for timestep 0.68\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 522 samples\n",
            "    Validation Meta-model accuracy: 0.7939, Validation Brier score: 0.1576\n",
            "Training meta-model for timestep 0.685\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 549 samples\n",
            "    Validation Meta-model accuracy: 0.7754, Validation Brier score: 0.1661\n",
            "Training meta-model for timestep 0.69\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 548 samples\n",
            "    Validation Meta-model accuracy: 0.7536, Validation Brier score: 0.1594\n",
            "Training meta-model for timestep 0.695\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 529 samples\n",
            "    Validation Meta-model accuracy: 0.7368, Validation Brier score: 0.1591\n",
            "Training meta-model for timestep 0.7\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 537 samples\n",
            "    Validation Meta-model accuracy: 0.7778, Validation Brier score: 0.1452\n",
            "Training meta-model for timestep 0.705\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 537 samples\n",
            "    Validation Meta-model accuracy: 0.7333, Validation Brier score: 0.1689\n",
            "Training meta-model for timestep 0.71\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 546 samples\n",
            "    Validation Meta-model accuracy: 0.7372, Validation Brier score: 0.1610\n",
            "Training meta-model for timestep 0.715\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 527 samples\n",
            "    Validation Meta-model accuracy: 0.8106, Validation Brier score: 0.1463\n",
            "Training meta-model for timestep 0.72\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 520 samples\n",
            "    Validation Meta-model accuracy: 0.7328, Validation Brier score: 0.1781\n",
            "Training meta-model for timestep 0.725\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 516 samples\n",
            "    Validation Meta-model accuracy: 0.7692, Validation Brier score: 0.1768\n",
            "Training meta-model for timestep 0.73\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 537 samples\n",
            "    Validation Meta-model accuracy: 0.7852, Validation Brier score: 0.1644\n",
            "Training meta-model for timestep 0.735\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 547 samples\n",
            "    Validation Meta-model accuracy: 0.7883, Validation Brier score: 0.1511\n",
            "Training meta-model for timestep 0.74\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 576 samples\n",
            "    Validation Meta-model accuracy: 0.8069, Validation Brier score: 0.1431\n",
            "Training meta-model for timestep 0.745\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 533 samples\n",
            "    Validation Meta-model accuracy: 0.7761, Validation Brier score: 0.1487\n",
            "Training meta-model for timestep 0.75\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 1091 samples\n",
            "    Validation Meta-model accuracy: 0.7692, Validation Brier score: 0.1552\n",
            "Training meta-model for timestep 0.755\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 571 samples\n",
            "    Validation Meta-model accuracy: 0.7902, Validation Brier score: 0.1545\n",
            "Training meta-model for timestep 0.76\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 468 samples\n",
            "    Validation Meta-model accuracy: 0.8136, Validation Brier score: 0.1397\n",
            "Training meta-model for timestep 0.765\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 607 samples\n",
            "    Validation Meta-model accuracy: 0.7961, Validation Brier score: 0.1325\n",
            "Training meta-model for timestep 0.77\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 501 samples\n",
            "    Validation Meta-model accuracy: 0.8413, Validation Brier score: 0.1302\n",
            "Training meta-model for timestep 0.775\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 569 samples\n",
            "    Validation Meta-model accuracy: 0.7622, Validation Brier score: 0.1584\n",
            "Training meta-model for timestep 0.78\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 541 samples\n",
            "    Validation Meta-model accuracy: 0.8015, Validation Brier score: 0.1343\n",
            "Training meta-model for timestep 0.785\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 511 samples\n",
            "    Validation Meta-model accuracy: 0.7891, Validation Brier score: 0.1544\n",
            "Training meta-model for timestep 0.79\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 565 samples\n",
            "    Validation Meta-model accuracy: 0.8451, Validation Brier score: 0.1165\n",
            "Training meta-model for timestep 0.795\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 554 samples\n",
            "    Validation Meta-model accuracy: 0.7770, Validation Brier score: 0.1612\n",
            "Training meta-model for timestep 0.8\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.8346, Validation Brier score: 0.1368\n",
            "Training meta-model for timestep 0.805\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 538 samples\n",
            "    Validation Meta-model accuracy: 0.8296, Validation Brier score: 0.1310\n",
            "Training meta-model for timestep 0.81\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 536 samples\n",
            "    Validation Meta-model accuracy: 0.8134, Validation Brier score: 0.1472\n",
            "Training meta-model for timestep 0.815\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 576 samples\n",
            "    Validation Meta-model accuracy: 0.7931, Validation Brier score: 0.1535\n",
            "Training meta-model for timestep 0.82\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 528 samples\n",
            "    Validation Meta-model accuracy: 0.8030, Validation Brier score: 0.1431\n",
            "Training meta-model for timestep 0.825\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 544 samples\n",
            "    Validation Meta-model accuracy: 0.8382, Validation Brier score: 0.1253\n",
            "Training meta-model for timestep 0.83\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 508 samples\n",
            "    Validation Meta-model accuracy: 0.8438, Validation Brier score: 0.1147\n",
            "Training meta-model for timestep 0.835\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 546 samples\n",
            "    Validation Meta-model accuracy: 0.7883, Validation Brier score: 0.1432\n",
            "Training meta-model for timestep 0.84\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 530 samples\n",
            "    Validation Meta-model accuracy: 0.8496, Validation Brier score: 0.1224\n",
            "Training meta-model for timestep 0.845\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 550 samples\n",
            "    Validation Meta-model accuracy: 0.7971, Validation Brier score: 0.1408\n",
            "Training meta-model for timestep 0.85\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 539 samples\n",
            "    Validation Meta-model accuracy: 0.7556, Validation Brier score: 0.1672\n",
            "Training meta-model for timestep 0.855\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 540 samples\n",
            "    Validation Meta-model accuracy: 0.7574, Validation Brier score: 0.1744\n",
            "Training meta-model for timestep 0.86\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 546 samples\n",
            "    Validation Meta-model accuracy: 0.8102, Validation Brier score: 0.1467\n",
            "Training meta-model for timestep 0.865\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 557 samples\n",
            "    Validation Meta-model accuracy: 0.8143, Validation Brier score: 0.1403\n",
            "Training meta-model for timestep 0.87\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 532 samples\n",
            "    Validation Meta-model accuracy: 0.8134, Validation Brier score: 0.1406\n",
            "Training meta-model for timestep 0.875\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 552 samples\n",
            "    Validation Meta-model accuracy: 0.7986, Validation Brier score: 0.1333\n",
            "Training meta-model for timestep 0.88\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 551 samples\n",
            "    Validation Meta-model accuracy: 0.8333, Validation Brier score: 0.1196\n",
            "Training meta-model for timestep 0.885\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 549 samples\n",
            "    Validation Meta-model accuracy: 0.7971, Validation Brier score: 0.1295\n",
            "Training meta-model for timestep 0.89\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 536 samples\n",
            "    Validation Meta-model accuracy: 0.8284, Validation Brier score: 0.1313\n",
            "Training meta-model for timestep 0.895\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 552 samples\n",
            "    Validation Meta-model accuracy: 0.8273, Validation Brier score: 0.1224\n",
            "Training meta-model for timestep 0.9\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 563 samples\n",
            "    Validation Meta-model accuracy: 0.8227, Validation Brier score: 0.1285\n",
            "Training meta-model for timestep 0.905\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 539 samples\n",
            "    Validation Meta-model accuracy: 0.8370, Validation Brier score: 0.1165\n",
            "Training meta-model for timestep 0.91\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 583 samples\n",
            "    Validation Meta-model accuracy: 0.8082, Validation Brier score: 0.1333\n",
            "Training meta-model for timestep 0.915\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 568 samples\n",
            "    Validation Meta-model accuracy: 0.8811, Validation Brier score: 0.0865\n",
            "Training meta-model for timestep 0.92\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 584 samples\n",
            "    Validation Meta-model accuracy: 0.8493, Validation Brier score: 0.1200\n",
            "Training meta-model for timestep 0.925\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 623 samples\n",
            "    Validation Meta-model accuracy: 0.8205, Validation Brier score: 0.1248\n",
            "Training meta-model for timestep 0.93\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 599 samples\n",
            "    Validation Meta-model accuracy: 0.8400, Validation Brier score: 0.1063\n",
            "Training meta-model for timestep 0.935\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 599 samples\n",
            "    Validation Meta-model accuracy: 0.8600, Validation Brier score: 0.1032\n",
            "Training meta-model for timestep 0.94\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 632 samples\n",
            "    Validation Meta-model accuracy: 0.8734, Validation Brier score: 0.1007\n",
            "Training meta-model for timestep 0.945\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 668 samples\n",
            "    Validation Meta-model accuracy: 0.8503, Validation Brier score: 0.1123\n",
            "Training meta-model for timestep 0.95\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 698 samples\n",
            "    Validation Meta-model accuracy: 0.8571, Validation Brier score: 0.1134\n",
            "Training meta-model for timestep 0.955\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 681 samples\n",
            "    Validation Meta-model accuracy: 0.8363, Validation Brier score: 0.1187\n",
            "Training meta-model for timestep 0.96\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 721 samples\n",
            "    Validation Meta-model accuracy: 0.8674, Validation Brier score: 0.1024\n",
            "Training meta-model for timestep 0.965\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 717 samples\n",
            "    Validation Meta-model accuracy: 0.8667, Validation Brier score: 0.0996\n",
            "Training meta-model for timestep 0.97\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 1436 samples\n",
            "    Validation Meta-model accuracy: 0.8719, Validation Brier score: 0.0968\n",
            "Training meta-model for timestep 0.975\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 728 samples\n",
            "    Validation Meta-model accuracy: 0.8681, Validation Brier score: 0.1057\n",
            "Training meta-model for timestep 0.98\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 656 samples\n",
            "    Validation Meta-model accuracy: 0.8232, Validation Brier score: 0.1335\n",
            "Training meta-model for timestep 0.985\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 817 samples\n",
            "    Validation Meta-model accuracy: 0.8976, Validation Brier score: 0.0855\n",
            "Training meta-model for timestep 0.99\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 764 samples\n",
            "    Validation Meta-model accuracy: 0.8953, Validation Brier score: 0.0780\n",
            "Training meta-model for timestep 0.995\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 791 samples\n",
            "    Validation Meta-model accuracy: 0.8788, Validation Brier score: 0.0921\n",
            "Training meta-model for timestep 1.0\n",
            "Training ensemble for this timestep...\n",
            "  Meta-model trained on 948 samples\n",
            "    Validation Meta-model accuracy: 0.9076, Validation Brier score: 0.0760\n"
          ]
        }
      ],
      "source": [
        "def setup_meta_models(ensemble_matrices, all_models, all_models_order, strategy='meta_model', meta_model=None):\n",
        "    models = {}\n",
        "    for timestep in ensemble_matrices:\n",
        "        print(f\"Training meta-model for timestep {timestep}\")\n",
        "        ensemble_matrix = ensemble_matrices[timestep]\n",
        "        x_train = ensemble_matrix[\"predictions\"]\n",
        "        y_train = ensemble_matrix[\"y_true\"]\n",
        "        all_models_for_timestep = {model_name: all_models[model_name][timestep] for model_name in all_models_order}\n",
        "        models[timestep] = EnsemblePredictor(all_models_for_timestep, all_models_order, strategy, meta_model)\n",
        "        models[timestep].train_ensemble(x_train, y_train, objective='brier')\n",
        "    return models\n",
        "\n",
        "ensemble_models = setup_meta_models(ensemble_matrices, all_models, all_models_order, strategy='meta_model', meta_model=LogisticRegressionMetaModel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestep 0.00%: Accuracy = 0.6442, Brier Score = 0.2266\n",
            "Timestep 0.50%: Accuracy = 0.6453, Brier Score = 0.2317\n",
            "Timestep 1.00%: Accuracy = 0.6436, Brier Score = 0.2351\n",
            "Timestep 1.50%: Accuracy = 0.6613, Brier Score = 0.2328\n",
            "Timestep 2.00%: Accuracy = 0.6548, Brier Score = 0.2285\n",
            "Timestep 2.50%: Accuracy = 0.6503, Brier Score = 0.2259\n",
            "Timestep 3.00%: Accuracy = 0.6518, Brier Score = 0.2284\n",
            "Timestep 3.50%: Accuracy = 0.6270, Brier Score = 0.2459\n",
            "Timestep 4.00%: Accuracy = 0.6190, Brier Score = 0.2484\n",
            "Timestep 4.50%: Accuracy = 0.6375, Brier Score = 0.2304\n",
            "Timestep 5.00%: Accuracy = 0.6532, Brier Score = 0.2274\n",
            "Timestep 5.50%: Accuracy = 0.6397, Brier Score = 0.2315\n",
            "Timestep 6.00%: Accuracy = 0.6696, Brier Score = 0.2237\n",
            "Timestep 6.50%: Accuracy = 0.6544, Brier Score = 0.2326\n",
            "Timestep 7.00%: Accuracy = 0.6687, Brier Score = 0.2307\n",
            "Timestep 7.50%: Accuracy = 0.6613, Brier Score = 0.2250\n",
            "Timestep 8.00%: Accuracy = 0.6715, Brier Score = 0.2220\n",
            "Timestep 8.50%: Accuracy = 0.6953, Brier Score = 0.2089\n",
            "Timestep 9.00%: Accuracy = 0.6423, Brier Score = 0.2333\n",
            "Timestep 9.50%: Accuracy = 0.6699, Brier Score = 0.2150\n",
            "Timestep 10.00%: Accuracy = 0.6695, Brier Score = 0.2196\n",
            "Timestep 10.50%: Accuracy = 0.6923, Brier Score = 0.2170\n",
            "Timestep 11.00%: Accuracy = 0.6667, Brier Score = 0.2248\n",
            "Timestep 11.50%: Accuracy = 0.6859, Brier Score = 0.2158\n",
            "Timestep 12.00%: Accuracy = 0.6814, Brier Score = 0.2155\n",
            "Timestep 12.50%: Accuracy = 0.6603, Brier Score = 0.2259\n",
            "Timestep 13.00%: Accuracy = 0.6733, Brier Score = 0.2225\n",
            "Timestep 13.50%: Accuracy = 0.6576, Brier Score = 0.2300\n",
            "Timestep 14.00%: Accuracy = 0.6804, Brier Score = 0.2142\n",
            "Timestep 14.50%: Accuracy = 0.6710, Brier Score = 0.2168\n",
            "Timestep 15.00%: Accuracy = 0.6626, Brier Score = 0.2271\n",
            "Timestep 15.50%: Accuracy = 0.6872, Brier Score = 0.2163\n",
            "Timestep 16.00%: Accuracy = 0.6799, Brier Score = 0.2133\n",
            "Timestep 16.50%: Accuracy = 0.6546, Brier Score = 0.2289\n",
            "Timestep 17.00%: Accuracy = 0.6725, Brier Score = 0.2212\n",
            "Timestep 17.50%: Accuracy = 0.6383, Brier Score = 0.2343\n",
            "Timestep 18.00%: Accuracy = 0.6827, Brier Score = 0.2161\n",
            "Timestep 18.50%: Accuracy = 0.6795, Brier Score = 0.2217\n",
            "Timestep 19.00%: Accuracy = 0.6473, Brier Score = 0.2301\n",
            "Timestep 19.50%: Accuracy = 0.6861, Brier Score = 0.2167\n",
            "Timestep 20.00%: Accuracy = 0.6878, Brier Score = 0.2137\n",
            "Timestep 20.50%: Accuracy = 0.6766, Brier Score = 0.2103\n",
            "Timestep 21.00%: Accuracy = 0.6817, Brier Score = 0.2118\n",
            "Timestep 21.50%: Accuracy = 0.6766, Brier Score = 0.2243\n",
            "Timestep 22.00%: Accuracy = 0.6804, Brier Score = 0.2080\n",
            "Timestep 22.50%: Accuracy = 0.6634, Brier Score = 0.2308\n",
            "Timestep 23.00%: Accuracy = 0.6620, Brier Score = 0.2261\n",
            "Timestep 23.50%: Accuracy = 0.6504, Brier Score = 0.2321\n",
            "Timestep 24.00%: Accuracy = 0.6750, Brier Score = 0.2128\n",
            "Timestep 24.50%: Accuracy = 0.6845, Brier Score = 0.2093\n",
            "Timestep 25.00%: Accuracy = 0.6671, Brier Score = 0.2268\n",
            "Timestep 25.50%: Accuracy = 0.6555, Brier Score = 0.2308\n",
            "Timestep 26.00%: Accuracy = 0.6643, Brier Score = 0.2214\n",
            "Timestep 26.50%: Accuracy = 0.6531, Brier Score = 0.2249\n",
            "Timestep 27.00%: Accuracy = 0.6743, Brier Score = 0.2098\n",
            "Timestep 27.50%: Accuracy = 0.6858, Brier Score = 0.2159\n",
            "Timestep 28.00%: Accuracy = 0.6632, Brier Score = 0.2180\n",
            "Timestep 28.50%: Accuracy = 0.6781, Brier Score = 0.2167\n",
            "Timestep 29.00%: Accuracy = 0.6746, Brier Score = 0.2119\n",
            "Timestep 29.50%: Accuracy = 0.6701, Brier Score = 0.2200\n",
            "Timestep 30.00%: Accuracy = 0.6681, Brier Score = 0.2142\n",
            "Timestep 30.50%: Accuracy = 0.6676, Brier Score = 0.2203\n",
            "Timestep 31.00%: Accuracy = 0.7026, Brier Score = 0.2072\n",
            "Timestep 31.50%: Accuracy = 0.6946, Brier Score = 0.2129\n",
            "Timestep 32.00%: Accuracy = 0.6975, Brier Score = 0.2099\n",
            "Timestep 32.50%: Accuracy = 0.6700, Brier Score = 0.2264\n",
            "Timestep 33.00%: Accuracy = 0.7109, Brier Score = 0.2027\n",
            "Timestep 33.50%: Accuracy = 0.6967, Brier Score = 0.2100\n",
            "Timestep 34.00%: Accuracy = 0.7009, Brier Score = 0.2044\n",
            "Timestep 34.50%: Accuracy = 0.6918, Brier Score = 0.2088\n",
            "Timestep 35.00%: Accuracy = 0.6906, Brier Score = 0.2110\n",
            "Timestep 35.50%: Accuracy = 0.6841, Brier Score = 0.2079\n",
            "Timestep 36.00%: Accuracy = 0.7003, Brier Score = 0.1981\n",
            "Timestep 36.50%: Accuracy = 0.7303, Brier Score = 0.1945\n",
            "Timestep 37.00%: Accuracy = 0.7021, Brier Score = 0.1960\n",
            "Timestep 37.50%: Accuracy = 0.7062, Brier Score = 0.1995\n",
            "Timestep 38.00%: Accuracy = 0.7349, Brier Score = 0.1821\n",
            "Timestep 38.50%: Accuracy = 0.7354, Brier Score = 0.1883\n",
            "Timestep 39.00%: Accuracy = 0.7204, Brier Score = 0.1881\n",
            "Timestep 39.50%: Accuracy = 0.7155, Brier Score = 0.1912\n",
            "Timestep 40.00%: Accuracy = 0.7379, Brier Score = 0.1877\n",
            "Timestep 40.50%: Accuracy = 0.7613, Brier Score = 0.1737\n",
            "Timestep 41.00%: Accuracy = 0.7113, Brier Score = 0.2085\n",
            "Timestep 41.50%: Accuracy = 0.7445, Brier Score = 0.1850\n",
            "Timestep 42.00%: Accuracy = 0.7132, Brier Score = 0.1990\n",
            "Timestep 42.50%: Accuracy = 0.7389, Brier Score = 0.1876\n",
            "Timestep 43.00%: Accuracy = 0.7449, Brier Score = 0.1874\n",
            "Timestep 43.50%: Accuracy = 0.7548, Brier Score = 0.1741\n",
            "Timestep 44.00%: Accuracy = 0.7464, Brier Score = 0.1775\n",
            "Timestep 44.50%: Accuracy = 0.7373, Brier Score = 0.1770\n",
            "Timestep 45.00%: Accuracy = 0.7385, Brier Score = 0.1817\n",
            "Timestep 45.50%: Accuracy = 0.7518, Brier Score = 0.1789\n",
            "Timestep 46.00%: Accuracy = 0.7596, Brier Score = 0.1774\n",
            "Timestep 46.50%: Accuracy = 0.7555, Brier Score = 0.1682\n",
            "Timestep 47.00%: Accuracy = 0.7356, Brier Score = 0.1834\n",
            "Timestep 47.50%: Accuracy = 0.7328, Brier Score = 0.1901\n",
            "Timestep 48.00%: Accuracy = 0.7548, Brier Score = 0.1770\n",
            "Timestep 48.50%: Accuracy = 0.7466, Brier Score = 0.1730\n",
            "Timestep 49.00%: Accuracy = 0.7841, Brier Score = 0.1587\n",
            "Timestep 49.50%: Accuracy = 0.7448, Brier Score = 0.1822\n",
            "Timestep 50.00%: Accuracy = 0.7559, Brier Score = 0.1717\n",
            "Timestep 50.50%: Accuracy = 0.7669, Brier Score = 0.1703\n",
            "Timestep 51.00%: Accuracy = 0.7647, Brier Score = 0.1715\n",
            "Timestep 51.50%: Accuracy = 0.7573, Brier Score = 0.1718\n",
            "Timestep 52.00%: Accuracy = 0.7520, Brier Score = 0.1710\n",
            "Timestep 52.50%: Accuracy = 0.7485, Brier Score = 0.1804\n",
            "Timestep 53.00%: Accuracy = 0.7466, Brier Score = 0.1777\n",
            "Timestep 53.50%: Accuracy = 0.7531, Brier Score = 0.1856\n",
            "Timestep 54.00%: Accuracy = 0.7590, Brier Score = 0.1750\n",
            "Timestep 54.50%: Accuracy = 0.7703, Brier Score = 0.1653\n",
            "Timestep 55.00%: Accuracy = 0.7758, Brier Score = 0.1637\n",
            "Timestep 55.50%: Accuracy = 0.7688, Brier Score = 0.1686\n",
            "Timestep 56.00%: Accuracy = 0.7599, Brier Score = 0.1660\n",
            "Timestep 56.50%: Accuracy = 0.7687, Brier Score = 0.1644\n",
            "Timestep 57.00%: Accuracy = 0.7557, Brier Score = 0.1729\n",
            "Timestep 57.50%: Accuracy = 0.7521, Brier Score = 0.1771\n",
            "Timestep 58.00%: Accuracy = 0.7902, Brier Score = 0.1530\n",
            "Timestep 58.50%: Accuracy = 0.7785, Brier Score = 0.1577\n",
            "Timestep 59.00%: Accuracy = 0.7848, Brier Score = 0.1542\n",
            "Timestep 59.50%: Accuracy = 0.7711, Brier Score = 0.1628\n",
            "Timestep 60.00%: Accuracy = 0.8000, Brier Score = 0.1486\n",
            "Timestep 60.50%: Accuracy = 0.7604, Brier Score = 0.1709\n",
            "Timestep 61.00%: Accuracy = 0.7936, Brier Score = 0.1565\n",
            "Timestep 61.50%: Accuracy = 0.7985, Brier Score = 0.1545\n",
            "Timestep 62.00%: Accuracy = 0.7696, Brier Score = 0.1663\n",
            "Timestep 62.50%: Accuracy = 0.7966, Brier Score = 0.1478\n",
            "Timestep 63.00%: Accuracy = 0.7870, Brier Score = 0.1530\n",
            "Timestep 63.50%: Accuracy = 0.7965, Brier Score = 0.1564\n",
            "Timestep 64.00%: Accuracy = 0.8061, Brier Score = 0.1429\n",
            "Timestep 64.50%: Accuracy = 0.8107, Brier Score = 0.1476\n",
            "Timestep 65.00%: Accuracy = 0.7786, Brier Score = 0.1582\n",
            "Timestep 65.50%: Accuracy = 0.8097, Brier Score = 0.1416\n",
            "Timestep 66.00%: Accuracy = 0.7839, Brier Score = 0.1499\n",
            "Timestep 66.50%: Accuracy = 0.7916, Brier Score = 0.1474\n",
            "Timestep 67.00%: Accuracy = 0.8141, Brier Score = 0.1401\n",
            "Timestep 67.50%: Accuracy = 0.7825, Brier Score = 0.1634\n",
            "Timestep 68.00%: Accuracy = 0.8217, Brier Score = 0.1291\n",
            "Timestep 68.50%: Accuracy = 0.7832, Brier Score = 0.1574\n",
            "Timestep 69.00%: Accuracy = 0.8029, Brier Score = 0.1451\n",
            "Timestep 69.50%: Accuracy = 0.8070, Brier Score = 0.1387\n",
            "Timestep 70.00%: Accuracy = 0.7831, Brier Score = 0.1543\n",
            "Timestep 70.50%: Accuracy = 0.8122, Brier Score = 0.1351\n",
            "Timestep 71.00%: Accuracy = 0.8029, Brier Score = 0.1409\n",
            "Timestep 71.50%: Accuracy = 0.8076, Brier Score = 0.1447\n",
            "Timestep 72.00%: Accuracy = 0.8200, Brier Score = 0.1298\n",
            "Timestep 72.50%: Accuracy = 0.8245, Brier Score = 0.1320\n",
            "Timestep 73.00%: Accuracy = 0.8225, Brier Score = 0.1319\n",
            "Timestep 73.50%: Accuracy = 0.8385, Brier Score = 0.1278\n",
            "Timestep 74.00%: Accuracy = 0.8370, Brier Score = 0.1221\n",
            "Timestep 74.50%: Accuracy = 0.8121, Brier Score = 0.1431\n",
            "Timestep 75.00%: Accuracy = 0.8199, Brier Score = 0.1329\n",
            "Timestep 75.50%: Accuracy = 0.8336, Brier Score = 0.1256\n",
            "Timestep 76.00%: Accuracy = 0.8440, Brier Score = 0.1237\n",
            "Timestep 76.50%: Accuracy = 0.8548, Brier Score = 0.1119\n",
            "Timestep 77.00%: Accuracy = 0.8323, Brier Score = 0.1258\n",
            "Timestep 77.50%: Accuracy = 0.8382, Brier Score = 0.1224\n",
            "Timestep 78.00%: Accuracy = 0.8537, Brier Score = 0.1159\n",
            "Timestep 78.50%: Accuracy = 0.8517, Brier Score = 0.1106\n",
            "Timestep 79.00%: Accuracy = 0.8441, Brier Score = 0.1171\n",
            "Timestep 79.50%: Accuracy = 0.8408, Brier Score = 0.1227\n",
            "Timestep 80.00%: Accuracy = 0.8517, Brier Score = 0.1170\n",
            "Timestep 80.50%: Accuracy = 0.8535, Brier Score = 0.1164\n",
            "Timestep 81.00%: Accuracy = 0.8578, Brier Score = 0.1110\n",
            "Timestep 81.50%: Accuracy = 0.8585, Brier Score = 0.1092\n",
            "Timestep 82.00%: Accuracy = 0.8421, Brier Score = 0.1158\n",
            "Timestep 82.50%: Accuracy = 0.8573, Brier Score = 0.1048\n",
            "Timestep 83.00%: Accuracy = 0.8647, Brier Score = 0.1060\n",
            "Timestep 83.50%: Accuracy = 0.8551, Brier Score = 0.1102\n",
            "Timestep 84.00%: Accuracy = 0.8510, Brier Score = 0.1158\n",
            "Timestep 84.50%: Accuracy = 0.8514, Brier Score = 0.1076\n",
            "Timestep 85.00%: Accuracy = 0.8647, Brier Score = 0.1050\n",
            "Timestep 85.50%: Accuracy = 0.8518, Brier Score = 0.1223\n",
            "Timestep 86.00%: Accuracy = 0.8732, Brier Score = 0.0972\n",
            "Timestep 86.50%: Accuracy = 0.8653, Brier Score = 0.1056\n",
            "Timestep 87.00%: Accuracy = 0.8732, Brier Score = 0.0952\n",
            "Timestep 87.50%: Accuracy = 0.8490, Brier Score = 0.1064\n",
            "Timestep 88.00%: Accuracy = 0.8881, Brier Score = 0.0893\n",
            "Timestep 88.50%: Accuracy = 0.8746, Brier Score = 0.0966\n",
            "Timestep 89.00%: Accuracy = 0.8832, Brier Score = 0.0873\n",
            "Timestep 89.50%: Accuracy = 0.9009, Brier Score = 0.0834\n",
            "Timestep 90.00%: Accuracy = 0.8843, Brier Score = 0.0901\n",
            "Timestep 90.50%: Accuracy = 0.8743, Brier Score = 0.0895\n",
            "Timestep 91.00%: Accuracy = 0.8719, Brier Score = 0.0954\n",
            "Timestep 91.50%: Accuracy = 0.9030, Brier Score = 0.0759\n",
            "Timestep 92.00%: Accuracy = 0.8793, Brier Score = 0.0815\n",
            "Timestep 92.50%: Accuracy = 0.8859, Brier Score = 0.0854\n",
            "Timestep 93.00%: Accuracy = 0.8765, Brier Score = 0.0902\n",
            "Timestep 93.50%: Accuracy = 0.8836, Brier Score = 0.0835\n",
            "Timestep 94.00%: Accuracy = 0.8989, Brier Score = 0.0816\n",
            "Timestep 94.50%: Accuracy = 0.8828, Brier Score = 0.0932\n",
            "Timestep 95.00%: Accuracy = 0.8811, Brier Score = 0.0941\n",
            "Timestep 95.50%: Accuracy = 0.8765, Brier Score = 0.0914\n",
            "Timestep 96.00%: Accuracy = 0.8749, Brier Score = 0.0924\n",
            "Timestep 96.50%: Accuracy = 0.8934, Brier Score = 0.0745\n",
            "Timestep 97.00%: Accuracy = 0.8923, Brier Score = 0.0837\n",
            "Timestep 97.50%: Accuracy = 0.8845, Brier Score = 0.0878\n",
            "Timestep 98.00%: Accuracy = 0.8794, Brier Score = 0.0897\n",
            "Timestep 98.50%: Accuracy = 0.9047, Brier Score = 0.0731\n",
            "Timestep 99.00%: Accuracy = 0.8871, Brier Score = 0.0850\n",
            "Timestep 99.50%: Accuracy = 0.8863, Brier Score = 0.0894\n",
            "Timestep 100.00%: Accuracy = 0.9113, Brier Score = 0.0654\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary Statistics:\n",
            "Average Accuracy: 0.7585 ± 0.0813\n",
            "Average Brier Score: 0.1689 ± 0.0493\n",
            "Best Accuracy: 0.9113 at timestep 100.00%\n",
            "Best Brier Score: 0.0654 at timestep 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Test accuracy and Brier score of model for each timestep on test data and plot\n",
        "accuracies = []\n",
        "brier_scores = []\n",
        "timesteps = []\n",
        "def brier_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "for timestep, i in zip(ensemble_models, test_data.keys()):\n",
        "    model = ensemble_models[timestep]\n",
        "    # Convert test data to array\n",
        "    y_test = np.array([row[\"label\"] for row in test_data_seq[i]])\n",
        "    X_test = np.array([row[\"rows\"] for row in test_data_seq[i]])\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    \n",
        "    # Calculate Brier score\n",
        "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probability predictions\n",
        "    brier_score = brier_loss(y_test, y_test_pred_proba)\n",
        "    \n",
        "    print(f\"Timestep {timestep:.2%}: Accuracy = {accuracy:.4f}, Brier Score = {brier_score:.4f}\")\n",
        "    accuracies.append(accuracy)\n",
        "    brier_scores.append(brier_score)\n",
        "    timesteps.append(timestep)\n",
        "\n",
        "# Create subplots for both metrics\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot accuracy\n",
        "ax1.plot(timesteps, accuracies, 'b-', linewidth=2, marker='o', markersize=3)\n",
        "ax1.set_xlabel(\"Timestep\")\n",
        "ax1.set_ylabel(\"Accuracy\")\n",
        "ax1.set_title(\"Test Accuracy vs Timestep\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([min(accuracies) * 0.95, max(accuracies) * 1.05])\n",
        "\n",
        "# Plot Brier score\n",
        "ax2.plot(timesteps, brier_scores, 'r-', linewidth=2, marker='s', markersize=3)\n",
        "ax2.set_xlabel(\"Timestep\")\n",
        "ax2.set_ylabel(\"Brier Score\")\n",
        "ax2.set_title(\"Test Brier Score vs Timestep\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim([min(brier_scores) * 0.95, max(brier_scores) * 1.05])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\nSummary Statistics:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
        "print(f\"Average Brier Score: {np.mean(brier_scores):.4f} ± {np.std(brier_scores):.4f}\")\n",
        "print(f\"Best Accuracy: {max(accuracies):.4f} at timestep {timesteps[np.argmax(accuracies)]:.2%}\")\n",
        "print(f\"Best Brier Score: {min(brier_scores):.4f} at timestep {timesteps[np.argmin(brier_scores)]:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2024\n",
            "Processed file:  game_401671629.csv\n",
            "Processed file:  game_401671601.csv\n",
            "Processed file:  game_401671826.csv\n",
            "Processed file:  game_401671832.csv\n",
            "Processed file:  game_401671749.csv\n",
            "Processed file:  game_401671775.csv\n",
            "Processed file:  game_401671761.csv\n",
            "Processed file:  game_401671760.csv\n",
            "Processed file:  game_401671774.csv\n",
            "Processed file:  game_401671748.csv\n",
            "Processed file:  game_401671833.csv\n",
            "Processed file:  game_401671827.csv\n",
            "Processed file:  game_401671600.csv\n",
            "Processed file:  game_401671628.csv\n",
            "Processed file:  game_401671616.csv\n",
            "Processed file:  game_401671831.csv\n",
            "Processed file:  game_401671825.csv\n",
            "Processed file:  game_401671819.csv\n",
            "Processed file:  game_401671762.csv\n",
            "Processed file:  game_401671776.csv\n",
            "Processed file:  game_401671789.csv\n",
            "Processed file:  game_401671788.csv\n",
            "Processed file:  game_401671777.csv\n",
            "Processed file:  game_401671763.csv\n",
            "Processed file:  game_401671818.csv\n",
            "Processed file:  game_401671824.csv\n",
            "Processed file:  game_401671830.csv\n",
            "Processed file:  game_401671617.csv\n",
            "Processed file:  game_401671808.csv\n",
            "Processed file:  game_401671834.csv\n",
            "Processed file:  game_401671820.csv\n",
            "Processed file:  game_401671767.csv\n",
            "Processed file:  game_401671773.csv\n",
            "Processed file:  game_401671798.csv\n",
            "Processed file:  game_401671799.csv\n",
            "Processed file:  game_401671772.csv\n",
            "Processed file:  game_401671766.csv\n",
            "Processed file:  game_401671821.csv\n",
            "Processed file:  game_401671835.csv\n",
            "Processed file:  game_401671809.csv\n",
            "Processed file:  game_401671638.csv\n",
            "Processed file:  game_401671823.csv\n",
            "Processed file:  game_401671837.csv\n",
            "Processed file:  game_401671599.csv\n",
            "Processed file:  game_401671770.csv\n",
            "Processed file:  game_401671764.csv\n",
            "Processed file:  game_401671758.csv\n",
            "Processed file:  game_401671759.csv\n",
            "Processed file:  game_401671765.csv\n",
            "Processed file:  game_401671771.csv\n",
            "Processed file:  game_401671836.csv\n",
            "Processed file:  game_401671822.csv\n",
            "Processed file:  game_401671639.csv\n",
            "Processed file:  game_401671662.csv\n",
            "Processed file:  game_401671676.csv\n",
            "Processed file:  game_401671845.csv\n",
            "Processed file:  game_401671851.csv\n",
            "Processed file:  game_401671689.csv\n",
            "Processed file:  game_401671716.csv\n",
            "Processed file:  game_401671702.csv\n",
            "Processed file:  game_401671703.csv\n",
            "Processed file:  game_401671717.csv\n",
            "Processed file:  game_401671688.csv\n",
            "Processed file:  game_401671850.csv\n",
            "Processed file:  game_401671844.csv\n",
            "Processed file:  game_401671677.csv\n",
            "Processed file:  game_401671663.csv\n",
            "Processed file:  game_401671649.csv\n",
            "Processed file:  game_401671675.csv\n",
            "Processed file:  game_401671661.csv\n",
            "Processed file:  game_401671852.csv\n",
            "Processed file:  game_401671846.csv\n",
            "Processed file:  game_401671729.csv\n",
            "Processed file:  game_401671701.csv\n",
            "Processed file:  game_401671715.csv\n",
            "Processed file:  game_401671714.csv\n",
            "Processed file:  game_401671700.csv\n",
            "Processed file:  game_401671728.csv\n",
            "Processed file:  game_401671489.csv\n",
            "Processed file:  game_401671847.csv\n",
            "Processed file:  game_401671853.csv\n",
            "Processed file:  game_401671660.csv\n",
            "Processed file:  game_401671674.csv\n",
            "Processed file:  game_401671648.csv\n",
            "Processed file:  game_401671670.csv\n",
            "Processed file:  game_401671664.csv\n",
            "Processed file:  game_401671658.csv\n",
            "Processed file:  game_401671857.csv\n",
            "Processed file:  game_401671843.csv\n",
            "Processed file:  game_401671704.csv\n",
            "Processed file:  game_401671710.csv\n",
            "Processed file:  game_401671738.csv\n",
            "Processed file:  game_401671739.csv\n",
            "Processed file:  game_401671711.csv\n",
            "Processed file:  game_401671705.csv\n",
            "Processed file:  game_401671842.csv\n",
            "Processed file:  game_401671856.csv\n",
            "Processed file:  game_401671659.csv\n",
            "Processed file:  game_401671665.csv\n",
            "Processed file:  game_401671671.csv\n",
            "Processed file:  game_401671667.csv\n",
            "Processed file:  game_401671673.csv\n",
            "Processed file:  game_401671868.csv\n",
            "Processed file:  game_401671840.csv\n",
            "Processed file:  game_401671698.csv\n",
            "Processed file:  game_401671854.csv\n",
            "Processed file:  game_401671713.csv\n",
            "Processed file:  game_401671707.csv\n",
            "Processed file:  game_401671706.csv\n",
            "Processed file:  game_401671712.csv\n",
            "Processed file:  game_401671855.csv\n",
            "Processed file:  game_401671699.csv\n",
            "Processed file:  game_401671841.csv\n",
            "Processed file:  game_401671869.csv\n",
            "Processed file:  game_401671672.csv\n",
            "Processed file:  game_401671666.csv\n",
            "Processed file:  game_401671643.csv\n",
            "Processed file:  game_401671657.csv\n",
            "Processed file:  game_401671864.csv\n",
            "Processed file:  game_401671870.csv\n",
            "Processed file:  game_401671858.csv\n",
            "Processed file:  game_401671680.csv\n",
            "Processed file:  game_401671694.csv\n",
            "Processed file:  game_401671737.csv\n",
            "Processed file:  game_401671723.csv\n",
            "Processed file:  game_401671722.csv\n",
            "Processed file:  game_401671736.csv\n",
            "Processed file:  game_401671695.csv\n",
            "Processed file:  game_401671681.csv\n",
            "Processed file:  game_401671859.csv\n",
            "Processed file:  game_401671871.csv\n",
            "Processed file:  game_401671865.csv\n",
            "Processed file:  game_401671656.csv\n",
            "Processed file:  game_401671642.csv\n",
            "Processed file:  game_401671668.csv\n",
            "Processed file:  game_401671654.csv\n",
            "Processed file:  game_401671640.csv\n",
            "Processed file:  game_401671873.csv\n",
            "Processed file:  game_401671867.csv\n",
            "Processed file:  game_401671697.csv\n",
            "Processed file:  game_401671683.csv\n",
            "Processed file:  game_401671495.csv\n",
            "Processed file:  game_401671708.csv\n",
            "Processed file:  game_401671720.csv\n",
            "Processed file:  game_401671734.csv\n",
            "Processed file:  game_401671735.csv\n",
            "Processed file:  game_401671721.csv\n",
            "Processed file:  game_401671709.csv\n",
            "Processed file:  game_401671494.csv\n",
            "Processed file:  game_401671682.csv\n",
            "Processed file:  game_401671696.csv\n",
            "Processed file:  game_401671866.csv\n",
            "Processed file:  game_401671872.csv\n",
            "Processed file:  game_401671641.csv\n",
            "Processed file:  game_401671655.csv\n",
            "Processed file:  game_401671669.csv\n",
            "Processed file:  game_401671651.csv\n",
            "Processed file:  game_401671645.csv\n",
            "Processed file:  game_401671679.csv\n",
            "Processed file:  game_401671692.csv\n",
            "Processed file:  game_401671686.csv\n",
            "Processed file:  game_401671876.csv\n",
            "Processed file:  game_401671862.csv\n",
            "Processed file:  game_401671490.csv\n",
            "Processed file:  game_401671725.csv\n",
            "Processed file:  game_401671731.csv\n",
            "Processed file:  game_401671719.csv\n",
            "Processed file:  game_401671718.csv\n",
            "Processed file:  game_401671730.csv\n",
            "Processed file:  game_401671724.csv\n",
            "Processed file:  game_401671491.csv\n",
            "Processed file:  game_401671863.csv\n",
            "Processed file:  game_401671877.csv\n",
            "Processed file:  game_401671687.csv\n",
            "Processed file:  game_401671693.csv\n",
            "Processed file:  game_401671678.csv\n",
            "Processed file:  game_401671644.csv\n",
            "Processed file:  game_401671650.csv\n",
            "Processed file:  game_401671646.csv\n",
            "Processed file:  game_401671652.csv\n",
            "Processed file:  game_401671685.csv\n",
            "Processed file:  game_401671849.csv\n",
            "Processed file:  game_401671691.csv\n",
            "Processed file:  game_401671861.csv\n",
            "Processed file:  game_401671875.csv\n",
            "Processed file:  game_401671493.csv\n",
            "Processed file:  game_401671732.csv\n",
            "Processed file:  game_401671726.csv\n",
            "Processed file:  game_401671727.csv\n",
            "Processed file:  game_401671733.csv\n",
            "Processed file:  game_401671492.csv\n",
            "Processed file:  game_401671874.csv\n",
            "Processed file:  game_401671860.csv\n",
            "Processed file:  game_401671690.csv\n",
            "Processed file:  game_401671848.csv\n",
            "Processed file:  game_401671684.csv\n",
            "Processed file:  game_401671653.csv\n",
            "Processed file:  game_401671647.csv\n",
            "Processed file:  game_401671620.csv\n",
            "Processed file:  game_401671634.csv\n",
            "Processed file:  game_401671807.csv\n",
            "Processed file:  game_401671813.csv\n",
            "Processed file:  game_401671768.csv\n",
            "Processed file:  game_401671754.csv\n",
            "Processed file:  game_401671740.csv\n",
            "Processed file:  game_401671797.csv\n",
            "Processed file:  game_401671783.csv\n",
            "Processed file:  game_401671782.csv\n",
            "Processed file:  game_401671796.csv\n",
            "Processed file:  game_401671741.csv\n",
            "Processed file:  game_401671755.csv\n",
            "Processed file:  game_401671769.csv\n",
            "Processed file:  game_401671812.csv\n",
            "Processed file:  game_401671806.csv\n",
            "Processed file:  game_401671635.csv\n",
            "Processed file:  game_401671621.csv\n",
            "Processed file:  game_401671637.csv\n",
            "Processed file:  game_401671623.csv\n",
            "Processed file:  game_401671810.csv\n",
            "Processed file:  game_401671804.csv\n",
            "Processed file:  game_401671838.csv\n",
            "Processed file:  game_401671743.csv\n",
            "Processed file:  game_401671757.csv\n",
            "Processed file:  game_401671780.csv\n",
            "Processed file:  game_401671794.csv\n",
            "Processed file:  game_401671795.csv\n",
            "Processed file:  game_401671781.csv\n",
            "Processed file:  game_401671756.csv\n",
            "Processed file:  game_401671742.csv\n",
            "Processed file:  game_401671839.csv\n",
            "Processed file:  game_401671805.csv\n",
            "Processed file:  game_401671811.csv\n",
            "Processed file:  game_401671622.csv\n",
            "Processed file:  game_401671636.csv\n",
            "Processed file:  game_401671632.csv\n",
            "Processed file:  game_401671626.csv\n",
            "Processed file:  game_401671829.csv\n",
            "Processed file:  game_401671815.csv\n",
            "Processed file:  game_401671801.csv\n",
            "Processed file:  game_401671746.csv\n",
            "Processed file:  game_401671752.csv\n",
            "Processed file:  game_401671785.csv\n",
            "Processed file:  game_401671791.csv\n",
            "Processed file:  game_401671790.csv\n",
            "Processed file:  game_401671784.csv\n",
            "Processed file:  game_401671753.csv\n",
            "Processed file:  game_401671747.csv\n",
            "Processed file:  game_401671800.csv\n",
            "Processed file:  game_401671814.csv\n",
            "Processed file:  game_401671828.csv\n",
            "Processed file:  game_401671627.csv\n",
            "Processed file:  game_401671633.csv\n",
            "Processed file:  game_401671625.csv\n",
            "Processed file:  game_401671631.csv\n",
            "Processed file:  game_401671619.csv\n",
            "Processed file:  game_401671802.csv\n",
            "Processed file:  game_401671816.csv\n",
            "Processed file:  game_401671751.csv\n",
            "Processed file:  game_401671745.csv\n",
            "Processed file:  game_401671779.csv\n",
            "Processed file:  game_401671792.csv\n",
            "Processed file:  game_401671786.csv\n",
            "Processed file:  game_401671787.csv\n",
            "Processed file:  game_401671793.csv\n",
            "Processed file:  game_401671778.csv\n",
            "Processed file:  game_401671744.csv\n",
            "Processed file:  game_401671750.csv\n",
            "Processed file:  game_401671817.csv\n",
            "Processed file:  game_401671803.csv\n",
            "Processed file:  game_401671618.csv\n",
            "Processed file:  game_401671630.csv\n",
            "Processed file:  game_401671624.csv\n"
          ]
        }
      ],
      "source": [
        "# Write predictions to csv file\n",
        "from process_data import write_predictions\n",
        "write_predictions(ensemble_models, interpolated_dir, [2024], 4, features, replace_nan_val = 0, phat_b = \"ensemble_phat_b\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NFL env",
      "language": "python",
      "name": "nfl_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
