{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensemble training (1 year of testing, 2 years of validation, the rest is training)\n",
        "    # Learned weights on validation data (Constrained optimization)\n",
        "    # Meta-learning using an other ML model\n",
        "\n",
        "# Models used:\n",
        "# - XGBoost\n",
        "# - Neural Network\n",
        "# - Logistic Regression\n",
        "# - LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML\n"
          ]
        }
      ],
      "source": [
        "# Set up paths and load data\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "sys.path.append(parent_dir)\n",
        "print(parent_dir)\n",
        "\n",
        "interpolated_dir = os.path.join(parent_dir, \"dataset_interpolated_fixed\")\n",
        "features = [\"game_completed\", \"relative_strength\", \"score_difference\", \"type.id\", \"home_has_possession\", \"end.down\", \"end.yardsToEndzone\", \"end.distance\", \"field_position_shift\", \"home_timeouts_left\", \"away_timeouts_left\"]\n",
        "# Import necessary modules\n",
        "from sklearn.metrics import brier_score_loss, accuracy_score, log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.optimize import minimize\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326405.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326412.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2021/game_401326412.csv\n",
            "  Completed processing 2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
            "  Completed processing 2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "  Processing 255 CSV files in parallel with 8 workers...\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220254.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2020/game_401220161.csv\n",
            "  Completed processing 2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
            "  NaN found in file: /Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024/game_401671770.csv\n",
            "  Completed processing 2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n"
          ]
        }
      ],
      "source": [
        "# Load data for ensemble training\n",
        "import process_data\n",
        "# training_data = process_data.load_data(interpolated_dir, \n",
        "#                                        years = [2016, 2017, 2018, 2019, 2020, 2021], \n",
        "#                                        history_length = 0, \n",
        "#                                        features = features, \n",
        "#                                        label_feature = \"home_win\")\n",
        "\n",
        "training_data = process_data.load_data(interpolated_dir, \n",
        "                                       years = [2021], \n",
        "                                       history_length = 0, \n",
        "                                       features = features, \n",
        "                                       label_feature = \"home_win\")\n",
        "\n",
        "\n",
        "ensemble_data = process_data.load_data(interpolated_dir, \n",
        "                                         years = [2023], \n",
        "                                         history_length = 0, \n",
        "                                         features = features, \n",
        "                                         label_feature = \"home_win\",\n",
        "                                         train = True\n",
        "                                         )\n",
        "\n",
        "test_data = process_data.load_data(interpolated_dir, \n",
        "                                   years = [2024],\n",
        "                                   history_length = 0, \n",
        "                                   features = features, \n",
        "                                   label_feature = \"home_win\",\n",
        "                                   train = False\n",
        "                                   )\n",
        "\n",
        "# training_data_seq = process_data.load_data(interpolated_dir, \n",
        "#                                        years = [2016, 2017, 2018, 2019, 2020], \n",
        "#                                        history_length = 4, \n",
        "#                                        features = features, \n",
        "#                                        label_feature = \"home_win\",\n",
        "#                                        train = True\n",
        "#                                        )\n",
        "\n",
        "training_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                       years = [2020], \n",
        "                                       history_length = 4, \n",
        "                                       features = features, \n",
        "                                       label_feature = \"home_win\",\n",
        "                                       train = True\n",
        "                                       )\n",
        "\n",
        "ensemble_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                         years = [2023], \n",
        "                                         history_length = 4, \n",
        "                                         features = features, \n",
        "                                         label_feature = \"home_win\",\n",
        "                                         train = True\n",
        "                                         )\n",
        "\n",
        "test_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                   years = [2024],\n",
        "                                   history_length = 4, \n",
        "                                   features = features, \n",
        "                                   label_feature = \"home_win\",\n",
        "                                   train = False\n",
        "                                   )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "class EnsemblePredictor:\n",
        "    \"\"\"\n",
        "    Ensemble predictor class, one per timestep\n",
        "    \"\"\"\n",
        "    def __init__(self, all_models, all_models_order, all_features, strategy='meta_model', meta_model=None):\n",
        "        self.all_models = all_models\n",
        "        self.all_models_order = all_models_order\n",
        "        self.strategy = strategy\n",
        "        self.all_features = all_features\n",
        "        if self.strategy != 'meta_model' and self.strategy != 'weighted_average':\n",
        "            raise ValueError(\"Invalid strategy\")\n",
        "        if meta_model is None and self.strategy == 'meta_model':\n",
        "            raise ValueError(\"Meta model is required for meta_model strategy\")\n",
        "        self.meta_model = meta_model\n",
        "        self.ensemble_weights = None # Will be a 1D array of shape (n_models,) once trained\n",
        " \n",
        "    def train_ensemble(self, x_train, y_train, objective='brier'):\n",
        "        \"\"\"\n",
        "        Train the ensemble for a single timestep using validation data.\n",
        "        \"\"\"\n",
        "        print(f\"Training ensemble for this timestep...\")\n",
        "        if self.strategy == 'weighted_average':\n",
        "            self.optimize_ensemble_weights(x_train, y_train, objective)\n",
        "        elif self.strategy == 'meta_model':\n",
        "            self.train_meta_model(x_train, y_train)\n",
        "\n",
        "    def optimize_ensemble_weights(self, x_train, y_train, objective='brier'):\n",
        "        \"\"\"\n",
        "        Optimize ensemble weights for a single timestep using validation data.\n",
        "        \"\"\"\n",
        "        print(f\"Optimizing ensemble weights for this timestep...\")\n",
        "\n",
        "        n_models = x_train.shape[1]\n",
        "\n",
        "        def objective_function(weights):\n",
        "            weights = weights / np.sum(weights)  # Normalize weights\n",
        "            ensemble_preds = np.dot(x_train, weights)\n",
        "\n",
        "            if objective == 'brier':\n",
        "                return brier_score_loss(y_train, ensemble_preds)\n",
        "            elif objective == 'logloss':\n",
        "                # Clip predictions to avoid log(0)\n",
        "                ensemble_preds = np.clip(ensemble_preds, 1e-15, 1-1e-15)\n",
        "                return log_loss(y_train, ensemble_preds)\n",
        "            elif objective == 'accuracy':\n",
        "                return -accuracy_score(y_train, ensemble_preds > 0.5)  # Negative for minimization\n",
        "\n",
        "        # Constraints: weights sum to 1 and are non-negative\n",
        "        constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
        "        bounds = [(0, 1) for _ in range(n_models)]\n",
        "\n",
        "        # Initialize with equal weights\n",
        "        initial_weights = np.ones(n_models) / n_models\n",
        "\n",
        "        result = minimize(objective_function, initial_weights,\n",
        "                          method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "\n",
        "        if result.success:\n",
        "            self.ensemble_weights = result.x\n",
        "            print(f\"  Optimized weights: {dict(zip(self.all_models_order, result.x.round(4)))} (score: {result.fun:.6f})\")\n",
        "        else:\n",
        "            print(f\"  Optimization failed, using equal weights\")\n",
        "            self.ensemble_weights = initial_weights\n",
        "\n",
        "        return self.ensemble_weights\n",
        "\n",
        "    def train_meta_model(self, x_train, y_train):\n",
        "        \"\"\"\n",
        "        Train a meta-model for a single timestep to predict based on base model outputs.\n",
        "        \"\"\"\n",
        "        X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "        # Train meta-model: input=base_model_predictions, output=final_prediction\n",
        "        self.meta_model.fit(X_train, y_train.reshape(-1, 1))\n",
        "\n",
        "        # Test the meta-model's prediction capability\n",
        "        meta_predictions = self.meta_model.predict_proba(X_val)[:, 1]\n",
        "        meta_accuracy = accuracy_score(y_val, meta_predictions > 0.5)\n",
        "        meta_brier = brier_score_loss(y_val, meta_predictions)\n",
        "\n",
        "        print(f\"  Meta-model trained on {len(X_train)} samples\")\n",
        "        print(f\"    Validation Meta-model accuracy: {meta_accuracy:.4f}, Validation Brier score: {meta_brier:.4f}\")\n",
        "\n",
        "        return self.meta_model\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probability of the positive class for a given input\n",
        "        \"\"\"\n",
        "        # Generate predictions from each individual model\n",
        "        # Convert X to a 3D array of shape (n_samples, n_history, n_features)\n",
        "        predictions = [] # Will be a 2D array of shape (n_samples, n_models)\n",
        "        for i, model_name in enumerate(self.all_models_order):\n",
        "            model = self.all_models[model_name]\n",
        "            print(\"Model name: \", model_name)\n",
        "            if model_name == \"lstm\":\n",
        "                print(X.shape)\n",
        "                pred = model.predict_proba(X)\n",
        "                print(pred)\n",
        "                predictions.append(pred[:, 1])\n",
        "            else:\n",
        "                print(X.shape)\n",
        "                x = np.array([X[i][-1] for i in range(X.shape[0])]) if len(X.shape) == 3 else np.array([X[-1]])\n",
        "                print(x.shape)\n",
        "                pred = model.predict_proba(x)\n",
        "                print(pred)\n",
        "                predictions.append(pred[:, 1]) # Will be a 1D array of shape (n_samples,) for each model\n",
        "        predictions = np.array(predictions) # Will be a 2D array of shape (n_models, n_samples)\n",
        "        predictions = predictions.T # Reshape to be a 2D array of shape (n_samples, n_models)\n",
        "        if self.strategy == 'weighted_average':\n",
        "            return np.dot(predictions, self.ensemble_weights)\n",
        "        elif self.strategy == 'meta_model':\n",
        "            return self.meta_model.predict_proba(predictions)[:, 1]\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probability of the positive class for a given input\n",
        "        \"\"\"\n",
        "        pred = self.predict(X).flatten()\n",
        "        return np.column_stack([1 - pred, pred])\n",
        "\n",
        "    def predict_proba_single(self, X):\n",
        "        preds = self.predict_proba(X)\n",
        "        return preds[:, 1]\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        Score the ensemble for a given input\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "        y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "        return np.mean(y_pred_labels == y)\n",
        "    \n",
        "    def SHAP_analysis(self, X_test, X_train, plot = True):\n",
        "        \"\"\"\n",
        "        Model interpretability with SHAP values\n",
        "        \"\"\"\n",
        "        feature_names = self.all_features\n",
        "        masker = shap.maskers.Independent(X_train[:10])\n",
        "        explainer = shap.Explainer(self.predict_proba_single, masker, feature_names=self.all_features)\n",
        "        shap_values = explainer(X_test)\n",
        "        if plot:\n",
        "            shap.plots.bar(shap_values)\n",
        "        return shap_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload modules\n",
        "modules_to_reload = [\n",
        "    'models.xg_boost',\n",
        "    'models.direct_prediction_network_lstm',\n",
        "    'models.direct_prediction_network',\n",
        "    'models.logistic_regression',\n",
        "    'models.Model'\n",
        "]\n",
        "\n",
        "for module_name in modules_to_reload:\n",
        "    if module_name in sys.modules:\n",
        "        del sys.modules[module_name]\n",
        "from models.xg_boost import setup_xgboost_models\n",
        "from models.direct_prediction_network_lstm import setup_direct_lstm_models\n",
        "from models.direct_prediction_network import setup_direct_models\n",
        "from models.logistic_regression import setup_logistic_regression_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split training data: 450 train, 50 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.0, 0.005]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 1/201 completed\n",
            "Split training data: 136 train, 16 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.005, 0.01]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 2/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.01, 0.015]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 3/201 completed\n",
            "Split training data: 223 train, 25 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.015, 0.02]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 4/201 completed\n",
            "Split training data: 257 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.02, 0.025]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 5/201 completed\n",
            "Split training data: 276 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.025, 0.03]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 6/201 completed\n",
            "Split training data: 243 train, 27 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.03, 0.035]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 7/201 completed\n",
            "Split training data: 266 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.035, 0.04]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.7406, Train Loss: 0.2014, Val Acc: 0.7000, Val Loss: 0.2088\n",
            "Restored model from best epoch 15 with val_loss: 0.208819\n",
            "NFL LSTM model 8/201 completed\n",
            "Split training data: 249 train, 28 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.04, 0.045]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 9/201 completed\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.045, 0.05]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 10/201 completed\n",
            "Split training data: 273 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.05, 0.055]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.7509, Train Loss: 0.1873, Val Acc: 0.6774, Val Loss: 0.1765\n",
            "Restored model from best epoch 24 with val_loss: 0.176472\n",
            "NFL LSTM model 11/201 completed\n",
            "Split training data: 265 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.055, 0.06]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.6679, Train Loss: 0.2193, Val Acc: 0.5667, Val Loss: 0.2365\n",
            "Restored model from best epoch 11 with val_loss: 0.236472\n",
            "NFL LSTM model 12/201 completed\n",
            "Split training data: 261 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.06, 0.065]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 13/201 completed\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.065, 0.07]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.7076, Train Loss: 0.1982, Val Acc: 0.7097, Val Loss: 0.2154\n",
            "Restored model from best epoch 17 with val_loss: 0.215428\n",
            "NFL LSTM model 14/201 completed\n",
            "Split training data: 280 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.07, 0.075]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 15/201 completed\n",
            "Split training data: 274 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.075, 0.08]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 16/201 completed\n",
            "Split training data: 269 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.08, 0.085]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 17/201 completed\n",
            "Split training data: 306 train, 34 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.085, 0.09]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.6503, Train Loss: 0.2278, Val Acc: 0.7647, Val Loss: 0.1915\n",
            "Restored model from best epoch 8 with val_loss: 0.191470\n",
            "NFL LSTM model 18/201 completed\n",
            "Split training data: 272 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.09, 0.095]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 6\n",
            "Best epoch: 1, Train Acc: 0.4743, Train Loss: 0.2656, Val Acc: 0.5161, Val Loss: 0.2567\n",
            "Restored model from best epoch 1 with val_loss: 0.256713\n",
            "NFL LSTM model 19/201 completed\n",
            "Split training data: 258 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.095, 0.1]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 20/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.1, 0.105]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 21/201 completed\n",
            "Split training data: 270 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.105, 0.11]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 22/201 completed\n",
            "Split training data: 270 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.11, 0.115]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 23/201 completed\n",
            "Split training data: 261 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.115, 0.12]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.6782, Train Loss: 0.2061, Val Acc: 0.5667, Val Loss: 0.2196\n",
            "Restored model from best epoch 9 with val_loss: 0.219582\n",
            "NFL LSTM model 24/201 completed\n",
            "Split training data: 286 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.12, 0.125]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 25/201 completed\n",
            "Split training data: 290 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.125, 0.13]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 26/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.13, 0.135]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.6631, Train Loss: 0.2040, Val Acc: 0.6129, Val Loss: 0.2275\n",
            "Restored model from best epoch 13 with val_loss: 0.227490\n",
            "NFL LSTM model 27/201 completed\n",
            "Split training data: 279 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.135, 0.14]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 28/201 completed\n",
            "Split training data: 273 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.14, 0.145]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 29/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.145, 0.15]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 30/201 completed\n",
            "Split training data: 282 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.15, 0.155]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 31/201 completed\n",
            "Split training data: 281 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.155, 0.16]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 32/201 completed\n",
            "Split training data: 264 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.16, 0.165]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 33/201 completed\n",
            "Split training data: 275 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.165, 0.17]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.7455, Train Loss: 0.1761, Val Acc: 0.8065, Val Loss: 0.1683\n",
            "Restored model from best epoch 24 with val_loss: 0.168345\n",
            "NFL LSTM model 34/201 completed\n",
            "Split training data: 285 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.17, 0.175]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 35/201 completed\n",
            "Split training data: 255 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.175, 0.18]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 36/201 completed\n",
            "Split training data: 266 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.18, 0.185]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 37/201 completed\n",
            "Split training data: 282 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.185, 0.19]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 38/201 completed\n",
            "Split training data: 287 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.19, 0.195]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 39/201 completed\n",
            "Split training data: 254 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.195, 0.2]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 40/201 completed\n",
            "Split training data: 269 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.2, 0.205]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 41/201 completed\n",
            "Split training data: 265 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.205, 0.21]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 42/201 completed\n",
            "Split training data: 292 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.21, 0.215]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 7\n",
            "Best epoch: 2, Train Acc: 0.5753, Train Loss: 0.2382, Val Acc: 0.5758, Val Loss: 0.1804\n",
            "Restored model from best epoch 2 with val_loss: 0.180389\n",
            "NFL LSTM model 43/201 completed\n",
            "Split training data: 256 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.215, 0.22]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.7422, Train Loss: 0.1843, Val Acc: 0.7241, Val Loss: 0.1838\n",
            "Restored model from best epoch 22 with val_loss: 0.183795\n",
            "NFL LSTM model 44/201 completed\n",
            "Split training data: 272 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.22, 0.225]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 45/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.225, 0.23]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 46/201 completed\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.23, 0.235]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 47/201 completed\n",
            "Split training data: 287 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.235, 0.24]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 48/201 completed\n",
            "Split training data: 271 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.24, 0.245]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 49/201 completed\n",
            "Split training data: 265 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.245, 0.25]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 50/201 completed\n",
            "Split training data: 879 train, 98 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.25, 0.255]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 51/201 completed\n",
            "Split training data: 134 train, 15 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.255, 0.26]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 52/201 completed\n",
            "Split training data: 231 train, 26 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.26, 0.265]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 53/201 completed\n",
            "Split training data: 281 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.265, 0.27]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.7189, Train Loss: 0.1779, Val Acc: 0.6250, Val Loss: 0.1860\n",
            "Restored model from best epoch 23 with val_loss: 0.185975\n",
            "NFL LSTM model 54/201 completed\n",
            "Split training data: 253 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.27, 0.275]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 55/201 completed\n",
            "Split training data: 285 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.275, 0.28]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 56/201 completed\n",
            "Split training data: 248 train, 28 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.28, 0.285]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.7298, Train Loss: 0.1830, Val Acc: 0.7143, Val Loss: 0.1961\n",
            "Restored model from best epoch 15 with val_loss: 0.196058\n",
            "NFL LSTM model 57/201 completed\n",
            "Split training data: 306 train, 35 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.285, 0.29]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 58/201 completed\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.29, 0.295]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.7201, Train Loss: 0.1827, Val Acc: 0.6667, Val Loss: 0.1984\n",
            "Restored model from best epoch 20 with val_loss: 0.198433\n",
            "NFL LSTM model 59/201 completed\n",
            "Split training data: 266 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.295, 0.3]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7180, Train Loss: 0.1993, Val Acc: 0.6333, Val Loss: 0.2053\n",
            "Restored model from best epoch 11 with val_loss: 0.205280\n",
            "NFL LSTM model 60/201 completed\n",
            "Split training data: 261 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.3, 0.305]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 61/201 completed\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.305, 0.31]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.7690, Train Loss: 0.1591, Val Acc: 0.7419, Val Loss: 0.1870\n",
            "Restored model from best epoch 22 with val_loss: 0.187045\n",
            "NFL LSTM model 62/201 completed\n",
            "Split training data: 294 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.31, 0.315]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 63/201 completed\n",
            "Split training data: 254 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.315, 0.32]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 64/201 completed\n",
            "Split training data: 285 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.32, 0.325]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.7439, Train Loss: 0.1748, Val Acc: 0.7500, Val Loss: 0.1717\n",
            "Restored model from best epoch 14 with val_loss: 0.171709\n",
            "NFL LSTM model 65/201 completed\n",
            "Split training data: 261 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.325, 0.33]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.7510, Train Loss: 0.1668, Val Acc: 0.8966, Val Loss: 0.1327\n",
            "Restored model from best epoch 23 with val_loss: 0.132650\n",
            "NFL LSTM model 66/201 completed\n",
            "Split training data: 295 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.33, 0.335]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 67/201 completed\n",
            "Split training data: 282 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.335, 0.34]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 68/201 completed\n",
            "Split training data: 290 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.34, 0.345]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 69/201 completed\n",
            "Split training data: 278 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.345, 0.35]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 70/201 completed\n",
            "Split training data: 276 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.35, 0.355]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 71/201 completed\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.355, 0.36]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 72/201 completed\n",
            "Split training data: 281 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.36, 0.365]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.7580, Train Loss: 0.1796, Val Acc: 0.6250, Val Loss: 0.2204\n",
            "Restored model from best epoch 15 with val_loss: 0.220433\n",
            "NFL LSTM model 73/201 completed\n",
            "Split training data: 299 train, 34 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.365, 0.37]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 6\n",
            "Best epoch: 1, Train Acc: 0.5251, Train Loss: 0.2493, Val Acc: 0.5588, Val Loss: 0.2103\n",
            "Restored model from best epoch 1 with val_loss: 0.210335\n",
            "NFL LSTM model 74/201 completed\n",
            "Split training data: 258 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.37, 0.375]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.7674, Train Loss: 0.1731, Val Acc: 0.6897, Val Loss: 0.2110\n",
            "Restored model from best epoch 24 with val_loss: 0.211009\n",
            "NFL LSTM model 75/201 completed\n",
            "Split training data: 270 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.375, 0.38]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 76/201 completed\n",
            "Split training data: 267 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.38, 0.385]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 77/201 completed\n",
            "Split training data: 292 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.385, 0.39]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 78/201 completed\n",
            "Split training data: 267 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.39, 0.395]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 79/201 completed\n",
            "Split training data: 286 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.395, 0.4]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.7552, Train Loss: 0.1711, Val Acc: 0.6562, Val Loss: 0.2015\n",
            "Restored model from best epoch 20 with val_loss: 0.201477\n",
            "NFL LSTM model 80/201 completed\n",
            "Split training data: 278 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.4, 0.405]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 81/201 completed\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.405, 0.41]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.7985, Train Loss: 0.1456, Val Acc: 0.8667, Val Loss: 0.1192\n",
            "Restored model from best epoch 24 with val_loss: 0.119200\n",
            "NFL LSTM model 82/201 completed\n",
            "Split training data: 279 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.41, 0.415]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 83/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.415, 0.42]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 84/201 completed\n",
            "Split training data: 302 train, 34 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.42, 0.425]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 6\n",
            "Best epoch: 1, Train Acc: 0.4834, Train Loss: 0.2734, Val Acc: 0.4412, Val Loss: 0.2280\n",
            "Restored model from best epoch 1 with val_loss: 0.228003\n",
            "NFL LSTM model 85/201 completed\n",
            "Split training data: 293 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.425, 0.43]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 86/201 completed\n",
            "Split training data: 264 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.43, 0.435]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 87/201 completed\n",
            "Split training data: 293 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.435, 0.44]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 88/201 completed\n",
            "Split training data: 260 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.44, 0.445]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 89/201 completed\n",
            "Split training data: 272 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.445, 0.45]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 90/201 completed\n",
            "Split training data: 292 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.45, 0.455]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 91/201 completed\n",
            "Split training data: 265 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.455, 0.46]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.7925, Train Loss: 0.1416, Val Acc: 0.6667, Val Loss: 0.1976\n",
            "Restored model from best epoch 20 with val_loss: 0.197582\n",
            "NFL LSTM model 92/201 completed\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.46, 0.465]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.7545, Train Loss: 0.1716, Val Acc: 0.6452, Val Loss: 0.2151\n",
            "Restored model from best epoch 15 with val_loss: 0.215139\n",
            "NFL LSTM model 93/201 completed\n",
            "Split training data: 253 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.465, 0.47]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 94/201 completed\n",
            "Split training data: 769 train, 86 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.47, 0.475]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 95/201 completed\n",
            "Split training data: 370 train, 42 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.475, 0.48]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 96/201 completed\n",
            "Split training data: 414 train, 47 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.48, 0.485]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.8140, Train Loss: 0.1359, Val Acc: 0.7660, Val Loss: 0.1602\n",
            "Restored model from best epoch 19 with val_loss: 0.160238\n",
            "NFL LSTM model 97/201 completed\n",
            "Split training data: 495 train, 56 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.485, 0.49]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 98/201 completed\n",
            "Split training data: 601 train, 67 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.49, 0.495]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 99/201 completed\n",
            "Split training data: 756 train, 85 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.495, 0.5]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.8360, Train Loss: 0.1237, Val Acc: 0.8588, Val Loss: 0.1140\n",
            "Restored model from best epoch 20 with val_loss: 0.113962\n",
            "NFL LSTM model 100/201 completed\n",
            "Split training data: 1296 train, 144 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.5, 0.505]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 101/201 completed\n",
            "Split training data: 169 train, 19 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.505, 0.51]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 102/201 completed\n",
            "Split training data: 253 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.51, 0.515]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 103/201 completed\n",
            "Split training data: 237 train, 27 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.515, 0.52]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 104/201 completed\n",
            "Split training data: 245 train, 28 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.52, 0.525]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 105/201 completed\n",
            "Split training data: 276 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.525, 0.53]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 106/201 completed\n",
            "Split training data: 265 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.53, 0.535]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 107/201 completed\n",
            "Split training data: 265 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.535, 0.54]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 108/201 completed\n",
            "Split training data: 273 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.54, 0.545]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8132, Train Loss: 0.1406, Val Acc: 0.7419, Val Loss: 0.1726\n",
            "Restored model from best epoch 14 with val_loss: 0.172595\n",
            "NFL LSTM model 109/201 completed\n",
            "Split training data: 266 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.545, 0.55]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 110/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.55, 0.555]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 111/201 completed\n",
            "Split training data: 272 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.555, 0.56]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.8493, Train Loss: 0.1334, Val Acc: 0.7742, Val Loss: 0.1554\n",
            "Restored model from best epoch 24 with val_loss: 0.155364\n",
            "NFL LSTM model 112/201 completed\n",
            "Split training data: 271 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.56, 0.565]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 113/201 completed\n",
            "Split training data: 279 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.565, 0.57]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.8387, Train Loss: 0.1246, Val Acc: 0.8750, Val Loss: 0.0831\n",
            "Restored model from best epoch 23 with val_loss: 0.083109\n",
            "NFL LSTM model 114/201 completed\n",
            "Split training data: 270 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.57, 0.575]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 115/201 completed\n",
            "Split training data: 272 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.575, 0.58]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 116/201 completed\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.58, 0.585]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.8159, Train Loss: 0.1339, Val Acc: 0.7742, Val Loss: 0.1675\n",
            "Restored model from best epoch 20 with val_loss: 0.167549\n",
            "NFL LSTM model 117/201 completed\n",
            "Split training data: 267 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.585, 0.59]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 118/201 completed\n",
            "Split training data: 297 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.59, 0.595]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 119/201 completed\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.595, 0.6]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 120/201 completed\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.6, 0.605]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 121/201 completed\n",
            "Split training data: 280 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.605, 0.61]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 122/201 completed\n",
            "Split training data: 283 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.61, 0.615]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 123/201 completed\n",
            "Split training data: 283 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.615, 0.62]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 124/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.62, 0.625]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.8280, Train Loss: 0.1319, Val Acc: 0.8065, Val Loss: 0.1296\n",
            "Restored model from best epoch 24 with val_loss: 0.129630\n",
            "NFL LSTM model 125/201 completed\n",
            "Split training data: 275 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.625, 0.63]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 126/201 completed\n",
            "Split training data: 258 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.63, 0.635]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 127/201 completed\n",
            "Split training data: 288 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.635, 0.64]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 128/201 completed\n",
            "Split training data: 243 train, 28 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.64, 0.645]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 129/201 completed\n",
            "Split training data: 271 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.645, 0.65]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 130/201 completed\n",
            "Split training data: 273 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.65, 0.655]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.8718, Train Loss: 0.1155, Val Acc: 0.7742, Val Loss: 0.1482\n",
            "Restored model from best epoch 23 with val_loss: 0.148228\n",
            "NFL LSTM model 131/201 completed\n",
            "Split training data: 281 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.655, 0.66]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 132/201 completed\n",
            "Split training data: 297 train, 34 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.66, 0.665]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 133/201 completed\n",
            "Split training data: 299 train, 34 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.665, 0.67]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8194, Train Loss: 0.1475, Val Acc: 0.7353, Val Loss: 0.2081\n",
            "Restored model from best epoch 8 with val_loss: 0.208114\n",
            "NFL LSTM model 134/201 completed\n",
            "Split training data: 259 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.67, 0.675]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8147, Train Loss: 0.1588, Val Acc: 0.8276, Val Loss: 0.1272\n",
            "Restored model from best epoch 22 with val_loss: 0.127190\n",
            "NFL LSTM model 135/201 completed\n",
            "Split training data: 283 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.675, 0.68]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 136/201 completed\n",
            "Split training data: 266 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.68, 0.685]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 137/201 completed\n",
            "Split training data: 288 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.685, 0.69]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 138/201 completed\n",
            "Split training data: 266 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.69, 0.695]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 139/201 completed\n",
            "Split training data: 262 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.695, 0.7]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 140/201 completed\n",
            "Split training data: 288 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.7, 0.705]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8368, Train Loss: 0.1524, Val Acc: 0.6875, Val Loss: 0.1948\n",
            "Restored model from best epoch 17 with val_loss: 0.194797\n",
            "NFL LSTM model 141/201 completed\n",
            "Split training data: 266 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.705, 0.71]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 142/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.71, 0.715]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 143/201 completed\n",
            "Split training data: 270 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.715, 0.72]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.8741, Train Loss: 0.1013, Val Acc: 0.8710, Val Loss: 0.1147\n",
            "Restored model from best epoch 25 with val_loss: 0.114682\n",
            "NFL LSTM model 144/201 completed\n",
            "Split training data: 286 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.72, 0.725]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 145/201 completed\n",
            "Split training data: 307 train, 35 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.725, 0.73]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.8339, Train Loss: 0.1228, Val Acc: 0.8000, Val Loss: 0.1676\n",
            "Restored model from best epoch 23 with val_loss: 0.167619\n",
            "NFL LSTM model 146/201 completed\n",
            "Split training data: 279 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.73, 0.735]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 147/201 completed\n",
            "Split training data: 275 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.735, 0.74]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.8800, Train Loss: 0.0974, Val Acc: 0.8065, Val Loss: 0.1613\n",
            "Restored model from best epoch 24 with val_loss: 0.161342\n",
            "NFL LSTM model 148/201 completed\n",
            "Split training data: 256 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.74, 0.745]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 149/201 completed\n",
            "Split training data: 239 train, 27 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.745, 0.75]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 150/201 completed\n",
            "Split training data: 833 train, 93 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.75, 0.755]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 151/201 completed\n",
            "Split training data: 129 train, 15 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.755, 0.76]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 152/201 completed\n",
            "Split training data: 215 train, 24 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.76, 0.765]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 153/201 completed\n",
            "Split training data: 298 train, 34 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.765, 0.77]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 154/201 completed\n",
            "Split training data: 246 train, 28 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.77, 0.775]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 155/201 completed\n",
            "Split training data: 324 train, 37 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.775, 0.78]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8611, Train Loss: 0.1101, Val Acc: 0.8378, Val Loss: 0.1574\n",
            "Restored model from best epoch 17 with val_loss: 0.157389\n",
            "NFL LSTM model 156/201 completed\n",
            "Split training data: 263 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.78, 0.785]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.8631, Train Loss: 0.1075, Val Acc: 0.8000, Val Loss: 0.1279\n",
            "Restored model from best epoch 25 with val_loss: 0.127904\n",
            "NFL LSTM model 157/201 completed\n",
            "Split training data: 263 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.785, 0.79]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 158/201 completed\n",
            "Split training data: 258 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.79, 0.795]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 159/201 completed\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.795, 0.8]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 160/201 completed\n",
            "Split training data: 295 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.8, 0.805]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 161/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.805, 0.81]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 162/201 completed\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.81, 0.815]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 163/201 completed\n",
            "Split training data: 283 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.815, 0.82]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.8940, Train Loss: 0.0973, Val Acc: 0.7500, Val Loss: 0.1643\n",
            "Restored model from best epoch 20 with val_loss: 0.164329\n",
            "NFL LSTM model 164/201 completed\n",
            "Split training data: 279 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.82, 0.825]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 165/201 completed\n",
            "Split training data: 254 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.825, 0.83]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 166/201 completed\n",
            "Split training data: 295 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.83, 0.835]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 167/201 completed\n",
            "Split training data: 287 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.835, 0.84]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 168/201 completed\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.84, 0.845]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 169/201 completed\n",
            "Split training data: 272 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.845, 0.85]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 170/201 completed\n",
            "Split training data: 301 train, 34 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.85, 0.855]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 171/201 completed\n",
            "Split training data: 288 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.855, 0.86]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 172/201 completed\n",
            "Split training data: 273 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.86, 0.865]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 173/201 completed\n",
            "Split training data: 267 train, 30 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.865, 0.87]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 174/201 completed\n",
            "Split training data: 296 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.87, 0.875]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 175/201 completed\n",
            "Split training data: 275 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.875, 0.88]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 176/201 completed\n",
            "Split training data: 284 train, 32 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.88, 0.885]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 177/201 completed\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.885, 0.89]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 178/201 completed\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.89, 0.895]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 179/201 completed\n",
            "Split training data: 315 train, 36 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.895, 0.9]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 180/201 completed\n",
            "Split training data: 258 train, 29 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.9, 0.905]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 181/201 completed\n",
            "Split training data: 299 train, 34 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.905, 0.91]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7860, Train Loss: 0.1717, Val Acc: 0.8529, Val Loss: 0.1694\n",
            "Restored model from best epoch 12 with val_loss: 0.169427\n",
            "NFL LSTM model 182/201 completed\n",
            "Split training data: 292 train, 33 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.91, 0.915]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 183/201 completed\n",
            "Split training data: 298 train, 34 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.915, 0.92]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 184/201 completed\n",
            "Split training data: 320 train, 36 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.92, 0.925]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 185/201 completed\n",
            "Split training data: 312 train, 35 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.925, 0.93]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.9006, Train Loss: 0.0872, Val Acc: 0.7714, Val Loss: 0.1913\n",
            "Restored model from best epoch 25 with val_loss: 0.191252\n",
            "NFL LSTM model 186/201 completed\n",
            "Split training data: 312 train, 35 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.93, 0.935]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 187/201 completed\n",
            "Split training data: 355 train, 40 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.935, 0.94]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 188/201 completed\n",
            "Split training data: 371 train, 42 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.94, 0.945]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.9137, Train Loss: 0.0731, Val Acc: 0.8571, Val Loss: 0.0980\n",
            "Restored model from best epoch 23 with val_loss: 0.097958\n",
            "NFL LSTM model 189/201 completed\n",
            "Split training data: 347 train, 39 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.945, 0.95]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.9308, Train Loss: 0.0596, Val Acc: 0.6667, Val Loss: 0.0891\n",
            "Restored model from best epoch 21 with val_loss: 0.089146\n",
            "NFL LSTM model 190/201 completed\n",
            "Split training data: 355 train, 40 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.95, 0.955]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 191/201 completed\n",
            "Split training data: 322 train, 36 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.955, 0.96]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 192/201 completed\n",
            "Split training data: 358 train, 40 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.96, 0.965]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 193/201 completed\n",
            "Split training data: 352 train, 40 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.965, 0.97]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 194/201 completed\n",
            "Split training data: 831 train, 93 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.97, 0.975]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 195/201 completed\n",
            "Split training data: 405 train, 45 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.975, 0.98]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 196/201 completed\n",
            "Split training data: 364 train, 41 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.98, 0.985]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 197/201 completed\n",
            "Split training data: 352 train, 40 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.985, 0.99]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 198/201 completed\n",
            "Split training data: 372 train, 42 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.99, 0.995]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 199/201 completed\n",
            "Split training data: 377 train, 42 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.995, 1.0]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 200/201 completed\n",
            "Split training data: 457 train, 51 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [1.0, 1.005]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.9475, Train Loss: 0.0536, Val Acc: 0.9804, Val Loss: 0.0342\n",
            "Restored model from best epoch 23 with val_loss: 0.034192\n",
            "NFL LSTM model 201/201 completed\n"
          ]
        }
      ],
      "source": [
        "all_models[\"lstm\"] = setup_direct_lstm_models(training_data_seq, None, num_models=201)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original data shape: (477, 11)\n",
            "Flattened data shape: (477, 11)\n",
            "Split training data: 429 train, 48 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.0, 0.005]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 82\n",
            "Best epoch: 72, Train Acc: 0.8159, Train Loss: 0.1356, Val Acc: 0.7708, Val Loss: 0.1664\n",
            "Restored model from best epoch 72 with val_loss: 0.166404\n",
            "NFL direct model 1/201 completed\n",
            "Original data shape: (180, 11)\n",
            "Flattened data shape: (180, 11)\n",
            "Split training data: 162 train, 18 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.005, 0.01]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.6605, Train Loss: 0.2175, Val Acc: 0.6667, Val Loss: 0.2309\n",
            "Restored model from best epoch 13 with val_loss: 0.230942\n",
            "NFL direct model 2/201 completed\n",
            "Original data shape: (300, 11)\n",
            "Flattened data shape: (300, 11)\n",
            "Split training data: 270 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.01, 0.015]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 40\n",
            "Best epoch: 30, Train Acc: 0.7185, Train Loss: 0.1913, Val Acc: 0.6667, Val Loss: 0.2030\n",
            "Restored model from best epoch 30 with val_loss: 0.202998\n",
            "NFL direct model 3/201 completed\n",
            "Original data shape: (280, 11)\n",
            "Flattened data shape: (280, 11)\n",
            "Split training data: 252 train, 28 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.015, 0.02]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.6587, Train Loss: 0.2197, Val Acc: 0.5000, Val Loss: 0.2389\n",
            "Restored model from best epoch 12 with val_loss: 0.238936\n",
            "NFL direct model 4/201 completed\n",
            "Original data shape: (294, 11)\n",
            "Flattened data shape: (294, 11)\n",
            "Split training data: 264 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.02, 0.025]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.5644, Train Loss: 0.2466, Val Acc: 0.6333, Val Loss: 0.2443\n",
            "Restored model from best epoch 3 with val_loss: 0.244257\n",
            "NFL direct model 5/201 completed\n",
            "Original data shape: (328, 11)\n",
            "Flattened data shape: (328, 11)\n",
            "Split training data: 295 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.025, 0.03]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.6949, Train Loss: 0.1993, Val Acc: 0.7273, Val Loss: 0.1918\n",
            "Restored model from best epoch 20 with val_loss: 0.191802\n",
            "NFL direct model 6/201 completed\n",
            "Original data shape: (283, 11)\n",
            "Flattened data shape: (283, 11)\n",
            "Split training data: 254 train, 29 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.03, 0.035]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.6535, Train Loss: 0.2095, Val Acc: 0.5862, Val Loss: 0.2261\n",
            "Restored model from best epoch 14 with val_loss: 0.226136\n",
            "NFL direct model 7/201 completed\n",
            "Original data shape: (331, 11)\n",
            "Flattened data shape: (331, 11)\n",
            "Split training data: 297 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.035, 0.04]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.4916, Train Loss: 0.2518, Val Acc: 0.6471, Val Loss: 0.2521\n",
            "Restored model from best epoch 1 with val_loss: 0.252106\n",
            "NFL direct model 8/201 completed\n",
            "Original data shape: (315, 11)\n",
            "Flattened data shape: (315, 11)\n",
            "Split training data: 283 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.04, 0.045]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.7138, Train Loss: 0.1763, Val Acc: 0.7188, Val Loss: 0.1947\n",
            "Restored model from best epoch 29 with val_loss: 0.194652\n",
            "NFL direct model 9/201 completed\n",
            "Original data shape: (316, 11)\n",
            "Flattened data shape: (316, 11)\n",
            "Split training data: 284 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.045, 0.05]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7007, Train Loss: 0.1943, Val Acc: 0.6562, Val Loss: 0.2171\n",
            "Restored model from best epoch 17 with val_loss: 0.217142\n",
            "NFL direct model 10/201 completed\n",
            "Original data shape: (325, 11)\n",
            "Flattened data shape: (325, 11)\n",
            "Split training data: 292 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.05, 0.055]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 19, Train Acc: 0.6952, Train Loss: 0.1874, Val Acc: 0.6667, Val Loss: 0.2177\n",
            "Restored model from best epoch 19 with val_loss: 0.217664\n",
            "NFL direct model 11/201 completed\n",
            "Original data shape: (311, 11)\n",
            "Flattened data shape: (311, 11)\n",
            "Split training data: 279 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.055, 0.06]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.6416, Train Loss: 0.2088, Val Acc: 0.6250, Val Loss: 0.2373\n",
            "Restored model from best epoch 16 with val_loss: 0.237322\n",
            "NFL direct model 12/201 completed\n",
            "Original data shape: (326, 11)\n",
            "Flattened data shape: (326, 11)\n",
            "Split training data: 293 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.06, 0.065]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.5563, Train Loss: 0.2416, Val Acc: 0.5152, Val Loss: 0.2545\n",
            "Restored model from best epoch 2 with val_loss: 0.254519\n",
            "NFL direct model 13/201 completed\n",
            "Original data shape: (321, 11)\n",
            "Flattened data shape: (321, 11)\n",
            "Split training data: 288 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.065, 0.07]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.5799, Train Loss: 0.2400, Val Acc: 0.6061, Val Loss: 0.2349\n",
            "Restored model from best epoch 7 with val_loss: 0.234935\n",
            "NFL direct model 14/201 completed\n",
            "Original data shape: (344, 11)\n",
            "Flattened data shape: (344, 11)\n",
            "Split training data: 309 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.07, 0.075]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.6505, Train Loss: 0.2263, Val Acc: 0.6000, Val Loss: 0.2373\n",
            "Restored model from best epoch 8 with val_loss: 0.237257\n",
            "NFL direct model 15/201 completed\n",
            "Original data shape: (321, 11)\n",
            "Flattened data shape: (321, 11)\n",
            "Split training data: 288 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.075, 0.08]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.6875, Train Loss: 0.2125, Val Acc: 0.6667, Val Loss: 0.2291\n",
            "Restored model from best epoch 10 with val_loss: 0.229089\n",
            "NFL direct model 16/201 completed\n",
            "Original data shape: (315, 11)\n",
            "Flattened data shape: (315, 11)\n",
            "Split training data: 283 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.08, 0.085]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.6784, Train Loss: 0.1987, Val Acc: 0.6562, Val Loss: 0.2224\n",
            "Restored model from best epoch 18 with val_loss: 0.222425\n",
            "NFL direct model 17/201 completed\n",
            "Original data shape: (335, 11)\n",
            "Flattened data shape: (335, 11)\n",
            "Split training data: 301 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.085, 0.09]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.5914, Train Loss: 0.2296, Val Acc: 0.5294, Val Loss: 0.2508\n",
            "Restored model from best epoch 6 with val_loss: 0.250829\n",
            "NFL direct model 18/201 completed\n",
            "Original data shape: (305, 11)\n",
            "Flattened data shape: (305, 11)\n",
            "Split training data: 274 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.09, 0.095]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6460, Train Loss: 0.2346, Val Acc: 0.6452, Val Loss: 0.2344\n",
            "Restored model from best epoch 7 with val_loss: 0.234416\n",
            "NFL direct model 19/201 completed\n",
            "Original data shape: (338, 11)\n",
            "Flattened data shape: (338, 11)\n",
            "Split training data: 304 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.095, 0.1]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7007, Train Loss: 0.1961, Val Acc: 0.5588, Val Loss: 0.2193\n",
            "Restored model from best epoch 16 with val_loss: 0.219321\n",
            "NFL direct model 20/201 completed\n",
            "Original data shape: (302, 11)\n",
            "Flattened data shape: (302, 11)\n",
            "Split training data: 271 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.1, 0.105]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6310, Train Loss: 0.2321, Val Acc: 0.6129, Val Loss: 0.2408\n",
            "Restored model from best epoch 6 with val_loss: 0.240809\n",
            "NFL direct model 21/201 completed\n",
            "Original data shape: (313, 11)\n",
            "Flattened data shape: (313, 11)\n",
            "Split training data: 281 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.105, 0.11]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.5836, Train Loss: 0.2386, Val Acc: 0.4688, Val Loss: 0.2465\n",
            "Restored model from best epoch 3 with val_loss: 0.246536\n",
            "NFL direct model 22/201 completed\n",
            "Original data shape: (337, 11)\n",
            "Flattened data shape: (337, 11)\n",
            "Split training data: 303 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.11, 0.115]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.5908, Train Loss: 0.2442, Val Acc: 0.5294, Val Loss: 0.2449\n",
            "Restored model from best epoch 3 with val_loss: 0.244899\n",
            "NFL direct model 23/201 completed\n",
            "Original data shape: (341, 11)\n",
            "Flattened data shape: (341, 11)\n",
            "Split training data: 306 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.115, 0.12]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 37\n",
            "Best epoch: 27, Train Acc: 0.7451, Train Loss: 0.1720, Val Acc: 0.6286, Val Loss: 0.2330\n",
            "Restored model from best epoch 27 with val_loss: 0.233042\n",
            "NFL direct model 24/201 completed\n",
            "Original data shape: (313, 11)\n",
            "Flattened data shape: (313, 11)\n",
            "Split training data: 281 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.12, 0.125]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.4804, Train Loss: 0.2555, Val Acc: 0.4375, Val Loss: 0.2498\n",
            "Restored model from best epoch 1 with val_loss: 0.249784\n",
            "NFL direct model 25/201 completed\n",
            "Original data shape: (351, 11)\n",
            "Flattened data shape: (351, 11)\n",
            "Split training data: 315 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.125, 0.13]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 46\n",
            "Best epoch: 36, Train Acc: 0.7778, Train Loss: 0.1565, Val Acc: 0.7500, Val Loss: 0.1642\n",
            "Restored model from best epoch 36 with val_loss: 0.164206\n",
            "NFL direct model 26/201 completed\n",
            "Original data shape: (313, 11)\n",
            "Flattened data shape: (313, 11)\n",
            "Split training data: 281 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.13, 0.135]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.7260, Train Loss: 0.1600, Val Acc: 0.8125, Val Loss: 0.1720\n",
            "Restored model from best epoch 24 with val_loss: 0.171996\n",
            "NFL direct model 27/201 completed\n",
            "Original data shape: (312, 11)\n",
            "Flattened data shape: (312, 11)\n",
            "Split training data: 280 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.135, 0.14]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7214, Train Loss: 0.1860, Val Acc: 0.6562, Val Loss: 0.2324\n",
            "Restored model from best epoch 14 with val_loss: 0.232406\n",
            "NFL direct model 28/201 completed\n",
            "Original data shape: (312, 11)\n",
            "Flattened data shape: (312, 11)\n",
            "Split training data: 280 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.14, 0.145]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.6821, Train Loss: 0.1980, Val Acc: 0.6562, Val Loss: 0.2374\n",
            "Restored model from best epoch 9 with val_loss: 0.237398\n",
            "NFL direct model 29/201 completed\n",
            "Original data shape: (307, 11)\n",
            "Flattened data shape: (307, 11)\n",
            "Split training data: 276 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.145, 0.15]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.7355, Train Loss: 0.1767, Val Acc: 0.8065, Val Loss: 0.1746\n",
            "Restored model from best epoch 24 with val_loss: 0.174621\n",
            "NFL direct model 30/201 completed\n",
            "Original data shape: (359, 11)\n",
            "Flattened data shape: (359, 11)\n",
            "Split training data: 323 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.15, 0.155]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7121, Train Loss: 0.1831, Val Acc: 0.7222, Val Loss: 0.1812\n",
            "Restored model from best epoch 17 with val_loss: 0.181238\n",
            "NFL direct model 31/201 completed\n",
            "Original data shape: (301, 11)\n",
            "Flattened data shape: (301, 11)\n",
            "Split training data: 270 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.155, 0.16]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 54\n",
            "Best epoch: 44, Train Acc: 0.8000, Train Loss: 0.1341, Val Acc: 0.7097, Val Loss: 0.2073\n",
            "Restored model from best epoch 44 with val_loss: 0.207299\n",
            "NFL direct model 32/201 completed\n",
            "Original data shape: (361, 11)\n",
            "Flattened data shape: (361, 11)\n",
            "Split training data: 324 train, 37 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.16, 0.165]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.6636, Train Loss: 0.2186, Val Acc: 0.6216, Val Loss: 0.2353\n",
            "Restored model from best epoch 10 with val_loss: 0.235335\n",
            "NFL direct model 33/201 completed\n",
            "Original data shape: (292, 11)\n",
            "Flattened data shape: (292, 11)\n",
            "Split training data: 262 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.165, 0.17]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.6947, Train Loss: 0.2257, Val Acc: 0.6333, Val Loss: 0.2178\n",
            "Restored model from best epoch 22 with val_loss: 0.217820\n",
            "NFL direct model 34/201 completed\n",
            "Original data shape: (308, 11)\n",
            "Flattened data shape: (308, 11)\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.17, 0.175]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6931, Train Loss: 0.2095, Val Acc: 0.6452, Val Loss: 0.2390\n",
            "Restored model from best epoch 7 with val_loss: 0.239005\n",
            "NFL direct model 35/201 completed\n",
            "Original data shape: (345, 11)\n",
            "Flattened data shape: (345, 11)\n",
            "Split training data: 310 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.175, 0.18]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6645, Train Loss: 0.2097, Val Acc: 0.6286, Val Loss: 0.2086\n",
            "Restored model from best epoch 7 with val_loss: 0.208579\n",
            "NFL direct model 36/201 completed\n",
            "Original data shape: (306, 11)\n",
            "Flattened data shape: (306, 11)\n",
            "Split training data: 275 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.18, 0.185]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7055, Train Loss: 0.1993, Val Acc: 0.4839, Val Loss: 0.2492\n",
            "Restored model from best epoch 6 with val_loss: 0.249202\n",
            "NFL direct model 37/201 completed\n",
            "Original data shape: (340, 11)\n",
            "Flattened data shape: (340, 11)\n",
            "Split training data: 306 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.185, 0.19]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.5261, Train Loss: 0.2491, Val Acc: 0.5882, Val Loss: 0.2470\n",
            "Restored model from best epoch 1 with val_loss: 0.247023\n",
            "NFL direct model 38/201 completed\n",
            "Original data shape: (287, 11)\n",
            "Flattened data shape: (287, 11)\n",
            "Split training data: 258 train, 29 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.19, 0.195]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.6744, Train Loss: 0.2207, Val Acc: 0.6897, Val Loss: 0.1815\n",
            "Restored model from best epoch 22 with val_loss: 0.181501\n",
            "NFL direct model 39/201 completed\n",
            "Original data shape: (365, 11)\n",
            "Flattened data shape: (365, 11)\n",
            "Split training data: 328 train, 37 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.195, 0.2]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7073, Train Loss: 0.1822, Val Acc: 0.6486, Val Loss: 0.2021\n",
            "Restored model from best epoch 14 with val_loss: 0.202070\n",
            "NFL direct model 40/201 completed\n",
            "Original data shape: (319, 11)\n",
            "Flattened data shape: (319, 11)\n",
            "Split training data: 287 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.2, 0.205]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6063, Train Loss: 0.2378, Val Acc: 0.5938, Val Loss: 0.2421\n",
            "Restored model from best epoch 3 with val_loss: 0.242145\n",
            "NFL direct model 41/201 completed\n",
            "Original data shape: (324, 11)\n",
            "Flattened data shape: (324, 11)\n",
            "Split training data: 291 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.205, 0.21]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 60\n",
            "Best epoch: 50, Train Acc: 0.8110, Train Loss: 0.1416, Val Acc: 0.7273, Val Loss: 0.2282\n",
            "Restored model from best epoch 50 with val_loss: 0.228157\n",
            "NFL direct model 42/201 completed\n",
            "Original data shape: (340, 11)\n",
            "Flattened data shape: (340, 11)\n",
            "Split training data: 306 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.21, 0.215]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.7484, Train Loss: 0.1847, Val Acc: 0.7353, Val Loss: 0.1861\n",
            "Restored model from best epoch 13 with val_loss: 0.186098\n",
            "NFL direct model 43/201 completed\n",
            "Original data shape: (305, 11)\n",
            "Flattened data shape: (305, 11)\n",
            "Split training data: 274 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.215, 0.22]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.7956, Train Loss: 0.1336, Val Acc: 0.7742, Val Loss: 0.1529\n",
            "Restored model from best epoch 26 with val_loss: 0.152926\n",
            "NFL direct model 44/201 completed\n",
            "Original data shape: (340, 11)\n",
            "Flattened data shape: (340, 11)\n",
            "Split training data: 306 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.22, 0.225]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7484, Train Loss: 0.1839, Val Acc: 0.5294, Val Loss: 0.2388\n",
            "Restored model from best epoch 10 with val_loss: 0.238849\n",
            "NFL direct model 45/201 completed\n",
            "Original data shape: (326, 11)\n",
            "Flattened data shape: (326, 11)\n",
            "Split training data: 293 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.225, 0.23]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.7713, Train Loss: 0.1596, Val Acc: 0.7576, Val Loss: 0.1899\n",
            "Restored model from best epoch 26 with val_loss: 0.189915\n",
            "NFL direct model 46/201 completed\n",
            "Original data shape: (295, 11)\n",
            "Flattened data shape: (295, 11)\n",
            "Split training data: 265 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.23, 0.235]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7698, Train Loss: 0.1856, Val Acc: 0.7000, Val Loss: 0.1826\n",
            "Restored model from best epoch 17 with val_loss: 0.182578\n",
            "NFL direct model 47/201 completed\n",
            "Original data shape: (330, 11)\n",
            "Flattened data shape: (330, 11)\n",
            "Split training data: 297 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.235, 0.24]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.7744, Train Loss: 0.1471, Val Acc: 0.6970, Val Loss: 0.1886\n",
            "Restored model from best epoch 22 with val_loss: 0.188622\n",
            "NFL direct model 48/201 completed\n",
            "Original data shape: (310, 11)\n",
            "Flattened data shape: (310, 11)\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.24, 0.245]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.7706, Train Loss: 0.1697, Val Acc: 0.7097, Val Loss: 0.1998\n",
            "Restored model from best epoch 15 with val_loss: 0.199814\n",
            "NFL direct model 49/201 completed\n",
            "Original data shape: (286, 11)\n",
            "Flattened data shape: (286, 11)\n",
            "Split training data: 257 train, 29 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.245, 0.25]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.6693, Train Loss: 0.2256, Val Acc: 0.6897, Val Loss: 0.2310\n",
            "Restored model from best epoch 12 with val_loss: 0.230957\n",
            "NFL direct model 50/201 completed\n",
            "Original data shape: (962, 11)\n",
            "Flattened data shape: (962, 11)\n",
            "Split training data: 865 train, 97 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.25, 0.255]\n",
            "Starting training on device: cpu\n",
            "NFL direct model 51/201 completed\n",
            "Original data shape: (176, 11)\n",
            "Flattened data shape: (176, 11)\n",
            "Split training data: 158 train, 18 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.255, 0.26]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7975, Train Loss: 0.1607, Val Acc: 0.6667, Val Loss: 0.2234\n",
            "Restored model from best epoch 12 with val_loss: 0.223449\n",
            "NFL direct model 52/201 completed\n",
            "Original data shape: (228, 11)\n",
            "Flattened data shape: (228, 11)\n",
            "Split training data: 205 train, 23 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.26, 0.265]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7707, Train Loss: 0.1584, Val Acc: 0.6957, Val Loss: 0.2022\n",
            "Restored model from best epoch 17 with val_loss: 0.202220\n",
            "NFL direct model 53/201 completed\n",
            "Original data shape: (339, 11)\n",
            "Flattened data shape: (339, 11)\n",
            "Split training data: 305 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.265, 0.27]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7475, Train Loss: 0.1826, Val Acc: 0.6471, Val Loss: 0.2294\n",
            "Restored model from best epoch 9 with val_loss: 0.229411\n",
            "NFL direct model 54/201 completed\n",
            "Original data shape: (306, 11)\n",
            "Flattened data shape: (306, 11)\n",
            "Split training data: 275 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.27, 0.275]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.7709, Train Loss: 0.1754, Val Acc: 0.6774, Val Loss: 0.2093\n",
            "Restored model from best epoch 18 with val_loss: 0.209349\n",
            "NFL direct model 55/201 completed\n",
            "Original data shape: (357, 11)\n",
            "Flattened data shape: (357, 11)\n",
            "Split training data: 321 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.275, 0.28]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 31\n",
            "Best epoch: 21, Train Acc: 0.7508, Train Loss: 0.1647, Val Acc: 0.6944, Val Loss: 0.1954\n",
            "Restored model from best epoch 21 with val_loss: 0.195378\n",
            "NFL direct model 56/201 completed\n",
            "Original data shape: (315, 11)\n",
            "Flattened data shape: (315, 11)\n",
            "Split training data: 283 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.28, 0.285]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7102, Train Loss: 0.1915, Val Acc: 0.7500, Val Loss: 0.1897\n",
            "Restored model from best epoch 10 with val_loss: 0.189731\n",
            "NFL direct model 57/201 completed\n",
            "Original data shape: (342, 11)\n",
            "Flattened data shape: (342, 11)\n",
            "Split training data: 307 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.285, 0.29]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.5309, Train Loss: 0.2441, Val Acc: 0.5429, Val Loss: 0.2489\n",
            "Restored model from best epoch 4 with val_loss: 0.248865\n",
            "NFL direct model 58/201 completed\n",
            "Original data shape: (330, 11)\n",
            "Flattened data shape: (330, 11)\n",
            "Split training data: 297 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.29, 0.295]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.7273, Train Loss: 0.1779, Val Acc: 0.8485, Val Loss: 0.1450\n",
            "Restored model from best epoch 13 with val_loss: 0.144983\n",
            "NFL direct model 59/201 completed\n",
            "Original data shape: (337, 11)\n",
            "Flattened data shape: (337, 11)\n",
            "Split training data: 303 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.295, 0.3]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6997, Train Loss: 0.2011, Val Acc: 0.6176, Val Loss: 0.2322\n",
            "Restored model from best epoch 6 with val_loss: 0.232239\n",
            "NFL direct model 60/201 completed\n",
            "Original data shape: (304, 11)\n",
            "Flattened data shape: (304, 11)\n",
            "Split training data: 273 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.3, 0.305]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.7363, Train Loss: 0.1728, Val Acc: 0.7419, Val Loss: 0.1514\n",
            "Restored model from best epoch 15 with val_loss: 0.151448\n",
            "NFL direct model 61/201 completed\n",
            "Original data shape: (297, 11)\n",
            "Flattened data shape: (297, 11)\n",
            "Split training data: 267 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.305, 0.31]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7378, Train Loss: 0.1759, Val Acc: 0.7000, Val Loss: 0.1696\n",
            "Restored model from best epoch 14 with val_loss: 0.169624\n",
            "NFL direct model 62/201 completed\n",
            "Original data shape: (309, 11)\n",
            "Flattened data shape: (309, 11)\n",
            "Split training data: 278 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.31, 0.315]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.6942, Train Loss: 0.1624, Val Acc: 0.7097, Val Loss: 0.1769\n",
            "Restored model from best epoch 16 with val_loss: 0.176861\n",
            "NFL direct model 63/201 completed\n",
            "Original data shape: (354, 11)\n",
            "Flattened data shape: (354, 11)\n",
            "Split training data: 318 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.315, 0.32]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 46\n",
            "Best epoch: 36, Train Acc: 0.8208, Train Loss: 0.1234, Val Acc: 0.8056, Val Loss: 0.1512\n",
            "Restored model from best epoch 36 with val_loss: 0.151218\n",
            "NFL direct model 64/201 completed\n",
            "Original data shape: (332, 11)\n",
            "Flattened data shape: (332, 11)\n",
            "Split training data: 298 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.32, 0.325]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.7483, Train Loss: 0.1929, Val Acc: 0.6765, Val Loss: 0.2067\n",
            "Restored model from best epoch 8 with val_loss: 0.206748\n",
            "NFL direct model 65/201 completed\n",
            "Original data shape: (328, 11)\n",
            "Flattened data shape: (328, 11)\n",
            "Split training data: 295 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.325, 0.33]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 40\n",
            "Best epoch: 30, Train Acc: 0.8034, Train Loss: 0.1382, Val Acc: 0.7879, Val Loss: 0.1765\n",
            "Restored model from best epoch 30 with val_loss: 0.176458\n",
            "NFL direct model 66/201 completed\n",
            "Original data shape: (323, 11)\n",
            "Flattened data shape: (323, 11)\n",
            "Split training data: 290 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.33, 0.335]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 49\n",
            "Best epoch: 39, Train Acc: 0.8414, Train Loss: 0.1114, Val Acc: 0.8182, Val Loss: 0.1537\n",
            "Restored model from best epoch 39 with val_loss: 0.153689\n",
            "NFL direct model 67/201 completed\n",
            "Original data shape: (334, 11)\n",
            "Flattened data shape: (334, 11)\n",
            "Split training data: 300 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.335, 0.34]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.7900, Train Loss: 0.1346, Val Acc: 0.7353, Val Loss: 0.1864\n",
            "Restored model from best epoch 20 with val_loss: 0.186435\n",
            "NFL direct model 68/201 completed\n",
            "Original data shape: (310, 11)\n",
            "Flattened data shape: (310, 11)\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.34, 0.345]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.7814, Train Loss: 0.1528, Val Acc: 0.8065, Val Loss: 0.1689\n",
            "Restored model from best epoch 18 with val_loss: 0.168858\n",
            "NFL direct model 69/201 completed\n",
            "Original data shape: (322, 11)\n",
            "Flattened data shape: (322, 11)\n",
            "Split training data: 289 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.345, 0.35]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.6990, Train Loss: 0.1875, Val Acc: 0.6667, Val Loss: 0.2122\n",
            "Restored model from best epoch 10 with val_loss: 0.212191\n",
            "NFL direct model 70/201 completed\n",
            "Original data shape: (327, 11)\n",
            "Flattened data shape: (327, 11)\n",
            "Split training data: 294 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.35, 0.355]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7347, Train Loss: 0.1774, Val Acc: 0.5455, Val Loss: 0.2109\n",
            "Restored model from best epoch 16 with val_loss: 0.210852\n",
            "NFL direct model 71/201 completed\n",
            "Original data shape: (350, 11)\n",
            "Flattened data shape: (350, 11)\n",
            "Split training data: 315 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.355, 0.36]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7714, Train Loss: 0.1636, Val Acc: 0.7429, Val Loss: 0.1818\n",
            "Restored model from best epoch 16 with val_loss: 0.181806\n",
            "NFL direct model 72/201 completed\n",
            "Original data shape: (327, 11)\n",
            "Flattened data shape: (327, 11)\n",
            "Split training data: 294 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.36, 0.365]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 35\n",
            "Best epoch: 25, Train Acc: 0.8435, Train Loss: 0.1135, Val Acc: 0.7879, Val Loss: 0.1794\n",
            "Restored model from best epoch 25 with val_loss: 0.179380\n",
            "NFL direct model 73/201 completed\n",
            "Original data shape: (357, 11)\n",
            "Flattened data shape: (357, 11)\n",
            "Split training data: 321 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.365, 0.37]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.8255, Train Loss: 0.1180, Val Acc: 0.8333, Val Loss: 0.1288\n",
            "Restored model from best epoch 29 with val_loss: 0.128765\n",
            "NFL direct model 74/201 completed\n",
            "Original data shape: (303, 11)\n",
            "Flattened data shape: (303, 11)\n",
            "Split training data: 272 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.37, 0.375]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.7941, Train Loss: 0.1461, Val Acc: 0.8387, Val Loss: 0.1448\n",
            "Restored model from best epoch 24 with val_loss: 0.144823\n",
            "NFL direct model 75/201 completed\n",
            "Original data shape: (341, 11)\n",
            "Flattened data shape: (341, 11)\n",
            "Split training data: 306 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.375, 0.38]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.8431, Train Loss: 0.1240, Val Acc: 0.8286, Val Loss: 0.1416\n",
            "Restored model from best epoch 24 with val_loss: 0.141645\n",
            "NFL direct model 76/201 completed\n",
            "Original data shape: (318, 11)\n",
            "Flattened data shape: (318, 11)\n",
            "Split training data: 286 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.38, 0.385]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 45\n",
            "Best epoch: 35, Train Acc: 0.8392, Train Loss: 0.1202, Val Acc: 0.6875, Val Loss: 0.1843\n",
            "Restored model from best epoch 35 with val_loss: 0.184262\n",
            "NFL direct model 77/201 completed\n",
            "Original data shape: (300, 11)\n",
            "Flattened data shape: (300, 11)\n",
            "Split training data: 270 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.385, 0.39]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7815, Train Loss: 0.1478, Val Acc: 0.6000, Val Loss: 0.2157\n",
            "Restored model from best epoch 14 with val_loss: 0.215675\n",
            "NFL direct model 78/201 completed\n",
            "Original data shape: (327, 11)\n",
            "Flattened data shape: (327, 11)\n",
            "Split training data: 294 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.39, 0.395]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 62\n",
            "Best epoch: 52, Train Acc: 0.8980, Train Loss: 0.0861, Val Acc: 0.7879, Val Loss: 0.1230\n",
            "Restored model from best epoch 52 with val_loss: 0.122975\n",
            "NFL direct model 79/201 completed\n",
            "Original data shape: (339, 11)\n",
            "Flattened data shape: (339, 11)\n",
            "Split training data: 305 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.395, 0.4]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8066, Train Loss: 0.1638, Val Acc: 0.6765, Val Loss: 0.2060\n",
            "Restored model from best epoch 8 with val_loss: 0.205997\n",
            "NFL direct model 80/201 completed\n",
            "Original data shape: (322, 11)\n",
            "Flattened data shape: (322, 11)\n",
            "Split training data: 289 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.4, 0.405]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7336, Train Loss: 0.1867, Val Acc: 0.6061, Val Loss: 0.2195\n",
            "Restored model from best epoch 7 with val_loss: 0.219478\n",
            "NFL direct model 81/201 completed\n",
            "Original data shape: (301, 11)\n",
            "Flattened data shape: (301, 11)\n",
            "Split training data: 270 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.405, 0.41]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7741, Train Loss: 0.1634, Val Acc: 0.7419, Val Loss: 0.2005\n",
            "Restored model from best epoch 10 with val_loss: 0.200520\n",
            "NFL direct model 82/201 completed\n",
            "Original data shape: (353, 11)\n",
            "Flattened data shape: (353, 11)\n",
            "Split training data: 317 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.41, 0.415]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 37\n",
            "Best epoch: 27, Train Acc: 0.7950, Train Loss: 0.1409, Val Acc: 0.9444, Val Loss: 0.0621\n",
            "Restored model from best epoch 27 with val_loss: 0.062064\n",
            "NFL direct model 83/201 completed\n",
            "Original data shape: (292, 11)\n",
            "Flattened data shape: (292, 11)\n",
            "Split training data: 262 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.415, 0.42]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.7328, Train Loss: 0.2049, Val Acc: 0.6000, Val Loss: 0.2289\n",
            "Restored model from best epoch 8 with val_loss: 0.228869\n",
            "NFL direct model 84/201 completed\n",
            "Original data shape: (324, 11)\n",
            "Flattened data shape: (324, 11)\n",
            "Split training data: 291 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.42, 0.425]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7113, Train Loss: 0.1923, Val Acc: 0.6667, Val Loss: 0.1878\n",
            "Restored model from best epoch 7 with val_loss: 0.187756\n",
            "NFL direct model 85/201 completed\n",
            "Original data shape: (319, 11)\n",
            "Flattened data shape: (319, 11)\n",
            "Split training data: 287 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.425, 0.43]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 47\n",
            "Best epoch: 37, Train Acc: 0.8676, Train Loss: 0.1030, Val Acc: 0.9062, Val Loss: 0.0890\n",
            "Restored model from best epoch 37 with val_loss: 0.088962\n",
            "NFL direct model 86/201 completed\n",
            "Original data shape: (335, 11)\n",
            "Flattened data shape: (335, 11)\n",
            "Split training data: 301 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.43, 0.435]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7475, Train Loss: 0.1737, Val Acc: 0.7647, Val Loss: 0.1494\n",
            "Restored model from best epoch 9 with val_loss: 0.149439\n",
            "NFL direct model 87/201 completed\n",
            "Original data shape: (335, 11)\n",
            "Flattened data shape: (335, 11)\n",
            "Split training data: 301 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.435, 0.44]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7442, Train Loss: 0.1738, Val Acc: 0.7353, Val Loss: 0.1915\n",
            "Restored model from best epoch 12 with val_loss: 0.191495\n",
            "NFL direct model 88/201 completed\n",
            "Original data shape: (316, 11)\n",
            "Flattened data shape: (316, 11)\n",
            "Split training data: 284 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.44, 0.445]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.7817, Train Loss: 0.1588, Val Acc: 0.7812, Val Loss: 0.1629\n",
            "Restored model from best epoch 8 with val_loss: 0.162939\n",
            "NFL direct model 89/201 completed\n",
            "Original data shape: (351, 11)\n",
            "Flattened data shape: (351, 11)\n",
            "Split training data: 315 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.445, 0.45]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.8222, Train Loss: 0.1265, Val Acc: 0.7500, Val Loss: 0.1666\n",
            "Restored model from best epoch 23 with val_loss: 0.166593\n",
            "NFL direct model 90/201 completed\n",
            "Original data shape: (319, 11)\n",
            "Flattened data shape: (319, 11)\n",
            "Split training data: 287 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.45, 0.455]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7840, Train Loss: 0.1605, Val Acc: 0.7188, Val Loss: 0.1738\n",
            "Restored model from best epoch 10 with val_loss: 0.173822\n",
            "NFL direct model 91/201 completed\n",
            "Original data shape: (342, 11)\n",
            "Flattened data shape: (342, 11)\n",
            "Split training data: 307 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.455, 0.46]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 31\n",
            "Best epoch: 21, Train Acc: 0.8339, Train Loss: 0.1298, Val Acc: 0.8000, Val Loss: 0.1493\n",
            "Restored model from best epoch 21 with val_loss: 0.149316\n",
            "NFL direct model 92/201 completed\n",
            "Original data shape: (295, 11)\n",
            "Flattened data shape: (295, 11)\n",
            "Split training data: 265 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.46, 0.465]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 44\n",
            "Best epoch: 34, Train Acc: 0.8792, Train Loss: 0.1310, Val Acc: 0.9000, Val Loss: 0.0725\n",
            "Restored model from best epoch 34 with val_loss: 0.072537\n",
            "NFL direct model 93/201 completed\n",
            "Original data shape: (319, 11)\n",
            "Flattened data shape: (319, 11)\n",
            "Split training data: 287 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.465, 0.47]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 37\n",
            "Best epoch: 27, Train Acc: 0.8676, Train Loss: 0.1035, Val Acc: 0.8750, Val Loss: 0.1133\n",
            "Restored model from best epoch 27 with val_loss: 0.113320\n",
            "NFL direct model 94/201 completed\n",
            "Original data shape: (951, 11)\n",
            "Flattened data shape: (951, 11)\n",
            "Split training data: 855 train, 96 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.47, 0.475]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7368, Train Loss: 0.1850, Val Acc: 0.6979, Val Loss: 0.1784\n",
            "Restored model from best epoch 3 with val_loss: 0.178390\n",
            "NFL direct model 95/201 completed\n",
            "Original data shape: (489, 11)\n",
            "Flattened data shape: (489, 11)\n",
            "Split training data: 440 train, 49 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.475, 0.48]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8205, Train Loss: 0.1313, Val Acc: 0.7755, Val Loss: 0.1377\n",
            "Restored model from best epoch 14 with val_loss: 0.137688\n",
            "NFL direct model 96/201 completed\n",
            "Original data shape: (485, 11)\n",
            "Flattened data shape: (485, 11)\n",
            "Split training data: 436 train, 49 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.48, 0.485]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 38\n",
            "Best epoch: 28, Train Acc: 0.8440, Train Loss: 0.1128, Val Acc: 0.8571, Val Loss: 0.1061\n",
            "Restored model from best epoch 28 with val_loss: 0.106101\n",
            "NFL direct model 97/201 completed\n",
            "Original data shape: (573, 11)\n",
            "Flattened data shape: (573, 11)\n",
            "Split training data: 515 train, 58 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.485, 0.49]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.7767, Train Loss: 0.1616, Val Acc: 0.7759, Val Loss: 0.1381\n",
            "Restored model from best epoch 22 with val_loss: 0.138057\n",
            "NFL direct model 98/201 completed\n",
            "Original data shape: (659, 11)\n",
            "Flattened data shape: (659, 11)\n",
            "Split training data: 593 train, 66 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.49, 0.495]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8212, Train Loss: 0.1233, Val Acc: 0.8182, Val Loss: 0.0838\n",
            "Restored model from best epoch 17 with val_loss: 0.083812\n",
            "NFL direct model 99/201 completed\n",
            "Original data shape: (896, 11)\n",
            "Flattened data shape: (896, 11)\n",
            "Split training data: 806 train, 90 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.495, 0.5]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.8548, Train Loss: 0.1136, Val Acc: 0.8889, Val Loss: 0.0666\n",
            "Restored model from best epoch 29 with val_loss: 0.066590\n",
            "NFL direct model 100/201 completed\n",
            "Original data shape: (1501, 11)\n",
            "Flattened data shape: (1501, 11)\n",
            "Split training data: 1350 train, 151 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.5, 0.505]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7778, Train Loss: 0.1647, Val Acc: 0.7285, Val Loss: 0.1638\n",
            "Restored model from best epoch 3 with val_loss: 0.163820\n",
            "NFL direct model 101/201 completed\n",
            "Original data shape: (197, 11)\n",
            "Flattened data shape: (197, 11)\n",
            "Split training data: 177 train, 20 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.505, 0.51]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8362, Train Loss: 0.1437, Val Acc: 0.7500, Val Loss: 0.1758\n",
            "Restored model from best epoch 12 with val_loss: 0.175845\n",
            "NFL direct model 102/201 completed\n",
            "Original data shape: (301, 11)\n",
            "Flattened data shape: (301, 11)\n",
            "Split training data: 270 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.51, 0.515]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.8630, Train Loss: 0.1178, Val Acc: 0.8710, Val Loss: 0.1166\n",
            "Restored model from best epoch 23 with val_loss: 0.116605\n",
            "NFL direct model 103/201 completed\n",
            "Original data shape: (263, 11)\n",
            "Flattened data shape: (263, 11)\n",
            "Split training data: 236 train, 27 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.515, 0.52]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 19, Train Acc: 0.8602, Train Loss: 0.1098, Val Acc: 0.8519, Val Loss: 0.1007\n",
            "Restored model from best epoch 19 with val_loss: 0.100746\n",
            "NFL direct model 104/201 completed\n",
            "Original data shape: (308, 11)\n",
            "Flattened data shape: (308, 11)\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.52, 0.525]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7906, Train Loss: 0.1598, Val Acc: 0.8065, Val Loss: 0.1325\n",
            "Restored model from best epoch 12 with val_loss: 0.132511\n",
            "NFL direct model 105/201 completed\n",
            "Original data shape: (312, 11)\n",
            "Flattened data shape: (312, 11)\n",
            "Split training data: 280 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.525, 0.53]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 74\n",
            "Best epoch: 64, Train Acc: 0.9107, Train Loss: 0.0724, Val Acc: 0.9375, Val Loss: 0.0539\n",
            "Restored model from best epoch 64 with val_loss: 0.053855\n",
            "NFL direct model 106/201 completed\n",
            "Original data shape: (298, 11)\n",
            "Flattened data shape: (298, 11)\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.53, 0.535]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8134, Train Loss: 0.1532, Val Acc: 0.8333, Val Loss: 0.1414\n",
            "Restored model from best epoch 13 with val_loss: 0.141431\n",
            "NFL direct model 107/201 completed\n",
            "Original data shape: (330, 11)\n",
            "Flattened data shape: (330, 11)\n",
            "Split training data: 297 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.535, 0.54]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 31\n",
            "Best epoch: 21, Train Acc: 0.8721, Train Loss: 0.1038, Val Acc: 0.7273, Val Loss: 0.1659\n",
            "Restored model from best epoch 21 with val_loss: 0.165949\n",
            "NFL direct model 108/201 completed\n",
            "Original data shape: (313, 11)\n",
            "Flattened data shape: (313, 11)\n",
            "Split training data: 281 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.54, 0.545]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 57\n",
            "Best epoch: 47, Train Acc: 0.9110, Train Loss: 0.0785, Val Acc: 0.9062, Val Loss: 0.0526\n",
            "Restored model from best epoch 47 with val_loss: 0.052563\n",
            "NFL direct model 109/201 completed\n",
            "Original data shape: (310, 11)\n",
            "Flattened data shape: (310, 11)\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.545, 0.55]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 63\n",
            "Best epoch: 53, Train Acc: 0.8889, Train Loss: 0.0768, Val Acc: 0.8710, Val Loss: 0.0932\n",
            "Restored model from best epoch 53 with val_loss: 0.093220\n",
            "NFL direct model 110/201 completed\n",
            "Original data shape: (316, 11)\n",
            "Flattened data shape: (316, 11)\n",
            "Split training data: 284 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.55, 0.555]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 35\n",
            "Best epoch: 25, Train Acc: 0.8768, Train Loss: 0.1042, Val Acc: 0.9062, Val Loss: 0.1004\n",
            "Restored model from best epoch 25 with val_loss: 0.100353\n",
            "NFL direct model 111/201 completed\n",
            "Original data shape: (321, 11)\n",
            "Flattened data shape: (321, 11)\n",
            "Split training data: 288 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.555, 0.56]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8333, Train Loss: 0.1331, Val Acc: 0.7273, Val Loss: 0.1849\n",
            "Restored model from best epoch 12 with val_loss: 0.184896\n",
            "NFL direct model 112/201 completed\n",
            "Original data shape: (298, 11)\n",
            "Flattened data shape: (298, 11)\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.56, 0.565]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8396, Train Loss: 0.1200, Val Acc: 0.7667, Val Loss: 0.1471\n",
            "Restored model from best epoch 15 with val_loss: 0.147103\n",
            "NFL direct model 113/201 completed\n",
            "Original data shape: (340, 11)\n",
            "Flattened data shape: (340, 11)\n",
            "Split training data: 306 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.565, 0.57]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8627, Train Loss: 0.1169, Val Acc: 0.7941, Val Loss: 0.1276\n",
            "Restored model from best epoch 15 with val_loss: 0.127560\n",
            "NFL direct model 114/201 completed\n",
            "Original data shape: (355, 11)\n",
            "Flattened data shape: (355, 11)\n",
            "Split training data: 319 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.57, 0.575]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8401, Train Loss: 0.1216, Val Acc: 0.7500, Val Loss: 0.2023\n",
            "Restored model from best epoch 17 with val_loss: 0.202262\n",
            "NFL direct model 115/201 completed\n",
            "Original data shape: (312, 11)\n",
            "Flattened data shape: (312, 11)\n",
            "Split training data: 280 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.575, 0.58]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.8321, Train Loss: 0.1265, Val Acc: 0.8125, Val Loss: 0.1448\n",
            "Restored model from best epoch 22 with val_loss: 0.144753\n",
            "NFL direct model 116/201 completed\n",
            "Original data shape: (298, 11)\n",
            "Flattened data shape: (298, 11)\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.58, 0.585]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 51\n",
            "Best epoch: 41, Train Acc: 0.9142, Train Loss: 0.0744, Val Acc: 0.8667, Val Loss: 0.1031\n",
            "Restored model from best epoch 41 with val_loss: 0.103090\n",
            "NFL direct model 117/201 completed\n",
            "Original data shape: (310, 11)\n",
            "Flattened data shape: (310, 11)\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.585, 0.59]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.8781, Train Loss: 0.0965, Val Acc: 0.9355, Val Loss: 0.0567\n",
            "Restored model from best epoch 29 with val_loss: 0.056656\n",
            "NFL direct model 118/201 completed\n",
            "Original data shape: (325, 11)\n",
            "Flattened data shape: (325, 11)\n",
            "Split training data: 292 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.59, 0.595]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8459, Train Loss: 0.1160, Val Acc: 0.7879, Val Loss: 0.1560\n",
            "Restored model from best epoch 17 with val_loss: 0.155976\n",
            "NFL direct model 119/201 completed\n",
            "Original data shape: (371, 11)\n",
            "Flattened data shape: (371, 11)\n",
            "Split training data: 333 train, 38 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.595, 0.6]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8138, Train Loss: 0.1230, Val Acc: 0.8421, Val Loss: 0.1091\n",
            "Restored model from best epoch 14 with val_loss: 0.109080\n",
            "NFL direct model 120/201 completed\n",
            "Original data shape: (315, 11)\n",
            "Flattened data shape: (315, 11)\n",
            "Split training data: 283 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.6, 0.605]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8269, Train Loss: 0.1335, Val Acc: 0.7500, Val Loss: 0.1755\n",
            "Restored model from best epoch 9 with val_loss: 0.175548\n",
            "NFL direct model 121/201 completed\n",
            "Original data shape: (347, 11)\n",
            "Flattened data shape: (347, 11)\n",
            "Split training data: 312 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.605, 0.61]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.8782, Train Loss: 0.0906, Val Acc: 0.8000, Val Loss: 0.1181\n",
            "Restored model from best epoch 22 with val_loss: 0.118084\n",
            "NFL direct model 122/201 completed\n",
            "Original data shape: (317, 11)\n",
            "Flattened data shape: (317, 11)\n",
            "Split training data: 285 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.61, 0.615]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 53\n",
            "Best epoch: 43, Train Acc: 0.8596, Train Loss: 0.1125, Val Acc: 0.8750, Val Loss: 0.1115\n",
            "Restored model from best epoch 43 with val_loss: 0.111475\n",
            "NFL direct model 123/201 completed\n",
            "Original data shape: (323, 11)\n",
            "Flattened data shape: (323, 11)\n",
            "Split training data: 290 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.615, 0.62]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8483, Train Loss: 0.1082, Val Acc: 0.8182, Val Loss: 0.1430\n",
            "Restored model from best epoch 15 with val_loss: 0.142999\n",
            "NFL direct model 124/201 completed\n",
            "Original data shape: (344, 11)\n",
            "Flattened data shape: (344, 11)\n",
            "Split training data: 309 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.62, 0.625]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.8673, Train Loss: 0.0994, Val Acc: 0.8857, Val Loss: 0.1118\n",
            "Restored model from best epoch 18 with val_loss: 0.111842\n",
            "NFL direct model 125/201 completed\n",
            "Original data shape: (310, 11)\n",
            "Flattened data shape: (310, 11)\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.625, 0.63]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.8602, Train Loss: 0.1096, Val Acc: 0.8710, Val Loss: 0.0777\n",
            "Restored model from best epoch 20 with val_loss: 0.077683\n",
            "NFL direct model 126/201 completed\n",
            "Original data shape: (341, 11)\n",
            "Flattened data shape: (341, 11)\n",
            "Split training data: 306 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.63, 0.635]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.8856, Train Loss: 0.0900, Val Acc: 0.8000, Val Loss: 0.1418\n",
            "Restored model from best epoch 24 with val_loss: 0.141786\n",
            "NFL direct model 127/201 completed\n",
            "Original data shape: (307, 11)\n",
            "Flattened data shape: (307, 11)\n",
            "Split training data: 276 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.635, 0.64]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8659, Train Loss: 0.1014, Val Acc: 0.9032, Val Loss: 0.1081\n",
            "Restored model from best epoch 13 with val_loss: 0.108072\n",
            "NFL direct model 128/201 completed\n",
            "Original data shape: (329, 11)\n",
            "Flattened data shape: (329, 11)\n",
            "Split training data: 296 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.64, 0.645]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7838, Train Loss: 0.1591, Val Acc: 0.6364, Val Loss: 0.2110\n",
            "Restored model from best epoch 6 with val_loss: 0.210984\n",
            "NFL direct model 129/201 completed\n",
            "Original data shape: (350, 11)\n",
            "Flattened data shape: (350, 11)\n",
            "Split training data: 315 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.645, 0.65]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8540, Train Loss: 0.1223, Val Acc: 0.8286, Val Loss: 0.1312\n",
            "Restored model from best epoch 11 with val_loss: 0.131220\n",
            "NFL direct model 130/201 completed\n",
            "Original data shape: (330, 11)\n",
            "Flattened data shape: (330, 11)\n",
            "Split training data: 297 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.65, 0.655]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8519, Train Loss: 0.1058, Val Acc: 0.8182, Val Loss: 0.1229\n",
            "Restored model from best epoch 13 with val_loss: 0.122911\n",
            "NFL direct model 131/201 completed\n",
            "Original data shape: (344, 11)\n",
            "Flattened data shape: (344, 11)\n",
            "Split training data: 309 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.655, 0.66]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.8770, Train Loss: 0.0842, Val Acc: 0.9429, Val Loss: 0.0647\n",
            "Restored model from best epoch 26 with val_loss: 0.064675\n",
            "NFL direct model 132/201 completed\n",
            "Original data shape: (328, 11)\n",
            "Flattened data shape: (328, 11)\n",
            "Split training data: 295 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.66, 0.665]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 31\n",
            "Best epoch: 21, Train Acc: 0.8847, Train Loss: 0.0826, Val Acc: 0.8182, Val Loss: 0.1290\n",
            "Restored model from best epoch 21 with val_loss: 0.128988\n",
            "NFL direct model 133/201 completed\n",
            "Original data shape: (312, 11)\n",
            "Flattened data shape: (312, 11)\n",
            "Split training data: 280 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.665, 0.67]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8750, Train Loss: 0.0972, Val Acc: 0.9062, Val Loss: 0.0763\n",
            "Restored model from best epoch 14 with val_loss: 0.076329\n",
            "NFL direct model 134/201 completed\n",
            "Original data shape: (341, 11)\n",
            "Flattened data shape: (341, 11)\n",
            "Split training data: 306 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.67, 0.675]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8725, Train Loss: 0.0881, Val Acc: 0.8571, Val Loss: 0.1119\n",
            "Restored model from best epoch 17 with val_loss: 0.111884\n",
            "NFL direct model 135/201 completed\n",
            "Original data shape: (310, 11)\n",
            "Flattened data shape: (310, 11)\n",
            "Split training data: 279 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.675, 0.68]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 37\n",
            "Best epoch: 27, Train Acc: 0.8961, Train Loss: 0.0812, Val Acc: 0.9355, Val Loss: 0.0450\n",
            "Restored model from best epoch 27 with val_loss: 0.045004\n",
            "NFL direct model 136/201 completed\n",
            "Original data shape: (302, 11)\n",
            "Flattened data shape: (302, 11)\n",
            "Split training data: 271 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.68, 0.685]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 62\n",
            "Best epoch: 52, Train Acc: 0.9299, Train Loss: 0.0527, Val Acc: 0.9677, Val Loss: 0.0478\n",
            "Restored model from best epoch 52 with val_loss: 0.047797\n",
            "NFL direct model 137/201 completed\n",
            "Original data shape: (347, 11)\n",
            "Flattened data shape: (347, 11)\n",
            "Split training data: 312 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.685, 0.69]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.8942, Train Loss: 0.0793, Val Acc: 0.8857, Val Loss: 0.0888\n",
            "Restored model from best epoch 22 with val_loss: 0.088807\n",
            "NFL direct model 138/201 completed\n",
            "Original data shape: (342, 11)\n",
            "Flattened data shape: (342, 11)\n",
            "Split training data: 307 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.69, 0.695]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8534, Train Loss: 0.1050, Val Acc: 0.8000, Val Loss: 0.1125\n",
            "Restored model from best epoch 13 with val_loss: 0.112517\n",
            "NFL direct model 139/201 completed\n",
            "Original data shape: (318, 11)\n",
            "Flattened data shape: (318, 11)\n",
            "Split training data: 286 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.695, 0.7]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8427, Train Loss: 0.1120, Val Acc: 0.7812, Val Loss: 0.1522\n",
            "Restored model from best epoch 11 with val_loss: 0.152172\n",
            "NFL direct model 140/201 completed\n",
            "Original data shape: (317, 11)\n",
            "Flattened data shape: (317, 11)\n",
            "Split training data: 285 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.7, 0.705]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.8912, Train Loss: 0.0851, Val Acc: 0.8750, Val Loss: 0.0965\n",
            "Restored model from best epoch 29 with val_loss: 0.096503\n",
            "NFL direct model 141/201 completed\n",
            "Original data shape: (319, 11)\n",
            "Flattened data shape: (319, 11)\n",
            "Split training data: 287 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.705, 0.71]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.9233, Train Loss: 0.0771, Val Acc: 0.9062, Val Loss: 0.0936\n",
            "Restored model from best epoch 24 with val_loss: 0.093561\n",
            "NFL direct model 142/201 completed\n",
            "Original data shape: (314, 11)\n",
            "Flattened data shape: (314, 11)\n",
            "Split training data: 282 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.71, 0.715]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8723, Train Loss: 0.1107, Val Acc: 0.8438, Val Loss: 0.0897\n",
            "Restored model from best epoch 16 with val_loss: 0.089659\n",
            "NFL direct model 143/201 completed\n",
            "Original data shape: (341, 11)\n",
            "Flattened data shape: (341, 11)\n",
            "Split training data: 306 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.715, 0.72]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8431, Train Loss: 0.1439, Val Acc: 0.7143, Val Loss: 0.1697\n",
            "Restored model from best epoch 10 with val_loss: 0.169707\n",
            "NFL direct model 144/201 completed\n",
            "Original data shape: (326, 11)\n",
            "Flattened data shape: (326, 11)\n",
            "Split training data: 293 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.72, 0.725]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.8976, Train Loss: 0.0707, Val Acc: 0.8788, Val Loss: 0.0955\n",
            "Restored model from best epoch 23 with val_loss: 0.095461\n",
            "NFL direct model 145/201 completed\n",
            "Original data shape: (328, 11)\n",
            "Flattened data shape: (328, 11)\n",
            "Split training data: 295 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.725, 0.73]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8915, Train Loss: 0.0793, Val Acc: 0.8182, Val Loss: 0.1338\n",
            "Restored model from best epoch 11 with val_loss: 0.133781\n",
            "NFL direct model 146/201 completed\n",
            "Original data shape: (355, 11)\n",
            "Flattened data shape: (355, 11)\n",
            "Split training data: 319 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.73, 0.735]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 67\n",
            "Best epoch: 57, Train Acc: 0.9467, Train Loss: 0.0488, Val Acc: 0.9722, Val Loss: 0.0232\n",
            "Restored model from best epoch 57 with val_loss: 0.023171\n",
            "NFL direct model 147/201 completed\n",
            "Original data shape: (330, 11)\n",
            "Flattened data shape: (330, 11)\n",
            "Split training data: 297 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.735, 0.74]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.9024, Train Loss: 0.0854, Val Acc: 0.8485, Val Loss: 0.1264\n",
            "Restored model from best epoch 22 with val_loss: 0.126449\n",
            "NFL direct model 148/201 completed\n",
            "Original data shape: (298, 11)\n",
            "Flattened data shape: (298, 11)\n",
            "Split training data: 268 train, 30 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.74, 0.745]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8694, Train Loss: 0.0945, Val Acc: 0.8333, Val Loss: 0.1419\n",
            "Restored model from best epoch 10 with val_loss: 0.141925\n",
            "NFL direct model 149/201 completed\n",
            "Original data shape: (279, 11)\n",
            "Flattened data shape: (279, 11)\n",
            "Split training data: 251 train, 28 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.745, 0.75]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.9044, Train Loss: 0.0842, Val Acc: 0.8571, Val Loss: 0.0979\n",
            "Restored model from best epoch 22 with val_loss: 0.097945\n",
            "NFL direct model 150/201 completed\n",
            "Original data shape: (987, 11)\n",
            "Flattened data shape: (987, 11)\n",
            "Split training data: 888 train, 99 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.75, 0.755]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8637, Train Loss: 0.1076, Val Acc: 0.8182, Val Loss: 0.1301\n",
            "Restored model from best epoch 6 with val_loss: 0.130117\n",
            "NFL direct model 151/201 completed\n",
            "Original data shape: (173, 11)\n",
            "Flattened data shape: (173, 11)\n",
            "Split training data: 155 train, 18 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.755, 0.76]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.9097, Train Loss: 0.0653, Val Acc: 0.8889, Val Loss: 0.0963\n",
            "Restored model from best epoch 26 with val_loss: 0.096312\n",
            "NFL direct model 152/201 completed\n",
            "Original data shape: (263, 11)\n",
            "Flattened data shape: (263, 11)\n",
            "Split training data: 236 train, 27 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.76, 0.765]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 53\n",
            "Best epoch: 43, Train Acc: 0.9534, Train Loss: 0.0476, Val Acc: 0.8519, Val Loss: 0.1058\n",
            "Restored model from best epoch 43 with val_loss: 0.105825\n",
            "NFL direct model 153/201 completed\n",
            "Original data shape: (319, 11)\n",
            "Flattened data shape: (319, 11)\n",
            "Split training data: 287 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.765, 0.77]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.9303, Train Loss: 0.0611, Val Acc: 0.8438, Val Loss: 0.1298\n",
            "Restored model from best epoch 20 with val_loss: 0.129756\n",
            "NFL direct model 154/201 completed\n",
            "Original data shape: (308, 11)\n",
            "Flattened data shape: (308, 11)\n",
            "Split training data: 277 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.77, 0.775]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8881, Train Loss: 0.0860, Val Acc: 0.8710, Val Loss: 0.0813\n",
            "Restored model from best epoch 17 with val_loss: 0.081272\n",
            "NFL direct model 155/201 completed\n",
            "Original data shape: (341, 11)\n",
            "Flattened data shape: (341, 11)\n",
            "Split training data: 306 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.775, 0.78]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 35\n",
            "Best epoch: 25, Train Acc: 0.9248, Train Loss: 0.0637, Val Acc: 0.8857, Val Loss: 0.1051\n",
            "Restored model from best epoch 25 with val_loss: 0.105090\n",
            "NFL direct model 156/201 completed\n",
            "Original data shape: (309, 11)\n",
            "Flattened data shape: (309, 11)\n",
            "Split training data: 278 train, 31 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.78, 0.785]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8921, Train Loss: 0.0928, Val Acc: 0.8710, Val Loss: 0.1168\n",
            "Restored model from best epoch 16 with val_loss: 0.116755\n",
            "NFL direct model 157/201 completed\n",
            "Original data shape: (350, 11)\n",
            "Flattened data shape: (350, 11)\n",
            "Split training data: 315 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.785, 0.79]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 69\n",
            "Best epoch: 59, Train Acc: 0.9651, Train Loss: 0.0346, Val Acc: 0.9714, Val Loss: 0.0148\n",
            "Restored model from best epoch 59 with val_loss: 0.014760\n",
            "NFL direct model 158/201 completed\n",
            "Original data shape: (313, 11)\n",
            "Flattened data shape: (313, 11)\n",
            "Split training data: 281 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.79, 0.795]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8790, Train Loss: 0.0914, Val Acc: 0.8750, Val Loss: 0.0845\n",
            "Restored model from best epoch 10 with val_loss: 0.084531\n",
            "NFL direct model 159/201 completed\n",
            "Original data shape: (314, 11)\n",
            "Flattened data shape: (314, 11)\n",
            "Split training data: 282 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.795, 0.8]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.8865, Train Loss: 0.0856, Val Acc: 0.8438, Val Loss: 0.0882\n",
            "Restored model from best epoch 18 with val_loss: 0.088235\n",
            "NFL direct model 160/201 completed\n",
            "Original data shape: (349, 11)\n",
            "Flattened data shape: (349, 11)\n",
            "Split training data: 314 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.8, 0.805]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.9108, Train Loss: 0.0754, Val Acc: 0.9429, Val Loss: 0.0361\n",
            "Restored model from best epoch 23 with val_loss: 0.036114\n",
            "NFL direct model 161/201 completed\n",
            "Original data shape: (333, 11)\n",
            "Flattened data shape: (333, 11)\n",
            "Split training data: 299 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.805, 0.81]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.9164, Train Loss: 0.0721, Val Acc: 0.8824, Val Loss: 0.1001\n",
            "Restored model from best epoch 20 with val_loss: 0.100109\n",
            "NFL direct model 162/201 completed\n",
            "Original data shape: (327, 11)\n",
            "Flattened data shape: (327, 11)\n",
            "Split training data: 294 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.81, 0.815]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8878, Train Loss: 0.0859, Val Acc: 0.8485, Val Loss: 0.1200\n",
            "Restored model from best epoch 14 with val_loss: 0.119987\n",
            "NFL direct model 163/201 completed\n",
            "Original data shape: (344, 11)\n",
            "Flattened data shape: (344, 11)\n",
            "Split training data: 309 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.815, 0.82]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.9061, Train Loss: 0.0765, Val Acc: 0.8857, Val Loss: 0.0895\n",
            "Restored model from best epoch 16 with val_loss: 0.089477\n",
            "NFL direct model 164/201 completed\n",
            "Original data shape: (372, 11)\n",
            "Flattened data shape: (372, 11)\n",
            "Split training data: 334 train, 38 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.82, 0.825]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.9042, Train Loss: 0.0834, Val Acc: 0.8684, Val Loss: 0.1046\n",
            "Restored model from best epoch 18 with val_loss: 0.104633\n",
            "NFL direct model 165/201 completed\n",
            "Original data shape: (321, 11)\n",
            "Flattened data shape: (321, 11)\n",
            "Split training data: 288 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.825, 0.83]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 38\n",
            "Best epoch: 28, Train Acc: 0.9340, Train Loss: 0.0588, Val Acc: 0.8182, Val Loss: 0.1285\n",
            "Restored model from best epoch 28 with val_loss: 0.128454\n",
            "NFL direct model 166/201 completed\n",
            "Original data shape: (322, 11)\n",
            "Flattened data shape: (322, 11)\n",
            "Split training data: 289 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.83, 0.835]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8374, Train Loss: 0.1238, Val Acc: 0.7576, Val Loss: 0.1628\n",
            "Restored model from best epoch 8 with val_loss: 0.162776\n",
            "NFL direct model 167/201 completed\n",
            "Original data shape: (332, 11)\n",
            "Flattened data shape: (332, 11)\n",
            "Split training data: 298 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.835, 0.84]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.9262, Train Loss: 0.0530, Val Acc: 0.9412, Val Loss: 0.0559\n",
            "Restored model from best epoch 26 with val_loss: 0.055929\n",
            "NFL direct model 168/201 completed\n",
            "Original data shape: (335, 11)\n",
            "Flattened data shape: (335, 11)\n",
            "Split training data: 301 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.84, 0.845]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 42\n",
            "Best epoch: 32, Train Acc: 0.9302, Train Loss: 0.0510, Val Acc: 0.8824, Val Loss: 0.1120\n",
            "Restored model from best epoch 32 with val_loss: 0.111991\n",
            "NFL direct model 169/201 completed\n",
            "Original data shape: (333, 11)\n",
            "Flattened data shape: (333, 11)\n",
            "Split training data: 299 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.845, 0.85]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 45\n",
            "Best epoch: 35, Train Acc: 0.9465, Train Loss: 0.0475, Val Acc: 0.9706, Val Loss: 0.0231\n",
            "Restored model from best epoch 35 with val_loss: 0.023079\n",
            "NFL direct model 170/201 completed\n",
            "Original data shape: (348, 11)\n",
            "Flattened data shape: (348, 11)\n",
            "Split training data: 313 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.85, 0.855]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.9265, Train Loss: 0.0640, Val Acc: 0.9429, Val Loss: 0.0393\n",
            "Restored model from best epoch 22 with val_loss: 0.039332\n",
            "NFL direct model 171/201 completed\n",
            "Original data shape: (312, 11)\n",
            "Flattened data shape: (312, 11)\n",
            "Split training data: 280 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.855, 0.86]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.9179, Train Loss: 0.0665, Val Acc: 0.8125, Val Loss: 0.1558\n",
            "Restored model from best epoch 12 with val_loss: 0.155793\n",
            "NFL direct model 172/201 completed\n",
            "Original data shape: (327, 11)\n",
            "Flattened data shape: (327, 11)\n",
            "Split training data: 294 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.86, 0.865]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.9354, Train Loss: 0.0659, Val Acc: 0.8788, Val Loss: 0.0668\n",
            "Restored model from best epoch 16 with val_loss: 0.066751\n",
            "NFL direct model 173/201 completed\n",
            "Original data shape: (347, 11)\n",
            "Flattened data shape: (347, 11)\n",
            "Split training data: 312 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.865, 0.87]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 47\n",
            "Best epoch: 37, Train Acc: 0.9679, Train Loss: 0.0348, Val Acc: 0.9714, Val Loss: 0.0369\n",
            "Restored model from best epoch 37 with val_loss: 0.036941\n",
            "NFL direct model 174/201 completed\n",
            "Original data shape: (312, 11)\n",
            "Flattened data shape: (312, 11)\n",
            "Split training data: 280 train, 32 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.87, 0.875]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 43\n",
            "Best epoch: 33, Train Acc: 0.9179, Train Loss: 0.0676, Val Acc: 0.9375, Val Loss: 0.0570\n",
            "Restored model from best epoch 33 with val_loss: 0.057017\n",
            "NFL direct model 175/201 completed\n",
            "Original data shape: (353, 11)\n",
            "Flattened data shape: (353, 11)\n",
            "Split training data: 317 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.875, 0.88]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.9148, Train Loss: 0.0728, Val Acc: 0.9167, Val Loss: 0.0959\n",
            "Restored model from best epoch 13 with val_loss: 0.095913\n",
            "NFL direct model 176/201 completed\n",
            "Original data shape: (328, 11)\n",
            "Flattened data shape: (328, 11)\n",
            "Split training data: 295 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.88, 0.885]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 79\n",
            "Best epoch: 69, Train Acc: 0.9729, Train Loss: 0.0268, Val Acc: 0.9697, Val Loss: 0.0318\n",
            "Restored model from best epoch 69 with val_loss: 0.031782\n",
            "NFL direct model 177/201 completed\n",
            "Original data shape: (340, 11)\n",
            "Flattened data shape: (340, 11)\n",
            "Split training data: 306 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.885, 0.89]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.9150, Train Loss: 0.0669, Val Acc: 0.9412, Val Loss: 0.0405\n",
            "Restored model from best epoch 17 with val_loss: 0.040454\n",
            "NFL direct model 178/201 completed\n",
            "Original data shape: (323, 11)\n",
            "Flattened data shape: (323, 11)\n",
            "Split training data: 290 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.89, 0.895]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 19, Train Acc: 0.9345, Train Loss: 0.0542, Val Acc: 0.9091, Val Loss: 0.0680\n",
            "Restored model from best epoch 19 with val_loss: 0.068021\n",
            "NFL direct model 179/201 completed\n",
            "Original data shape: (337, 11)\n",
            "Flattened data shape: (337, 11)\n",
            "Split training data: 303 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.895, 0.9]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 40\n",
            "Best epoch: 30, Train Acc: 0.9670, Train Loss: 0.0330, Val Acc: 1.0000, Val Loss: 0.0087\n",
            "Restored model from best epoch 30 with val_loss: 0.008678\n",
            "NFL direct model 180/201 completed\n",
            "Original data shape: (336, 11)\n",
            "Flattened data shape: (336, 11)\n",
            "Split training data: 302 train, 34 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.9, 0.905]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 42\n",
            "Best epoch: 32, Train Acc: 0.9338, Train Loss: 0.0475, Val Acc: 0.8824, Val Loss: 0.0810\n",
            "Restored model from best epoch 32 with val_loss: 0.081002\n",
            "NFL direct model 181/201 completed\n",
            "Original data shape: (341, 11)\n",
            "Flattened data shape: (341, 11)\n",
            "Split training data: 306 train, 35 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.905, 0.91]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8954, Train Loss: 0.0869, Val Acc: 0.8571, Val Loss: 0.0717\n",
            "Restored model from best epoch 11 with val_loss: 0.071664\n",
            "NFL direct model 182/201 completed\n",
            "Original data shape: (356, 11)\n",
            "Flattened data shape: (356, 11)\n",
            "Split training data: 320 train, 36 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.91, 0.915]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.9219, Train Loss: 0.0671, Val Acc: 0.9444, Val Loss: 0.0472\n",
            "Restored model from best epoch 16 with val_loss: 0.047236\n",
            "NFL direct model 183/201 completed\n",
            "Original data shape: (321, 11)\n",
            "Flattened data shape: (321, 11)\n",
            "Split training data: 288 train, 33 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.915, 0.92]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 31\n",
            "Best epoch: 21, Train Acc: 0.9062, Train Loss: 0.0638, Val Acc: 0.9394, Val Loss: 0.0374\n",
            "Restored model from best epoch 21 with val_loss: 0.037368\n",
            "NFL direct model 184/201 completed\n",
            "Original data shape: (366, 11)\n",
            "Flattened data shape: (366, 11)\n",
            "Split training data: 329 train, 37 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.92, 0.925]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 49\n",
            "Best epoch: 39, Train Acc: 0.9605, Train Loss: 0.0297, Val Acc: 0.9730, Val Loss: 0.0343\n",
            "Restored model from best epoch 39 with val_loss: 0.034273\n",
            "NFL direct model 185/201 completed\n",
            "Original data shape: (433, 11)\n",
            "Flattened data shape: (433, 11)\n",
            "Split training data: 389 train, 44 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.925, 0.93]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 35\n",
            "Best epoch: 25, Train Acc: 0.9306, Train Loss: 0.0603, Val Acc: 0.9318, Val Loss: 0.0482\n",
            "Restored model from best epoch 25 with val_loss: 0.048210\n",
            "NFL direct model 186/201 completed\n",
            "Original data shape: (383, 11)\n",
            "Flattened data shape: (383, 11)\n",
            "Split training data: 344 train, 39 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.93, 0.935]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.9331, Train Loss: 0.0593, Val Acc: 0.8974, Val Loss: 0.0808\n",
            "Restored model from best epoch 13 with val_loss: 0.080843\n",
            "NFL direct model 187/201 completed\n",
            "Original data shape: (368, 11)\n",
            "Flattened data shape: (368, 11)\n",
            "Split training data: 331 train, 37 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.935, 0.94]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 41\n",
            "Best epoch: 31, Train Acc: 0.9668, Train Loss: 0.0250, Val Acc: 0.9459, Val Loss: 0.0384\n",
            "Restored model from best epoch 31 with val_loss: 0.038428\n",
            "NFL direct model 188/201 completed\n",
            "Original data shape: (440, 11)\n",
            "Flattened data shape: (440, 11)\n",
            "Split training data: 396 train, 44 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.94, 0.945]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.9167, Train Loss: 0.0539, Val Acc: 0.9091, Val Loss: 0.0733\n",
            "Restored model from best epoch 17 with val_loss: 0.073335\n",
            "NFL direct model 189/201 completed\n",
            "Original data shape: (435, 11)\n",
            "Flattened data shape: (435, 11)\n",
            "Split training data: 391 train, 44 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.945, 0.95]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.9386, Train Loss: 0.0444, Val Acc: 0.9545, Val Loss: 0.0415\n",
            "Restored model from best epoch 20 with val_loss: 0.041490\n",
            "NFL direct model 190/201 completed\n",
            "Original data shape: (433, 11)\n",
            "Flattened data shape: (433, 11)\n",
            "Split training data: 389 train, 44 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.95, 0.955]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.9203, Train Loss: 0.0519, Val Acc: 1.0000, Val Loss: 0.0128\n",
            "Restored model from best epoch 24 with val_loss: 0.012836\n",
            "NFL direct model 191/201 completed\n",
            "Original data shape: (400, 11)\n",
            "Flattened data shape: (400, 11)\n",
            "Split training data: 360 train, 40 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.955, 0.96]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 42\n",
            "Best epoch: 32, Train Acc: 0.9583, Train Loss: 0.0306, Val Acc: 0.9500, Val Loss: 0.0607\n",
            "Restored model from best epoch 32 with val_loss: 0.060718\n",
            "NFL direct model 192/201 completed\n",
            "Original data shape: (494, 11)\n",
            "Flattened data shape: (494, 11)\n",
            "Split training data: 444 train, 50 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.96, 0.965]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.9437, Train Loss: 0.0405, Val Acc: 0.9800, Val Loss: 0.0168\n",
            "Restored model from best epoch 26 with val_loss: 0.016836\n",
            "NFL direct model 193/201 completed\n",
            "Original data shape: (406, 11)\n",
            "Flattened data shape: (406, 11)\n",
            "Split training data: 365 train, 41 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.965, 0.97]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 37\n",
            "Best epoch: 27, Train Acc: 0.9425, Train Loss: 0.0472, Val Acc: 0.8780, Val Loss: 0.0882\n",
            "Restored model from best epoch 27 with val_loss: 0.088244\n",
            "NFL direct model 194/201 completed\n",
            "Original data shape: (902, 11)\n",
            "Flattened data shape: (902, 11)\n",
            "Split training data: 811 train, 91 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.97, 0.975]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.9309, Train Loss: 0.0546, Val Acc: 0.9231, Val Loss: 0.0661\n",
            "Restored model from best epoch 14 with val_loss: 0.066117\n",
            "NFL direct model 195/201 completed\n",
            "Original data shape: (388, 11)\n",
            "Flattened data shape: (388, 11)\n",
            "Split training data: 349 train, 39 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.975, 0.98]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 31\n",
            "Best epoch: 21, Train Acc: 0.9255, Train Loss: 0.0687, Val Acc: 1.0000, Val Loss: 0.0077\n",
            "Restored model from best epoch 21 with val_loss: 0.007665\n",
            "NFL direct model 196/201 completed\n",
            "Original data shape: (496, 11)\n",
            "Flattened data shape: (496, 11)\n",
            "Split training data: 446 train, 50 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.98, 0.985]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.9058, Train Loss: 0.0677, Val Acc: 0.9600, Val Loss: 0.0318\n",
            "Restored model from best epoch 10 with val_loss: 0.031814\n",
            "NFL direct model 197/201 completed\n",
            "Original data shape: (461, 11)\n",
            "Flattened data shape: (461, 11)\n",
            "Split training data: 414 train, 47 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.985, 0.99]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 79\n",
            "Best epoch: 69, Train Acc: 0.9807, Train Loss: 0.0205, Val Acc: 0.9787, Val Loss: 0.0284\n",
            "Restored model from best epoch 69 with val_loss: 0.028357\n",
            "NFL direct model 198/201 completed\n",
            "Original data shape: (450, 11)\n",
            "Flattened data shape: (450, 11)\n",
            "Split training data: 405 train, 45 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.99, 0.995]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.9407, Train Loss: 0.0473, Val Acc: 0.9333, Val Loss: 0.0530\n",
            "Restored model from best epoch 24 with val_loss: 0.053044\n",
            "NFL direct model 199/201 completed\n",
            "Original data shape: (486, 11)\n",
            "Flattened data shape: (486, 11)\n",
            "Split training data: 437 train, 49 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.995, 1.0]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 42\n",
            "Best epoch: 32, Train Acc: 0.9725, Train Loss: 0.0293, Val Acc: 1.0000, Val Loss: 0.0092\n",
            "Restored model from best epoch 32 with val_loss: 0.009180\n",
            "NFL direct model 200/201 completed\n",
            "Original data shape: (518, 11)\n",
            "Flattened data shape: (518, 11)\n",
            "Split training data: 466 train, 52 validation\n",
            "\n",
            "Training direct prediction model for timestep range [1.0, 1.005]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 40\n",
            "Best epoch: 30, Train Acc: 0.9592, Train Loss: 0.0294, Val Acc: 0.9423, Val Loss: 0.0465\n",
            "Restored model from best epoch 30 with val_loss: 0.046463\n",
            "NFL direct model 201/201 completed\n"
          ]
        }
      ],
      "source": [
        "all_models[\"nn\"] = setup_direct_models(training_data, None, num_models=201)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing timestep: 0.0\n",
            "Timestep 0.00% : Training Loss = 0.6468, Accuracy = 0.6543, Test Loss = 0.5912, Test Accuracy = 0.6944\n",
            "Processing timestep: 0.005\n",
            "Timestep 0.50% : Training Loss = 0.6015, Accuracy = 0.6601, Test Loss = 0.6674, Test Accuracy = 0.6667\n",
            "Processing timestep: 0.01\n",
            "Timestep 1.00% : Training Loss = 0.6395, Accuracy = 0.6314, Test Loss = 0.6252, Test Accuracy = 0.6000\n",
            "Processing timestep: 0.015\n",
            "Timestep 1.50% : Training Loss = 0.6224, Accuracy = 0.6345, Test Loss = 0.7122, Test Accuracy = 0.5952\n",
            "Processing timestep: 0.02\n",
            "Timestep 2.00% : Training Loss = 0.6600, Accuracy = 0.6345, Test Loss = 0.6229, Test Accuracy = 0.6444\n",
            "Processing timestep: 0.025\n",
            "Timestep 2.50% : Training Loss = 0.6244, Accuracy = 0.6475, Test Loss = 0.7668, Test Accuracy = 0.6000\n",
            "Processing timestep: 0.03\n",
            "Timestep 3.00% : Training Loss = 0.6395, Accuracy = 0.6333, Test Loss = 0.6520, Test Accuracy = 0.5814\n",
            "Processing timestep: 0.035\n",
            "Timestep 3.50% : Training Loss = 0.6218, Accuracy = 0.6584, Test Loss = 0.6776, Test Accuracy = 0.6000\n",
            "Processing timestep: 0.04\n",
            "Timestep 4.00% : Training Loss = 0.6492, Accuracy = 0.6255, Test Loss = 0.6018, Test Accuracy = 0.6250\n",
            "Processing timestep: 0.045\n",
            "Timestep 4.50% : Training Loss = 0.6374, Accuracy = 0.6306, Test Loss = 0.5771, Test Accuracy = 0.7708\n",
            "Processing timestep: 0.05\n",
            "Timestep 5.00% : Training Loss = 0.6511, Accuracy = 0.6232, Test Loss = 0.5904, Test Accuracy = 0.7347\n",
            "Processing timestep: 0.055\n",
            "Timestep 5.50% : Training Loss = 0.6248, Accuracy = 0.6553, Test Loss = 0.5680, Test Accuracy = 0.6596\n",
            "Processing timestep: 0.06\n",
            "Timestep 6.00% : Training Loss = 0.6445, Accuracy = 0.6715, Test Loss = 0.5496, Test Accuracy = 0.7755\n",
            "Processing timestep: 0.065\n",
            "Timestep 6.50% : Training Loss = 0.6391, Accuracy = 0.6287, Test Loss = 0.5962, Test Accuracy = 0.6939\n",
            "Processing timestep: 0.07\n",
            "Timestep 7.00% : Training Loss = 0.6374, Accuracy = 0.6438, Test Loss = 0.6133, Test Accuracy = 0.7115\n",
            "Processing timestep: 0.075\n",
            "Timestep 7.50% : Training Loss = 0.6489, Accuracy = 0.6176, Test Loss = 0.5695, Test Accuracy = 0.7143\n",
            "Processing timestep: 0.08\n",
            "Timestep 8.00% : Training Loss = 0.6435, Accuracy = 0.6292, Test Loss = 0.5757, Test Accuracy = 0.7083\n",
            "Processing timestep: 0.085\n",
            "Timestep 8.50% : Training Loss = 0.6580, Accuracy = 0.6162, Test Loss = 0.6388, Test Accuracy = 0.6275\n",
            "Processing timestep: 0.09\n",
            "Timestep 9.00% : Training Loss = 0.6535, Accuracy = 0.6409, Test Loss = 0.5928, Test Accuracy = 0.7391\n",
            "Processing timestep: 0.095\n",
            "Timestep 9.50% : Training Loss = 0.6450, Accuracy = 0.6411, Test Loss = 0.5758, Test Accuracy = 0.6863\n",
            "Processing timestep: 0.1\n",
            "Timestep 10.00% : Training Loss = 0.6216, Accuracy = 0.6523, Test Loss = 0.5734, Test Accuracy = 0.7174\n",
            "Processing timestep: 0.105\n",
            "Timestep 10.50% : Training Loss = 0.6436, Accuracy = 0.6241, Test Loss = 0.6234, Test Accuracy = 0.6809\n",
            "Processing timestep: 0.11\n",
            "Timestep 11.00% : Training Loss = 0.6382, Accuracy = 0.6573, Test Loss = 0.6094, Test Accuracy = 0.7451\n",
            "Processing timestep: 0.115\n",
            "Timestep 11.50% : Training Loss = 0.5955, Accuracy = 0.6817, Test Loss = 0.6444, Test Accuracy = 0.6538\n",
            "Processing timestep: 0.12\n",
            "Timestep 12.00% : Training Loss = 0.6294, Accuracy = 0.6316, Test Loss = 0.6106, Test Accuracy = 0.6809\n",
            "Processing timestep: 0.125\n",
            "Timestep 12.50% : Training Loss = 0.6161, Accuracy = 0.6879, Test Loss = 0.6382, Test Accuracy = 0.6415\n",
            "Processing timestep: 0.13\n",
            "Timestep 13.00% : Training Loss = 0.6064, Accuracy = 0.6617, Test Loss = 0.5915, Test Accuracy = 0.6596\n",
            "Processing timestep: 0.135\n",
            "Timestep 13.50% : Training Loss = 0.6129, Accuracy = 0.6830, Test Loss = 0.5982, Test Accuracy = 0.7447\n",
            "Processing timestep: 0.14\n",
            "Timestep 14.00% : Training Loss = 0.6349, Accuracy = 0.6340, Test Loss = 0.5082, Test Accuracy = 0.7872\n",
            "Processing timestep: 0.145\n",
            "Timestep 14.50% : Training Loss = 0.5943, Accuracy = 0.6885, Test Loss = 0.5895, Test Accuracy = 0.6809\n",
            "Processing timestep: 0.15\n",
            "Timestep 15.00% : Training Loss = 0.6180, Accuracy = 0.6656, Test Loss = 0.5915, Test Accuracy = 0.6667\n",
            "Processing timestep: 0.155\n",
            "Timestep 15.50% : Training Loss = 0.6251, Accuracy = 0.6627, Test Loss = 0.5642, Test Accuracy = 0.6739\n",
            "Processing timestep: 0.16\n",
            "Timestep 16.00% : Training Loss = 0.6198, Accuracy = 0.6307, Test Loss = 0.5411, Test Accuracy = 0.7455\n",
            "Processing timestep: 0.165\n",
            "Timestep 16.50% : Training Loss = 0.6457, Accuracy = 0.6290, Test Loss = 0.6308, Test Accuracy = 0.6591\n",
            "Processing timestep: 0.17\n",
            "Timestep 17.00% : Training Loss = 0.6096, Accuracy = 0.6743, Test Loss = 0.5378, Test Accuracy = 0.7447\n",
            "Processing timestep: 0.175\n",
            "Timestep 17.50% : Training Loss = 0.5895, Accuracy = 0.6826, Test Loss = 0.6617, Test Accuracy = 0.6538\n",
            "Processing timestep: 0.18\n",
            "Timestep 18.00% : Training Loss = 0.5692, Accuracy = 0.7077, Test Loss = 0.5412, Test Accuracy = 0.6522\n",
            "Processing timestep: 0.185\n",
            "Timestep 18.50% : Training Loss = 0.6184, Accuracy = 0.6332, Test Loss = 0.5374, Test Accuracy = 0.7843\n",
            "Processing timestep: 0.19\n",
            "Timestep 19.00% : Training Loss = 0.6093, Accuracy = 0.6214, Test Loss = 0.6381, Test Accuracy = 0.6591\n",
            "Processing timestep: 0.195\n",
            "Timestep 19.50% : Training Loss = 0.6182, Accuracy = 0.6419, Test Loss = 0.4845, Test Accuracy = 0.7818\n",
            "Processing timestep: 0.2\n",
            "Timestep 20.00% : Training Loss = 0.6097, Accuracy = 0.6679, Test Loss = 0.5820, Test Accuracy = 0.7292\n",
            "Processing timestep: 0.205\n",
            "Timestep 20.50% : Training Loss = 0.6000, Accuracy = 0.6982, Test Loss = 0.5691, Test Accuracy = 0.6531\n",
            "Processing timestep: 0.21\n",
            "Timestep 21.00% : Training Loss = 0.5972, Accuracy = 0.6644, Test Loss = 0.5164, Test Accuracy = 0.8039\n",
            "Processing timestep: 0.215\n",
            "Timestep 21.50% : Training Loss = 0.5409, Accuracy = 0.7259, Test Loss = 0.5691, Test Accuracy = 0.6739\n",
            "Processing timestep: 0.22\n",
            "Timestep 22.00% : Training Loss = 0.5709, Accuracy = 0.7197, Test Loss = 0.5350, Test Accuracy = 0.7451\n",
            "Processing timestep: 0.225\n",
            "Timestep 22.50% : Training Loss = 0.6069, Accuracy = 0.6390, Test Loss = 0.5234, Test Accuracy = 0.8163\n",
            "Processing timestep: 0.23\n",
            "Timestep 23.00% : Training Loss = 0.6048, Accuracy = 0.6600, Test Loss = 0.3616, Test Accuracy = 0.8889\n",
            "Processing timestep: 0.235\n",
            "Timestep 23.50% : Training Loss = 0.5639, Accuracy = 0.6893, Test Loss = 0.4731, Test Accuracy = 0.8000\n",
            "Processing timestep: 0.24\n",
            "Timestep 24.00% : Training Loss = 0.5735, Accuracy = 0.7224, Test Loss = 0.6008, Test Accuracy = 0.7021\n",
            "Processing timestep: 0.245\n",
            "Timestep 24.50% : Training Loss = 0.6165, Accuracy = 0.6420, Test Loss = 0.4821, Test Accuracy = 0.8372\n",
            "Processing timestep: 0.25\n",
            "Timestep 25.00% : Training Loss = 0.5943, Accuracy = 0.6536, Test Loss = 0.4971, Test Accuracy = 0.8000\n",
            "Processing timestep: 0.255\n",
            "Timestep 25.50% : Training Loss = 0.4903, Accuracy = 0.7584, Test Loss = 0.3458, Test Accuracy = 0.9259\n",
            "Processing timestep: 0.26\n",
            "Timestep 26.00% : Training Loss = 0.5671, Accuracy = 0.6943, Test Loss = 0.6644, Test Accuracy = 0.6857\n",
            "Processing timestep: 0.265\n",
            "Timestep 26.50% : Training Loss = 0.5882, Accuracy = 0.6910, Test Loss = 0.4987, Test Accuracy = 0.8039\n",
            "Processing timestep: 0.27\n",
            "Timestep 27.00% : Training Loss = 0.5715, Accuracy = 0.7000, Test Loss = 0.4999, Test Accuracy = 0.7609\n",
            "Processing timestep: 0.275\n",
            "Timestep 27.50% : Training Loss = 0.5927, Accuracy = 0.6997, Test Loss = 0.5153, Test Accuracy = 0.8148\n",
            "Processing timestep: 0.28\n",
            "Timestep 28.00% : Training Loss = 0.5802, Accuracy = 0.6966, Test Loss = 0.5724, Test Accuracy = 0.7292\n",
            "Processing timestep: 0.285\n",
            "Timestep 28.50% : Training Loss = 0.6212, Accuracy = 0.6414, Test Loss = 0.5564, Test Accuracy = 0.7115\n",
            "Processing timestep: 0.29\n",
            "Timestep 29.00% : Training Loss = 0.5560, Accuracy = 0.6964, Test Loss = 0.5279, Test Accuracy = 0.7400\n",
            "Processing timestep: 0.295\n",
            "Timestep 29.50% : Training Loss = 0.5647, Accuracy = 0.7238, Test Loss = 0.5197, Test Accuracy = 0.7647\n",
            "Processing timestep: 0.3\n",
            "Timestep 30.00% : Training Loss = 0.5529, Accuracy = 0.7054, Test Loss = 0.6903, Test Accuracy = 0.7174\n",
            "Processing timestep: 0.305\n",
            "Timestep 30.50% : Training Loss = 0.5599, Accuracy = 0.7143, Test Loss = 0.5124, Test Accuracy = 0.7333\n",
            "Processing timestep: 0.31\n",
            "Timestep 31.00% : Training Loss = 0.5853, Accuracy = 0.6756, Test Loss = 0.4458, Test Accuracy = 0.8085\n",
            "Processing timestep: 0.315\n",
            "Timestep 31.50% : Training Loss = 0.5845, Accuracy = 0.6933, Test Loss = 0.5454, Test Accuracy = 0.6852\n",
            "Processing timestep: 0.32\n",
            "Timestep 32.00% : Training Loss = 0.5662, Accuracy = 0.7057, Test Loss = 0.4708, Test Accuracy = 0.7200\n",
            "Processing timestep: 0.325\n",
            "Timestep 32.50% : Training Loss = 0.5781, Accuracy = 0.6942, Test Loss = 0.5033, Test Accuracy = 0.7400\n",
            "Processing timestep: 0.33\n",
            "Timestep 33.00% : Training Loss = 0.5607, Accuracy = 0.7409, Test Loss = 0.5540, Test Accuracy = 0.7143\n",
            "Processing timestep: 0.335\n",
            "Timestep 33.50% : Training Loss = 0.5640, Accuracy = 0.6926, Test Loss = 0.3837, Test Accuracy = 0.9608\n",
            "Processing timestep: 0.34\n",
            "Timestep 34.00% : Training Loss = 0.5406, Accuracy = 0.7376, Test Loss = 0.4291, Test Accuracy = 0.9149\n",
            "Processing timestep: 0.345\n",
            "Timestep 34.50% : Training Loss = 0.5669, Accuracy = 0.6813, Test Loss = 0.4995, Test Accuracy = 0.8776\n",
            "Processing timestep: 0.35\n",
            "Timestep 35.00% : Training Loss = 0.5869, Accuracy = 0.6859, Test Loss = 0.4412, Test Accuracy = 0.8200\n",
            "Processing timestep: 0.355\n",
            "Timestep 35.50% : Training Loss = 0.5743, Accuracy = 0.7003, Test Loss = 0.4731, Test Accuracy = 0.8113\n",
            "Processing timestep: 0.36\n",
            "Timestep 36.00% : Training Loss = 0.5561, Accuracy = 0.7256, Test Loss = 0.4474, Test Accuracy = 0.8400\n",
            "Processing timestep: 0.365\n",
            "Timestep 36.50% : Training Loss = 0.5251, Accuracy = 0.7624, Test Loss = 0.4246, Test Accuracy = 0.7778\n",
            "Processing timestep: 0.37\n",
            "Timestep 37.00% : Training Loss = 0.5728, Accuracy = 0.7432, Test Loss = 0.5204, Test Accuracy = 0.6957\n",
            "Processing timestep: 0.375\n",
            "Timestep 37.50% : Training Loss = 0.4948, Accuracy = 0.7612, Test Loss = 0.5327, Test Accuracy = 0.7308\n",
            "Processing timestep: 0.38\n",
            "Timestep 38.00% : Training Loss = 0.5547, Accuracy = 0.7481, Test Loss = 0.4768, Test Accuracy = 0.7500\n",
            "Processing timestep: 0.385\n",
            "Timestep 38.50% : Training Loss = 0.5219, Accuracy = 0.7451, Test Loss = 0.4829, Test Accuracy = 0.7778\n",
            "Processing timestep: 0.39\n",
            "Timestep 39.00% : Training Loss = 0.5596, Accuracy = 0.7184, Test Loss = 0.5444, Test Accuracy = 0.7600\n",
            "Processing timestep: 0.395\n",
            "Timestep 39.50% : Training Loss = 0.5285, Accuracy = 0.7222, Test Loss = 0.5221, Test Accuracy = 0.7451\n",
            "Processing timestep: 0.4\n",
            "Timestep 40.00% : Training Loss = 0.5122, Accuracy = 0.7546, Test Loss = 0.5532, Test Accuracy = 0.6327\n",
            "Processing timestep: 0.405\n",
            "Timestep 40.50% : Training Loss = 0.5287, Accuracy = 0.7255, Test Loss = 0.4281, Test Accuracy = 0.8043\n",
            "Processing timestep: 0.41\n",
            "Timestep 41.00% : Training Loss = 0.5070, Accuracy = 0.7367, Test Loss = 0.5399, Test Accuracy = 0.6792\n",
            "Processing timestep: 0.415\n",
            "Timestep 41.50% : Training Loss = 0.5611, Accuracy = 0.6653, Test Loss = 0.4501, Test Accuracy = 0.8409\n",
            "Processing timestep: 0.42\n",
            "Timestep 42.00% : Training Loss = 0.5428, Accuracy = 0.7200, Test Loss = 0.5170, Test Accuracy = 0.7551\n",
            "Processing timestep: 0.425\n",
            "Timestep 42.50% : Training Loss = 0.5324, Accuracy = 0.7343, Test Loss = 0.4983, Test Accuracy = 0.7500\n",
            "Processing timestep: 0.43\n",
            "Timestep 43.00% : Training Loss = 0.5148, Accuracy = 0.7641, Test Loss = 0.4479, Test Accuracy = 0.7451\n",
            "Processing timestep: 0.435\n",
            "Timestep 43.50% : Training Loss = 0.5183, Accuracy = 0.7218, Test Loss = 0.6683, Test Accuracy = 0.7059\n",
            "Processing timestep: 0.44\n",
            "Timestep 44.00% : Training Loss = 0.5232, Accuracy = 0.7388, Test Loss = 0.5156, Test Accuracy = 0.7083\n",
            "Processing timestep: 0.445\n",
            "Timestep 44.50% : Training Loss = 0.5253, Accuracy = 0.7248, Test Loss = 0.5111, Test Accuracy = 0.7547\n",
            "Processing timestep: 0.45\n",
            "Timestep 45.00% : Training Loss = 0.5138, Accuracy = 0.7491, Test Loss = 0.6421, Test Accuracy = 0.7292\n",
            "Processing timestep: 0.455\n",
            "Timestep 45.50% : Training Loss = 0.5227, Accuracy = 0.7448, Test Loss = 0.4698, Test Accuracy = 0.8077\n",
            "Processing timestep: 0.46\n",
            "Timestep 46.00% : Training Loss = 0.4752, Accuracy = 0.8040, Test Loss = 0.5354, Test Accuracy = 0.7778\n",
            "Processing timestep: 0.465\n",
            "Timestep 46.50% : Training Loss = 0.5026, Accuracy = 0.7823, Test Loss = 0.4854, Test Accuracy = 0.7500\n",
            "Processing timestep: 0.47\n",
            "Timestep 47.00% : Training Loss = 0.5286, Accuracy = 0.7389, Test Loss = 0.5413, Test Accuracy = 0.7273\n",
            "Processing timestep: 0.475\n",
            "Timestep 47.50% : Training Loss = 0.4693, Accuracy = 0.7880, Test Loss = 0.5301, Test Accuracy = 0.7432\n",
            "Processing timestep: 0.48\n",
            "Timestep 48.00% : Training Loss = 0.4800, Accuracy = 0.7767, Test Loss = 0.4748, Test Accuracy = 0.7945\n",
            "Processing timestep: 0.485\n",
            "Timestep 48.50% : Training Loss = 0.4921, Accuracy = 0.7454, Test Loss = 0.5414, Test Accuracy = 0.7326\n",
            "Processing timestep: 0.49\n",
            "Timestep 49.00% : Training Loss = 0.4725, Accuracy = 0.7821, Test Loss = 0.5475, Test Accuracy = 0.8081\n",
            "Processing timestep: 0.495\n",
            "Timestep 49.50% : Training Loss = 0.4736, Accuracy = 0.7845, Test Loss = 0.5448, Test Accuracy = 0.8074\n",
            "Processing timestep: 0.5\n",
            "Timestep 50.00% : Training Loss = 0.4643, Accuracy = 0.7733, Test Loss = 0.4802, Test Accuracy = 0.7965\n",
            "Processing timestep: 0.505\n",
            "Timestep 50.50% : Training Loss = 0.4073, Accuracy = 0.8263, Test Loss = 0.3962, Test Accuracy = 0.8000\n",
            "Processing timestep: 0.51\n",
            "Timestep 51.00% : Training Loss = 0.4560, Accuracy = 0.7843, Test Loss = 0.4291, Test Accuracy = 0.7391\n",
            "Processing timestep: 0.515\n",
            "Timestep 51.50% : Training Loss = 0.4185, Accuracy = 0.8251, Test Loss = 0.3563, Test Accuracy = 0.8250\n",
            "Processing timestep: 0.52\n",
            "Timestep 52.00% : Training Loss = 0.4650, Accuracy = 0.7854, Test Loss = 0.5079, Test Accuracy = 0.7660\n",
            "Processing timestep: 0.525\n",
            "Timestep 52.50% : Training Loss = 0.3958, Accuracy = 0.8113, Test Loss = 0.4286, Test Accuracy = 0.8298\n",
            "Processing timestep: 0.53\n",
            "Timestep 53.00% : Training Loss = 0.4881, Accuracy = 0.7273, Test Loss = 0.5566, Test Accuracy = 0.7333\n",
            "Processing timestep: 0.535\n",
            "Timestep 53.50% : Training Loss = 0.4222, Accuracy = 0.8036, Test Loss = 0.4541, Test Accuracy = 0.8000\n",
            "Processing timestep: 0.54\n",
            "Timestep 54.00% : Training Loss = 0.4542, Accuracy = 0.8008, Test Loss = 0.4786, Test Accuracy = 0.7660\n",
            "Processing timestep: 0.545\n",
            "Timestep 54.50% : Training Loss = 0.4403, Accuracy = 0.7871, Test Loss = 0.5850, Test Accuracy = 0.6809\n",
            "Processing timestep: 0.55\n",
            "Timestep 55.00% : Training Loss = 0.3972, Accuracy = 0.8284, Test Loss = 0.4754, Test Accuracy = 0.8333\n",
            "Processing timestep: 0.555\n",
            "Timestep 55.50% : Training Loss = 0.4195, Accuracy = 0.8162, Test Loss = 0.5478, Test Accuracy = 0.7959\n",
            "Processing timestep: 0.56\n",
            "Timestep 56.00% : Training Loss = 0.3927, Accuracy = 0.8498, Test Loss = 0.5435, Test Accuracy = 0.6889\n",
            "Processing timestep: 0.565\n",
            "Timestep 56.50% : Training Loss = 0.4116, Accuracy = 0.8304, Test Loss = 0.4079, Test Accuracy = 0.8039\n",
            "Processing timestep: 0.57\n",
            "Timestep 57.00% : Training Loss = 0.4276, Accuracy = 0.8140, Test Loss = 0.4711, Test Accuracy = 0.8148\n",
            "Processing timestep: 0.575\n",
            "Timestep 57.50% : Training Loss = 0.4409, Accuracy = 0.7698, Test Loss = 0.4737, Test Accuracy = 0.7872\n",
            "Processing timestep: 0.58\n",
            "Timestep 58.00% : Training Loss = 0.3998, Accuracy = 0.8221, Test Loss = 0.3819, Test Accuracy = 0.8000\n",
            "Processing timestep: 0.585\n",
            "Timestep 58.50% : Training Loss = 0.3809, Accuracy = 0.8251, Test Loss = 0.4676, Test Accuracy = 0.7872\n",
            "Processing timestep: 0.59\n",
            "Timestep 59.00% : Training Loss = 0.3948, Accuracy = 0.8188, Test Loss = 0.4018, Test Accuracy = 0.8163\n",
            "Processing timestep: 0.595\n",
            "Timestep 59.50% : Training Loss = 0.3988, Accuracy = 0.8032, Test Loss = 0.3540, Test Accuracy = 0.8750\n",
            "Processing timestep: 0.6\n",
            "Timestep 60.00% : Training Loss = 0.3931, Accuracy = 0.8090, Test Loss = 0.4874, Test Accuracy = 0.7083\n",
            "Processing timestep: 0.605\n",
            "Timestep 60.50% : Training Loss = 0.3642, Accuracy = 0.8401, Test Loss = 0.3233, Test Accuracy = 0.8113\n",
            "Processing timestep: 0.61\n",
            "Timestep 61.00% : Training Loss = 0.4442, Accuracy = 0.7993, Test Loss = 0.4924, Test Accuracy = 0.7500\n",
            "Processing timestep: 0.615\n",
            "Timestep 61.50% : Training Loss = 0.3616, Accuracy = 0.8504, Test Loss = 0.4087, Test Accuracy = 0.7959\n",
            "Processing timestep: 0.62\n",
            "Timestep 62.00% : Training Loss = 0.4112, Accuracy = 0.8288, Test Loss = 0.3580, Test Accuracy = 0.8269\n",
            "Processing timestep: 0.625\n",
            "Timestep 62.50% : Training Loss = 0.3947, Accuracy = 0.8137, Test Loss = 0.3308, Test Accuracy = 0.8511\n",
            "Processing timestep: 0.63\n",
            "Timestep 63.00% : Training Loss = 0.4284, Accuracy = 0.8097, Test Loss = 0.3302, Test Accuracy = 0.8654\n",
            "Processing timestep: 0.635\n",
            "Timestep 63.50% : Training Loss = 0.3667, Accuracy = 0.8423, Test Loss = 0.3512, Test Accuracy = 0.8511\n",
            "Processing timestep: 0.64\n",
            "Timestep 64.00% : Training Loss = 0.3836, Accuracy = 0.8315, Test Loss = 0.4133, Test Accuracy = 0.8000\n",
            "Processing timestep: 0.645\n",
            "Timestep 64.50% : Training Loss = 0.3982, Accuracy = 0.8047, Test Loss = 0.4002, Test Accuracy = 0.8113\n",
            "Processing timestep: 0.65\n",
            "Timestep 65.00% : Training Loss = 0.3544, Accuracy = 0.8750, Test Loss = 0.3168, Test Accuracy = 0.8800\n",
            "Processing timestep: 0.655\n",
            "Timestep 65.50% : Training Loss = 0.3565, Accuracy = 0.8356, Test Loss = 0.4451, Test Accuracy = 0.8077\n",
            "Processing timestep: 0.66\n",
            "Timestep 66.00% : Training Loss = 0.3523, Accuracy = 0.8453, Test Loss = 0.3618, Test Accuracy = 0.8400\n",
            "Processing timestep: 0.665\n",
            "Timestep 66.50% : Training Loss = 0.3417, Accuracy = 0.8906, Test Loss = 0.3916, Test Accuracy = 0.7660\n",
            "Processing timestep: 0.67\n",
            "Timestep 67.00% : Training Loss = 0.3287, Accuracy = 0.8651, Test Loss = 0.4619, Test Accuracy = 0.7692\n",
            "Processing timestep: 0.675\n",
            "Timestep 67.50% : Training Loss = 0.3675, Accuracy = 0.8403, Test Loss = 0.4427, Test Accuracy = 0.7872\n",
            "Processing timestep: 0.68\n",
            "Timestep 68.00% : Training Loss = 0.3166, Accuracy = 0.8477, Test Loss = 0.4449, Test Accuracy = 0.7609\n",
            "Processing timestep: 0.685\n",
            "Timestep 68.50% : Training Loss = 0.3200, Accuracy = 0.8537, Test Loss = 0.3761, Test Accuracy = 0.8302\n",
            "Processing timestep: 0.69\n",
            "Timestep 69.00% : Training Loss = 0.3622, Accuracy = 0.8448, Test Loss = 0.3607, Test Accuracy = 0.8077\n",
            "Processing timestep: 0.695\n",
            "Timestep 69.50% : Training Loss = 0.3349, Accuracy = 0.8444, Test Loss = 0.3341, Test Accuracy = 0.8750\n",
            "Processing timestep: 0.7\n",
            "Timestep 70.00% : Training Loss = 0.3943, Accuracy = 0.8178, Test Loss = 0.4382, Test Accuracy = 0.7917\n",
            "Processing timestep: 0.705\n",
            "Timestep 70.50% : Training Loss = 0.3540, Accuracy = 0.8487, Test Loss = 0.3950, Test Accuracy = 0.8125\n",
            "Processing timestep: 0.71\n",
            "Timestep 71.00% : Training Loss = 0.3569, Accuracy = 0.8534, Test Loss = 0.3668, Test Accuracy = 0.8333\n",
            "Processing timestep: 0.715\n",
            "Timestep 71.50% : Training Loss = 0.3314, Accuracy = 0.8720, Test Loss = 0.5333, Test Accuracy = 0.7115\n",
            "Processing timestep: 0.72\n",
            "Timestep 72.00% : Training Loss = 0.3234, Accuracy = 0.8773, Test Loss = 0.3541, Test Accuracy = 0.8367\n",
            "Processing timestep: 0.725\n",
            "Timestep 72.50% : Training Loss = 0.2978, Accuracy = 0.8813, Test Loss = 0.3147, Test Accuracy = 0.8200\n",
            "Processing timestep: 0.73\n",
            "Timestep 73.00% : Training Loss = 0.3447, Accuracy = 0.8439, Test Loss = 0.3725, Test Accuracy = 0.7963\n",
            "Processing timestep: 0.735\n",
            "Timestep 73.50% : Training Loss = 0.3464, Accuracy = 0.8750, Test Loss = 0.3592, Test Accuracy = 0.8800\n",
            "Processing timestep: 0.74\n",
            "Timestep 74.00% : Training Loss = 0.3052, Accuracy = 0.8775, Test Loss = 0.3396, Test Accuracy = 0.8444\n",
            "Processing timestep: 0.745\n",
            "Timestep 74.50% : Training Loss = 0.3253, Accuracy = 0.8819, Test Loss = 0.4569, Test Accuracy = 0.8333\n",
            "Processing timestep: 0.75\n",
            "Timestep 75.00% : Training Loss = 0.3443, Accuracy = 0.8353, Test Loss = 0.3741, Test Accuracy = 0.8859\n",
            "Processing timestep: 0.755\n",
            "Timestep 75.50% : Training Loss = 0.2777, Accuracy = 0.8980, Test Loss = 0.2182, Test Accuracy = 0.8846\n",
            "Processing timestep: 0.76\n",
            "Timestep 76.00% : Training Loss = 0.3732, Accuracy = 0.8296, Test Loss = 0.3404, Test Accuracy = 0.8250\n",
            "Processing timestep: 0.765\n",
            "Timestep 76.50% : Training Loss = 0.2941, Accuracy = 0.8930, Test Loss = 0.2291, Test Accuracy = 0.9583\n",
            "Processing timestep: 0.77\n",
            "Timestep 77.00% : Training Loss = 0.3258, Accuracy = 0.8582, Test Loss = 0.2859, Test Accuracy = 0.8936\n",
            "Processing timestep: 0.775\n",
            "Timestep 77.50% : Training Loss = 0.2922, Accuracy = 0.8997, Test Loss = 0.3740, Test Accuracy = 0.8654\n",
            "Processing timestep: 0.78\n",
            "Timestep 78.00% : Training Loss = 0.3151, Accuracy = 0.8626, Test Loss = 0.3116, Test Accuracy = 0.8511\n",
            "Processing timestep: 0.785\n",
            "Timestep 78.50% : Training Loss = 0.3309, Accuracy = 0.8721, Test Loss = 0.5260, Test Accuracy = 0.8302\n",
            "Processing timestep: 0.79\n",
            "Timestep 79.00% : Training Loss = 0.2562, Accuracy = 0.8985, Test Loss = 0.2884, Test Accuracy = 0.8936\n",
            "Processing timestep: 0.795\n",
            "Timestep 79.50% : Training Loss = 0.3201, Accuracy = 0.8684, Test Loss = 0.4572, Test Accuracy = 0.8125\n",
            "Processing timestep: 0.8\n",
            "Timestep 80.00% : Training Loss = 0.3224, Accuracy = 0.8851, Test Loss = 0.2833, Test Accuracy = 0.8679\n",
            "Processing timestep: 0.805\n",
            "Timestep 80.50% : Training Loss = 0.3176, Accuracy = 0.8869, Test Loss = 0.2282, Test Accuracy = 0.9000\n",
            "Processing timestep: 0.81\n",
            "Timestep 81.00% : Training Loss = 0.2997, Accuracy = 0.8989, Test Loss = 0.4274, Test Accuracy = 0.8400\n",
            "Processing timestep: 0.815\n",
            "Timestep 81.50% : Training Loss = 0.2852, Accuracy = 0.8767, Test Loss = 0.3484, Test Accuracy = 0.8269\n",
            "Processing timestep: 0.82\n",
            "Timestep 82.00% : Training Loss = 0.3127, Accuracy = 0.8703, Test Loss = 0.2146, Test Accuracy = 0.9286\n",
            "Processing timestep: 0.825\n",
            "Timestep 82.50% : Training Loss = 0.3290, Accuracy = 0.8566, Test Loss = 0.2475, Test Accuracy = 0.9184\n",
            "Processing timestep: 0.83\n",
            "Timestep 83.00% : Training Loss = 0.2868, Accuracy = 0.8681, Test Loss = 0.3006, Test Accuracy = 0.8571\n",
            "Processing timestep: 0.835\n",
            "Timestep 83.50% : Training Loss = 0.2854, Accuracy = 0.8901, Test Loss = 0.3087, Test Accuracy = 0.8600\n",
            "Processing timestep: 0.84\n",
            "Timestep 84.00% : Training Loss = 0.2914, Accuracy = 0.9049, Test Loss = 0.2418, Test Accuracy = 0.8824\n",
            "Processing timestep: 0.845\n",
            "Timestep 84.50% : Training Loss = 0.2988, Accuracy = 0.9046, Test Loss = 0.3670, Test Accuracy = 0.8600\n",
            "Processing timestep: 0.85\n",
            "Timestep 85.00% : Training Loss = 0.2818, Accuracy = 0.8915, Test Loss = 0.2808, Test Accuracy = 0.9057\n",
            "Processing timestep: 0.855\n",
            "Timestep 85.50% : Training Loss = 0.2643, Accuracy = 0.9094, Test Loss = 0.2656, Test Accuracy = 0.8723\n",
            "Processing timestep: 0.86\n",
            "Timestep 86.00% : Training Loss = 0.2410, Accuracy = 0.9278, Test Loss = 0.3014, Test Accuracy = 0.8200\n",
            "Processing timestep: 0.865\n",
            "Timestep 86.50% : Training Loss = 0.2599, Accuracy = 0.8980, Test Loss = 0.2604, Test Accuracy = 0.8679\n",
            "Processing timestep: 0.87\n",
            "Timestep 87.00% : Training Loss = 0.2874, Accuracy = 0.8906, Test Loss = 0.2082, Test Accuracy = 0.9362\n",
            "Processing timestep: 0.875\n",
            "Timestep 87.50% : Training Loss = 0.2602, Accuracy = 0.9167, Test Loss = 0.2947, Test Accuracy = 0.8679\n",
            "Processing timestep: 0.88\n",
            "Timestep 88.00% : Training Loss = 0.2742, Accuracy = 0.9029, Test Loss = 0.2927, Test Accuracy = 0.8600\n",
            "Processing timestep: 0.885\n",
            "Timestep 88.50% : Training Loss = 0.2633, Accuracy = 0.8962, Test Loss = 0.2442, Test Accuracy = 0.9020\n",
            "Processing timestep: 0.89\n",
            "Timestep 89.00% : Training Loss = 0.2605, Accuracy = 0.9015, Test Loss = 0.2198, Test Accuracy = 0.8980\n",
            "Processing timestep: 0.895\n",
            "Timestep 89.50% : Training Loss = 0.2445, Accuracy = 0.8986, Test Loss = 0.2172, Test Accuracy = 0.9216\n",
            "Processing timestep: 0.9\n",
            "Timestep 90.00% : Training Loss = 0.3175, Accuracy = 0.8772, Test Loss = 0.1909, Test Accuracy = 0.9412\n",
            "Processing timestep: 0.905\n",
            "Timestep 90.50% : Training Loss = 0.2656, Accuracy = 0.9170, Test Loss = 0.1846, Test Accuracy = 0.9231\n",
            "Processing timestep: 0.91\n",
            "Timestep 91.00% : Training Loss = 0.2429, Accuracy = 0.9205, Test Loss = 0.2859, Test Accuracy = 0.9074\n",
            "Processing timestep: 0.915\n",
            "Timestep 91.50% : Training Loss = 0.2447, Accuracy = 0.9191, Test Loss = 0.3276, Test Accuracy = 0.8776\n",
            "Processing timestep: 0.92\n",
            "Timestep 92.00% : Training Loss = 0.2377, Accuracy = 0.9293, Test Loss = 0.2449, Test Accuracy = 0.9091\n",
            "Processing timestep: 0.925\n",
            "Timestep 92.50% : Training Loss = 0.2526, Accuracy = 0.8995, Test Loss = 0.2453, Test Accuracy = 0.9231\n",
            "Processing timestep: 0.93\n",
            "Timestep 93.00% : Training Loss = 0.2048, Accuracy = 0.9354, Test Loss = 0.3362, Test Accuracy = 0.8448\n",
            "Processing timestep: 0.935\n",
            "Timestep 93.50% : Training Loss = 0.1977, Accuracy = 0.9519, Test Loss = 0.2565, Test Accuracy = 0.8750\n",
            "Processing timestep: 0.94\n",
            "Timestep 94.00% : Training Loss = 0.2178, Accuracy = 0.9198, Test Loss = 0.1639, Test Accuracy = 0.9091\n",
            "Processing timestep: 0.945\n",
            "Timestep 94.50% : Training Loss = 0.2328, Accuracy = 0.9133, Test Loss = 0.1803, Test Accuracy = 0.9545\n",
            "Processing timestep: 0.95\n",
            "Timestep 95.00% : Training Loss = 0.2191, Accuracy = 0.9348, Test Loss = 0.2471, Test Accuracy = 0.8769\n",
            "Processing timestep: 0.955\n",
            "Timestep 95.50% : Training Loss = 0.2377, Accuracy = 0.9265, Test Loss = 0.1377, Test Accuracy = 0.9500\n",
            "Processing timestep: 0.96\n",
            "Timestep 96.00% : Training Loss = 0.2018, Accuracy = 0.9284, Test Loss = 0.2517, Test Accuracy = 0.9200\n",
            "Processing timestep: 0.965\n",
            "Timestep 96.50% : Training Loss = 0.2430, Accuracy = 0.8870, Test Loss = 0.2560, Test Accuracy = 0.9016\n",
            "Processing timestep: 0.97\n",
            "Timestep 97.00% : Training Loss = 0.2192, Accuracy = 0.9151, Test Loss = 0.2652, Test Accuracy = 0.8750\n",
            "Processing timestep: 0.975\n",
            "Timestep 97.50% : Training Loss = 0.2239, Accuracy = 0.9301, Test Loss = 0.5594, Test Accuracy = 0.8305\n",
            "Processing timestep: 0.98\n",
            "Timestep 98.00% : Training Loss = 0.2069, Accuracy = 0.9382, Test Loss = 0.1644, Test Accuracy = 0.9733\n",
            "Processing timestep: 0.985\n",
            "Timestep 98.50% : Training Loss = 0.1990, Accuracy = 0.9386, Test Loss = 0.3894, Test Accuracy = 0.8286\n",
            "Processing timestep: 0.99\n",
            "Timestep 99.00% : Training Loss = 0.2324, Accuracy = 0.9188, Test Loss = 0.3411, Test Accuracy = 0.8529\n",
            "Processing timestep: 0.995\n",
            "Timestep 99.50% : Training Loss = 0.2365, Accuracy = 0.9177, Test Loss = 0.2314, Test Accuracy = 0.9315\n",
            "Processing timestep: 1.0\n",
            "Timestep 100.00% : Training Loss = 0.2247, Accuracy = 0.9386, Test Loss = 0.2441, Test Accuracy = 0.8974\n"
          ]
        }
      ],
      "source": [
        "other_features = [\n",
        "            \"type.id\",             # Play type (categorical)\n",
        "            \"home_has_possession\", # Binary indicator\n",
        "            \"end.down\",            # Down number (1-4, discrete)\n",
        "            \"home_timeouts_left\",  # Discrete count (0-3)\n",
        "            \"away_timeouts_left\",  # Discrete count (0-3)\n",
        "        ]\n",
        "numeric_features = [\n",
        "    \"score_difference\",\n",
        "    \"relative_strength\", \n",
        "    \"end.yardsToEndzone\", \n",
        "    \"end.distance\", \n",
        "    \"field_position_shift\"\n",
        "]\n",
        "all_models[\"logistic\"] = setup_logistic_regression_models(training_data, None, numeric_features, other_features, features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestep 0.00%(Calibrated): Training Loss = 0.3277, Accuracy = 0.6723, Validation Loss = 0.1846, Validation Accuracy = 0.7333\n",
            "Timestep 0.50%(Calibrated): Training Loss = 0.3333, Accuracy = 0.6667, Validation Loss = 0.2039, Validation Accuracy = 0.7111\n",
            "Timestep 1.00%(Calibrated): Training Loss = 0.3644, Accuracy = 0.6356, Validation Loss = 0.2269, Validation Accuracy = 0.6400\n",
            "Timestep 1.50%(Calibrated): Training Loss = 0.3619, Accuracy = 0.6381, Validation Loss = 0.2282, Validation Accuracy = 0.6143\n",
            "Timestep 2.00%(Calibrated): Training Loss = 0.3955, Accuracy = 0.6045, Validation Loss = 0.2119, Validation Accuracy = 0.6622\n",
            "Timestep 2.50%(Calibrated): Training Loss = 0.3862, Accuracy = 0.6138, Validation Loss = 0.1661, Validation Accuracy = 0.7439\n",
            "Timestep 3.00%(Calibrated): Training Loss = 0.3255, Accuracy = 0.6745, Validation Loss = 0.2205, Validation Accuracy = 0.6338\n",
            "Timestep 3.50%(Calibrated): Training Loss = 0.3508, Accuracy = 0.6492, Validation Loss = 0.1921, Validation Accuracy = 0.6506\n",
            "Timestep 4.00%(Calibrated): Training Loss = 0.3390, Accuracy = 0.6610, Validation Loss = 0.2181, Validation Accuracy = 0.6709\n",
            "Timestep 4.50%(Calibrated): Training Loss = 0.3840, Accuracy = 0.6160, Validation Loss = 0.1628, Validation Accuracy = 0.7595\n",
            "Timestep 5.00%(Calibrated): Training Loss = 0.3663, Accuracy = 0.6337, Validation Loss = 0.2046, Validation Accuracy = 0.6829\n",
            "Timestep 5.50%(Calibrated): Training Loss = 0.3691, Accuracy = 0.6309, Validation Loss = 0.2166, Validation Accuracy = 0.6410\n",
            "Timestep 6.00%(Calibrated): Training Loss = 0.3443, Accuracy = 0.6557, Validation Loss = 0.1888, Validation Accuracy = 0.6951\n",
            "Timestep 6.50%(Calibrated): Training Loss = 0.3625, Accuracy = 0.6375, Validation Loss = 0.1782, Validation Accuracy = 0.7160\n",
            "Timestep 7.00%(Calibrated): Training Loss = 0.3411, Accuracy = 0.6589, Validation Loss = 0.2012, Validation Accuracy = 0.6395\n",
            "Timestep 7.50%(Calibrated): Training Loss = 0.3708, Accuracy = 0.6292, Validation Loss = 0.2119, Validation Accuracy = 0.6790\n",
            "Timestep 8.00%(Calibrated): Training Loss = 0.3729, Accuracy = 0.6271, Validation Loss = 0.2098, Validation Accuracy = 0.6835\n",
            "Timestep 8.50%(Calibrated): Training Loss = 0.4064, Accuracy = 0.5936, Validation Loss = 0.2283, Validation Accuracy = 0.6190\n",
            "Timestep 9.00%(Calibrated): Training Loss = 0.3377, Accuracy = 0.6623, Validation Loss = 0.1903, Validation Accuracy = 0.7143\n",
            "Timestep 9.50%(Calibrated): Training Loss = 0.3320, Accuracy = 0.6680, Validation Loss = 0.1872, Validation Accuracy = 0.6941\n",
            "Timestep 10.00%(Calibrated): Training Loss = 0.3761, Accuracy = 0.6239, Validation Loss = 0.2077, Validation Accuracy = 0.6579\n",
            "Timestep 10.50%(Calibrated): Training Loss = 0.3974, Accuracy = 0.6026, Validation Loss = 0.2105, Validation Accuracy = 0.6962\n",
            "Timestep 11.00%(Calibrated): Training Loss = 0.3651, Accuracy = 0.6349, Validation Loss = 0.2172, Validation Accuracy = 0.6235\n",
            "Timestep 11.50%(Calibrated): Training Loss = 0.3647, Accuracy = 0.6353, Validation Loss = 0.2029, Validation Accuracy = 0.6744\n",
            "Timestep 12.00%(Calibrated): Training Loss = 0.3761, Accuracy = 0.6239, Validation Loss = 0.2082, Validation Accuracy = 0.6582\n",
            "Timestep 12.50%(Calibrated): Training Loss = 0.3536, Accuracy = 0.6464, Validation Loss = 0.1680, Validation Accuracy = 0.7273\n",
            "Timestep 13.00%(Calibrated): Training Loss = 0.3205, Accuracy = 0.6795, Validation Loss = 0.2153, Validation Accuracy = 0.6456\n",
            "Timestep 13.50%(Calibrated): Training Loss = 0.3291, Accuracy = 0.6709, Validation Loss = 0.1839, Validation Accuracy = 0.7051\n",
            "Timestep 14.00%(Calibrated): Training Loss = 0.3675, Accuracy = 0.6325, Validation Loss = 0.1642, Validation Accuracy = 0.7436\n",
            "Timestep 14.50%(Calibrated): Training Loss = 0.3565, Accuracy = 0.6435, Validation Loss = 0.2188, Validation Accuracy = 0.6234\n",
            "Timestep 15.00%(Calibrated): Training Loss = 0.3643, Accuracy = 0.6357, Validation Loss = 0.1982, Validation Accuracy = 0.6889\n",
            "Timestep 15.50%(Calibrated): Training Loss = 0.3067, Accuracy = 0.6933, Validation Loss = 0.1846, Validation Accuracy = 0.6974\n",
            "Timestep 16.00%(Calibrated): Training Loss = 0.3407, Accuracy = 0.6593, Validation Loss = 0.1983, Validation Accuracy = 0.6923\n",
            "Timestep 16.50%(Calibrated): Training Loss = 0.3379, Accuracy = 0.6621, Validation Loss = 0.1842, Validation Accuracy = 0.6986\n",
            "Timestep 17.00%(Calibrated): Training Loss = 0.3074, Accuracy = 0.6926, Validation Loss = 0.1807, Validation Accuracy = 0.6883\n",
            "Timestep 17.50%(Calibrated): Training Loss = 0.3062, Accuracy = 0.6938, Validation Loss = 0.1882, Validation Accuracy = 0.7126\n",
            "Timestep 18.00%(Calibrated): Training Loss = 0.2882, Accuracy = 0.7118, Validation Loss = 0.1786, Validation Accuracy = 0.7143\n",
            "Timestep 18.50%(Calibrated): Training Loss = 0.3608, Accuracy = 0.6392, Validation Loss = 0.1522, Validation Accuracy = 0.7529\n",
            "Timestep 19.00%(Calibrated): Training Loss = 0.3256, Accuracy = 0.6744, Validation Loss = 0.2094, Validation Accuracy = 0.6806\n",
            "Timestep 19.50%(Calibrated): Training Loss = 0.3187, Accuracy = 0.6813, Validation Loss = 0.1501, Validation Accuracy = 0.7826\n",
            "Timestep 20.00%(Calibrated): Training Loss = 0.3431, Accuracy = 0.6569, Validation Loss = 0.1868, Validation Accuracy = 0.6875\n",
            "Timestep 20.50%(Calibrated): Training Loss = 0.3086, Accuracy = 0.6914, Validation Loss = 0.1765, Validation Accuracy = 0.7407\n",
            "Timestep 21.00%(Calibrated): Training Loss = 0.3098, Accuracy = 0.6902, Validation Loss = 0.1739, Validation Accuracy = 0.7412\n",
            "Timestep 21.50%(Calibrated): Training Loss = 0.2675, Accuracy = 0.7325, Validation Loss = 0.1702, Validation Accuracy = 0.7273\n",
            "Timestep 22.00%(Calibrated): Training Loss = 0.3412, Accuracy = 0.6588, Validation Loss = 0.1950, Validation Accuracy = 0.6824\n",
            "Timestep 22.50%(Calibrated): Training Loss = 0.3033, Accuracy = 0.6967, Validation Loss = 0.1776, Validation Accuracy = 0.7439\n",
            "Timestep 23.00%(Calibrated): Training Loss = 0.3122, Accuracy = 0.6878, Validation Loss = 0.1505, Validation Accuracy = 0.7838\n",
            "Timestep 23.50%(Calibrated): Training Loss = 0.2996, Accuracy = 0.7004, Validation Loss = 0.1848, Validation Accuracy = 0.7108\n",
            "Timestep 24.00%(Calibrated): Training Loss = 0.3190, Accuracy = 0.6810, Validation Loss = 0.2030, Validation Accuracy = 0.6667\n",
            "Timestep 24.50%(Calibrated): Training Loss = 0.3458, Accuracy = 0.6542, Validation Loss = 0.1851, Validation Accuracy = 0.7083\n",
            "Completed 50/201 timesteps\n",
            "Timestep 25.00%(Calibrated): Training Loss = 0.2621, Accuracy = 0.7379, Validation Loss = 0.1943, Validation Accuracy = 0.6722\n",
            "Timestep 25.50%(Calibrated): Training Loss = 0.3485, Accuracy = 0.6515, Validation Loss = 0.1477, Validation Accuracy = 0.7500\n",
            "Timestep 26.00%(Calibrated): Training Loss = 0.2807, Accuracy = 0.7193, Validation Loss = 0.1855, Validation Accuracy = 0.7018\n",
            "Timestep 26.50%(Calibrated): Training Loss = 0.3071, Accuracy = 0.6929, Validation Loss = 0.1639, Validation Accuracy = 0.7765\n",
            "Timestep 27.00%(Calibrated): Training Loss = 0.2707, Accuracy = 0.7293, Validation Loss = 0.1596, Validation Accuracy = 0.7532\n",
            "Timestep 27.50%(Calibrated): Training Loss = 0.2996, Accuracy = 0.7004, Validation Loss = 0.1991, Validation Accuracy = 0.6778\n",
            "Timestep 28.00%(Calibrated): Training Loss = 0.2669, Accuracy = 0.7331, Validation Loss = 0.1352, Validation Accuracy = 0.7975\n",
            "Timestep 28.50%(Calibrated): Training Loss = 0.4219, Accuracy = 0.5781, Validation Loss = 0.1946, Validation Accuracy = 0.6628\n",
            "Timestep 29.00%(Calibrated): Training Loss = 0.2834, Accuracy = 0.7166, Validation Loss = 0.1618, Validation Accuracy = 0.7590\n",
            "Timestep 29.50%(Calibrated): Training Loss = 0.2738, Accuracy = 0.7262, Validation Loss = 0.1393, Validation Accuracy = 0.8118\n",
            "Timestep 30.00%(Calibrated): Training Loss = 0.3026, Accuracy = 0.6974, Validation Loss = 0.1888, Validation Accuracy = 0.6711\n",
            "Timestep 30.50%(Calibrated): Training Loss = 0.2658, Accuracy = 0.7342, Validation Loss = 0.1718, Validation Accuracy = 0.7333\n",
            "Timestep 31.00%(Calibrated): Training Loss = 0.2814, Accuracy = 0.7186, Validation Loss = 0.1865, Validation Accuracy = 0.7051\n",
            "Timestep 31.50%(Calibrated): Training Loss = 0.3245, Accuracy = 0.6755, Validation Loss = 0.1816, Validation Accuracy = 0.7191\n",
            "Timestep 32.00%(Calibrated): Training Loss = 0.3092, Accuracy = 0.6908, Validation Loss = 0.1338, Validation Accuracy = 0.8072\n",
            "Timestep 32.50%(Calibrated): Training Loss = 0.2683, Accuracy = 0.7317, Validation Loss = 0.1347, Validation Accuracy = 0.8293\n",
            "Timestep 33.00%(Calibrated): Training Loss = 0.2479, Accuracy = 0.7521, Validation Loss = 0.1502, Validation Accuracy = 0.7778\n",
            "Timestep 33.50%(Calibrated): Training Loss = 0.2800, Accuracy = 0.7200, Validation Loss = 0.1529, Validation Accuracy = 0.7619\n",
            "Timestep 34.00%(Calibrated): Training Loss = 0.2759, Accuracy = 0.7241, Validation Loss = 0.1628, Validation Accuracy = 0.7692\n",
            "Timestep 34.50%(Calibrated): Training Loss = 0.2614, Accuracy = 0.7386, Validation Loss = 0.1603, Validation Accuracy = 0.7654\n",
            "Timestep 35.00%(Calibrated): Training Loss = 0.2694, Accuracy = 0.7306, Validation Loss = 0.1504, Validation Accuracy = 0.7683\n",
            "Timestep 35.50%(Calibrated): Training Loss = 0.2710, Accuracy = 0.7290, Validation Loss = 0.1166, Validation Accuracy = 0.8409\n",
            "Timestep 36.00%(Calibrated): Training Loss = 0.2490, Accuracy = 0.7510, Validation Loss = 0.1427, Validation Accuracy = 0.7805\n",
            "Timestep 36.50%(Calibrated): Training Loss = 0.2060, Accuracy = 0.7940, Validation Loss = 0.1533, Validation Accuracy = 0.7333\n",
            "Timestep 37.00%(Calibrated): Training Loss = 0.2335, Accuracy = 0.7665, Validation Loss = 0.1435, Validation Accuracy = 0.7895\n",
            "Timestep 37.50%(Calibrated): Training Loss = 0.2510, Accuracy = 0.7490, Validation Loss = 0.1641, Validation Accuracy = 0.7558\n",
            "Timestep 38.00%(Calibrated): Training Loss = 0.3067, Accuracy = 0.6933, Validation Loss = 0.1595, Validation Accuracy = 0.7875\n",
            "Timestep 38.50%(Calibrated): Training Loss = 0.3022, Accuracy = 0.6978, Validation Loss = 0.1216, Validation Accuracy = 0.8400\n",
            "Timestep 39.00%(Calibrated): Training Loss = 0.2857, Accuracy = 0.7143, Validation Loss = 0.1384, Validation Accuracy = 0.7927\n",
            "Timestep 39.50%(Calibrated): Training Loss = 0.2677, Accuracy = 0.7323, Validation Loss = 0.1553, Validation Accuracy = 0.7529\n",
            "Timestep 40.00%(Calibrated): Training Loss = 0.2116, Accuracy = 0.7884, Validation Loss = 0.1602, Validation Accuracy = 0.7531\n",
            "Timestep 40.50%(Calibrated): Training Loss = 0.2711, Accuracy = 0.7289, Validation Loss = 0.1405, Validation Accuracy = 0.8158\n",
            "Timestep 41.00%(Calibrated): Training Loss = 0.2159, Accuracy = 0.7841, Validation Loss = 0.1548, Validation Accuracy = 0.7416\n",
            "Timestep 41.50%(Calibrated): Training Loss = 0.3151, Accuracy = 0.6849, Validation Loss = 0.1519, Validation Accuracy = 0.7808\n",
            "Timestep 42.00%(Calibrated): Training Loss = 0.2757, Accuracy = 0.7243, Validation Loss = 0.1334, Validation Accuracy = 0.8025\n",
            "Timestep 42.50%(Calibrated): Training Loss = 0.1925, Accuracy = 0.8075, Validation Loss = 0.1567, Validation Accuracy = 0.7500\n",
            "Timestep 43.00%(Calibrated): Training Loss = 0.2430, Accuracy = 0.7570, Validation Loss = 0.1087, Validation Accuracy = 0.8690\n",
            "Timestep 43.50%(Calibrated): Training Loss = 0.2590, Accuracy = 0.7410, Validation Loss = 0.1908, Validation Accuracy = 0.7143\n",
            "Timestep 44.00%(Calibrated): Training Loss = 0.3122, Accuracy = 0.6878, Validation Loss = 0.1362, Validation Accuracy = 0.7722\n",
            "Timestep 44.50%(Calibrated): Training Loss = 0.3422, Accuracy = 0.6578, Validation Loss = 0.1226, Validation Accuracy = 0.8295\n",
            "Timestep 45.00%(Calibrated): Training Loss = 0.2845, Accuracy = 0.7155, Validation Loss = 0.1606, Validation Accuracy = 0.7750\n",
            "Timestep 45.50%(Calibrated): Training Loss = 0.2109, Accuracy = 0.7891, Validation Loss = 0.1386, Validation Accuracy = 0.7674\n",
            "Timestep 46.00%(Calibrated): Training Loss = 0.2715, Accuracy = 0.7285, Validation Loss = 0.1575, Validation Accuracy = 0.7703\n",
            "Timestep 46.50%(Calibrated): Training Loss = 0.2929, Accuracy = 0.7071, Validation Loss = 0.1489, Validation Accuracy = 0.8000\n",
            "Timestep 47.00%(Calibrated): Training Loss = 0.2076, Accuracy = 0.7924, Validation Loss = 0.1492, Validation Accuracy = 0.7689\n",
            "Timestep 47.50%(Calibrated): Training Loss = 0.2158, Accuracy = 0.7842, Validation Loss = 0.1494, Validation Accuracy = 0.7642\n",
            "Timestep 48.00%(Calibrated): Training Loss = 0.1791, Accuracy = 0.8209, Validation Loss = 0.1243, Validation Accuracy = 0.8443\n",
            "Timestep 48.50%(Calibrated): Training Loss = 0.2168, Accuracy = 0.7832, Validation Loss = 0.1568, Validation Accuracy = 0.7708\n",
            "Timestep 49.00%(Calibrated): Training Loss = 0.1842, Accuracy = 0.8158, Validation Loss = 0.1564, Validation Accuracy = 0.7636\n",
            "Timestep 49.50%(Calibrated): Training Loss = 0.1518, Accuracy = 0.8482, Validation Loss = 0.1686, Validation Accuracy = 0.7679\n",
            "Completed 100/201 timesteps\n",
            "Timestep 50.00%(Calibrated): Training Loss = 0.1840, Accuracy = 0.8160, Validation Loss = 0.1570, Validation Accuracy = 0.7766\n",
            "Timestep 50.50%(Calibrated): Training Loss = 0.1837, Accuracy = 0.8163, Validation Loss = 0.1128, Validation Accuracy = 0.8600\n",
            "Timestep 51.00%(Calibrated): Training Loss = 0.2089, Accuracy = 0.7911, Validation Loss = 0.1447, Validation Accuracy = 0.8026\n",
            "Timestep 51.50%(Calibrated): Training Loss = 0.1777, Accuracy = 0.8223, Validation Loss = 0.1316, Validation Accuracy = 0.8030\n",
            "Timestep 52.00%(Calibrated): Training Loss = 0.1861, Accuracy = 0.8139, Validation Loss = 0.1533, Validation Accuracy = 0.7792\n",
            "Timestep 52.50%(Calibrated): Training Loss = 0.1667, Accuracy = 0.8333, Validation Loss = 0.1324, Validation Accuracy = 0.7821\n",
            "Timestep 53.00%(Calibrated): Training Loss = 0.2152, Accuracy = 0.7848, Validation Loss = 0.1749, Validation Accuracy = 0.7467\n",
            "Timestep 53.50%(Calibrated): Training Loss = 0.1943, Accuracy = 0.8057, Validation Loss = 0.1464, Validation Accuracy = 0.8072\n",
            "Timestep 54.00%(Calibrated): Training Loss = 0.2650, Accuracy = 0.7350, Validation Loss = 0.1238, Validation Accuracy = 0.8101\n",
            "Timestep 54.50%(Calibrated): Training Loss = 0.1897, Accuracy = 0.8103, Validation Loss = 0.1546, Validation Accuracy = 0.7692\n",
            "Timestep 55.00%(Calibrated): Training Loss = 0.1603, Accuracy = 0.8397, Validation Loss = 0.1614, Validation Accuracy = 0.7722\n",
            "Timestep 55.50%(Calibrated): Training Loss = 0.1917, Accuracy = 0.8083, Validation Loss = 0.1688, Validation Accuracy = 0.7778\n",
            "Timestep 56.00%(Calibrated): Training Loss = 0.1614, Accuracy = 0.8386, Validation Loss = 0.1683, Validation Accuracy = 0.7333\n",
            "Timestep 56.50%(Calibrated): Training Loss = 0.1804, Accuracy = 0.8196, Validation Loss = 0.1338, Validation Accuracy = 0.8118\n",
            "Timestep 57.00%(Calibrated): Training Loss = 0.1805, Accuracy = 0.8195, Validation Loss = 0.1480, Validation Accuracy = 0.7978\n",
            "Timestep 57.50%(Calibrated): Training Loss = 0.2137, Accuracy = 0.7863, Validation Loss = 0.1656, Validation Accuracy = 0.7308\n",
            "Timestep 58.00%(Calibrated): Training Loss = 0.1839, Accuracy = 0.8161, Validation Loss = 0.1147, Validation Accuracy = 0.8267\n",
            "Timestep 58.50%(Calibrated): Training Loss = 0.1897, Accuracy = 0.8103, Validation Loss = 0.1568, Validation Accuracy = 0.7949\n",
            "Timestep 59.00%(Calibrated): Training Loss = 0.1811, Accuracy = 0.8189, Validation Loss = 0.1243, Validation Accuracy = 0.8293\n",
            "Timestep 59.50%(Calibrated): Training Loss = 0.1942, Accuracy = 0.8058, Validation Loss = 0.1245, Validation Accuracy = 0.8065\n",
            "Timestep 60.00%(Calibrated): Training Loss = 0.1695, Accuracy = 0.8305, Validation Loss = 0.1401, Validation Accuracy = 0.7848\n",
            "Timestep 60.50%(Calibrated): Training Loss = 0.1769, Accuracy = 0.8231, Validation Loss = 0.0789, Validation Accuracy = 0.8736\n",
            "Timestep 61.00%(Calibrated): Training Loss = 0.2278, Accuracy = 0.7722, Validation Loss = 0.1781, Validation Accuracy = 0.7125\n",
            "Timestep 61.50%(Calibrated): Training Loss = 0.1942, Accuracy = 0.8058, Validation Loss = 0.1037, Validation Accuracy = 0.8642\n",
            "Timestep 62.00%(Calibrated): Training Loss = 0.1240, Accuracy = 0.8760, Validation Loss = 0.1798, Validation Accuracy = 0.7326\n",
            "Timestep 62.50%(Calibrated): Training Loss = 0.1940, Accuracy = 0.8060, Validation Loss = 0.0872, Validation Accuracy = 0.8718\n",
            "Timestep 63.00%(Calibrated): Training Loss = 0.1686, Accuracy = 0.8314, Validation Loss = 0.1290, Validation Accuracy = 0.8256\n",
            "Timestep 63.50%(Calibrated): Training Loss = 0.1565, Accuracy = 0.8435, Validation Loss = 0.1385, Validation Accuracy = 0.8182\n",
            "Timestep 64.00%(Calibrated): Training Loss = 0.1585, Accuracy = 0.8415, Validation Loss = 0.1429, Validation Accuracy = 0.7711\n",
            "Timestep 64.50%(Calibrated): Training Loss = 0.1679, Accuracy = 0.8321, Validation Loss = 0.1438, Validation Accuracy = 0.7955\n",
            "Timestep 65.00%(Calibrated): Training Loss = 0.1296, Accuracy = 0.8704, Validation Loss = 0.1069, Validation Accuracy = 0.8554\n",
            "Timestep 65.50%(Calibrated): Training Loss = 0.1473, Accuracy = 0.8527, Validation Loss = 0.1468, Validation Accuracy = 0.7907\n",
            "Timestep 66.00%(Calibrated): Training Loss = 0.1545, Accuracy = 0.8455, Validation Loss = 0.1063, Validation Accuracy = 0.8659\n",
            "Timestep 66.50%(Calibrated): Training Loss = 0.1368, Accuracy = 0.8632, Validation Loss = 0.1371, Validation Accuracy = 0.7949\n",
            "Timestep 67.00%(Calibrated): Training Loss = 0.1451, Accuracy = 0.8549, Validation Loss = 0.1178, Validation Accuracy = 0.8372\n",
            "Timestep 67.50%(Calibrated): Training Loss = 0.1767, Accuracy = 0.8233, Validation Loss = 0.1321, Validation Accuracy = 0.8077\n",
            "Timestep 68.00%(Calibrated): Training Loss = 0.1726, Accuracy = 0.8274, Validation Loss = 0.1391, Validation Accuracy = 0.8026\n",
            "Timestep 68.50%(Calibrated): Training Loss = 0.1231, Accuracy = 0.8769, Validation Loss = 0.1204, Validation Accuracy = 0.8161\n",
            "Timestep 69.00%(Calibrated): Training Loss = 0.1250, Accuracy = 0.8750, Validation Loss = 0.1186, Validation Accuracy = 0.8372\n",
            "Timestep 69.50%(Calibrated): Training Loss = 0.1345, Accuracy = 0.8655, Validation Loss = 0.1202, Validation Accuracy = 0.8375\n",
            "Timestep 70.00%(Calibrated): Training Loss = 0.1435, Accuracy = 0.8565, Validation Loss = 0.1115, Validation Accuracy = 0.8500\n",
            "Timestep 70.50%(Calibrated): Training Loss = 0.1339, Accuracy = 0.8661, Validation Loss = 0.1284, Validation Accuracy = 0.8375\n",
            "Timestep 71.00%(Calibrated): Training Loss = 0.1617, Accuracy = 0.8383, Validation Loss = 0.0966, Validation Accuracy = 0.8734\n",
            "Timestep 71.50%(Calibrated): Training Loss = 0.1255, Accuracy = 0.8745, Validation Loss = 0.1487, Validation Accuracy = 0.7791\n",
            "Timestep 72.00%(Calibrated): Training Loss = 0.1598, Accuracy = 0.8402, Validation Loss = 0.0792, Validation Accuracy = 0.9024\n",
            "Timestep 72.50%(Calibrated): Training Loss = 0.1382, Accuracy = 0.8618, Validation Loss = 0.0722, Validation Accuracy = 0.9146\n",
            "Timestep 73.00%(Calibrated): Training Loss = 0.1541, Accuracy = 0.8459, Validation Loss = 0.1420, Validation Accuracy = 0.8090\n",
            "Timestep 73.50%(Calibrated): Training Loss = 0.1336, Accuracy = 0.8664, Validation Loss = 0.1141, Validation Accuracy = 0.8554\n",
            "Timestep 74.00%(Calibrated): Training Loss = 0.1256, Accuracy = 0.8744, Validation Loss = 0.1231, Validation Accuracy = 0.8400\n",
            "Timestep 74.50%(Calibrated): Training Loss = 0.1627, Accuracy = 0.8373, Validation Loss = 0.1094, Validation Accuracy = 0.8571\n",
            "Completed 150/201 timesteps\n",
            "Timestep 75.00%(Calibrated): Training Loss = 0.1216, Accuracy = 0.8784, Validation Loss = 0.1180, Validation Accuracy = 0.8502\n",
            "Timestep 75.50%(Calibrated): Training Loss = 0.1938, Accuracy = 0.8062, Validation Loss = 0.0411, Validation Accuracy = 0.9545\n",
            "Timestep 76.00%(Calibrated): Training Loss = 0.1371, Accuracy = 0.8629, Validation Loss = 0.0917, Validation Accuracy = 0.8939\n",
            "Timestep 76.50%(Calibrated): Training Loss = 0.1255, Accuracy = 0.8745, Validation Loss = 0.1143, Validation Accuracy = 0.8500\n",
            "Timestep 77.00%(Calibrated): Training Loss = 0.1212, Accuracy = 0.8788, Validation Loss = 0.1096, Validation Accuracy = 0.8701\n",
            "Timestep 77.50%(Calibrated): Training Loss = 0.1255, Accuracy = 0.8745, Validation Loss = 0.1125, Validation Accuracy = 0.8372\n",
            "Timestep 78.00%(Calibrated): Training Loss = 0.1515, Accuracy = 0.8485, Validation Loss = 0.0560, Validation Accuracy = 0.9231\n",
            "Timestep 78.50%(Calibrated): Training Loss = 0.1947, Accuracy = 0.8053, Validation Loss = 0.1032, Validation Accuracy = 0.8636\n",
            "Timestep 79.00%(Calibrated): Training Loss = 0.0940, Accuracy = 0.9060, Validation Loss = 0.1041, Validation Accuracy = 0.8608\n",
            "Timestep 79.50%(Calibrated): Training Loss = 0.1532, Accuracy = 0.8468, Validation Loss = 0.1396, Validation Accuracy = 0.8101\n",
            "Timestep 80.00%(Calibrated): Training Loss = 0.1188, Accuracy = 0.8812, Validation Loss = 0.1001, Validation Accuracy = 0.8750\n",
            "Timestep 80.50%(Calibrated): Training Loss = 0.1084, Accuracy = 0.8916, Validation Loss = 0.0738, Validation Accuracy = 0.8929\n",
            "Timestep 81.00%(Calibrated): Training Loss = 0.1102, Accuracy = 0.8898, Validation Loss = 0.1503, Validation Accuracy = 0.7927\n",
            "Timestep 81.50%(Calibrated): Training Loss = 0.0969, Accuracy = 0.9031, Validation Loss = 0.0945, Validation Accuracy = 0.8837\n",
            "Timestep 82.00%(Calibrated): Training Loss = 0.1039, Accuracy = 0.8961, Validation Loss = 0.0685, Validation Accuracy = 0.9140\n",
            "Timestep 82.50%(Calibrated): Training Loss = 0.0875, Accuracy = 0.9125, Validation Loss = 0.1076, Validation Accuracy = 0.8642\n",
            "Timestep 83.00%(Calibrated): Training Loss = 0.1120, Accuracy = 0.8880, Validation Loss = 0.1192, Validation Accuracy = 0.8519\n",
            "Timestep 83.50%(Calibrated): Training Loss = 0.1044, Accuracy = 0.8956, Validation Loss = 0.0853, Validation Accuracy = 0.8916\n",
            "Timestep 84.00%(Calibrated): Training Loss = 0.1155, Accuracy = 0.8845, Validation Loss = 0.0800, Validation Accuracy = 0.9048\n",
            "Timestep 84.50%(Calibrated): Training Loss = 0.1606, Accuracy = 0.8394, Validation Loss = 0.0858, Validation Accuracy = 0.8810\n",
            "Timestep 85.00%(Calibrated): Training Loss = 0.1034, Accuracy = 0.8966, Validation Loss = 0.0908, Validation Accuracy = 0.8851\n",
            "Timestep 85.50%(Calibrated): Training Loss = 0.1154, Accuracy = 0.8846, Validation Loss = 0.0463, Validation Accuracy = 0.9487\n",
            "Timestep 86.00%(Calibrated): Training Loss = 0.0980, Accuracy = 0.9020, Validation Loss = 0.0837, Validation Accuracy = 0.8902\n",
            "Timestep 86.50%(Calibrated): Training Loss = 0.0923, Accuracy = 0.9077, Validation Loss = 0.0614, Validation Accuracy = 0.9310\n",
            "Timestep 87.00%(Calibrated): Training Loss = 0.1239, Accuracy = 0.8761, Validation Loss = 0.0559, Validation Accuracy = 0.9359\n",
            "Timestep 87.50%(Calibrated): Training Loss = 0.1023, Accuracy = 0.8977, Validation Loss = 0.0653, Validation Accuracy = 0.9213\n",
            "Timestep 88.00%(Calibrated): Training Loss = 0.1057, Accuracy = 0.8943, Validation Loss = 0.0737, Validation Accuracy = 0.9146\n",
            "Timestep 88.50%(Calibrated): Training Loss = 0.1137, Accuracy = 0.8863, Validation Loss = 0.0563, Validation Accuracy = 0.9294\n",
            "Timestep 89.00%(Calibrated): Training Loss = 0.0992, Accuracy = 0.9008, Validation Loss = 0.0589, Validation Accuracy = 0.9136\n",
            "Timestep 89.50%(Calibrated): Training Loss = 0.1071, Accuracy = 0.8929, Validation Loss = 0.0416, Validation Accuracy = 0.9529\n",
            "Timestep 90.00%(Calibrated): Training Loss = 0.1270, Accuracy = 0.8730, Validation Loss = 0.0758, Validation Accuracy = 0.8929\n",
            "Timestep 90.50%(Calibrated): Training Loss = 0.0863, Accuracy = 0.9137, Validation Loss = 0.0653, Validation Accuracy = 0.9186\n",
            "Timestep 91.00%(Calibrated): Training Loss = 0.1011, Accuracy = 0.8989, Validation Loss = 0.0580, Validation Accuracy = 0.9213\n",
            "Timestep 91.50%(Calibrated): Training Loss = 0.1125, Accuracy = 0.8875, Validation Loss = 0.0831, Validation Accuracy = 0.8889\n",
            "Timestep 92.00%(Calibrated): Training Loss = 0.1168, Accuracy = 0.8832, Validation Loss = 0.1133, Validation Accuracy = 0.8370\n",
            "Timestep 92.50%(Calibrated): Training Loss = 0.1049, Accuracy = 0.8951, Validation Loss = 0.0337, Validation Accuracy = 0.9633\n",
            "Timestep 93.00%(Calibrated): Training Loss = 0.0627, Accuracy = 0.9373, Validation Loss = 0.1046, Validation Accuracy = 0.8646\n",
            "Timestep 93.50%(Calibrated): Training Loss = 0.1051, Accuracy = 0.8949, Validation Loss = 0.0440, Validation Accuracy = 0.9457\n",
            "Timestep 94.00%(Calibrated): Training Loss = 0.0939, Accuracy = 0.9061, Validation Loss = 0.0443, Validation Accuracy = 0.9455\n",
            "Timestep 94.50%(Calibrated): Training Loss = 0.1196, Accuracy = 0.8804, Validation Loss = 0.0597, Validation Accuracy = 0.9174\n",
            "Timestep 95.00%(Calibrated): Training Loss = 0.0833, Accuracy = 0.9167, Validation Loss = 0.0529, Validation Accuracy = 0.9266\n",
            "Timestep 95.50%(Calibrated): Training Loss = 0.1067, Accuracy = 0.8933, Validation Loss = 0.0478, Validation Accuracy = 0.9400\n",
            "Timestep 96.00%(Calibrated): Training Loss = 0.0892, Accuracy = 0.9108, Validation Loss = 0.0601, Validation Accuracy = 0.9274\n",
            "Timestep 96.50%(Calibrated): Training Loss = 0.1053, Accuracy = 0.8947, Validation Loss = 0.0627, Validation Accuracy = 0.9118\n",
            "Timestep 97.00%(Calibrated): Training Loss = 0.0636, Accuracy = 0.9364, Validation Loss = 0.0639, Validation Accuracy = 0.9159\n",
            "Timestep 97.50%(Calibrated): Training Loss = 0.0859, Accuracy = 0.9141, Validation Loss = 0.0839, Validation Accuracy = 0.8969\n",
            "Timestep 98.00%(Calibrated): Training Loss = 0.0645, Accuracy = 0.9355, Validation Loss = 0.0353, Validation Accuracy = 0.9597\n",
            "Timestep 98.50%(Calibrated): Training Loss = 0.0783, Accuracy = 0.9217, Validation Loss = 0.0446, Validation Accuracy = 0.9483\n",
            "Timestep 99.00%(Calibrated): Training Loss = 0.0979, Accuracy = 0.9021, Validation Loss = 0.0751, Validation Accuracy = 0.9115\n",
            "Timestep 99.50%(Calibrated): Training Loss = 0.0934, Accuracy = 0.9066, Validation Loss = 0.0402, Validation Accuracy = 0.9344\n",
            "Completed 200/201 timesteps\n",
            "Timestep 100.00%(Calibrated): Training Loss = 0.1031, Accuracy = 0.8969, Validation Loss = 0.0373, Validation Accuracy = 0.9385\n",
            "Completed 201/201 timesteps\n"
          ]
        }
      ],
      "source": [
        "all_models[\"xgboost\"] = setup_xgboost_models(training_data, None, numeric_features, other_features, features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['lstm', 'nn', 'logistic', 'xgboost'])\n",
            "Generating predictions for timestep 0.0\n",
            "Generating predictions for timestep 0.005\n",
            "Generating predictions for timestep 0.01\n",
            "Generating predictions for timestep 0.015\n",
            "Generating predictions for timestep 0.02\n",
            "Generating predictions for timestep 0.025\n",
            "Generating predictions for timestep 0.03\n",
            "Generating predictions for timestep 0.035\n",
            "Generating predictions for timestep 0.04\n",
            "Generating predictions for timestep 0.045\n",
            "Generating predictions for timestep 0.05\n",
            "Generating predictions for timestep 0.055\n",
            "Generating predictions for timestep 0.06\n",
            "Generating predictions for timestep 0.065\n",
            "Generating predictions for timestep 0.07\n",
            "Generating predictions for timestep 0.075\n",
            "Generating predictions for timestep 0.08\n",
            "Generating predictions for timestep 0.085\n",
            "Generating predictions for timestep 0.09\n",
            "Generating predictions for timestep 0.095\n",
            "Generating predictions for timestep 0.1\n",
            "Generating predictions for timestep 0.105\n",
            "Generating predictions for timestep 0.11\n",
            "Generating predictions for timestep 0.115\n",
            "Generating predictions for timestep 0.12\n",
            "Generating predictions for timestep 0.125\n",
            "Generating predictions for timestep 0.13\n",
            "Generating predictions for timestep 0.135\n",
            "Generating predictions for timestep 0.14\n",
            "Generating predictions for timestep 0.145\n",
            "Generating predictions for timestep 0.15\n",
            "Generating predictions for timestep 0.155\n",
            "Generating predictions for timestep 0.16\n",
            "Generating predictions for timestep 0.165\n",
            "Generating predictions for timestep 0.17\n",
            "Generating predictions for timestep 0.175\n",
            "Generating predictions for timestep 0.18\n",
            "Generating predictions for timestep 0.185\n",
            "Generating predictions for timestep 0.19\n",
            "Generating predictions for timestep 0.195\n",
            "Generating predictions for timestep 0.2\n",
            "Generating predictions for timestep 0.205\n",
            "Generating predictions for timestep 0.21\n",
            "Generating predictions for timestep 0.215\n",
            "Generating predictions for timestep 0.22\n",
            "Generating predictions for timestep 0.225\n",
            "Generating predictions for timestep 0.23\n",
            "Generating predictions for timestep 0.235\n",
            "Generating predictions for timestep 0.24\n",
            "Generating predictions for timestep 0.245\n",
            "Generating predictions for timestep 0.25\n",
            "Generating predictions for timestep 0.255\n",
            "Generating predictions for timestep 0.26\n",
            "Generating predictions for timestep 0.265\n",
            "Generating predictions for timestep 0.27\n",
            "Generating predictions for timestep 0.275\n",
            "Generating predictions for timestep 0.28\n",
            "Generating predictions for timestep 0.285\n",
            "Generating predictions for timestep 0.29\n",
            "Generating predictions for timestep 0.295\n",
            "Generating predictions for timestep 0.3\n",
            "Generating predictions for timestep 0.305\n",
            "Generating predictions for timestep 0.31\n",
            "Generating predictions for timestep 0.315\n",
            "Generating predictions for timestep 0.32\n",
            "Generating predictions for timestep 0.325\n",
            "Generating predictions for timestep 0.33\n",
            "Generating predictions for timestep 0.335\n",
            "Generating predictions for timestep 0.34\n",
            "Generating predictions for timestep 0.345\n",
            "Generating predictions for timestep 0.35\n",
            "Generating predictions for timestep 0.355\n",
            "Generating predictions for timestep 0.36\n",
            "Generating predictions for timestep 0.365\n",
            "Generating predictions for timestep 0.37\n",
            "Generating predictions for timestep 0.375\n",
            "Generating predictions for timestep 0.38\n",
            "Generating predictions for timestep 0.385\n",
            "Generating predictions for timestep 0.39\n",
            "Generating predictions for timestep 0.395\n",
            "Generating predictions for timestep 0.4\n",
            "Generating predictions for timestep 0.405\n",
            "Generating predictions for timestep 0.41\n",
            "Generating predictions for timestep 0.415\n",
            "Generating predictions for timestep 0.42\n",
            "Generating predictions for timestep 0.425\n",
            "Generating predictions for timestep 0.43\n",
            "Generating predictions for timestep 0.435\n",
            "Generating predictions for timestep 0.44\n",
            "Generating predictions for timestep 0.445\n",
            "Generating predictions for timestep 0.45\n",
            "Generating predictions for timestep 0.455\n",
            "Generating predictions for timestep 0.46\n",
            "Generating predictions for timestep 0.465\n",
            "Generating predictions for timestep 0.47\n",
            "Generating predictions for timestep 0.475\n",
            "Generating predictions for timestep 0.48\n",
            "Generating predictions for timestep 0.485\n",
            "Generating predictions for timestep 0.49\n",
            "Generating predictions for timestep 0.495\n",
            "Generating predictions for timestep 0.5\n",
            "Generating predictions for timestep 0.505\n",
            "Generating predictions for timestep 0.51\n",
            "Generating predictions for timestep 0.515\n",
            "Generating predictions for timestep 0.52\n",
            "Generating predictions for timestep 0.525\n",
            "Generating predictions for timestep 0.53\n",
            "Generating predictions for timestep 0.535\n",
            "Generating predictions for timestep 0.54\n",
            "Generating predictions for timestep 0.545\n",
            "Generating predictions for timestep 0.55\n",
            "Generating predictions for timestep 0.555\n",
            "Generating predictions for timestep 0.56\n",
            "Generating predictions for timestep 0.565\n",
            "Generating predictions for timestep 0.57\n",
            "Generating predictions for timestep 0.575\n",
            "Generating predictions for timestep 0.58\n",
            "Generating predictions for timestep 0.585\n",
            "Generating predictions for timestep 0.59\n",
            "Generating predictions for timestep 0.595\n",
            "Generating predictions for timestep 0.6\n",
            "Generating predictions for timestep 0.605\n",
            "Generating predictions for timestep 0.61\n",
            "Generating predictions for timestep 0.615\n",
            "Generating predictions for timestep 0.62\n",
            "Generating predictions for timestep 0.625\n",
            "Generating predictions for timestep 0.63\n",
            "Generating predictions for timestep 0.635\n",
            "Generating predictions for timestep 0.64\n",
            "Generating predictions for timestep 0.645\n",
            "Generating predictions for timestep 0.65\n",
            "Generating predictions for timestep 0.655\n",
            "Generating predictions for timestep 0.66\n",
            "Generating predictions for timestep 0.665\n",
            "Generating predictions for timestep 0.67\n",
            "Generating predictions for timestep 0.675\n",
            "Generating predictions for timestep 0.68\n",
            "Generating predictions for timestep 0.685\n",
            "Generating predictions for timestep 0.69\n",
            "Generating predictions for timestep 0.695\n",
            "Generating predictions for timestep 0.7\n",
            "Generating predictions for timestep 0.705\n",
            "Generating predictions for timestep 0.71\n",
            "Generating predictions for timestep 0.715\n",
            "Generating predictions for timestep 0.72\n",
            "Generating predictions for timestep 0.725\n",
            "Generating predictions for timestep 0.73\n",
            "Generating predictions for timestep 0.735\n",
            "Generating predictions for timestep 0.74\n",
            "Generating predictions for timestep 0.745\n",
            "Generating predictions for timestep 0.75\n",
            "Generating predictions for timestep 0.755\n",
            "Generating predictions for timestep 0.76\n",
            "Generating predictions for timestep 0.765\n",
            "Generating predictions for timestep 0.77\n",
            "Generating predictions for timestep 0.775\n",
            "Generating predictions for timestep 0.78\n",
            "Generating predictions for timestep 0.785\n",
            "Generating predictions for timestep 0.79\n",
            "Generating predictions for timestep 0.795\n",
            "Generating predictions for timestep 0.8\n",
            "Generating predictions for timestep 0.805\n",
            "Generating predictions for timestep 0.81\n",
            "Generating predictions for timestep 0.815\n",
            "Generating predictions for timestep 0.82\n",
            "Generating predictions for timestep 0.825\n",
            "Generating predictions for timestep 0.83\n",
            "Generating predictions for timestep 0.835\n",
            "Generating predictions for timestep 0.84\n",
            "Generating predictions for timestep 0.845\n",
            "Generating predictions for timestep 0.85\n",
            "Generating predictions for timestep 0.855\n",
            "Generating predictions for timestep 0.86\n",
            "Generating predictions for timestep 0.865\n",
            "Generating predictions for timestep 0.87\n",
            "Generating predictions for timestep 0.875\n",
            "Generating predictions for timestep 0.88\n",
            "Generating predictions for timestep 0.885\n",
            "Generating predictions for timestep 0.89\n",
            "Generating predictions for timestep 0.895\n",
            "Generating predictions for timestep 0.9\n",
            "Generating predictions for timestep 0.905\n",
            "Generating predictions for timestep 0.91\n",
            "Generating predictions for timestep 0.915\n",
            "Generating predictions for timestep 0.92\n",
            "Generating predictions for timestep 0.925\n",
            "Generating predictions for timestep 0.93\n",
            "Generating predictions for timestep 0.935\n",
            "Generating predictions for timestep 0.94\n",
            "Generating predictions for timestep 0.945\n",
            "Generating predictions for timestep 0.95\n",
            "Generating predictions for timestep 0.955\n",
            "Generating predictions for timestep 0.96\n",
            "Generating predictions for timestep 0.965\n",
            "Generating predictions for timestep 0.97\n",
            "Generating predictions for timestep 0.975\n",
            "Generating predictions for timestep 0.98\n",
            "Generating predictions for timestep 0.985\n",
            "Generating predictions for timestep 0.99\n",
            "Generating predictions for timestep 0.995\n",
            "Generating predictions for timestep 1.0\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "print(all_models.keys())\n",
        "all_models_order = [\"xgboost\", \"nn\", \"logistic\", \"lstm\"] # Strict ordering of models\n",
        "def generate_ensemble_matrix(models, all_models_order, data_dict_seq):\n",
        "    \"\"\"Generate predictions from a specific model type on given data\"\"\"\n",
        "    predictions = {}\n",
        "    # predictions:\n",
        "        # timestep:\n",
        "            # \"predictions\": [model_1_predictions, model_2_predictions, ..., model_n_predictions, \n",
        "            # model_1_predictions_seq, model_2_predictions_seq, ..., model_n_predictions_seq],\n",
        "            # \"y_true\": y_true\n",
        "    for timestep in data_dict_seq:\n",
        "        print(f\"Generating predictions for timestep {timestep}\")\n",
        "        # For each entry, take the last array from the \"rows\" list and pair with its label\n",
        "        non_sequential_data_for_timestep = [{\"rows\": entry[\"rows\"][-1], \"label\": entry[\"label\"]} for entry in data_dict_seq[timestep]]\n",
        "        X = np.array([row[\"rows\"] for row in non_sequential_data_for_timestep])\n",
        "        y = np.array([row[\"label\"] for row in non_sequential_data_for_timestep])\n",
        "        X_seq = np.array([row[\"rows\"] for row in data_dict_seq[timestep]])\n",
        "        predictions[timestep] = {\"predictions\": [], \"y_true\": []}\n",
        "        for i in range(len(X)):\n",
        "            predictions[timestep][\"predictions\"].append(np.array([\n",
        "                models[model][timestep].predict_proba(np.expand_dims(X_seq[i], axis=0))[:, 1].item() if model == \"lstm\" else models[model][timestep].predict_proba(np.expand_dims(X[i], axis=0))[:, 1].item()\n",
        "                for model in all_models_order\n",
        "            ]))\n",
        "            predictions[timestep][\"y_true\"].append(y[i])\n",
        "        predictions[timestep][\"y_true\"] = np.array(predictions[timestep][\"y_true\"])\n",
        "        predictions[timestep][\"predictions\"] = np.array(predictions[timestep][\"predictions\"])\n",
        "    return predictions\n",
        "\n",
        "ensemble_matrices = generate_ensemble_matrix(all_models, all_models_order, ensemble_data_seq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LogisticRegressionMetaModel:\n",
        "    def __init__(self):\n",
        "        self.meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.meta_model.fit(X, y)\n",
        "        if X_val is not None and y_val is not None:\n",
        "            self.meta_model.fit(X_val, y_val)\n",
        "    def predict(self, X):\n",
        "        return 1 if self.meta_model.predict_proba(X)[:, 1] > 0.5 else 0\n",
        "    def predict_proba(self, X):\n",
        "        return self.meta_model.predict_proba(X)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class SimpleMetaNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleMetaNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class NeuralNetworkMetaModel(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, input_dim=None, lr=0.01, epochs=30, batch_size=32, device=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        if self.input_dim is None:\n",
        "            self.input_dim = X.shape[1]\n",
        "        self.model = SimpleMetaNN(self.input_dim).to(self.device)\n",
        "        criterion = nn.BCELoss()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(self.device)\n",
        "        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        self.model.train()\n",
        "        for epoch in range(self.epochs):\n",
        "            for xb, yb in loader:\n",
        "                optimizer.zero_grad()\n",
        "                preds = self.model(xb)\n",
        "                loss = criterion(preds, yb)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).cpu().numpy().flatten()\n",
        "        return (probs > 0.5).astype(int)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).cpu().numpy().flatten()\n",
        "        return np.column_stack([1 - probs, probs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training meta-model for timestep 0.0\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1183, 'logistic': 0.4258, 'lstm': 0.4559} (score: 0.222985)\n",
            "Training meta-model for timestep 0.005\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.556, 'logistic': 0.2871, 'lstm': 0.157} (score: 0.245724)\n",
            "Training meta-model for timestep 0.01\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2662, 'nn': 0.0, 'logistic': 0.1808, 'lstm': 0.5531} (score: 0.225142)\n",
            "Training meta-model for timestep 0.015\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0711, 'nn': 0.2089, 'logistic': 0.0, 'lstm': 0.72} (score: 0.233980)\n",
            "Training meta-model for timestep 0.02\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.3745, 'logistic': 0.3332, 'lstm': 0.2923} (score: 0.236269)\n",
            "Training meta-model for timestep 0.025\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3154, 'nn': 0.11, 'logistic': 0.1311, 'lstm': 0.4434} (score: 0.227487)\n",
            "Training meta-model for timestep 0.03\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4169, 'nn': 0.0, 'logistic': 0.0709, 'lstm': 0.5122} (score: 0.228582)\n",
            "Training meta-model for timestep 0.035\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1117, 'nn': 0.3445, 'logistic': 0.0, 'lstm': 0.5438} (score: 0.243286)\n",
            "Training meta-model for timestep 0.04\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.2974, 'lstm': 0.7026} (score: 0.244046)\n",
            "Training meta-model for timestep 0.045\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0389, 'nn': 0.2919, 'logistic': 0.4392, 'lstm': 0.2301} (score: 0.231308)\n",
            "Training meta-model for timestep 0.05\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1169, 'logistic': 0.675, 'lstm': 0.2081} (score: 0.226632)\n",
            "Training meta-model for timestep 0.055\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1662, 'nn': 0.0836, 'logistic': 0.1519, 'lstm': 0.5983} (score: 0.224523)\n",
            "Training meta-model for timestep 0.06\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1378, 'nn': 0.0, 'logistic': 0.4181, 'lstm': 0.4441} (score: 0.234668)\n",
            "Training meta-model for timestep 0.065\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2774, 'nn': 0.1647, 'logistic': 0.5316, 'lstm': 0.0263} (score: 0.219612)\n",
            "Training meta-model for timestep 0.07\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3208, 'nn': 0.2498, 'logistic': 0.4294, 'lstm': 0.0} (score: 0.232222)\n",
            "Training meta-model for timestep 0.075\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.5881, 'logistic': 0.3385, 'lstm': 0.0734} (score: 0.213469)\n",
            "Training meta-model for timestep 0.08\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3375, 'nn': 0.0379, 'logistic': 0.4352, 'lstm': 0.1894} (score: 0.223928)\n",
            "Training meta-model for timestep 0.085\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.7337, 'logistic': 0.207, 'lstm': 0.0593} (score: 0.217392)\n",
            "Training meta-model for timestep 0.09\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.8178, 'lstm': 0.1822} (score: 0.242302)\n",
            "Training meta-model for timestep 0.095\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0981, 'nn': 0.1879, 'logistic': 0.3111, 'lstm': 0.4029} (score: 0.212646)\n",
            "Training meta-model for timestep 0.1\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2723, 'nn': 0.0, 'logistic': 0.7152, 'lstm': 0.0124} (score: 0.210916)\n",
            "Training meta-model for timestep 0.105\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0751, 'nn': 0.0598, 'logistic': 0.6312, 'lstm': 0.2339} (score: 0.216567)\n",
            "Training meta-model for timestep 0.11\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0365, 'nn': 0.7256, 'logistic': 0.2379, 'lstm': 0.0} (score: 0.221345)\n",
            "Training meta-model for timestep 0.115\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2472, 'nn': 0.0868, 'logistic': 0.152, 'lstm': 0.514} (score: 0.214584)\n",
            "Training meta-model for timestep 0.12\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1375, 'nn': 0.5163, 'logistic': 0.1651, 'lstm': 0.181} (score: 0.225121)\n",
            "Training meta-model for timestep 0.125\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0271, 'logistic': 0.1783, 'lstm': 0.7946} (score: 0.230433)\n",
            "Training meta-model for timestep 0.13\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.6316, 'lstm': 0.3684} (score: 0.221554)\n",
            "Training meta-model for timestep 0.135\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2883, 'nn': 0.2211, 'logistic': 0.3063, 'lstm': 0.1842} (score: 0.220970)\n",
            "Training meta-model for timestep 0.14\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1656, 'nn': 0.0, 'logistic': 0.8344, 'lstm': 0.0} (score: 0.222337)\n",
            "Training meta-model for timestep 0.145\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1291, 'nn': 0.0748, 'logistic': 0.1191, 'lstm': 0.6769} (score: 0.222429)\n",
            "Training meta-model for timestep 0.15\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1837, 'nn': 0.4933, 'logistic': 0.323, 'lstm': 0.0} (score: 0.207980)\n",
            "Training meta-model for timestep 0.155\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4977, 'nn': 0.0059, 'logistic': 0.3487, 'lstm': 0.1476} (score: 0.191942)\n",
            "Training meta-model for timestep 0.16\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0786, 'nn': 0.061, 'logistic': 0.4271, 'lstm': 0.4333} (score: 0.214288)\n",
            "Training meta-model for timestep 0.165\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1393, 'nn': 0.0, 'logistic': 0.6978, 'lstm': 0.1629} (score: 0.220717)\n",
            "Training meta-model for timestep 0.17\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3565, 'nn': 0.0, 'logistic': 0.6435, 'lstm': 0.0} (score: 0.218185)\n",
            "Training meta-model for timestep 0.175\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1547, 'nn': 0.1951, 'logistic': 0.3255, 'lstm': 0.3247} (score: 0.219983)\n",
            "Training meta-model for timestep 0.18\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0813, 'nn': 0.0, 'logistic': 0.6545, 'lstm': 0.2642} (score: 0.204797)\n",
            "Training meta-model for timestep 0.185\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4561, 'nn': 0.0, 'logistic': 0.2711, 'lstm': 0.2728} (score: 0.196787)\n",
            "Training meta-model for timestep 0.19\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0763, 'nn': 0.0, 'logistic': 0.5503, 'lstm': 0.3734} (score: 0.214769)\n",
            "Training meta-model for timestep 0.195\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.4243, 'logistic': 0.3244, 'lstm': 0.2512} (score: 0.191886)\n",
            "Training meta-model for timestep 0.2\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5472, 'nn': 0.0, 'logistic': 0.4528, 'lstm': 0.0} (score: 0.205795)\n",
            "Training meta-model for timestep 0.205\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1779, 'nn': 0.0, 'logistic': 0.3528, 'lstm': 0.4693} (score: 0.207244)\n",
            "Training meta-model for timestep 0.21\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1215, 'logistic': 0.873, 'lstm': 0.0055} (score: 0.202283)\n",
            "Training meta-model for timestep 0.215\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2506, 'nn': 0.0918, 'logistic': 0.5301, 'lstm': 0.1276} (score: 0.201170)\n",
            "Training meta-model for timestep 0.22\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3805, 'nn': 0.0122, 'logistic': 0.4599, 'lstm': 0.1474} (score: 0.198797)\n",
            "Training meta-model for timestep 0.225\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.094, 'nn': 0.0, 'logistic': 0.4427, 'lstm': 0.4633} (score: 0.189993)\n",
            "Training meta-model for timestep 0.23\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.3602, 'logistic': 0.3574, 'lstm': 0.2824} (score: 0.224972)\n",
            "Training meta-model for timestep 0.235\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4422, 'nn': 0.2149, 'logistic': 0.3429, 'lstm': 0.0} (score: 0.177591)\n",
            "Training meta-model for timestep 0.24\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4449, 'nn': 0.0, 'logistic': 0.5551, 'lstm': 0.0} (score: 0.187215)\n",
            "Training meta-model for timestep 0.245\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4038, 'nn': 0.5562, 'logistic': 0.04, 'lstm': 0.0} (score: 0.205022)\n",
            "Training meta-model for timestep 0.25\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1958, 'nn': 0.0843, 'logistic': 0.6137, 'lstm': 0.1062} (score: 0.195843)\n",
            "Training meta-model for timestep 0.255\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4468, 'nn': 0.0, 'logistic': 0.0, 'lstm': 0.5532} (score: 0.218720)\n",
            "Training meta-model for timestep 0.26\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1635, 'nn': 0.219, 'logistic': 0.2903, 'lstm': 0.3273} (score: 0.202841)\n",
            "Training meta-model for timestep 0.265\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1879, 'nn': 0.0, 'logistic': 0.2336, 'lstm': 0.5784} (score: 0.203955)\n",
            "Training meta-model for timestep 0.27\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0535, 'nn': 0.0806, 'logistic': 0.8481, 'lstm': 0.0178} (score: 0.191635)\n",
            "Training meta-model for timestep 0.275\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0743, 'logistic': 0.4452, 'lstm': 0.4805} (score: 0.188054)\n",
            "Training meta-model for timestep 0.28\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.056, 'nn': 0.3098, 'logistic': 0.3091, 'lstm': 0.3251} (score: 0.200935)\n",
            "Training meta-model for timestep 0.285\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.253, 'nn': 0.0, 'logistic': 0.1272, 'lstm': 0.6198} (score: 0.189117)\n",
            "Training meta-model for timestep 0.29\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3399, 'nn': 0.0262, 'logistic': 0.0089, 'lstm': 0.625} (score: 0.199806)\n",
            "Training meta-model for timestep 0.295\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.187909)\n",
            "Training meta-model for timestep 0.3\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1458, 'nn': 0.0645, 'logistic': 0.1932, 'lstm': 0.5965} (score: 0.201501)\n",
            "Training meta-model for timestep 0.305\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.521, 'nn': 0.2425, 'logistic': 0.0, 'lstm': 0.2365} (score: 0.203328)\n",
            "Training meta-model for timestep 0.31\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.180246)\n",
            "Training meta-model for timestep 0.315\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1901, 'nn': 0.0, 'logistic': 0.6846, 'lstm': 0.1254} (score: 0.187496)\n",
            "Training meta-model for timestep 0.32\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1025, 'nn': 0.3893, 'logistic': 0.3714, 'lstm': 0.1368} (score: 0.199484)\n",
            "Training meta-model for timestep 0.325\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0782, 'logistic': 0.9218, 'lstm': 0.0} (score: 0.199436)\n",
            "Training meta-model for timestep 0.33\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1919, 'logistic': 0.5887, 'lstm': 0.2194} (score: 0.190803)\n",
            "Training meta-model for timestep 0.335\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.8914, 'lstm': 0.1086} (score: 0.182572)\n",
            "Training meta-model for timestep 0.34\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1133, 'nn': 0.3368, 'logistic': 0.4222, 'lstm': 0.1276} (score: 0.169678)\n",
            "Training meta-model for timestep 0.345\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5249, 'nn': 0.0, 'logistic': 0.4751, 'lstm': 0.0} (score: 0.180126)\n",
            "Training meta-model for timestep 0.35\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.413, 'nn': 0.0, 'logistic': 0.587, 'lstm': 0.0} (score: 0.185117)\n",
            "Training meta-model for timestep 0.355\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1162, 'nn': 0.0, 'logistic': 0.8838, 'lstm': 0.0} (score: 0.181733)\n",
            "Training meta-model for timestep 0.36\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2998, 'nn': 0.0693, 'logistic': 0.2013, 'lstm': 0.4296} (score: 0.183922)\n",
            "Training meta-model for timestep 0.365\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1413, 'nn': 0.2772, 'logistic': 0.2209, 'lstm': 0.3606} (score: 0.192939)\n",
            "Training meta-model for timestep 0.37\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5255, 'nn': 0.0, 'logistic': 0.0, 'lstm': 0.4745} (score: 0.187771)\n",
            "Training meta-model for timestep 0.375\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1497, 'nn': 0.0537, 'logistic': 0.2845, 'lstm': 0.5121} (score: 0.187806)\n",
            "Training meta-model for timestep 0.38\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1507, 'nn': 0.1067, 'logistic': 0.3491, 'lstm': 0.3935} (score: 0.177301)\n",
            "Training meta-model for timestep 0.385\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0773, 'nn': 0.2669, 'logistic': 0.0, 'lstm': 0.6557} (score: 0.181801)\n",
            "Training meta-model for timestep 0.39\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1071, 'nn': 0.0761, 'logistic': 0.5562, 'lstm': 0.2606} (score: 0.183905)\n",
            "Training meta-model for timestep 0.395\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3618, 'nn': 0.0, 'logistic': 0.1573, 'lstm': 0.4809} (score: 0.189087)\n",
            "Training meta-model for timestep 0.4\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2894, 'nn': 0.0, 'logistic': 0.339, 'lstm': 0.3716} (score: 0.186327)\n",
            "Training meta-model for timestep 0.405\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5245, 'nn': 0.3535, 'logistic': 0.1163, 'lstm': 0.0056} (score: 0.180041)\n",
            "Training meta-model for timestep 0.41\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4852, 'nn': 0.1721, 'logistic': 0.0, 'lstm': 0.3426} (score: 0.200152)\n",
            "Training meta-model for timestep 0.415\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1006, 'nn': 0.1972, 'logistic': 0.7022, 'lstm': 0.0} (score: 0.181987)\n",
            "Training meta-model for timestep 0.42\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0184, 'nn': 0.5133, 'logistic': 0.0, 'lstm': 0.4684} (score: 0.200117)\n",
            "Training meta-model for timestep 0.425\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.7883, 'lstm': 0.2117} (score: 0.199582)\n",
            "Training meta-model for timestep 0.43\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.217, 'nn': 0.0, 'logistic': 0.5488, 'lstm': 0.2342} (score: 0.182746)\n",
            "Training meta-model for timestep 0.435\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2339, 'logistic': 0.6047, 'lstm': 0.1614} (score: 0.169447)\n",
            "Training meta-model for timestep 0.44\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1796, 'nn': 0.2798, 'logistic': 0.2407, 'lstm': 0.2999} (score: 0.163996)\n",
            "Training meta-model for timestep 0.445\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0614, 'nn': 0.1446, 'logistic': 0.394, 'lstm': 0.4001} (score: 0.200156)\n",
            "Training meta-model for timestep 0.45\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0375, 'logistic': 0.9528, 'lstm': 0.0098} (score: 0.164179)\n",
            "Training meta-model for timestep 0.455\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2967, 'logistic': 0.6353, 'lstm': 0.068} (score: 0.168796)\n",
            "Training meta-model for timestep 0.46\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.243, 'nn': 0.0372, 'logistic': 0.3104, 'lstm': 0.4094} (score: 0.175715)\n",
            "Training meta-model for timestep 0.465\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2397, 'nn': 0.0, 'logistic': 0.6024, 'lstm': 0.1579} (score: 0.171889)\n",
            "Training meta-model for timestep 0.47\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0616, 'nn': 0.4715, 'logistic': 0.4669, 'lstm': 0.0} (score: 0.183180)\n",
            "Training meta-model for timestep 0.475\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1573, 'logistic': 0.3794, 'lstm': 0.4633} (score: 0.181871)\n",
            "Training meta-model for timestep 0.48\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0736, 'logistic': 0.7403, 'lstm': 0.1862} (score: 0.172584)\n",
            "Training meta-model for timestep 0.485\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.6684, 'logistic': 0.3316, 'lstm': 0.0} (score: 0.161439)\n",
            "Training meta-model for timestep 0.49\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.268, 'nn': 0.2811, 'logistic': 0.4509, 'lstm': 0.0} (score: 0.172650)\n",
            "Training meta-model for timestep 0.495\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1124, 'logistic': 0.8221, 'lstm': 0.0655} (score: 0.164260)\n",
            "Training meta-model for timestep 0.5\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0164, 'logistic': 0.8813, 'lstm': 0.1023} (score: 0.160424)\n",
            "Training meta-model for timestep 0.505\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2602, 'nn': 0.088, 'logistic': 0.6519, 'lstm': 0.0} (score: 0.161597)\n",
            "Training meta-model for timestep 0.51\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.142729)\n",
            "Training meta-model for timestep 0.515\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3537, 'nn': 0.0, 'logistic': 0.4089, 'lstm': 0.2374} (score: 0.170860)\n",
            "Training meta-model for timestep 0.52\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.7471, 'lstm': 0.2529} (score: 0.162375)\n",
            "Training meta-model for timestep 0.525\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.087, 'nn': 0.1395, 'logistic': 0.7735, 'lstm': 0.0} (score: 0.162825)\n",
            "Training meta-model for timestep 0.53\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2565, 'nn': 0.0081, 'logistic': 0.7354, 'lstm': 0.0} (score: 0.152497)\n",
            "Training meta-model for timestep 0.535\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0916, 'nn': 0.098, 'logistic': 0.8105, 'lstm': 0.0} (score: 0.149054)\n",
            "Training meta-model for timestep 0.54\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2157, 'nn': 0.0722, 'logistic': 0.7122, 'lstm': 0.0} (score: 0.167107)\n",
            "Training meta-model for timestep 0.545\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1539, 'nn': 0.1245, 'logistic': 0.4689, 'lstm': 0.2527} (score: 0.168852)\n",
            "Training meta-model for timestep 0.55\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4109, 'nn': 0.0381, 'logistic': 0.2256, 'lstm': 0.3253} (score: 0.164529)\n",
            "Training meta-model for timestep 0.555\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3168, 'nn': 0.0, 'logistic': 0.5132, 'lstm': 0.17} (score: 0.152050)\n",
            "Training meta-model for timestep 0.56\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0658, 'nn': 0.0, 'logistic': 0.9342, 'lstm': 0.0} (score: 0.139418)\n",
            "Training meta-model for timestep 0.565\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.6177, 'nn': 0.2371, 'logistic': 0.1452, 'lstm': 0.0} (score: 0.139043)\n",
            "Training meta-model for timestep 0.57\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2266, 'nn': 0.2575, 'logistic': 0.4164, 'lstm': 0.0995} (score: 0.151708)\n",
            "Training meta-model for timestep 0.575\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.097, 'nn': 0.074, 'logistic': 0.4826, 'lstm': 0.3464} (score: 0.177471)\n",
            "Training meta-model for timestep 0.58\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1697, 'nn': 0.0162, 'logistic': 0.6359, 'lstm': 0.1781} (score: 0.162325)\n",
            "Training meta-model for timestep 0.585\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1283, 'nn': 0.0005, 'logistic': 0.6306, 'lstm': 0.2406} (score: 0.164104)\n",
            "Training meta-model for timestep 0.59\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3987, 'nn': 0.0, 'logistic': 0.5455, 'lstm': 0.0558} (score: 0.155568)\n",
            "Training meta-model for timestep 0.595\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4634, 'nn': 0.0, 'logistic': 0.4025, 'lstm': 0.134} (score: 0.144800)\n",
            "Training meta-model for timestep 0.6\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2332, 'nn': 0.0, 'logistic': 0.494, 'lstm': 0.2728} (score: 0.169481)\n",
            "Training meta-model for timestep 0.605\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0389, 'nn': 0.0972, 'logistic': 0.8361, 'lstm': 0.0277} (score: 0.150278)\n",
            "Training meta-model for timestep 0.61\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.145123)\n",
            "Training meta-model for timestep 0.615\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1537, 'nn': 0.3651, 'logistic': 0.2233, 'lstm': 0.2578} (score: 0.146704)\n",
            "Training meta-model for timestep 0.62\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2486, 'nn': 0.2159, 'logistic': 0.5355, 'lstm': 0.0} (score: 0.145115)\n",
            "Training meta-model for timestep 0.625\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3518, 'nn': 0.0, 'logistic': 0.5047, 'lstm': 0.1434} (score: 0.133699)\n",
            "Training meta-model for timestep 0.63\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.9265, 'lstm': 0.0735} (score: 0.125020)\n",
            "Training meta-model for timestep 0.635\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0693, 'nn': 0.206, 'logistic': 0.5791, 'lstm': 0.1456} (score: 0.168634)\n",
            "Training meta-model for timestep 0.64\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.7385, 'lstm': 0.2615} (score: 0.142784)\n",
            "Training meta-model for timestep 0.645\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0149, 'nn': 0.0, 'logistic': 0.8157, 'lstm': 0.1694} (score: 0.151567)\n",
            "Training meta-model for timestep 0.65\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1657, 'nn': 0.0, 'logistic': 0.7199, 'lstm': 0.1144} (score: 0.147544)\n",
            "Training meta-model for timestep 0.655\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0299, 'nn': 0.0451, 'logistic': 0.8284, 'lstm': 0.0966} (score: 0.142753)\n",
            "Training meta-model for timestep 0.66\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4703, 'nn': 0.0, 'logistic': 0.217, 'lstm': 0.3127} (score: 0.152977)\n",
            "Training meta-model for timestep 0.665\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2427, 'nn': 0.0191, 'logistic': 0.548, 'lstm': 0.1902} (score: 0.134123)\n",
            "Training meta-model for timestep 0.67\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.296, 'nn': 0.1982, 'logistic': 0.2675, 'lstm': 0.2382} (score: 0.141281)\n",
            "Training meta-model for timestep 0.675\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.6095, 'nn': 0.2387, 'logistic': 0.0, 'lstm': 0.1518} (score: 0.166201)\n",
            "Training meta-model for timestep 0.68\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1969, 'nn': 0.0637, 'logistic': 0.4745, 'lstm': 0.2649} (score: 0.151130)\n",
            "Training meta-model for timestep 0.685\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0906, 'nn': 0.0, 'logistic': 0.8092, 'lstm': 0.1003} (score: 0.141365)\n",
            "Training meta-model for timestep 0.69\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2412, 'nn': 0.0, 'logistic': 0.6514, 'lstm': 0.1074} (score: 0.130726)\n",
            "Training meta-model for timestep 0.695\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3284, 'nn': 0.2813, 'logistic': 0.2236, 'lstm': 0.1666} (score: 0.139722)\n",
            "Training meta-model for timestep 0.7\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0367, 'nn': 0.2843, 'logistic': 0.5292, 'lstm': 0.1497} (score: 0.143400)\n",
            "Training meta-model for timestep 0.705\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0041, 'nn': 0.1061, 'logistic': 0.4156, 'lstm': 0.4741} (score: 0.141231)\n",
            "Training meta-model for timestep 0.71\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0157, 'logistic': 0.6969, 'lstm': 0.2874} (score: 0.145216)\n",
            "Training meta-model for timestep 0.715\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.521, 'nn': 0.1552, 'logistic': 0.3238, 'lstm': 0.0} (score: 0.160200)\n",
            "Training meta-model for timestep 0.72\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1006, 'nn': 0.1984, 'logistic': 0.2441, 'lstm': 0.4568} (score: 0.141710)\n",
            "Training meta-model for timestep 0.725\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2562, 'nn': 0.1679, 'logistic': 0.5268, 'lstm': 0.0491} (score: 0.145725)\n",
            "Training meta-model for timestep 0.73\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3141, 'nn': 0.0, 'logistic': 0.6859, 'lstm': 0.0} (score: 0.130423)\n",
            "Training meta-model for timestep 0.735\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2728, 'nn': 0.0, 'logistic': 0.5498, 'lstm': 0.1774} (score: 0.141303)\n",
            "Training meta-model for timestep 0.74\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2015, 'nn': 0.055, 'logistic': 0.5162, 'lstm': 0.2274} (score: 0.128072)\n",
            "Training meta-model for timestep 0.745\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2142, 'nn': 0.1112, 'logistic': 0.6746, 'lstm': 0.0} (score: 0.125592)\n",
            "Training meta-model for timestep 0.75\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2641, 'nn': 0.1378, 'logistic': 0.5553, 'lstm': 0.0428} (score: 0.137532)\n",
            "Training meta-model for timestep 0.755\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1008, 'nn': 0.7087, 'logistic': 0.1905, 'lstm': 0.0} (score: 0.130143)\n",
            "Training meta-model for timestep 0.76\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.098, 'nn': 0.3897, 'logistic': 0.5123, 'lstm': 0.0} (score: 0.109918)\n",
            "Training meta-model for timestep 0.765\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.6111, 'nn': 0.0653, 'logistic': 0.0094, 'lstm': 0.3141} (score: 0.105941)\n",
            "Training meta-model for timestep 0.77\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4387, 'nn': 0.0, 'logistic': 0.3241, 'lstm': 0.2372} (score: 0.137640)\n",
            "Training meta-model for timestep 0.775\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1576, 'nn': 0.0, 'logistic': 0.7059, 'lstm': 0.1366} (score: 0.110075)\n",
            "Training meta-model for timestep 0.78\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3272, 'nn': 0.0, 'logistic': 0.6728, 'lstm': 0.0} (score: 0.132142)\n",
            "Training meta-model for timestep 0.785\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.9539, 'lstm': 0.0461} (score: 0.105276)\n",
            "Training meta-model for timestep 0.79\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.6963, 'nn': 0.014, 'logistic': 0.2898, 'lstm': 0.0} (score: 0.114815)\n",
            "Training meta-model for timestep 0.795\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2675, 'logistic': 0.3201, 'lstm': 0.4124} (score: 0.126392)\n",
            "Training meta-model for timestep 0.8\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4116, 'nn': 0.2501, 'logistic': 0.3383, 'lstm': 0.0} (score: 0.117455)\n",
            "Training meta-model for timestep 0.805\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4321, 'nn': 0.0, 'logistic': 0.5076, 'lstm': 0.0603} (score: 0.111112)\n",
            "Training meta-model for timestep 0.81\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.274, 'logistic': 0.4345, 'lstm': 0.2915} (score: 0.119307)\n",
            "Training meta-model for timestep 0.815\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.258, 'nn': 0.0, 'logistic': 0.4936, 'lstm': 0.2483} (score: 0.115912)\n",
            "Training meta-model for timestep 0.82\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.115853)\n",
            "Training meta-model for timestep 0.825\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2275, 'nn': 0.0332, 'logistic': 0.7393, 'lstm': 0.0} (score: 0.110101)\n",
            "Training meta-model for timestep 0.83\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2771, 'nn': 0.0, 'logistic': 0.2586, 'lstm': 0.4642} (score: 0.100049)\n",
            "Training meta-model for timestep 0.835\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.115557)\n",
            "Training meta-model for timestep 0.84\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4401, 'nn': 0.0, 'logistic': 0.5599, 'lstm': 0.0} (score: 0.118789)\n",
            "Training meta-model for timestep 0.845\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3466, 'nn': 0.0, 'logistic': 0.4074, 'lstm': 0.246} (score: 0.094573)\n",
            "Training meta-model for timestep 0.85\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1851, 'nn': 0.2515, 'logistic': 0.1819, 'lstm': 0.3815} (score: 0.109793)\n",
            "Training meta-model for timestep 0.855\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3274, 'nn': 0.0299, 'logistic': 0.2066, 'lstm': 0.4361} (score: 0.119741)\n",
            "Training meta-model for timestep 0.86\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3083, 'nn': 0.1022, 'logistic': 0.2054, 'lstm': 0.3842} (score: 0.112634)\n",
            "Training meta-model for timestep 0.865\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.363, 'nn': 0.0, 'logistic': 0.4153, 'lstm': 0.2217} (score: 0.102805)\n",
            "Training meta-model for timestep 0.87\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0389, 'nn': 0.0, 'logistic': 0.5837, 'lstm': 0.3774} (score: 0.100675)\n",
            "Training meta-model for timestep 0.875\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1749, 'nn': 0.0, 'logistic': 0.4543, 'lstm': 0.3708} (score: 0.112307)\n",
            "Training meta-model for timestep 0.88\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1962, 'nn': 0.0855, 'logistic': 0.501, 'lstm': 0.2173} (score: 0.101544)\n",
            "Training meta-model for timestep 0.885\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.3486, 'logistic': 0.6362, 'lstm': 0.0152} (score: 0.101219)\n",
            "Training meta-model for timestep 0.89\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1018, 'nn': 0.25, 'logistic': 0.5465, 'lstm': 0.1017} (score: 0.089034)\n",
            "Training meta-model for timestep 0.895\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2448, 'nn': 0.0, 'logistic': 0.7552, 'lstm': 0.0} (score: 0.077105)\n",
            "Training meta-model for timestep 0.9\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.8173, 'nn': 0.1419, 'logistic': 0.0408, 'lstm': 0.0} (score: 0.079857)\n",
            "Training meta-model for timestep 0.905\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5099, 'nn': 0.0, 'logistic': 0.2942, 'lstm': 0.1958} (score: 0.089910)\n",
            "Training meta-model for timestep 0.91\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.6797, 'nn': 0.0342, 'logistic': 0.2287, 'lstm': 0.0574} (score: 0.101461)\n",
            "Training meta-model for timestep 0.915\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5851, 'nn': 0.0, 'logistic': 0.215, 'lstm': 0.1999} (score: 0.080971)\n",
            "Training meta-model for timestep 0.92\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.7996, 'nn': 0.1635, 'logistic': 0.0, 'lstm': 0.0369} (score: 0.085482)\n",
            "Training meta-model for timestep 0.925\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3803, 'nn': 0.1739, 'logistic': 0.288, 'lstm': 0.1578} (score: 0.080642)\n",
            "Training meta-model for timestep 0.93\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5627, 'nn': 0.2764, 'logistic': 0.0, 'lstm': 0.1609} (score: 0.081371)\n",
            "Training meta-model for timestep 0.935\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5077, 'nn': 0.2543, 'logistic': 0.0, 'lstm': 0.238} (score: 0.080104)\n",
            "Training meta-model for timestep 0.94\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2447, 'nn': 0.0, 'logistic': 0.1707, 'lstm': 0.5847} (score: 0.073031)\n",
            "Training meta-model for timestep 0.945\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4373, 'nn': 0.0, 'logistic': 0.3395, 'lstm': 0.2232} (score: 0.088816)\n",
            "Training meta-model for timestep 0.95\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4296, 'nn': 0.3154, 'logistic': 0.255, 'lstm': 0.0} (score: 0.090852)\n",
            "Training meta-model for timestep 0.955\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3128, 'nn': 0.1606, 'logistic': 0.4585, 'lstm': 0.0681} (score: 0.087416)\n",
            "Training meta-model for timestep 0.96\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1885, 'logistic': 0.8115, 'lstm': 0.0} (score: 0.092629)\n",
            "Training meta-model for timestep 0.965\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2233, 'nn': 0.1687, 'logistic': 0.6081, 'lstm': 0.0} (score: 0.077976)\n",
            "Training meta-model for timestep 0.97\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2367, 'nn': 0.0111, 'logistic': 0.7522, 'lstm': 0.0} (score: 0.082576)\n",
            "Training meta-model for timestep 0.975\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0967, 'logistic': 0.744, 'lstm': 0.1593} (score: 0.080475)\n",
            "Training meta-model for timestep 0.98\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0299, 'logistic': 0.9513, 'lstm': 0.0188} (score: 0.081504)\n",
            "Training meta-model for timestep 0.985\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1549, 'nn': 0.2363, 'logistic': 0.6088, 'lstm': 0.0} (score: 0.073738)\n",
            "Training meta-model for timestep 0.99\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1625, 'logistic': 0.7577, 'lstm': 0.0798} (score: 0.097672)\n",
            "Training meta-model for timestep 0.995\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2613, 'nn': 0.3501, 'logistic': 0.2995, 'lstm': 0.0891} (score: 0.086897)\n",
            "Training meta-model for timestep 1.0\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5603, 'nn': 0.2176, 'logistic': 0.2211, 'lstm': 0.001} (score: 0.045530)\n"
          ]
        }
      ],
      "source": [
        "def setup_meta_models(ensemble_matrices, all_models, all_models_order, strategy='meta_model', meta_model=None):\n",
        "    models = {}\n",
        "    for timestep in ensemble_matrices:\n",
        "        print(f\"Training meta-model for timestep {timestep}\")\n",
        "        ensemble_matrix = ensemble_matrices[timestep]\n",
        "        x_train = ensemble_matrix[\"predictions\"]\n",
        "        y_train = ensemble_matrix[\"y_true\"]\n",
        "        all_models_for_timestep = {model_name: all_models[model_name][timestep] for model_name in all_models_order}\n",
        "        models[timestep] = EnsemblePredictor(all_models_for_timestep, all_models_order, features, strategy, meta_model)\n",
        "        models[timestep].train_ensemble(x_train, y_train, objective='brier')\n",
        "    return models\n",
        "\n",
        "ensemble_models = setup_meta_models(ensemble_matrices, all_models, all_models_order, strategy='weighted_average', meta_model=LogisticRegressionMetaModel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test accuracy and Brier score of model for each timestep on test data and plot\n",
        "accuracies = []\n",
        "brier_scores = []\n",
        "timesteps = []\n",
        "def brier_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "for timestep, i in zip(ensemble_models, test_data.keys()):\n",
        "    model = ensemble_models[timestep]\n",
        "    # Convert test data to array\n",
        "    y_test = np.array([row[\"label\"] for row in test_data_seq[i]])\n",
        "    X_test = np.array([row[\"rows\"] for row in test_data_seq[i]])\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    \n",
        "    # Calculate Brier score\n",
        "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probability predictions\n",
        "    brier_score = brier_loss(y_test, y_test_pred_proba)\n",
        "    \n",
        "    print(f\"Timestep {timestep:.2%}: Accuracy = {accuracy:.4f}, Brier Score = {brier_score:.4f}\")\n",
        "    accuracies.append(accuracy)\n",
        "    brier_scores.append(brier_score)\n",
        "    timesteps.append(timestep)\n",
        "\n",
        "# Create subplots for both metrics\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot accuracy\n",
        "ax1.plot(timesteps, accuracies, 'b-', linewidth=2, marker='o', markersize=3)\n",
        "ax1.set_xlabel(\"Timestep\")\n",
        "ax1.set_ylabel(\"Accuracy\")\n",
        "ax1.set_title(\"Test Accuracy vs Timestep\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([min(accuracies) * 0.95, max(accuracies) * 1.05])\n",
        "\n",
        "# Plot Brier score\n",
        "ax2.plot(timesteps, brier_scores, 'r-', linewidth=2, marker='s', markersize=3)\n",
        "ax2.set_xlabel(\"Timestep\")\n",
        "ax2.set_ylabel(\"Brier Score\")\n",
        "ax2.set_title(\"Test Brier Score vs Timestep\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim([min(brier_scores) * 0.95, max(brier_scores) * 1.05])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\nSummary Statistics:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}  {np.std(accuracies):.4f}\")\n",
        "print(f\"Average Brier Score: {np.mean(brier_scores):.4f}  {np.std(brier_scores):.4f}\")\n",
        "print(f\"Best Accuracy: {max(accuracies):.4f} at timestep {timesteps[np.argmax(accuracies)]:.2%}\")\n",
        "print(f\"Best Brier Score: {min(brier_scores):.4f} at timestep {timesteps[np.argmin(brier_scores)]:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name:  xgboost\n",
            "(2, 5, 11)\n",
            "(2, 11)\n",
            "[[0.         1.        ]\n",
            " [0.19230769 0.80769231]]\n",
            "Model name:  nn\n",
            "(2, 5, 11)\n",
            "(2, 11)\n",
            "[[1. 0.]\n",
            " [1. 0.]]\n",
            "Model name:  logistic\n",
            "(2, 5, 11)\n",
            "(2, 11)\n",
            "[[0. 1.]\n",
            " [0. 1.]]\n",
            "Model name:  lstm\n",
            "(2, 5, 11)\n",
            "[[0.79934996 0.20065005]\n",
            " [0.7205218  0.27947822]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.48275698, 0.51724302],\n",
              "       [0.44681822, 0.55318178]])"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ensemble_models[0]\n",
        "model.predict_proba(np.arange(110).reshape(2, 5, 11))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2024\n",
            "Processed file:  game_401671629.csv\n",
            "Processed file:  game_401671601.csv\n",
            "Processed file:  game_401671826.csv\n",
            "Processed file:  game_401671832.csv\n",
            "Processed file:  game_401671749.csv\n",
            "Processed file:  game_401671775.csv\n",
            "Processed file:  game_401671761.csv\n",
            "Processed file:  game_401671760.csv\n",
            "Processed file:  game_401671774.csv\n",
            "Processed file:  game_401671748.csv\n",
            "Processed file:  game_401671833.csv\n",
            "Processed file:  game_401671827.csv\n",
            "Processed file:  game_401671600.csv\n",
            "Processed file:  game_401671628.csv\n",
            "Processed file:  game_401671616.csv\n",
            "Processed file:  game_401671831.csv\n",
            "Processed file:  game_401671825.csv\n",
            "Processed file:  game_401671819.csv\n",
            "Processed file:  game_401671762.csv\n",
            "Processed file:  game_401671776.csv\n",
            "Processed file:  game_401671789.csv\n",
            "Processed file:  game_401671788.csv\n",
            "Processed file:  game_401671777.csv\n",
            "Processed file:  game_401671763.csv\n",
            "Processed file:  game_401671818.csv\n",
            "Processed file:  game_401671824.csv\n",
            "Processed file:  game_401671830.csv\n",
            "Processed file:  game_401671617.csv\n",
            "Processed file:  game_401671808.csv\n",
            "Processed file:  game_401671834.csv\n",
            "Processed file:  game_401671820.csv\n",
            "Processed file:  game_401671767.csv\n",
            "Processed file:  game_401671773.csv\n",
            "Processed file:  game_401671798.csv\n",
            "Processed file:  game_401671799.csv\n",
            "Processed file:  game_401671772.csv\n",
            "Processed file:  game_401671766.csv\n",
            "Processed file:  game_401671821.csv\n",
            "Processed file:  game_401671835.csv\n",
            "Processed file:  game_401671809.csv\n",
            "Processed file:  game_401671638.csv\n",
            "Processed file:  game_401671823.csv\n",
            "Processed file:  game_401671837.csv\n",
            "Processed file:  game_401671599.csv\n",
            "Processed file:  game_401671770.csv\n",
            "Processed file:  game_401671764.csv\n",
            "Processed file:  game_401671758.csv\n",
            "Processed file:  game_401671759.csv\n",
            "Processed file:  game_401671765.csv\n",
            "Processed file:  game_401671771.csv\n",
            "Processed file:  game_401671836.csv\n",
            "Processed file:  game_401671822.csv\n",
            "Processed file:  game_401671639.csv\n",
            "Processed file:  game_401671662.csv\n",
            "Processed file:  game_401671676.csv\n",
            "Processed file:  game_401671845.csv\n",
            "Processed file:  game_401671851.csv\n",
            "Processed file:  game_401671689.csv\n",
            "Processed file:  game_401671716.csv\n",
            "Processed file:  game_401671702.csv\n",
            "Processed file:  game_401671703.csv\n",
            "Processed file:  game_401671717.csv\n",
            "Processed file:  game_401671688.csv\n",
            "Processed file:  game_401671850.csv\n",
            "Processed file:  game_401671844.csv\n",
            "Processed file:  game_401671677.csv\n",
            "Processed file:  game_401671663.csv\n",
            "Processed file:  game_401671649.csv\n",
            "Processed file:  game_401671675.csv\n",
            "Processed file:  game_401671661.csv\n",
            "Processed file:  game_401671852.csv\n",
            "Processed file:  game_401671846.csv\n",
            "Processed file:  game_401671729.csv\n",
            "Processed file:  game_401671701.csv\n",
            "Processed file:  game_401671715.csv\n",
            "Processed file:  game_401671714.csv\n",
            "Processed file:  game_401671700.csv\n",
            "Processed file:  game_401671728.csv\n",
            "Processed file:  game_401671489.csv\n",
            "Processed file:  game_401671847.csv\n",
            "Processed file:  game_401671853.csv\n",
            "Processed file:  game_401671660.csv\n",
            "Processed file:  game_401671674.csv\n",
            "Processed file:  game_401671648.csv\n",
            "Processed file:  game_401671670.csv\n",
            "Processed file:  game_401671664.csv\n",
            "Processed file:  game_401671658.csv\n",
            "Processed file:  game_401671857.csv\n",
            "Processed file:  game_401671843.csv\n",
            "Processed file:  game_401671704.csv\n",
            "Processed file:  game_401671710.csv\n",
            "Processed file:  game_401671738.csv\n",
            "Processed file:  game_401671739.csv\n",
            "Processed file:  game_401671711.csv\n",
            "Processed file:  game_401671705.csv\n",
            "Processed file:  game_401671842.csv\n",
            "Processed file:  game_401671856.csv\n",
            "Processed file:  game_401671659.csv\n",
            "Processed file:  game_401671665.csv\n",
            "Processed file:  game_401671671.csv\n",
            "Processed file:  game_401671667.csv\n",
            "Processed file:  game_401671673.csv\n",
            "Processed file:  game_401671868.csv\n",
            "Processed file:  game_401671840.csv\n",
            "Processed file:  game_401671698.csv\n",
            "Processed file:  game_401671854.csv\n",
            "Processed file:  game_401671713.csv\n",
            "Processed file:  game_401671707.csv\n",
            "Processed file:  game_401671706.csv\n",
            "Processed file:  game_401671712.csv\n",
            "Processed file:  game_401671855.csv\n",
            "Processed file:  game_401671699.csv\n",
            "Processed file:  game_401671841.csv\n",
            "Processed file:  game_401671869.csv\n",
            "Processed file:  game_401671672.csv\n",
            "Processed file:  game_401671666.csv\n",
            "Processed file:  game_401671643.csv\n",
            "Processed file:  game_401671657.csv\n",
            "Processed file:  game_401671864.csv\n",
            "Processed file:  game_401671870.csv\n",
            "Processed file:  game_401671858.csv\n",
            "Processed file:  game_401671680.csv\n",
            "Processed file:  game_401671694.csv\n",
            "Processed file:  game_401671737.csv\n",
            "Processed file:  game_401671723.csv\n",
            "Processed file:  game_401671722.csv\n",
            "Processed file:  game_401671736.csv\n",
            "Processed file:  game_401671695.csv\n",
            "Processed file:  game_401671681.csv\n",
            "Processed file:  game_401671859.csv\n",
            "Processed file:  game_401671871.csv\n",
            "Processed file:  game_401671865.csv\n",
            "Processed file:  game_401671656.csv\n",
            "Processed file:  game_401671642.csv\n",
            "Processed file:  game_401671668.csv\n",
            "Processed file:  game_401671654.csv\n",
            "Processed file:  game_401671640.csv\n",
            "Processed file:  game_401671873.csv\n",
            "Processed file:  game_401671867.csv\n",
            "Processed file:  game_401671697.csv\n",
            "Processed file:  game_401671683.csv\n",
            "Processed file:  game_401671495.csv\n",
            "Processed file:  game_401671708.csv\n",
            "Processed file:  game_401671720.csv\n",
            "Processed file:  game_401671734.csv\n",
            "Processed file:  game_401671735.csv\n",
            "Processed file:  game_401671721.csv\n",
            "Processed file:  game_401671709.csv\n",
            "Processed file:  game_401671494.csv\n",
            "Processed file:  game_401671682.csv\n",
            "Processed file:  game_401671696.csv\n",
            "Processed file:  game_401671866.csv\n",
            "Processed file:  game_401671872.csv\n",
            "Processed file:  game_401671641.csv\n",
            "Processed file:  game_401671655.csv\n",
            "Processed file:  game_401671669.csv\n",
            "Processed file:  game_401671651.csv\n",
            "Processed file:  game_401671645.csv\n",
            "Processed file:  game_401671679.csv\n",
            "Processed file:  game_401671692.csv\n",
            "Processed file:  game_401671686.csv\n",
            "Processed file:  game_401671876.csv\n",
            "Processed file:  game_401671862.csv\n",
            "Processed file:  game_401671490.csv\n",
            "Processed file:  game_401671725.csv\n",
            "Processed file:  game_401671731.csv\n",
            "Processed file:  game_401671719.csv\n",
            "Processed file:  game_401671718.csv\n",
            "Processed file:  game_401671730.csv\n",
            "Processed file:  game_401671724.csv\n",
            "Processed file:  game_401671491.csv\n",
            "Processed file:  game_401671863.csv\n",
            "Processed file:  game_401671877.csv\n",
            "Processed file:  game_401671687.csv\n",
            "Processed file:  game_401671693.csv\n",
            "Processed file:  game_401671678.csv\n",
            "Processed file:  game_401671644.csv\n",
            "Processed file:  game_401671650.csv\n",
            "Processed file:  game_401671646.csv\n",
            "Processed file:  game_401671652.csv\n",
            "Processed file:  game_401671685.csv\n",
            "Processed file:  game_401671849.csv\n",
            "Processed file:  game_401671691.csv\n",
            "Processed file:  game_401671861.csv\n",
            "Processed file:  game_401671875.csv\n",
            "Processed file:  game_401671493.csv\n",
            "Processed file:  game_401671732.csv\n",
            "Processed file:  game_401671726.csv\n",
            "Processed file:  game_401671727.csv\n",
            "Processed file:  game_401671733.csv\n",
            "Processed file:  game_401671492.csv\n",
            "Processed file:  game_401671874.csv\n",
            "Processed file:  game_401671860.csv\n",
            "Processed file:  game_401671690.csv\n",
            "Processed file:  game_401671848.csv\n",
            "Processed file:  game_401671684.csv\n",
            "Processed file:  game_401671653.csv\n",
            "Processed file:  game_401671647.csv\n",
            "Processed file:  game_401671620.csv\n",
            "Processed file:  game_401671634.csv\n",
            "Processed file:  game_401671807.csv\n",
            "Processed file:  game_401671813.csv\n",
            "Processed file:  game_401671768.csv\n",
            "Processed file:  game_401671754.csv\n",
            "Processed file:  game_401671740.csv\n",
            "Processed file:  game_401671797.csv\n",
            "Processed file:  game_401671783.csv\n",
            "Processed file:  game_401671782.csv\n",
            "Processed file:  game_401671796.csv\n",
            "Processed file:  game_401671741.csv\n",
            "Processed file:  game_401671755.csv\n",
            "Processed file:  game_401671769.csv\n",
            "Processed file:  game_401671812.csv\n",
            "Processed file:  game_401671806.csv\n",
            "Processed file:  game_401671635.csv\n",
            "Processed file:  game_401671621.csv\n",
            "Processed file:  game_401671637.csv\n",
            "Processed file:  game_401671623.csv\n",
            "Processed file:  game_401671810.csv\n",
            "Processed file:  game_401671804.csv\n",
            "Processed file:  game_401671838.csv\n",
            "Processed file:  game_401671743.csv\n",
            "Processed file:  game_401671757.csv\n",
            "Processed file:  game_401671780.csv\n",
            "Processed file:  game_401671794.csv\n",
            "Processed file:  game_401671795.csv\n",
            "Processed file:  game_401671781.csv\n",
            "Processed file:  game_401671756.csv\n",
            "Processed file:  game_401671742.csv\n",
            "Processed file:  game_401671839.csv\n",
            "Processed file:  game_401671805.csv\n",
            "Processed file:  game_401671811.csv\n",
            "Processed file:  game_401671622.csv\n",
            "Processed file:  game_401671636.csv\n",
            "Processed file:  game_401671632.csv\n",
            "Processed file:  game_401671626.csv\n",
            "Processed file:  game_401671829.csv\n",
            "Processed file:  game_401671815.csv\n",
            "Processed file:  game_401671801.csv\n",
            "Processed file:  game_401671746.csv\n",
            "Processed file:  game_401671752.csv\n",
            "Processed file:  game_401671785.csv\n",
            "Processed file:  game_401671791.csv\n",
            "Processed file:  game_401671790.csv\n",
            "Processed file:  game_401671784.csv\n",
            "Processed file:  game_401671753.csv\n",
            "Processed file:  game_401671747.csv\n",
            "Processed file:  game_401671800.csv\n",
            "Processed file:  game_401671814.csv\n",
            "Processed file:  game_401671828.csv\n",
            "Processed file:  game_401671627.csv\n",
            "Processed file:  game_401671633.csv\n",
            "Processed file:  game_401671625.csv\n",
            "Processed file:  game_401671631.csv\n",
            "Processed file:  game_401671619.csv\n",
            "Processed file:  game_401671802.csv\n",
            "Processed file:  game_401671816.csv\n",
            "Processed file:  game_401671751.csv\n",
            "Processed file:  game_401671745.csv\n",
            "Processed file:  game_401671779.csv\n",
            "Processed file:  game_401671792.csv\n",
            "Processed file:  game_401671786.csv\n",
            "Processed file:  game_401671787.csv\n",
            "Processed file:  game_401671793.csv\n",
            "Processed file:  game_401671778.csv\n",
            "Processed file:  game_401671744.csv\n",
            "Processed file:  game_401671750.csv\n",
            "Processed file:  game_401671817.csv\n",
            "Processed file:  game_401671803.csv\n",
            "Processed file:  game_401671618.csv\n",
            "Processed file:  game_401671630.csv\n",
            "Processed file:  game_401671624.csv\n"
          ]
        }
      ],
      "source": [
        "# Write predictions to csv file\n",
        "from process_data import write_predictions\n",
        "write_predictions(ensemble_models, interpolated_dir, [2024], 4, features, replace_nan_val = 0, phat_b = \"ensemble_phat_b_model\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NFL_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
