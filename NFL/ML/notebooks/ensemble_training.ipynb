{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensemble training (1 year of testing, 2 years of validation, the rest is training)\n",
        "    # Learned weights on validation data (Constrained optimization)\n",
        "    # Meta-learning using an other ML model\n",
        "\n",
        "# Models used:\n",
        "# - XGBoost\n",
        "# - Neural Network\n",
        "# - Logistic Regression\n",
        "# - LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML\n"
          ]
        }
      ],
      "source": [
        "# Set up paths and load data\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "sys.path.append(parent_dir)\n",
        "print(parent_dir)\n",
        "\n",
        "interpolated_dir = os.path.join(parent_dir, \"dataset_interpolated_fixed\")\n",
        "# features = [\"game_completed\", \"relative_strength\", \"score_difference\", \"type.id\", \"home_has_possession\", \"end.down\", \"end.yardsToEndzone\", \"end.distance\", \"field_position_shift\", \"home_timeouts_left\", \"away_timeouts_left\"]\n",
        "features = [\"relative_strength\", \"score_difference\", \"home_has_possession\", \"end.down\", \"end.distance\", \"end.yardsToEndzone\",  \"home_timeouts_left\", \"away_timeouts_left\"]\n",
        "# Import necessary modules\n",
        "from sklearn.metrics import brier_score_loss, accuracy_score, log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.optimize import minimize\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2022\n",
            "  Processing 271 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "  Processing 254 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2017\n",
            "Loading data for 2019\n",
            "  Processing 256 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2019\n",
            "Loading data for 2021\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2021\n",
            "Loading data for 2020\n",
            "  Processing 255 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2020\n",
            "Loading data for 2018\n",
            "  Processing 255 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2018\n",
            "Loading data for 2016\n",
            "  Processing 254 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2016\n",
            "Loading data for 2022\n",
            "  Processing 271 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n"
          ]
        }
      ],
      "source": [
        "# Load data for ensemble training\n",
        "import process_data\n",
        "training_data = process_data.load_data(interpolated_dir, \n",
        "                                       years = [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], \n",
        "                                       history_length = 0, \n",
        "                                       features = features, \n",
        "                                       label_feature = \"home_win\")\n",
        "\n",
        "ensemble_data = process_data.load_data(interpolated_dir, \n",
        "                                         years = [2022, 2023], \n",
        "                                         history_length = 0, \n",
        "                                         features = features, \n",
        "                                         label_feature = \"home_win\",\n",
        "                                         train = True\n",
        "                                         )\n",
        "\n",
        "test_data = process_data.load_data(interpolated_dir, \n",
        "                                   years = [2024],\n",
        "                                   history_length = 0, \n",
        "                                   features = features, \n",
        "                                   label_feature = \"home_win\",\n",
        "                                   train = False\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2022\n",
            "  Processing 271 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "  Processing 254 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2017\n",
            "Loading data for 2019\n",
            "  Processing 256 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2019\n",
            "Loading data for 2021\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2021\n",
            "Loading data for 2020\n",
            "  Processing 255 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2020\n",
            "Loading data for 2018\n",
            "  Processing 255 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2018\n",
            "Loading data for 2016\n",
            "  Processing 254 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2016\n",
            "Loading data for 2022\n",
            "  Processing 271 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n"
          ]
        }
      ],
      "source": [
        "\n",
        "training_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                       years = [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], \n",
        "                                       history_length = 4, \n",
        "                                       features = features, \n",
        "                                       label_feature = \"home_win\",\n",
        "                                       train = True\n",
        "                                       )\n",
        "\n",
        "ensemble_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                         years = [2022, 2023], \n",
        "                                         history_length = 4, \n",
        "                                         features = features, \n",
        "                                         label_feature = \"home_win\",\n",
        "                                         train = True\n",
        "                                         )\n",
        "\n",
        "test_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                   years = [2024],\n",
        "                                   history_length = 4, \n",
        "                                   features = features, \n",
        "                                   label_feature = \"home_win\",\n",
        "                                   train = False\n",
        "                                   )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "class EnsemblePredictor:\n",
        "    \"\"\"\n",
        "    Ensemble predictor class, one per timestep\n",
        "    \"\"\"\n",
        "    def __init__(self, all_models, all_models_order, all_features, strategy='meta_model', meta_model=None):\n",
        "        self.all_models = all_models\n",
        "        self.all_models_order = all_models_order\n",
        "        self.strategy = strategy\n",
        "        self.all_features = all_features\n",
        "        if self.strategy != 'meta_model' and self.strategy != 'weighted_average':\n",
        "            raise ValueError(\"Invalid strategy\")\n",
        "        if meta_model is None and self.strategy == 'meta_model':\n",
        "            raise ValueError(\"Meta model is required for meta_model strategy\")\n",
        "        self.meta_model = meta_model\n",
        "        self.ensemble_weights = None # Will be a 1D array of shape (n_models,) once trained\n",
        " \n",
        "    def train_ensemble(self, x_train, y_train, objective='brier'):\n",
        "        \"\"\"\n",
        "        Train the ensemble for a single timestep using validation data.\n",
        "        \"\"\"\n",
        "        print(f\"Training ensemble for this timestep...\")\n",
        "        if self.strategy == 'weighted_average':\n",
        "            self.optimize_ensemble_weights(x_train, y_train, objective)\n",
        "        elif self.strategy == 'meta_model':\n",
        "            self.train_meta_model(x_train, y_train)\n",
        "\n",
        "    def optimize_ensemble_weights(self, x_train, y_train, objective='brier'):\n",
        "        \"\"\"\n",
        "        Optimize ensemble weights for a single timestep using validation data.\n",
        "        \"\"\"\n",
        "        print(f\"Optimizing ensemble weights for this timestep...\")\n",
        "\n",
        "        n_models = x_train.shape[1]\n",
        "\n",
        "        def objective_function(weights):\n",
        "            weights = weights / np.sum(weights)  # Normalize weights\n",
        "            ensemble_preds = np.dot(x_train, weights)\n",
        "\n",
        "            if objective == 'brier':\n",
        "                ensemble_preds = np.clip(ensemble_preds, 1e-15, 1-1e-15)\n",
        "                return brier_score_loss(y_train, ensemble_preds)\n",
        "            elif objective == 'logloss':\n",
        "                # Clip predictions to avoid log(0)\n",
        "                ensemble_preds = np.clip(ensemble_preds, 1e-15, 1-1e-15)\n",
        "                return log_loss(y_train, ensemble_preds)\n",
        "            elif objective == 'accuracy':\n",
        "                return -accuracy_score(y_train, ensemble_preds > 0.5)  # Negative for minimization\n",
        "\n",
        "        # Constraints: weights sum to 1 and are non-negative\n",
        "        constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
        "        bounds = [(0, 1) for _ in range(n_models)]\n",
        "\n",
        "        # Initialize with equal weights\n",
        "        initial_weights = np.ones(n_models) / n_models\n",
        "\n",
        "        result = minimize(objective_function, initial_weights,\n",
        "                          method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "\n",
        "        if result.success:\n",
        "            self.ensemble_weights = result.x\n",
        "            print(f\"  Optimized weights: {dict(zip(self.all_models_order, result.x.round(4)))} (score: {result.fun:.6f})\")\n",
        "        else:\n",
        "            print(f\"  Optimization failed, using equal weights\")\n",
        "            self.ensemble_weights = initial_weights\n",
        "\n",
        "        return self.ensemble_weights\n",
        "\n",
        "    def train_meta_model(self, x_train, y_train):\n",
        "        \"\"\"\n",
        "        Train a meta-model for a single timestep to predict based on base model outputs.\n",
        "        \"\"\"\n",
        "        X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "        # Train meta-model: input=base_model_predictions, output=final_prediction\n",
        "        self.meta_model.fit(X_train, y_train.reshape(-1, 1))\n",
        "\n",
        "        # Test the meta-model's prediction capability\n",
        "        meta_predictions = self.meta_model.predict_proba(X_val)[:, 1]\n",
        "        meta_accuracy = accuracy_score(y_val, meta_predictions > 0.5)\n",
        "        meta_brier = brier_score_loss(y_val, meta_predictions)\n",
        "\n",
        "        print(f\"  Meta-model trained on {len(X_train)} samples\")\n",
        "        print(f\"    Validation Meta-model accuracy: {meta_accuracy:.4f}, Validation Brier score: {meta_brier:.4f}\")\n",
        "\n",
        "        return self.meta_model\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probability of the positive class for a given input\n",
        "        \"\"\"\n",
        "        # Generate predictions from each individual model\n",
        "        # Convert X to a 3D array of shape (n_samples, n_history, n_features)\n",
        "        predictions = [] # Will be a 2D array of shape (n_samples, n_models)\n",
        "        for i, model_name in enumerate(self.all_models_order):\n",
        "            model = self.all_models[model_name]\n",
        "            # print(\"Model name: \", model_name)\n",
        "            if model_name == \"lstm\":\n",
        "                # print(X.shape)\n",
        "                pred = model.predict_proba(X)\n",
        "                # print(pred)\n",
        "                predictions.append(pred[:, 1])\n",
        "            else:\n",
        "                # print(X.shape)\n",
        "                x = np.array([X[i][-1] for i in range(X.shape[0])]) if len(X.shape) == 3 else np.array([X[-1]])\n",
        "                # print(x.shape)\n",
        "                pred = model.predict_proba(x)\n",
        "                # print(pred)\n",
        "                predictions.append(pred[:, 1]) # Will be a 1D array of shape (n_samples,) for each model\n",
        "        predictions = np.array(predictions) # Will be a 2D array of shape (n_models, n_samples)\n",
        "        predictions = predictions.T # Reshape to be a 2D array of shape (n_samples, n_models)\n",
        "        if self.strategy == 'weighted_average':\n",
        "            return np.dot(predictions, self.ensemble_weights)\n",
        "        elif self.strategy == 'meta_model':\n",
        "            return self.meta_model.predict_proba(predictions)[:, 1]\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probability of the positive class for a given input\n",
        "        \"\"\"\n",
        "        pred = self.predict(X).flatten()\n",
        "        return np.column_stack([1 - pred, pred])\n",
        "\n",
        "    def predict_proba_single(self, X):\n",
        "        preds = self.predict_proba(X)\n",
        "        return preds[:, 1]\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        Score the ensemble for a given input\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "        y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "        return np.mean(y_pred_labels == y)\n",
        "    \n",
        "    def SHAP_analysis(self, X_test, X_train, plot = True):\n",
        "        \"\"\"\n",
        "        Model interpretability with SHAP values\n",
        "        \"\"\"\n",
        "        feature_names = self.all_features\n",
        "        masker = shap.maskers.Independent(X_train[:10])\n",
        "        explainer = shap.Explainer(self.predict_proba_single, masker, feature_names=self.all_features)\n",
        "        shap_values = explainer(X_test)\n",
        "        if plot:\n",
        "            shap.plots.bar(shap_values)\n",
        "        return shap_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload modules\n",
        "modules_to_reload = [\n",
        "    'models.xg_boost',\n",
        "    'models.direct_prediction_network_lstm',\n",
        "    'models.direct_prediction_network',\n",
        "    'models.logistic_regression',\n",
        "    'models.Model'\n",
        "    'models.DL_Model'\n",
        "]\n",
        "\n",
        "for module_name in modules_to_reload:\n",
        "    if module_name in sys.modules:\n",
        "        del sys.modules[module_name]\n",
        "from models.xg_boost import setup_xgboost_models\n",
        "from models.direct_prediction_network_lstm import setup_direct_lstm_models\n",
        "from models.direct_prediction_network import setup_direct_models\n",
        "from models.logistic_regression import setup_logistic_regression_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split training data: 3393 train, 377 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.0, 0.005]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.6519, Train Loss: 0.2180, Val Acc: 0.6605, Val Loss: 0.2183\n",
            "Restored model from best epoch 12 with val_loss: 0.218330\n",
            "NFL LSTM model 1/201 completed\n",
            "Split training data: 1139 train, 127 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.005, 0.01]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 2/201 completed\n",
            "Split training data: 2235 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.01, 0.015]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.6532, Train Loss: 0.2141, Val Acc: 0.6426, Val Loss: 0.2183\n",
            "Restored model from best epoch 19 with val_loss: 0.218267\n",
            "NFL LSTM model 3/201 completed\n",
            "Split training data: 1883 train, 210 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.015, 0.02]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 7\n",
            "Best epoch: 2, Train Acc: 0.6091, Train Loss: 0.2329, Val Acc: 0.6381, Val Loss: 0.2290\n",
            "Restored model from best epoch 2 with val_loss: 0.229039\n",
            "NFL LSTM model 4/201 completed\n",
            "Split training data: 2074 train, 231 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.02, 0.025]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.6369, Train Loss: 0.2237, Val Acc: 0.6407, Val Loss: 0.2178\n",
            "Restored model from best epoch 6 with val_loss: 0.217828\n",
            "NFL LSTM model 5/201 completed\n",
            "Split training data: 2161 train, 241 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.025, 0.03]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 7\n",
            "Best epoch: 2, Train Acc: 0.6085, Train Loss: 0.2326, Val Acc: 0.5851, Val Loss: 0.2414\n",
            "Restored model from best epoch 2 with val_loss: 0.241376\n",
            "NFL LSTM model 6/201 completed\n",
            "Split training data: 2041 train, 227 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.03, 0.035]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 7/201 completed\n",
            "Split training data: 2243 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.035, 0.04]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.6465, Train Loss: 0.2175, Val Acc: 0.6560, Val Loss: 0.2171\n",
            "Restored model from best epoch 18 with val_loss: 0.217102\n",
            "NFL LSTM model 8/201 completed\n",
            "Split training data: 2115 train, 236 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.04, 0.045]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6279, Train Loss: 0.2261, Val Acc: 0.5847, Val Loss: 0.2303\n",
            "Restored model from best epoch 3 with val_loss: 0.230344\n",
            "NFL LSTM model 9/201 completed\n",
            "Split training data: 2267 train, 252 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.045, 0.05]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.6480, Train Loss: 0.2197, Val Acc: 0.6429, Val Loss: 0.2119\n",
            "Restored model from best epoch 15 with val_loss: 0.211925\n",
            "NFL LSTM model 10/201 completed\n",
            "Split training data: 2220 train, 247 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.05, 0.055]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 7\n",
            "Best epoch: 2, Train Acc: 0.6338, Train Loss: 0.2267, Val Acc: 0.5628, Val Loss: 0.2339\n",
            "Restored model from best epoch 2 with val_loss: 0.233885\n",
            "NFL LSTM model 11/201 completed\n",
            "Split training data: 2097 train, 234 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.055, 0.06]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6466, Train Loss: 0.2231, Val Acc: 0.6538, Val Loss: 0.2256\n",
            "Restored model from best epoch 3 with val_loss: 0.225594\n",
            "NFL LSTM model 12/201 completed\n",
            "Split training data: 2318 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.06, 0.065]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 7\n",
            "Best epoch: 2, Train Acc: 0.6195, Train Loss: 0.2280, Val Acc: 0.6124, Val Loss: 0.2340\n",
            "Restored model from best epoch 2 with val_loss: 0.234020\n",
            "NFL LSTM model 13/201 completed\n",
            "Split training data: 2241 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.065, 0.07]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.6515, Train Loss: 0.2259, Val Acc: 0.7200, Val Loss: 0.2041\n",
            "Restored model from best epoch 11 with val_loss: 0.204119\n",
            "NFL LSTM model 14/201 completed\n",
            "Split training data: 2275 train, 253 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.07, 0.075]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6387, Train Loss: 0.2274, Val Acc: 0.6443, Val Loss: 0.2224\n",
            "Restored model from best epoch 3 with val_loss: 0.222425\n",
            "NFL LSTM model 15/201 completed\n",
            "Split training data: 2212 train, 246 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.075, 0.08]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6203, Train Loss: 0.2274, Val Acc: 0.6179, Val Loss: 0.2281\n",
            "Restored model from best epoch 3 with val_loss: 0.228103\n",
            "NFL LSTM model 16/201 completed\n",
            "Split training data: 2286 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.08, 0.085]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.6789, Train Loss: 0.2107, Val Acc: 0.6902, Val Loss: 0.2007\n",
            "Restored model from best epoch 14 with val_loss: 0.200704\n",
            "NFL LSTM model 17/201 completed\n",
            "Split training data: 2315 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.085, 0.09]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.6734, Train Loss: 0.2095, Val Acc: 0.6512, Val Loss: 0.2054\n",
            "Restored model from best epoch 17 with val_loss: 0.205418\n",
            "NFL LSTM model 18/201 completed\n",
            "Split training data: 2205 train, 245 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.09, 0.095]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.6594, Train Loss: 0.2141, Val Acc: 0.7020, Val Loss: 0.2079\n",
            "Restored model from best epoch 11 with val_loss: 0.207905\n",
            "NFL LSTM model 19/201 completed\n",
            "Split training data: 2305 train, 257 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.095, 0.1]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6360, Train Loss: 0.2235, Val Acc: 0.6381, Val Loss: 0.2230\n",
            "Restored model from best epoch 3 with val_loss: 0.223047\n",
            "NFL LSTM model 20/201 completed\n",
            "Split training data: 2294 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.1, 0.105]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.6944, Train Loss: 0.2017, Val Acc: 0.6941, Val Loss: 0.2023\n",
            "Restored model from best epoch 25 with val_loss: 0.202314\n",
            "NFL LSTM model 21/201 completed\n",
            "Split training data: 2244 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.105, 0.11]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.6809, Train Loss: 0.2077, Val Acc: 0.7160, Val Loss: 0.1935\n",
            "Restored model from best epoch 14 with val_loss: 0.193465\n",
            "NFL LSTM model 22/201 completed\n",
            "Split training data: 2311 train, 257 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.11, 0.115]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.6720, Train Loss: 0.2096, Val Acc: 0.6420, Val Loss: 0.1926\n",
            "Restored model from best epoch 12 with val_loss: 0.192577\n",
            "NFL LSTM model 23/201 completed\n",
            "Split training data: 2235 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.115, 0.12]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 24/201 completed\n",
            "Split training data: 2291 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.12, 0.125]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.6744, Train Loss: 0.2079, Val Acc: 0.6667, Val Loss: 0.2052\n",
            "Restored model from best epoch 16 with val_loss: 0.205160\n",
            "NFL LSTM model 25/201 completed\n",
            "Split training data: 2341 train, 261 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.125, 0.13]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 26/201 completed\n",
            "Split training data: 2284 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.13, 0.135]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.6940, Train Loss: 0.1964, Val Acc: 0.7008, Val Loss: 0.2013\n",
            "Restored model from best epoch 20 with val_loss: 0.201324\n",
            "NFL LSTM model 27/201 completed\n",
            "Split training data: 2243 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.135, 0.14]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 28/201 completed\n",
            "Split training data: 2242 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.14, 0.145]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6753, Train Loss: 0.2130, Val Acc: 0.6520, Val Loss: 0.2227\n",
            "Restored model from best epoch 3 with val_loss: 0.222690\n",
            "NFL LSTM model 29/201 completed\n",
            "Split training data: 2248 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.145, 0.15]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.6730, Train Loss: 0.2067, Val Acc: 0.6960, Val Loss: 0.2075\n",
            "Restored model from best epoch 6 with val_loss: 0.207548\n",
            "NFL LSTM model 30/201 completed\n",
            "Split training data: 2324 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.15, 0.155]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.6962, Train Loss: 0.2002, Val Acc: 0.6602, Val Loss: 0.2030\n",
            "Restored model from best epoch 10 with val_loss: 0.202999\n",
            "NFL LSTM model 31/201 completed\n",
            "Split training data: 2149 train, 239 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.155, 0.16]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.7040, Train Loss: 0.1955, Val Acc: 0.7238, Val Loss: 0.1899\n",
            "Restored model from best epoch 10 with val_loss: 0.189889\n",
            "NFL LSTM model 32/201 completed\n",
            "Split training data: 2342 train, 261 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.16, 0.165]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 33/201 completed\n",
            "Split training data: 2180 train, 243 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.165, 0.17]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.6963, Train Loss: 0.2022, Val Acc: 0.7119, Val Loss: 0.1979\n",
            "Restored model from best epoch 24 with val_loss: 0.197935\n",
            "NFL LSTM model 34/201 completed\n",
            "Split training data: 2304 train, 257 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.17, 0.175]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7023, Train Loss: 0.1996, Val Acc: 0.7121, Val Loss: 0.2049\n",
            "Restored model from best epoch 12 with val_loss: 0.204851\n",
            "NFL LSTM model 35/201 completed\n",
            "Split training data: 2300 train, 256 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.175, 0.18]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.6961, Train Loss: 0.2011, Val Acc: 0.6523, Val Loss: 0.2120\n",
            "Restored model from best epoch 25 with val_loss: 0.212042\n",
            "NFL LSTM model 36/201 completed\n",
            "Split training data: 2200 train, 245 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.18, 0.185]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.6959, Train Loss: 0.1978, Val Acc: 0.7020, Val Loss: 0.2001\n",
            "Restored model from best epoch 10 with val_loss: 0.200113\n",
            "NFL LSTM model 37/201 completed\n",
            "Split training data: 2241 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.185, 0.19]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6738, Train Loss: 0.2128, Val Acc: 0.6546, Val Loss: 0.2114\n",
            "Restored model from best epoch 3 with val_loss: 0.211402\n",
            "NFL LSTM model 38/201 completed\n",
            "Split training data: 2232 train, 248 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.19, 0.195]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.6935, Train Loss: 0.2002, Val Acc: 0.7419, Val Loss: 0.1872\n",
            "Restored model from best epoch 13 with val_loss: 0.187167\n",
            "NFL LSTM model 39/201 completed\n",
            "Split training data: 2286 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.195, 0.2]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7082, Train Loss: 0.1939, Val Acc: 0.6890, Val Loss: 0.2057\n",
            "Restored model from best epoch 11 with val_loss: 0.205746\n",
            "NFL LSTM model 40/201 completed\n",
            "Split training data: 2232 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.2, 0.205]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6810, Train Loss: 0.2080, Val Acc: 0.6827, Val Loss: 0.2045\n",
            "Restored model from best epoch 3 with val_loss: 0.204540\n",
            "NFL LSTM model 41/201 completed\n",
            "Split training data: 2255 train, 251 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.205, 0.21]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.7144, Train Loss: 0.1908, Val Acc: 0.6892, Val Loss: 0.1926\n",
            "Restored model from best epoch 24 with val_loss: 0.192608\n",
            "NFL LSTM model 42/201 completed\n",
            "Split training data: 2411 train, 268 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.21, 0.215]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.7018, Train Loss: 0.1926, Val Acc: 0.7537, Val Loss: 0.1763\n",
            "Restored model from best epoch 17 with val_loss: 0.176268\n",
            "NFL LSTM model 43/201 completed\n",
            "Split training data: 2185 train, 243 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.215, 0.22]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.6975, Train Loss: 0.2001, Val Acc: 0.7078, Val Loss: 0.1851\n",
            "Restored model from best epoch 15 with val_loss: 0.185068\n",
            "NFL LSTM model 44/201 completed\n",
            "Split training data: 2283 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.22, 0.225]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.7162, Train Loss: 0.1872, Val Acc: 0.7362, Val Loss: 0.1805\n",
            "Restored model from best epoch 24 with val_loss: 0.180510\n",
            "NFL LSTM model 45/201 completed\n",
            "Split training data: 2292 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.225, 0.23]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7125, Train Loss: 0.1934, Val Acc: 0.7255, Val Loss: 0.1767\n",
            "Restored model from best epoch 7 with val_loss: 0.176671\n",
            "NFL LSTM model 46/201 completed\n",
            "Split training data: 2232 train, 248 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.23, 0.235]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6855, Train Loss: 0.2049, Val Acc: 0.7016, Val Loss: 0.2135\n",
            "Restored model from best epoch 3 with val_loss: 0.213543\n",
            "NFL LSTM model 47/201 completed\n",
            "Split training data: 2323 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.235, 0.24]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.7155, Train Loss: 0.1905, Val Acc: 0.7413, Val Loss: 0.1861\n",
            "Restored model from best epoch 9 with val_loss: 0.186093\n",
            "NFL LSTM model 48/201 completed\n",
            "Split training data: 2203 train, 245 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.24, 0.245]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.6927, Train Loss: 0.1993, Val Acc: 0.6408, Val Loss: 0.2220\n",
            "Restored model from best epoch 8 with val_loss: 0.222028\n",
            "NFL LSTM model 49/201 completed\n",
            "Split training data: 2040 train, 227 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.245, 0.25]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6828, Train Loss: 0.2052, Val Acc: 0.6520, Val Loss: 0.2025\n",
            "Restored model from best epoch 4 with val_loss: 0.202453\n",
            "NFL LSTM model 50/201 completed\n",
            "Split training data: 6714 train, 746 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.25, 0.255]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.7148, Train Loss: 0.1884, Val Acc: 0.7292, Val Loss: 0.1769\n",
            "Restored model from best epoch 18 with val_loss: 0.176863\n",
            "NFL LSTM model 51/201 completed\n",
            "Split training data: 1301 train, 145 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.255, 0.26]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 52/201 completed\n",
            "Split training data: 1753 train, 195 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.26, 0.265]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.7159, Train Loss: 0.1905, Val Acc: 0.7231, Val Loss: 0.2060\n",
            "Restored model from best epoch 25 with val_loss: 0.206022\n",
            "NFL LSTM model 53/201 completed\n",
            "Split training data: 2403 train, 267 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.265, 0.27]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7220, Train Loss: 0.1861, Val Acc: 0.6929, Val Loss: 0.1860\n",
            "Restored model from best epoch 12 with val_loss: 0.185960\n",
            "NFL LSTM model 54/201 completed\n",
            "Split training data: 2106 train, 234 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.27, 0.275]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.7251, Train Loss: 0.1847, Val Acc: 0.6795, Val Loss: 0.2109\n",
            "Restored model from best epoch 22 with val_loss: 0.210903\n",
            "NFL LSTM model 55/201 completed\n",
            "Split training data: 2423 train, 270 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.275, 0.28]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 56/201 completed\n",
            "Split training data: 2113 train, 235 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.28, 0.285]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.7184, Train Loss: 0.1840, Val Acc: 0.6894, Val Loss: 0.2036\n",
            "Restored model from best epoch 23 with val_loss: 0.203637\n",
            "NFL LSTM model 57/201 completed\n",
            "Split training data: 2479 train, 276 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.285, 0.29]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7136, Train Loss: 0.1925, Val Acc: 0.7138, Val Loss: 0.1889\n",
            "Restored model from best epoch 4 with val_loss: 0.188881\n",
            "NFL LSTM model 58/201 completed\n",
            "Split training data: 2220 train, 247 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.29, 0.295]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.7068, Train Loss: 0.1953, Val Acc: 0.7085, Val Loss: 0.1881\n",
            "Restored model from best epoch 9 with val_loss: 0.188086\n",
            "NFL LSTM model 59/201 completed\n",
            "Split training data: 2266 train, 252 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.295, 0.3]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.7132, Train Loss: 0.1896, Val Acc: 0.6865, Val Loss: 0.2004\n",
            "Restored model from best epoch 16 with val_loss: 0.200409\n",
            "NFL LSTM model 60/201 completed\n",
            "Split training data: 2277 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.3, 0.305]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7137, Train Loss: 0.1884, Val Acc: 0.7362, Val Loss: 0.1853\n",
            "Restored model from best epoch 11 with val_loss: 0.185333\n",
            "NFL LSTM model 61/201 completed\n",
            "Split training data: 2205 train, 245 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.305, 0.31]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 62/201 completed\n",
            "Split training data: 2309 train, 257 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.31, 0.315]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7224, Train Loss: 0.1890, Val Acc: 0.7354, Val Loss: 0.1842\n",
            "Restored model from best epoch 5 with val_loss: 0.184170\n",
            "NFL LSTM model 63/201 completed\n",
            "Split training data: 2282 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.315, 0.32]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 64/201 completed\n",
            "Split training data: 2301 train, 256 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.32, 0.325]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 65/201 completed\n",
            "Split training data: 2222 train, 247 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.325, 0.33]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7097, Train Loss: 0.1900, Val Acc: 0.7166, Val Loss: 0.1859\n",
            "Restored model from best epoch 5 with val_loss: 0.185904\n",
            "NFL LSTM model 66/201 completed\n",
            "Split training data: 2290 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.33, 0.335]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6996, Train Loss: 0.1930, Val Acc: 0.7451, Val Loss: 0.1740\n",
            "Restored model from best epoch 5 with val_loss: 0.174026\n",
            "NFL LSTM model 67/201 completed\n",
            "Split training data: 2318 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.335, 0.34]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.7286, Train Loss: 0.1813, Val Acc: 0.7791, Val Loss: 0.1477\n",
            "Restored model from best epoch 14 with val_loss: 0.147702\n",
            "NFL LSTM model 68/201 completed\n",
            "Split training data: 2279 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.34, 0.345]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 69/201 completed\n",
            "Split training data: 2349 train, 262 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.345, 0.35]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.7246, Train Loss: 0.1886, Val Acc: 0.7061, Val Loss: 0.1887\n",
            "Restored model from best epoch 3 with val_loss: 0.188689\n",
            "NFL LSTM model 70/201 completed\n",
            "Split training data: 2272 train, 253 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.35, 0.355]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7183, Train Loss: 0.1870, Val Acc: 0.7312, Val Loss: 0.1866\n",
            "Restored model from best epoch 4 with val_loss: 0.186601\n",
            "NFL LSTM model 71/201 completed\n",
            "Split training data: 2321 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.355, 0.36]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 72/201 completed\n",
            "Split training data: 2238 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.36, 0.365]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.7319, Train Loss: 0.1831, Val Acc: 0.7550, Val Loss: 0.1687\n",
            "Restored model from best epoch 24 with val_loss: 0.168737\n",
            "NFL LSTM model 73/201 completed\n",
            "Split training data: 2331 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.365, 0.37]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7344, Train Loss: 0.1776, Val Acc: 0.7220, Val Loss: 0.1741\n",
            "Restored model from best epoch 12 with val_loss: 0.174108\n",
            "NFL LSTM model 74/201 completed\n",
            "Split training data: 2235 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.37, 0.375]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.7306, Train Loss: 0.1831, Val Acc: 0.7510, Val Loss: 0.1745\n",
            "Restored model from best epoch 15 with val_loss: 0.174490\n",
            "NFL LSTM model 75/201 completed\n",
            "Split training data: 2330 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.375, 0.38]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7451, Train Loss: 0.1769, Val Acc: 0.7220, Val Loss: 0.1884\n",
            "Restored model from best epoch 12 with val_loss: 0.188426\n",
            "NFL LSTM model 76/201 completed\n",
            "Split training data: 2268 train, 252 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.38, 0.385]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.7557, Train Loss: 0.1708, Val Acc: 0.7619, Val Loss: 0.1636\n",
            "Restored model from best epoch 22 with val_loss: 0.163590\n",
            "NFL LSTM model 77/201 completed\n",
            "Split training data: 2271 train, 253 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.385, 0.39]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.7525, Train Loss: 0.1705, Val Acc: 0.7826, Val Loss: 0.1684\n",
            "Restored model from best epoch 23 with val_loss: 0.168420\n",
            "NFL LSTM model 78/201 completed\n",
            "Split training data: 2249 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.39, 0.395]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7328, Train Loss: 0.1807, Val Acc: 0.7840, Val Loss: 0.1594\n",
            "Restored model from best epoch 8 with val_loss: 0.159427\n",
            "NFL LSTM model 79/201 completed\n",
            "Split training data: 2289 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.395, 0.4]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.7383, Train Loss: 0.1762, Val Acc: 0.7020, Val Loss: 0.1913\n",
            "Restored model from best epoch 17 with val_loss: 0.191298\n",
            "NFL LSTM model 80/201 completed\n",
            "Split training data: 2264 train, 252 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.4, 0.405]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7310, Train Loss: 0.1838, Val Acc: 0.6905, Val Loss: 0.1818\n",
            "Restored model from best epoch 6 with val_loss: 0.181754\n",
            "NFL LSTM model 81/201 completed\n",
            "Split training data: 2164 train, 241 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.405, 0.41]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 82/201 completed\n",
            "Split training data: 2355 train, 262 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.41, 0.415]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7329, Train Loss: 0.1787, Val Acc: 0.7328, Val Loss: 0.1740\n",
            "Restored model from best epoch 11 with val_loss: 0.174024\n",
            "NFL LSTM model 83/201 completed\n",
            "Split training data: 2241 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.415, 0.42]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 84/201 completed\n",
            "Split training data: 2340 train, 261 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.42, 0.425]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7167, Train Loss: 0.1868, Val Acc: 0.7471, Val Loss: 0.1738\n",
            "Restored model from best epoch 6 with val_loss: 0.173845\n",
            "NFL LSTM model 85/201 completed\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.425, 0.43]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.7562, Train Loss: 0.1676, Val Acc: 0.7558, Val Loss: 0.1536\n",
            "Restored model from best epoch 23 with val_loss: 0.153624\n",
            "NFL LSTM model 86/201 completed\n",
            "Split training data: 2240 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.43, 0.435]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 87/201 completed\n",
            "Split training data: 2331 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.435, 0.44]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.7602, Train Loss: 0.1705, Val Acc: 0.7683, Val Loss: 0.1601\n",
            "Restored model from best epoch 13 with val_loss: 0.160066\n",
            "NFL LSTM model 88/201 completed\n",
            "Split training data: 2250 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.44, 0.445]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.7476, Train Loss: 0.1719, Val Acc: 0.7320, Val Loss: 0.1739\n",
            "Restored model from best epoch 10 with val_loss: 0.173861\n",
            "NFL LSTM model 89/201 completed\n",
            "Split training data: 2328 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.445, 0.45]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7393, Train Loss: 0.1767, Val Acc: 0.7529, Val Loss: 0.1742\n",
            "Restored model from best epoch 7 with val_loss: 0.174192\n",
            "NFL LSTM model 90/201 completed\n",
            "Split training data: 2286 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.45, 0.455]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 91/201 completed\n",
            "Split training data: 2288 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.455, 0.46]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7378, Train Loss: 0.1801, Val Acc: 0.7647, Val Loss: 0.1640\n",
            "Restored model from best epoch 6 with val_loss: 0.163952\n",
            "NFL LSTM model 92/201 completed\n",
            "Split training data: 2358 train, 263 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.46, 0.465]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.7680, Train Loss: 0.1618, Val Acc: 0.7376, Val Loss: 0.1766\n",
            "Restored model from best epoch 15 with val_loss: 0.176560\n",
            "NFL LSTM model 93/201 completed\n",
            "Split training data: 2157 train, 240 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.465, 0.47]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 94/201 completed\n",
            "Split training data: 6358 train, 707 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.47, 0.475]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 95/201 completed\n",
            "Split training data: 3238 train, 360 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.475, 0.48]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 7\n",
            "Best epoch: 2, Train Acc: 0.7486, Train Loss: 0.1708, Val Acc: 0.7194, Val Loss: 0.1710\n",
            "Restored model from best epoch 2 with val_loss: 0.170992\n",
            "NFL LSTM model 96/201 completed\n",
            "Split training data: 3429 train, 381 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.48, 0.485]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.7900, Train Loss: 0.1513, Val Acc: 0.7900, Val Loss: 0.1504\n",
            "Restored model from best epoch 15 with val_loss: 0.150367\n",
            "NFL LSTM model 97/201 completed\n",
            "Split training data: 3904 train, 434 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.485, 0.49]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.7664, Train Loss: 0.1590, Val Acc: 0.8134, Val Loss: 0.1371\n",
            "Restored model from best epoch 14 with val_loss: 0.137110\n",
            "NFL LSTM model 98/201 completed\n",
            "Split training data: 4725 train, 525 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.49, 0.495]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.7858, Train Loss: 0.1535, Val Acc: 0.7695, Val Loss: 0.1592\n",
            "Restored model from best epoch 15 with val_loss: 0.159152\n",
            "NFL LSTM model 99/201 completed\n",
            "Split training data: 5760 train, 641 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.495, 0.5]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7832, Train Loss: 0.1539, Val Acc: 0.7988, Val Loss: 0.1712\n",
            "Restored model from best epoch 11 with val_loss: 0.171179\n",
            "NFL LSTM model 100/201 completed\n",
            "Split training data: 10401 train, 1156 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.5, 0.505]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7792, Train Loss: 0.1558, Val Acc: 0.8080, Val Loss: 0.1351\n",
            "Restored model from best epoch 6 with val_loss: 0.135124\n",
            "NFL LSTM model 101/201 completed\n",
            "Split training data: 1260 train, 140 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.505, 0.51]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 102/201 completed\n",
            "Split training data: 2133 train, 238 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.51, 0.515]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7782, Train Loss: 0.1537, Val Acc: 0.8067, Val Loss: 0.1515\n",
            "Restored model from best epoch 6 with val_loss: 0.151463\n",
            "NFL LSTM model 103/201 completed\n",
            "Split training data: 1874 train, 209 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.515, 0.52]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.7978, Train Loss: 0.1489, Val Acc: 0.7943, Val Loss: 0.1409\n",
            "Restored model from best epoch 19 with val_loss: 0.140938\n",
            "NFL LSTM model 104/201 completed\n",
            "Split training data: 2118 train, 236 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.52, 0.525]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7710, Train Loss: 0.1646, Val Acc: 0.8051, Val Loss: 0.1433\n",
            "Restored model from best epoch 4 with val_loss: 0.143282\n",
            "NFL LSTM model 105/201 completed\n",
            "Split training data: 2259 train, 251 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.525, 0.53]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.7902, Train Loss: 0.1449, Val Acc: 0.8008, Val Loss: 0.1539\n",
            "Restored model from best epoch 14 with val_loss: 0.153938\n",
            "NFL LSTM model 106/201 completed\n",
            "Split training data: 2111 train, 235 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.53, 0.535]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7674, Train Loss: 0.1647, Val Acc: 0.7872, Val Loss: 0.1453\n",
            "Restored model from best epoch 4 with val_loss: 0.145272\n",
            "NFL LSTM model 107/201 completed\n",
            "Split training data: 2259 train, 251 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.535, 0.54]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.7950, Train Loss: 0.1447, Val Acc: 0.8367, Val Loss: 0.1244\n",
            "Restored model from best epoch 21 with val_loss: 0.124364\n",
            "NFL LSTM model 108/201 completed\n",
            "Split training data: 2178 train, 242 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.54, 0.545]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7819, Train Loss: 0.1528, Val Acc: 0.7851, Val Loss: 0.1564\n",
            "Restored model from best epoch 8 with val_loss: 0.156447\n",
            "NFL LSTM model 109/201 completed\n",
            "Split training data: 2151 train, 239 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.545, 0.55]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 7\n",
            "Best epoch: 2, Train Acc: 0.7569, Train Loss: 0.1722, Val Acc: 0.7322, Val Loss: 0.1672\n",
            "Restored model from best epoch 2 with val_loss: 0.167235\n",
            "NFL LSTM model 110/201 completed\n",
            "Split training data: 2219 train, 247 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.55, 0.555]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.8053, Train Loss: 0.1420, Val Acc: 0.8219, Val Loss: 0.1383\n",
            "Restored model from best epoch 18 with val_loss: 0.138330\n",
            "NFL LSTM model 111/201 completed\n",
            "Split training data: 2216 train, 247 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.555, 0.56]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7893, Train Loss: 0.1577, Val Acc: 0.8057, Val Loss: 0.1397\n",
            "Restored model from best epoch 4 with val_loss: 0.139667\n",
            "NFL LSTM model 112/201 completed\n",
            "Split training data: 2277 train, 253 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.56, 0.565]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8085, Train Loss: 0.1421, Val Acc: 0.8419, Val Loss: 0.1192\n",
            "Restored model from best epoch 22 with val_loss: 0.119186\n",
            "NFL LSTM model 113/201 completed\n",
            "Split training data: 2237 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.565, 0.57]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.8011, Train Loss: 0.1424, Val Acc: 0.8032, Val Loss: 0.1436\n",
            "Restored model from best epoch 23 with val_loss: 0.143648\n",
            "NFL LSTM model 114/201 completed\n",
            "Split training data: 2301 train, 256 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.57, 0.575]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 115/201 completed\n",
            "Split training data: 2301 train, 256 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.575, 0.58]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.7931, Train Loss: 0.1502, Val Acc: 0.7656, Val Loss: 0.1643\n",
            "Restored model from best epoch 14 with val_loss: 0.164319\n",
            "NFL LSTM model 116/201 completed\n",
            "Split training data: 2237 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.58, 0.585]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.7957, Train Loss: 0.1447, Val Acc: 0.7671, Val Loss: 0.1565\n",
            "Restored model from best epoch 22 with val_loss: 0.156496\n",
            "NFL LSTM model 117/201 completed\n",
            "Split training data: 2281 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.585, 0.59]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7957, Train Loss: 0.1478, Val Acc: 0.7992, Val Loss: 0.1320\n",
            "Restored model from best epoch 6 with val_loss: 0.131959\n",
            "NFL LSTM model 118/201 completed\n",
            "Split training data: 2366 train, 263 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.59, 0.595]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.7899, Train Loss: 0.1487, Val Acc: 0.7909, Val Loss: 0.1437\n",
            "Restored model from best epoch 21 with val_loss: 0.143750\n",
            "NFL LSTM model 119/201 completed\n",
            "Split training data: 2289 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.595, 0.6]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.8117, Train Loss: 0.1379, Val Acc: 0.7686, Val Loss: 0.1602\n",
            "Restored model from best epoch 18 with val_loss: 0.160229\n",
            "NFL LSTM model 120/201 completed\n",
            "Split training data: 2282 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.6, 0.605]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 121/201 completed\n",
            "Split training data: 2314 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.605, 0.61]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7835, Train Loss: 0.1555, Val Acc: 0.8023, Val Loss: 0.1447\n",
            "Restored model from best epoch 4 with val_loss: 0.144664\n",
            "NFL LSTM model 122/201 completed\n",
            "Split training data: 2331 train, 260 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.61, 0.615]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 123/201 completed\n",
            "Split training data: 2274 train, 253 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.615, 0.62]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8026, Train Loss: 0.1416, Val Acc: 0.7549, Val Loss: 0.1582\n",
            "Restored model from best epoch 7 with val_loss: 0.158157\n",
            "NFL LSTM model 124/201 completed\n",
            "Split training data: 2240 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.62, 0.625]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 125/201 completed\n",
            "Split training data: 2330 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.625, 0.63]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8013, Train Loss: 0.1409, Val Acc: 0.7761, Val Loss: 0.1720\n",
            "Restored model from best epoch 12 with val_loss: 0.171961\n",
            "NFL LSTM model 126/201 completed\n",
            "Split training data: 2313 train, 257 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.63, 0.635]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8085, Train Loss: 0.1378, Val Acc: 0.7938, Val Loss: 0.1209\n",
            "Restored model from best epoch 9 with val_loss: 0.120925\n",
            "NFL LSTM model 127/201 completed\n",
            "Split training data: 2301 train, 256 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.635, 0.64]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 128/201 completed\n",
            "Split training data: 2157 train, 240 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.64, 0.645]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 129/201 completed\n",
            "Split training data: 2348 train, 261 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.645, 0.65]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.7930, Train Loss: 0.1529, Val Acc: 0.7778, Val Loss: 0.1670\n",
            "Restored model from best epoch 3 with val_loss: 0.166980\n",
            "NFL LSTM model 130/201 completed\n",
            "Split training data: 2275 train, 253 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.65, 0.655]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 131/201 completed\n",
            "Split training data: 2324 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.655, 0.66]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 132/201 completed\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.66, 0.665]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.7903, Train Loss: 0.1555, Val Acc: 0.7713, Val Loss: 0.1601\n",
            "Restored model from best epoch 3 with val_loss: 0.160076\n",
            "NFL LSTM model 133/201 completed\n",
            "Split training data: 2284 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.665, 0.67]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8100, Train Loss: 0.1334, Val Acc: 0.8307, Val Loss: 0.1218\n",
            "Restored model from best epoch 10 with val_loss: 0.121819\n",
            "NFL LSTM model 134/201 completed\n",
            "Split training data: 2227 train, 248 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.67, 0.675]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.8298, Train Loss: 0.1263, Val Acc: 0.8065, Val Loss: 0.1442\n",
            "Restored model from best epoch 16 with val_loss: 0.144227\n",
            "NFL LSTM model 135/201 completed\n",
            "Split training data: 2290 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.675, 0.68]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8066, Train Loss: 0.1378, Val Acc: 0.8039, Val Loss: 0.1338\n",
            "Restored model from best epoch 9 with val_loss: 0.133767\n",
            "NFL LSTM model 136/201 completed\n",
            "Split training data: 2250 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.68, 0.685]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8129, Train Loss: 0.1335, Val Acc: 0.8480, Val Loss: 0.1256\n",
            "Restored model from best epoch 14 with val_loss: 0.125593\n",
            "NFL LSTM model 137/201 completed\n",
            "Split training data: 2367 train, 263 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.685, 0.69]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.8221, Train Loss: 0.1312, Val Acc: 0.8023, Val Loss: 0.1182\n",
            "Restored model from best epoch 19 with val_loss: 0.118235\n",
            "NFL LSTM model 138/201 completed\n",
            "Split training data: 2286 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.69, 0.695]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.8093, Train Loss: 0.1391, Val Acc: 0.7992, Val Loss: 0.1410\n",
            "Restored model from best epoch 4 with val_loss: 0.141007\n",
            "NFL LSTM model 139/201 completed\n",
            "Split training data: 2281 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.695, 0.7]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8299, Train Loss: 0.1264, Val Acc: 0.8228, Val Loss: 0.1260\n",
            "Restored model from best epoch 11 with val_loss: 0.125958\n",
            "NFL LSTM model 140/201 completed\n",
            "Split training data: 2325 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.7, 0.705]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.8361, Train Loss: 0.1242, Val Acc: 0.8069, Val Loss: 0.1207\n",
            "Restored model from best epoch 20 with val_loss: 0.120695\n",
            "NFL LSTM model 141/201 completed\n",
            "Split training data: 2234 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.705, 0.71]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.8295, Train Loss: 0.1270, Val Acc: 0.8273, Val Loss: 0.1149\n",
            "Restored model from best epoch 13 with val_loss: 0.114926\n",
            "NFL LSTM model 142/201 completed\n",
            "Split training data: 2225 train, 248 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.71, 0.715]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8337, Train Loss: 0.1222, Val Acc: 0.8347, Val Loss: 0.1193\n",
            "Restored model from best epoch 17 with val_loss: 0.119322\n",
            "NFL LSTM model 143/201 completed\n",
            "Split training data: 2320 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.715, 0.72]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8095, Train Loss: 0.1350, Val Acc: 0.8101, Val Loss: 0.1301\n",
            "Restored model from best epoch 9 with val_loss: 0.130087\n",
            "NFL LSTM model 144/201 completed\n",
            "Split training data: 2279 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.72, 0.725]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8271, Train Loss: 0.1254, Val Acc: 0.8504, Val Loss: 0.1096\n",
            "Restored model from best epoch 11 with val_loss: 0.109612\n",
            "NFL LSTM model 145/201 completed\n",
            "Split training data: 2308 train, 257 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.725, 0.73]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.7782, Train Loss: 0.1553, Val Acc: 0.8405, Val Loss: 0.1578\n",
            "Restored model from best epoch 3 with val_loss: 0.157757\n",
            "NFL LSTM model 146/201 completed\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.73, 0.735]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8413, Train Loss: 0.1199, Val Acc: 0.8295, Val Loss: 0.1483\n",
            "Restored model from best epoch 17 with val_loss: 0.148281\n",
            "NFL LSTM model 147/201 completed\n",
            "Split training data: 2269 train, 253 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.735, 0.74]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8369, Train Loss: 0.1232, Val Acc: 0.8498, Val Loss: 0.1113\n",
            "Restored model from best epoch 21 with val_loss: 0.111267\n",
            "NFL LSTM model 148/201 completed\n",
            "Split training data: 2125 train, 237 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.74, 0.745]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.8221, Train Loss: 0.1313, Val Acc: 0.8397, Val Loss: 0.1236\n",
            "Restored model from best epoch 5 with val_loss: 0.123648\n",
            "NFL LSTM model 149/201 completed\n",
            "Split training data: 2034 train, 226 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.745, 0.75]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.8510, Train Loss: 0.1171, Val Acc: 0.8009, Val Loss: 0.1198\n",
            "Restored model from best epoch 24 with val_loss: 0.119757\n",
            "NFL LSTM model 150/201 completed\n",
            "Split training data: 6573 train, 731 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.75, 0.755]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.8326, Train Loss: 0.1193, Val Acc: 0.8536, Val Loss: 0.1007\n",
            "Restored model from best epoch 18 with val_loss: 0.100667\n",
            "NFL LSTM model 151/201 completed\n",
            "Split training data: 1322 train, 147 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.755, 0.76]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8464, Train Loss: 0.1171, Val Acc: 0.8503, Val Loss: 0.1235\n",
            "Restored model from best epoch 12 with val_loss: 0.123523\n",
            "NFL LSTM model 152/201 completed\n",
            "Split training data: 1754 train, 195 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.76, 0.765]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.8295, Train Loss: 0.1298, Val Acc: 0.8205, Val Loss: 0.1611\n",
            "Restored model from best epoch 4 with val_loss: 0.161131\n",
            "NFL LSTM model 153/201 completed\n",
            "Split training data: 2401 train, 267 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.765, 0.77]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8542, Train Loss: 0.1125, Val Acc: 0.8464, Val Loss: 0.1117\n",
            "Restored model from best epoch 7 with val_loss: 0.111684\n",
            "NFL LSTM model 154/201 completed\n",
            "Split training data: 2061 train, 229 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.77, 0.775]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8404, Train Loss: 0.1206, Val Acc: 0.8297, Val Loss: 0.1190\n",
            "Restored model from best epoch 15 with val_loss: 0.119048\n",
            "NFL LSTM model 155/201 completed\n",
            "Split training data: 2549 train, 284 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.775, 0.78]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.8423, Train Loss: 0.1105, Val Acc: 0.8310, Val Loss: 0.1130\n",
            "Restored model from best epoch 20 with val_loss: 0.113003\n",
            "NFL LSTM model 156/201 completed\n",
            "Split training data: 2151 train, 239 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.78, 0.785]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8424, Train Loss: 0.1205, Val Acc: 0.8243, Val Loss: 0.1195\n",
            "Restored model from best epoch 7 with val_loss: 0.119469\n",
            "NFL LSTM model 157/201 completed\n",
            "Split training data: 2360 train, 263 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.785, 0.79]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 158/201 completed\n",
            "Split training data: 2230 train, 248 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.79, 0.795]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8596, Train Loss: 0.1053, Val Acc: 0.8629, Val Loss: 0.1047\n",
            "Restored model from best epoch 10 with val_loss: 0.104731\n",
            "NFL LSTM model 159/201 completed\n",
            "Split training data: 2209 train, 246 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.795, 0.8]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8334, Train Loss: 0.1289, Val Acc: 0.8455, Val Loss: 0.1068\n",
            "Restored model from best epoch 11 with val_loss: 0.106816\n",
            "NFL LSTM model 160/201 completed\n",
            "Split training data: 2426 train, 270 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.8, 0.805]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8483, Train Loss: 0.1139, Val Acc: 0.8667, Val Loss: 0.1096\n",
            "Restored model from best epoch 6 with val_loss: 0.109561\n",
            "NFL LSTM model 161/201 completed\n",
            "Split training data: 2327 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.805, 0.81]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.8573, Train Loss: 0.1060, Val Acc: 0.8880, Val Loss: 0.0931\n",
            "Restored model from best epoch 20 with val_loss: 0.093094\n",
            "NFL LSTM model 162/201 completed\n",
            "Split training data: 2333 train, 260 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.81, 0.815]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8491, Train Loss: 0.1147, Val Acc: 0.8846, Val Loss: 0.0892\n",
            "Restored model from best epoch 6 with val_loss: 0.089247\n",
            "NFL LSTM model 163/201 completed\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.815, 0.82]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.8642, Train Loss: 0.1056, Val Acc: 0.8527, Val Loss: 0.1013\n",
            "Restored model from best epoch 19 with val_loss: 0.101331\n",
            "NFL LSTM model 164/201 completed\n",
            "Split training data: 2359 train, 263 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.82, 0.825]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8499, Train Loss: 0.1088, Val Acc: 0.8479, Val Loss: 0.1307\n",
            "Restored model from best epoch 12 with val_loss: 0.130682\n",
            "NFL LSTM model 165/201 completed\n",
            "Split training data: 2249 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.825, 0.83]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8502, Train Loss: 0.1144, Val Acc: 0.8040, Val Loss: 0.1370\n",
            "Restored model from best epoch 6 with val_loss: 0.136956\n",
            "NFL LSTM model 166/201 completed\n",
            "Split training data: 2259 train, 251 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.83, 0.835]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8548, Train Loss: 0.1077, Val Acc: 0.8765, Val Loss: 0.0927\n",
            "Restored model from best epoch 15 with val_loss: 0.092685\n",
            "NFL LSTM model 167/201 completed\n",
            "Split training data: 2285 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.835, 0.84]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8600, Train Loss: 0.1044, Val Acc: 0.8819, Val Loss: 0.0875\n",
            "Restored model from best epoch 10 with val_loss: 0.087468\n",
            "NFL LSTM model 168/201 completed\n",
            "Split training data: 2312 train, 257 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.84, 0.845]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8668, Train Loss: 0.1023, Val Acc: 0.8482, Val Loss: 0.0999\n",
            "Restored model from best epoch 6 with val_loss: 0.099944\n",
            "NFL LSTM model 169/201 completed\n",
            "Split training data: 2316 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.845, 0.85]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8558, Train Loss: 0.1063, Val Acc: 0.8488, Val Loss: 0.1059\n",
            "Restored model from best epoch 11 with val_loss: 0.105863\n",
            "NFL LSTM model 170/201 completed\n",
            "Split training data: 2299 train, 256 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.85, 0.855]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 23, Train Acc: 0.8643, Train Loss: 0.0989, Val Acc: 0.8789, Val Loss: 0.0988\n",
            "Restored model from best epoch 23 with val_loss: 0.098790\n",
            "NFL LSTM model 171/201 completed\n",
            "Split training data: 2289 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.855, 0.86]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.8554, Train Loss: 0.1088, Val Acc: 0.8510, Val Loss: 0.1058\n",
            "Restored model from best epoch 5 with val_loss: 0.105824\n",
            "NFL LSTM model 172/201 completed\n",
            "Split training data: 2304 train, 257 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.86, 0.865]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.8624, Train Loss: 0.1066, Val Acc: 0.8210, Val Loss: 0.1149\n",
            "Restored model from best epoch 4 with val_loss: 0.114940\n",
            "NFL LSTM model 173/201 completed\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.865, 0.87]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8629, Train Loss: 0.1027, Val Acc: 0.8682, Val Loss: 0.0884\n",
            "Restored model from best epoch 8 with val_loss: 0.088369\n",
            "NFL LSTM model 174/201 completed\n",
            "Split training data: 2283 train, 254 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.87, 0.875]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8686, Train Loss: 0.0996, Val Acc: 0.8543, Val Loss: 0.1047\n",
            "Restored model from best epoch 22 with val_loss: 0.104689\n",
            "NFL LSTM model 175/201 completed\n",
            "Split training data: 2358 train, 262 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.875, 0.88]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8567, Train Loss: 0.1008, Val Acc: 0.8626, Val Loss: 0.0961\n",
            "Restored model from best epoch 10 with val_loss: 0.096071\n",
            "NFL LSTM model 176/201 completed\n",
            "Split training data: 2326 train, 259 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.88, 0.885]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8667, Train Loss: 0.0986, Val Acc: 0.8417, Val Loss: 0.1131\n",
            "Restored model from best epoch 6 with val_loss: 0.113140\n",
            "NFL LSTM model 177/201 completed\n",
            "Split training data: 2346 train, 261 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.885, 0.89]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8551, Train Loss: 0.1033, Val Acc: 0.8391, Val Loss: 0.1121\n",
            "Restored model from best epoch 9 with val_loss: 0.112130\n",
            "NFL LSTM model 178/201 completed\n",
            "Split training data: 2318 train, 258 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.89, 0.895]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8805, Train Loss: 0.0940, Val Acc: 0.8527, Val Loss: 0.1055\n",
            "Restored model from best epoch 21 with val_loss: 0.105459\n",
            "NFL LSTM model 179/201 completed\n",
            "Split training data: 2385 train, 266 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.895, 0.9]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 180/201 completed\n",
            "Split training data: 2343 train, 261 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.9, 0.905]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 181/201 completed\n",
            "Split training data: 2337 train, 260 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.905, 0.91]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8810, Train Loss: 0.0901, Val Acc: 0.8692, Val Loss: 0.0868\n",
            "Restored model from best epoch 15 with val_loss: 0.086829\n",
            "NFL LSTM model 182/201 completed\n",
            "Split training data: 2422 train, 270 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.91, 0.915]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8774, Train Loss: 0.0899, Val Acc: 0.8815, Val Loss: 0.1007\n",
            "Restored model from best epoch 11 with val_loss: 0.100741\n",
            "NFL LSTM model 183/201 completed\n",
            "Split training data: 2387 train, 266 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.915, 0.92]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8957, Train Loss: 0.0814, Val Acc: 0.8609, Val Loss: 0.0900\n",
            "Restored model from best epoch 14 with val_loss: 0.090029\n",
            "NFL LSTM model 184/201 completed\n",
            "Split training data: 2553 train, 284 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.92, 0.925]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.8837, Train Loss: 0.0832, Val Acc: 0.8451, Val Loss: 0.0999\n",
            "Restored model from best epoch 19 with val_loss: 0.099944\n",
            "NFL LSTM model 185/201 completed\n",
            "Split training data: 2664 train, 297 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.925, 0.93]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 186/201 completed\n",
            "Split training data: 2603 train, 290 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.93, 0.935]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.8813, Train Loss: 0.0910, Val Acc: 0.8621, Val Loss: 0.0837\n",
            "Restored model from best epoch 4 with val_loss: 0.083738\n",
            "NFL LSTM model 187/201 completed\n",
            "Split training data: 2712 train, 302 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.935, 0.94]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8798, Train Loss: 0.0887, Val Acc: 0.9007, Val Loss: 0.0816\n",
            "Restored model from best epoch 10 with val_loss: 0.081585\n",
            "NFL LSTM model 188/201 completed\n",
            "Split training data: 2912 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.94, 0.945]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.8901, Train Loss: 0.0887, Val Acc: 0.8951, Val Loss: 0.0798\n",
            "Restored model from best epoch 3 with val_loss: 0.079767\n",
            "NFL LSTM model 189/201 completed\n",
            "Split training data: 2937 train, 327 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.945, 0.95]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8968, Train Loss: 0.0767, Val Acc: 0.9113, Val Loss: 0.0610\n",
            "Restored model from best epoch 14 with val_loss: 0.060964\n",
            "NFL LSTM model 190/201 completed\n",
            "Split training data: 3038 train, 338 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.95, 0.955]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8825, Train Loss: 0.0861, Val Acc: 0.9320, Val Loss: 0.0522\n",
            "Restored model from best epoch 14 with val_loss: 0.052171\n",
            "NFL LSTM model 191/201 completed\n",
            "Split training data: 2907 train, 324 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.955, 0.96]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8930, Train Loss: 0.0818, Val Acc: 0.8981, Val Loss: 0.0673\n",
            "Restored model from best epoch 9 with val_loss: 0.067336\n",
            "NFL LSTM model 192/201 completed\n",
            "Split training data: 3057 train, 340 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.96, 0.965]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8858, Train Loss: 0.0845, Val Acc: 0.8941, Val Loss: 0.0732\n",
            "Restored model from best epoch 14 with val_loss: 0.073224\n",
            "NFL LSTM model 193/201 completed\n",
            "Split training data: 2797 train, 311 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.965, 0.97]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8899, Train Loss: 0.0814, Val Acc: 0.8842, Val Loss: 0.0885\n",
            "Restored model from best epoch 9 with val_loss: 0.088527\n",
            "NFL LSTM model 194/201 completed\n",
            "Split training data: 6484 train, 721 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.97, 0.975]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8948, Train Loss: 0.0771, Val Acc: 0.9071, Val Loss: 0.0676\n",
            "Restored model from best epoch 11 with val_loss: 0.067634\n",
            "NFL LSTM model 195/201 completed\n",
            "Split training data: 2968 train, 330 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.975, 0.98]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 196/201 completed\n",
            "Split training data: 3126 train, 348 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.98, 0.985]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.9072, Train Loss: 0.0659, Val Acc: 0.9224, Val Loss: 0.0543\n",
            "Restored model from best epoch 22 with val_loss: 0.054291\n",
            "NFL LSTM model 197/201 completed\n",
            "Split training data: 3119 train, 347 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.985, 0.99]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.9179, Train Loss: 0.0617, Val Acc: 0.9049, Val Loss: 0.0676\n",
            "Restored model from best epoch 15 with val_loss: 0.067603\n",
            "NFL LSTM model 198/201 completed\n",
            "Split training data: 3122 train, 347 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.99, 0.995]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 199/201 completed\n",
            "Split training data: 3096 train, 344 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.995, 1.0]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.9154, Train Loss: 0.0637, Val Acc: 0.9070, Val Loss: 0.0732\n",
            "Restored model from best epoch 16 with val_loss: 0.073201\n",
            "NFL LSTM model 200/201 completed\n",
            "Split training data: 3779 train, 420 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [1.0, 1.005]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.9331, Train Loss: 0.0492, Val Acc: 0.9429, Val Loss: 0.0398\n",
            "Restored model from best epoch 15 with val_loss: 0.039829\n",
            "NFL LSTM model 201/201 completed\n"
          ]
        }
      ],
      "source": [
        "all_models[\"lstm\"] = setup_direct_lstm_models(training_data_seq, None, num_models=201)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original data shape: (3770, 8)\n",
            "Flattened data shape: (3770, 8)\n",
            "Split training data: 3393 train, 377 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.0, 0.005]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.6734, Train Loss: 0.6064, Val Acc: 0.6711, Val Loss: 0.6123\n",
            "Restored model from best epoch 26 with val_loss: 0.612320\n",
            "NFL direct model 1/201 completed\n",
            "Original data shape: (1266, 8)\n",
            "Flattened data shape: (1266, 8)\n",
            "Split training data: 1139 train, 127 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.005, 0.01]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.6409, Train Loss: 0.6364, Val Acc: 0.5591, Val Loss: 0.6641\n",
            "Restored model from best epoch 5 with val_loss: 0.664112\n",
            "NFL direct model 2/201 completed\n",
            "Original data shape: (2484, 8)\n",
            "Flattened data shape: (2484, 8)\n",
            "Split training data: 2235 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.01, 0.015]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6622, Train Loss: 0.6159, Val Acc: 0.6225, Val Loss: 0.6346\n",
            "Restored model from best epoch 7 with val_loss: 0.634574\n",
            "NFL direct model 3/201 completed\n",
            "Original data shape: (2093, 8)\n",
            "Flattened data shape: (2093, 8)\n",
            "Split training data: 1883 train, 210 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.015, 0.02]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6511, Train Loss: 0.6356, Val Acc: 0.6381, Val Loss: 0.6041\n",
            "Restored model from best epoch 4 with val_loss: 0.604064\n",
            "NFL direct model 4/201 completed\n",
            "Original data shape: (2305, 8)\n",
            "Flattened data shape: (2305, 8)\n",
            "Split training data: 2074 train, 231 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.02, 0.025]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.6553, Train Loss: 0.6225, Val Acc: 0.6104, Val Loss: 0.6348\n",
            "Restored model from best epoch 17 with val_loss: 0.634754\n",
            "NFL direct model 5/201 completed\n",
            "Original data shape: (2402, 8)\n",
            "Flattened data shape: (2402, 8)\n",
            "Split training data: 2161 train, 241 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.025, 0.03]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.6664, Train Loss: 0.6198, Val Acc: 0.6432, Val Loss: 0.6251\n",
            "Restored model from best epoch 11 with val_loss: 0.625124\n",
            "NFL direct model 6/201 completed\n",
            "Original data shape: (2268, 8)\n",
            "Flattened data shape: (2268, 8)\n",
            "Split training data: 2041 train, 227 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.03, 0.035]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.6663, Train Loss: 0.6193, Val Acc: 0.6300, Val Loss: 0.6304\n",
            "Restored model from best epoch 8 with val_loss: 0.630395\n",
            "NFL direct model 7/201 completed\n",
            "Original data shape: (2493, 8)\n",
            "Flattened data shape: (2493, 8)\n",
            "Split training data: 2243 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.035, 0.04]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6500, Train Loss: 0.6276, Val Acc: 0.6360, Val Loss: 0.6235\n",
            "Restored model from best epoch 7 with val_loss: 0.623475\n",
            "NFL direct model 8/201 completed\n",
            "Original data shape: (2351, 8)\n",
            "Flattened data shape: (2351, 8)\n",
            "Split training data: 2115 train, 236 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.04, 0.045]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.6600, Train Loss: 0.6182, Val Acc: 0.6695, Val Loss: 0.6092\n",
            "Restored model from best epoch 17 with val_loss: 0.609171\n",
            "NFL direct model 9/201 completed\n",
            "Original data shape: (2519, 8)\n",
            "Flattened data shape: (2519, 8)\n",
            "Split training data: 2267 train, 252 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.045, 0.05]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6330, Train Loss: 0.6406, Val Acc: 0.6905, Val Loss: 0.6068\n",
            "Restored model from best epoch 4 with val_loss: 0.606846\n",
            "NFL direct model 10/201 completed\n",
            "Original data shape: (2467, 8)\n",
            "Flattened data shape: (2467, 8)\n",
            "Split training data: 2220 train, 247 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.05, 0.055]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.6730, Train Loss: 0.6101, Val Acc: 0.6154, Val Loss: 0.6378\n",
            "Restored model from best epoch 15 with val_loss: 0.637756\n",
            "NFL direct model 11/201 completed\n",
            "Original data shape: (2331, 8)\n",
            "Flattened data shape: (2331, 8)\n",
            "Split training data: 2097 train, 234 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.055, 0.06]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6681, Train Loss: 0.6254, Val Acc: 0.6966, Val Loss: 0.6084\n",
            "Restored model from best epoch 4 with val_loss: 0.608398\n",
            "NFL direct model 12/201 completed\n",
            "Original data shape: (2576, 8)\n",
            "Flattened data shape: (2576, 8)\n",
            "Split training data: 2318 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.06, 0.065]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.6592, Train Loss: 0.6171, Val Acc: 0.6047, Val Loss: 0.6345\n",
            "Restored model from best epoch 5 with val_loss: 0.634527\n",
            "NFL direct model 13/201 completed\n",
            "Original data shape: (2491, 8)\n",
            "Flattened data shape: (2491, 8)\n",
            "Split training data: 2241 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.065, 0.07]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.6435, Train Loss: 0.6349, Val Acc: 0.6480, Val Loss: 0.6335\n",
            "Restored model from best epoch 2 with val_loss: 0.633500\n",
            "NFL direct model 14/201 completed\n",
            "Original data shape: (2528, 8)\n",
            "Flattened data shape: (2528, 8)\n",
            "Split training data: 2275 train, 253 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.07, 0.075]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.6664, Train Loss: 0.6114, Val Acc: 0.6759, Val Loss: 0.6111\n",
            "Restored model from best epoch 9 with val_loss: 0.611131\n",
            "NFL direct model 15/201 completed\n",
            "Original data shape: (2458, 8)\n",
            "Flattened data shape: (2458, 8)\n",
            "Split training data: 2212 train, 246 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.075, 0.08]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.5854, Train Loss: 0.6688, Val Acc: 0.6098, Val Loss: 0.6688\n",
            "Restored model from best epoch 1 with val_loss: 0.668802\n",
            "NFL direct model 16/201 completed\n",
            "Original data shape: (2541, 8)\n",
            "Flattened data shape: (2541, 8)\n",
            "Split training data: 2286 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.08, 0.085]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.6842, Train Loss: 0.6042, Val Acc: 0.6353, Val Loss: 0.6126\n",
            "Restored model from best epoch 5 with val_loss: 0.612562\n",
            "NFL direct model 17/201 completed\n",
            "Original data shape: (2573, 8)\n",
            "Flattened data shape: (2573, 8)\n",
            "Split training data: 2315 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.085, 0.09]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 54\n",
            "Best epoch: 44, Train Acc: 0.7045, Train Loss: 0.5749, Val Acc: 0.6589, Val Loss: 0.5397\n",
            "Restored model from best epoch 44 with val_loss: 0.539675\n",
            "NFL direct model 18/201 completed\n",
            "Original data shape: (2450, 8)\n",
            "Flattened data shape: (2450, 8)\n",
            "Split training data: 2205 train, 245 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.09, 0.095]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.6635, Train Loss: 0.6079, Val Acc: 0.6653, Val Loss: 0.5896\n",
            "Restored model from best epoch 13 with val_loss: 0.589649\n",
            "NFL direct model 19/201 completed\n",
            "Original data shape: (2562, 8)\n",
            "Flattened data shape: (2562, 8)\n",
            "Split training data: 2305 train, 257 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.095, 0.1]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.5744, Train Loss: 0.6737, Val Acc: 0.6226, Val Loss: 0.7038\n",
            "Restored model from best epoch 1 with val_loss: 0.703814\n",
            "NFL direct model 20/201 completed\n",
            "Original data shape: (2549, 8)\n",
            "Flattened data shape: (2549, 8)\n",
            "Split training data: 2294 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.1, 0.105]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.6809, Train Loss: 0.5927, Val Acc: 0.6392, Val Loss: 0.6175\n",
            "Restored model from best epoch 10 with val_loss: 0.617502\n",
            "NFL direct model 21/201 completed\n",
            "Original data shape: (2494, 8)\n",
            "Flattened data shape: (2494, 8)\n",
            "Split training data: 2244 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.105, 0.11]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 19, Train Acc: 0.6818, Train Loss: 0.5830, Val Acc: 0.7080, Val Loss: 0.5763\n",
            "Restored model from best epoch 19 with val_loss: 0.576259\n",
            "NFL direct model 22/201 completed\n",
            "Original data shape: (2568, 8)\n",
            "Flattened data shape: (2568, 8)\n",
            "Split training data: 2311 train, 257 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.11, 0.115]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6690, Train Loss: 0.6051, Val Acc: 0.6420, Val Loss: 0.5219\n",
            "Restored model from best epoch 6 with val_loss: 0.521874\n",
            "NFL direct model 23/201 completed\n",
            "Original data shape: (2484, 8)\n",
            "Flattened data shape: (2484, 8)\n",
            "Split training data: 2235 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.115, 0.12]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.6940, Train Loss: 0.5852, Val Acc: 0.7149, Val Loss: 0.5734\n",
            "Restored model from best epoch 13 with val_loss: 0.573449\n",
            "NFL direct model 24/201 completed\n",
            "Original data shape: (2546, 8)\n",
            "Flattened data shape: (2546, 8)\n",
            "Split training data: 2291 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.12, 0.125]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.6945, Train Loss: 0.5833, Val Acc: 0.6784, Val Loss: 0.5949\n",
            "Restored model from best epoch 14 with val_loss: 0.594909\n",
            "NFL direct model 25/201 completed\n",
            "Original data shape: (2602, 8)\n",
            "Flattened data shape: (2602, 8)\n",
            "Split training data: 2341 train, 261 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.125, 0.13]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 43\n",
            "Best epoch: 33, Train Acc: 0.7027, Train Loss: 0.5578, Val Acc: 0.6245, Val Loss: 0.6058\n",
            "Restored model from best epoch 33 with val_loss: 0.605774\n",
            "NFL direct model 26/201 completed\n",
            "Original data shape: (2538, 8)\n",
            "Flattened data shape: (2538, 8)\n",
            "Split training data: 2284 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.13, 0.135]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6821, Train Loss: 0.5966, Val Acc: 0.6890, Val Loss: 0.5917\n",
            "Restored model from best epoch 4 with val_loss: 0.591658\n",
            "NFL direct model 27/201 completed\n",
            "Original data shape: (2493, 8)\n",
            "Flattened data shape: (2493, 8)\n",
            "Split training data: 2243 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.135, 0.14]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.6821, Train Loss: 0.5875, Val Acc: 0.6800, Val Loss: 0.5811\n",
            "Restored model from best epoch 13 with val_loss: 0.581125\n",
            "NFL direct model 28/201 completed\n",
            "Original data shape: (2492, 8)\n",
            "Flattened data shape: (2492, 8)\n",
            "Split training data: 2242 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.14, 0.145]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.6191, Train Loss: 0.6507, Val Acc: 0.6120, Val Loss: 0.6692\n",
            "Restored model from best epoch 1 with val_loss: 0.669152\n",
            "NFL direct model 29/201 completed\n",
            "Original data shape: (2498, 8)\n",
            "Flattened data shape: (2498, 8)\n",
            "Split training data: 2248 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.145, 0.15]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.6975, Train Loss: 0.5895, Val Acc: 0.7320, Val Loss: 0.5580\n",
            "Restored model from best epoch 10 with val_loss: 0.557968\n",
            "NFL direct model 30/201 completed\n",
            "Original data shape: (2583, 8)\n",
            "Flattened data shape: (2583, 8)\n",
            "Split training data: 2324 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.15, 0.155]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7048, Train Loss: 0.5734, Val Acc: 0.6834, Val Loss: 0.5515\n",
            "Restored model from best epoch 17 with val_loss: 0.551474\n",
            "NFL direct model 31/201 completed\n",
            "Original data shape: (2388, 8)\n",
            "Flattened data shape: (2388, 8)\n",
            "Split training data: 2149 train, 239 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.155, 0.16]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6971, Train Loss: 0.5817, Val Acc: 0.6904, Val Loss: 0.5881\n",
            "Restored model from best epoch 4 with val_loss: 0.588074\n",
            "NFL direct model 32/201 completed\n",
            "Original data shape: (2603, 8)\n",
            "Flattened data shape: (2603, 8)\n",
            "Split training data: 2342 train, 261 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.16, 0.165]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7071, Train Loss: 0.5678, Val Acc: 0.6628, Val Loss: 0.6001\n",
            "Restored model from best epoch 17 with val_loss: 0.600128\n",
            "NFL direct model 33/201 completed\n",
            "Original data shape: (2423, 8)\n",
            "Flattened data shape: (2423, 8)\n",
            "Split training data: 2180 train, 243 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.165, 0.17]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.6807, Train Loss: 0.5855, Val Acc: 0.6955, Val Loss: 0.5935\n",
            "Restored model from best epoch 11 with val_loss: 0.593524\n",
            "NFL direct model 34/201 completed\n",
            "Original data shape: (2561, 8)\n",
            "Flattened data shape: (2561, 8)\n",
            "Split training data: 2304 train, 257 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.17, 0.175]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.7096, Train Loss: 0.5558, Val Acc: 0.7237, Val Loss: 0.5423\n",
            "Restored model from best epoch 29 with val_loss: 0.542341\n",
            "NFL direct model 35/201 completed\n",
            "Original data shape: (2556, 8)\n",
            "Flattened data shape: (2556, 8)\n",
            "Split training data: 2300 train, 256 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.175, 0.18]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.6896, Train Loss: 0.5860, Val Acc: 0.6641, Val Loss: 0.6097\n",
            "Restored model from best epoch 11 with val_loss: 0.609661\n",
            "NFL direct model 36/201 completed\n",
            "Original data shape: (2445, 8)\n",
            "Flattened data shape: (2445, 8)\n",
            "Split training data: 2200 train, 245 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.18, 0.185]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7068, Train Loss: 0.5756, Val Acc: 0.6980, Val Loss: 0.5798\n",
            "Restored model from best epoch 5 with val_loss: 0.579781\n",
            "NFL direct model 37/201 completed\n",
            "Original data shape: (2490, 8)\n",
            "Flattened data shape: (2490, 8)\n",
            "Split training data: 2241 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.185, 0.19]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7113, Train Loss: 0.5810, Val Acc: 0.6466, Val Loss: 0.5980\n",
            "Restored model from best epoch 14 with val_loss: 0.597997\n",
            "NFL direct model 38/201 completed\n",
            "Original data shape: (2480, 8)\n",
            "Flattened data shape: (2480, 8)\n",
            "Split training data: 2232 train, 248 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.19, 0.195]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6976, Train Loss: 0.5788, Val Acc: 0.7218, Val Loss: 0.5604\n",
            "Restored model from best epoch 7 with val_loss: 0.560404\n",
            "NFL direct model 39/201 completed\n",
            "Original data shape: (2540, 8)\n",
            "Flattened data shape: (2540, 8)\n",
            "Split training data: 2286 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.195, 0.2]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7161, Train Loss: 0.5623, Val Acc: 0.6811, Val Loss: 0.5790\n",
            "Restored model from best epoch 11 with val_loss: 0.578951\n",
            "NFL direct model 40/201 completed\n",
            "Original data shape: (2481, 8)\n",
            "Flattened data shape: (2481, 8)\n",
            "Split training data: 2232 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.2, 0.205]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.7222, Train Loss: 0.5573, Val Acc: 0.6988, Val Loss: 0.5755\n",
            "Restored model from best epoch 22 with val_loss: 0.575469\n",
            "NFL direct model 41/201 completed\n",
            "Original data shape: (2506, 8)\n",
            "Flattened data shape: (2506, 8)\n",
            "Split training data: 2255 train, 251 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.205, 0.21]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6922, Train Loss: 0.5810, Val Acc: 0.7171, Val Loss: 0.5687\n",
            "Restored model from best epoch 3 with val_loss: 0.568652\n",
            "NFL direct model 42/201 completed\n",
            "Original data shape: (2679, 8)\n",
            "Flattened data shape: (2679, 8)\n",
            "Split training data: 2411 train, 268 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.21, 0.215]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6947, Train Loss: 0.5943, Val Acc: 0.7351, Val Loss: 0.5361\n",
            "Restored model from best epoch 3 with val_loss: 0.536112\n",
            "NFL direct model 43/201 completed\n",
            "Original data shape: (2428, 8)\n",
            "Flattened data shape: (2428, 8)\n",
            "Split training data: 2185 train, 243 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.215, 0.22]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.6993, Train Loss: 0.5731, Val Acc: 0.7160, Val Loss: 0.5538\n",
            "Restored model from best epoch 8 with val_loss: 0.553777\n",
            "NFL direct model 44/201 completed\n",
            "Original data shape: (2537, 8)\n",
            "Flattened data shape: (2537, 8)\n",
            "Split training data: 2283 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.22, 0.225]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.6943, Train Loss: 0.5915, Val Acc: 0.7362, Val Loss: 0.5469\n",
            "Restored model from best epoch 2 with val_loss: 0.546915\n",
            "NFL direct model 45/201 completed\n",
            "Original data shape: (2547, 8)\n",
            "Flattened data shape: (2547, 8)\n",
            "Split training data: 2292 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.225, 0.23]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7064, Train Loss: 0.5751, Val Acc: 0.7412, Val Loss: 0.5336\n",
            "Restored model from best epoch 4 with val_loss: 0.533583\n",
            "NFL direct model 46/201 completed\n",
            "Original data shape: (2480, 8)\n",
            "Flattened data shape: (2480, 8)\n",
            "Split training data: 2232 train, 248 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.23, 0.235]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6935, Train Loss: 0.5838, Val Acc: 0.7056, Val Loss: 0.5835\n",
            "Restored model from best epoch 3 with val_loss: 0.583522\n",
            "NFL direct model 47/201 completed\n",
            "Original data shape: (2582, 8)\n",
            "Flattened data shape: (2582, 8)\n",
            "Split training data: 2323 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.235, 0.24]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.6578, Train Loss: 0.6315, Val Acc: 0.7143, Val Loss: 0.5621\n",
            "Restored model from best epoch 1 with val_loss: 0.562090\n",
            "NFL direct model 48/201 completed\n",
            "Original data shape: (2448, 8)\n",
            "Flattened data shape: (2448, 8)\n",
            "Split training data: 2203 train, 245 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.24, 0.245]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.6900, Train Loss: 0.5877, Val Acc: 0.6490, Val Loss: 0.6207\n",
            "Restored model from best epoch 3 with val_loss: 0.620685\n",
            "NFL direct model 49/201 completed\n",
            "Original data shape: (2267, 8)\n",
            "Flattened data shape: (2267, 8)\n",
            "Split training data: 2040 train, 227 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.245, 0.25]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7113, Train Loss: 0.5722, Val Acc: 0.6784, Val Loss: 0.5770\n",
            "Restored model from best epoch 11 with val_loss: 0.576970\n",
            "NFL direct model 50/201 completed\n",
            "Original data shape: (7460, 8)\n",
            "Flattened data shape: (7460, 8)\n",
            "Split training data: 6714 train, 746 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.25, 0.255]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 65\n",
            "Best epoch: 55, Train Acc: 0.7601, Train Loss: 0.4921, Val Acc: 0.7493, Val Loss: 0.5096\n",
            "Restored model from best epoch 55 with val_loss: 0.509602\n",
            "NFL direct model 51/201 completed\n",
            "Original data shape: (1446, 8)\n",
            "Flattened data shape: (1446, 8)\n",
            "Split training data: 1301 train, 145 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.255, 0.26]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.7248, Train Loss: 0.5337, Val Acc: 0.7172, Val Loss: 0.5620\n",
            "Restored model from best epoch 20 with val_loss: 0.561974\n",
            "NFL direct model 52/201 completed\n",
            "Original data shape: (1948, 8)\n",
            "Flattened data shape: (1948, 8)\n",
            "Split training data: 1753 train, 195 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.26, 0.265]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7068, Train Loss: 0.5758, Val Acc: 0.7744, Val Loss: 0.5981\n",
            "Restored model from best epoch 4 with val_loss: 0.598149\n",
            "NFL direct model 53/201 completed\n",
            "Original data shape: (2670, 8)\n",
            "Flattened data shape: (2670, 8)\n",
            "Split training data: 2403 train, 267 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.265, 0.27]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7154, Train Loss: 0.5460, Val Acc: 0.7041, Val Loss: 0.5312\n",
            "Restored model from best epoch 11 with val_loss: 0.531152\n",
            "NFL direct model 54/201 completed\n",
            "Original data shape: (2340, 8)\n",
            "Flattened data shape: (2340, 8)\n",
            "Split training data: 2106 train, 234 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.27, 0.275]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 56\n",
            "Best epoch: 46, Train Acc: 0.7502, Train Loss: 0.5038, Val Acc: 0.7179, Val Loss: 0.5476\n",
            "Restored model from best epoch 46 with val_loss: 0.547563\n",
            "NFL direct model 55/201 completed\n",
            "Original data shape: (2693, 8)\n",
            "Flattened data shape: (2693, 8)\n",
            "Split training data: 2423 train, 270 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.275, 0.28]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.7107, Train Loss: 0.5487, Val Acc: 0.6778, Val Loss: 0.5846\n",
            "Restored model from best epoch 13 with val_loss: 0.584573\n",
            "NFL direct model 56/201 completed\n",
            "Original data shape: (2348, 8)\n",
            "Flattened data shape: (2348, 8)\n",
            "Split training data: 2113 train, 235 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.28, 0.285]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7075, Train Loss: 0.5655, Val Acc: 0.6979, Val Loss: 0.5693\n",
            "Restored model from best epoch 3 with val_loss: 0.569290\n",
            "NFL direct model 57/201 completed\n",
            "Original data shape: (2755, 8)\n",
            "Flattened data shape: (2755, 8)\n",
            "Split training data: 2479 train, 276 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.285, 0.29]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7281, Train Loss: 0.5355, Val Acc: 0.7319, Val Loss: 0.4960\n",
            "Restored model from best epoch 16 with val_loss: 0.496002\n",
            "NFL direct model 58/201 completed\n",
            "Original data shape: (2467, 8)\n",
            "Flattened data shape: (2467, 8)\n",
            "Split training data: 2220 train, 247 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.29, 0.295]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.7153, Train Loss: 0.5440, Val Acc: 0.7085, Val Loss: 0.5387\n",
            "Restored model from best epoch 15 with val_loss: 0.538681\n",
            "NFL direct model 59/201 completed\n",
            "Original data shape: (2518, 8)\n",
            "Flattened data shape: (2518, 8)\n",
            "Split training data: 2266 train, 252 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.295, 0.3]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 42\n",
            "Best epoch: 32, Train Acc: 0.7436, Train Loss: 0.5199, Val Acc: 0.7222, Val Loss: 0.5296\n",
            "Restored model from best epoch 32 with val_loss: 0.529570\n",
            "NFL direct model 60/201 completed\n",
            "Original data shape: (2531, 8)\n",
            "Flattened data shape: (2531, 8)\n",
            "Split training data: 2277 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.3, 0.305]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7176, Train Loss: 0.5446, Val Acc: 0.7087, Val Loss: 0.5551\n",
            "Restored model from best epoch 10 with val_loss: 0.555120\n",
            "NFL direct model 61/201 completed\n",
            "Original data shape: (2450, 8)\n",
            "Flattened data shape: (2450, 8)\n",
            "Split training data: 2205 train, 245 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.305, 0.31]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7020, Train Loss: 0.5674, Val Acc: 0.7102, Val Loss: 0.5514\n",
            "Restored model from best epoch 3 with val_loss: 0.551351\n",
            "NFL direct model 62/201 completed\n",
            "Original data shape: (2566, 8)\n",
            "Flattened data shape: (2566, 8)\n",
            "Split training data: 2309 train, 257 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.31, 0.315]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7276, Train Loss: 0.5261, Val Acc: 0.7704, Val Loss: 0.4521\n",
            "Restored model from best epoch 12 with val_loss: 0.452080\n",
            "NFL direct model 63/201 completed\n",
            "Original data shape: (2536, 8)\n",
            "Flattened data shape: (2536, 8)\n",
            "Split training data: 2282 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.315, 0.32]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.7257, Train Loss: 0.5232, Val Acc: 0.7283, Val Loss: 0.5052\n",
            "Restored model from best epoch 29 with val_loss: 0.505191\n",
            "NFL direct model 64/201 completed\n",
            "Original data shape: (2557, 8)\n",
            "Flattened data shape: (2557, 8)\n",
            "Split training data: 2301 train, 256 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.32, 0.325]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.6962, Train Loss: 0.5623, Val Acc: 0.7500, Val Loss: 0.5380\n",
            "Restored model from best epoch 2 with val_loss: 0.538026\n",
            "NFL direct model 65/201 completed\n",
            "Original data shape: (2469, 8)\n",
            "Flattened data shape: (2469, 8)\n",
            "Split training data: 2222 train, 247 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.325, 0.33]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7282, Train Loss: 0.5397, Val Acc: 0.7045, Val Loss: 0.5413\n",
            "Restored model from best epoch 10 with val_loss: 0.541286\n",
            "NFL direct model 66/201 completed\n",
            "Original data shape: (2545, 8)\n",
            "Flattened data shape: (2545, 8)\n",
            "Split training data: 2290 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.33, 0.335]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7314, Train Loss: 0.5208, Val Acc: 0.7490, Val Loss: 0.5302\n",
            "Restored model from best epoch 17 with val_loss: 0.530220\n",
            "NFL direct model 67/201 completed\n",
            "Original data shape: (2576, 8)\n",
            "Flattened data shape: (2576, 8)\n",
            "Split training data: 2318 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.335, 0.34]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7170, Train Loss: 0.5450, Val Acc: 0.7326, Val Loss: 0.4742\n",
            "Restored model from best epoch 3 with val_loss: 0.474216\n",
            "NFL direct model 68/201 completed\n",
            "Original data shape: (2533, 8)\n",
            "Flattened data shape: (2533, 8)\n",
            "Split training data: 2279 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.34, 0.345]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7411, Train Loss: 0.5181, Val Acc: 0.7480, Val Loss: 0.5140\n",
            "Restored model from best epoch 10 with val_loss: 0.514044\n",
            "NFL direct model 69/201 completed\n",
            "Original data shape: (2611, 8)\n",
            "Flattened data shape: (2611, 8)\n",
            "Split training data: 2349 train, 262 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.345, 0.35]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.7518, Train Loss: 0.5051, Val Acc: 0.7137, Val Loss: 0.6326\n",
            "Restored model from best epoch 20 with val_loss: 0.632553\n",
            "NFL direct model 70/201 completed\n",
            "Original data shape: (2525, 8)\n",
            "Flattened data shape: (2525, 8)\n",
            "Split training data: 2272 train, 253 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.35, 0.355]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 45\n",
            "Best epoch: 35, Train Acc: 0.7658, Train Loss: 0.4944, Val Acc: 0.7510, Val Loss: 0.5360\n",
            "Restored model from best epoch 35 with val_loss: 0.535995\n",
            "NFL direct model 71/201 completed\n",
            "Original data shape: (2579, 8)\n",
            "Flattened data shape: (2579, 8)\n",
            "Split training data: 2321 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.355, 0.36]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7299, Train Loss: 0.5504, Val Acc: 0.7287, Val Loss: 0.4812\n",
            "Restored model from best epoch 3 with val_loss: 0.481166\n",
            "NFL direct model 72/201 completed\n",
            "Original data shape: (2487, 8)\n",
            "Flattened data shape: (2487, 8)\n",
            "Split training data: 2238 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.36, 0.365]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7288, Train Loss: 0.5356, Val Acc: 0.7550, Val Loss: 0.5000\n",
            "Restored model from best epoch 11 with val_loss: 0.500001\n",
            "NFL direct model 73/201 completed\n",
            "Original data shape: (2590, 8)\n",
            "Flattened data shape: (2590, 8)\n",
            "Split training data: 2331 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.365, 0.37]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 37\n",
            "Best epoch: 27, Train Acc: 0.7662, Train Loss: 0.5023, Val Acc: 0.7529, Val Loss: 0.4779\n",
            "Restored model from best epoch 27 with val_loss: 0.477856\n",
            "NFL direct model 74/201 completed\n",
            "Original data shape: (2484, 8)\n",
            "Flattened data shape: (2484, 8)\n",
            "Split training data: 2235 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.37, 0.375]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7342, Train Loss: 0.5422, Val Acc: 0.7711, Val Loss: 0.5346\n",
            "Restored model from best epoch 5 with val_loss: 0.534645\n",
            "NFL direct model 75/201 completed\n",
            "Original data shape: (2589, 8)\n",
            "Flattened data shape: (2589, 8)\n",
            "Split training data: 2330 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.375, 0.38]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7232, Train Loss: 0.5583, Val Acc: 0.7490, Val Loss: 0.5131\n",
            "Restored model from best epoch 2 with val_loss: 0.513075\n",
            "NFL direct model 76/201 completed\n",
            "Original data shape: (2520, 8)\n",
            "Flattened data shape: (2520, 8)\n",
            "Split training data: 2268 train, 252 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.38, 0.385]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7474, Train Loss: 0.5206, Val Acc: 0.7262, Val Loss: 0.5310\n",
            "Restored model from best epoch 6 with val_loss: 0.531044\n",
            "NFL direct model 77/201 completed\n",
            "Original data shape: (2524, 8)\n",
            "Flattened data shape: (2524, 8)\n",
            "Split training data: 2271 train, 253 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.385, 0.39]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 48\n",
            "Best epoch: 38, Train Acc: 0.7653, Train Loss: 0.4806, Val Acc: 0.7391, Val Loss: 0.4994\n",
            "Restored model from best epoch 38 with val_loss: 0.499432\n",
            "NFL direct model 78/201 completed\n",
            "Original data shape: (2499, 8)\n",
            "Flattened data shape: (2499, 8)\n",
            "Split training data: 2249 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.39, 0.395]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 40\n",
            "Best epoch: 30, Train Acc: 0.7443, Train Loss: 0.4895, Val Acc: 0.7480, Val Loss: 0.4942\n",
            "Restored model from best epoch 30 with val_loss: 0.494158\n",
            "NFL direct model 79/201 completed\n",
            "Original data shape: (2544, 8)\n",
            "Flattened data shape: (2544, 8)\n",
            "Split training data: 2289 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.395, 0.4]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7466, Train Loss: 0.5075, Val Acc: 0.7490, Val Loss: 0.5294\n",
            "Restored model from best epoch 17 with val_loss: 0.529359\n",
            "NFL direct model 80/201 completed\n",
            "Original data shape: (2516, 8)\n",
            "Flattened data shape: (2516, 8)\n",
            "Split training data: 2264 train, 252 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.4, 0.405]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7425, Train Loss: 0.5150, Val Acc: 0.7381, Val Loss: 0.5153\n",
            "Restored model from best epoch 14 with val_loss: 0.515330\n",
            "NFL direct model 81/201 completed\n",
            "Original data shape: (2405, 8)\n",
            "Flattened data shape: (2405, 8)\n",
            "Split training data: 2164 train, 241 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.405, 0.41]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.7699, Train Loss: 0.4823, Val Acc: 0.7718, Val Loss: 0.4510\n",
            "Restored model from best epoch 26 with val_loss: 0.451031\n",
            "NFL direct model 82/201 completed\n",
            "Original data shape: (2617, 8)\n",
            "Flattened data shape: (2617, 8)\n",
            "Split training data: 2355 train, 262 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.41, 0.415]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7079, Train Loss: 0.5933, Val Acc: 0.7176, Val Loss: 0.5626\n",
            "Restored model from best epoch 2 with val_loss: 0.562576\n",
            "NFL direct model 83/201 completed\n",
            "Original data shape: (2491, 8)\n",
            "Flattened data shape: (2491, 8)\n",
            "Split training data: 2241 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.415, 0.42]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7492, Train Loss: 0.5123, Val Acc: 0.7200, Val Loss: 0.5234\n",
            "Restored model from best epoch 14 with val_loss: 0.523381\n",
            "NFL direct model 84/201 completed\n",
            "Original data shape: (2601, 8)\n",
            "Flattened data shape: (2601, 8)\n",
            "Split training data: 2340 train, 261 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.42, 0.425]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7397, Train Loss: 0.5209, Val Acc: 0.7433, Val Loss: 0.5011\n",
            "Restored model from best epoch 11 with val_loss: 0.501082\n",
            "NFL direct model 85/201 completed\n",
            "Original data shape: (2571, 8)\n",
            "Flattened data shape: (2571, 8)\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.425, 0.43]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7566, Train Loss: 0.5083, Val Acc: 0.7636, Val Loss: 0.4596\n",
            "Restored model from best epoch 12 with val_loss: 0.459649\n",
            "NFL direct model 86/201 completed\n",
            "Original data shape: (2489, 8)\n",
            "Flattened data shape: (2489, 8)\n",
            "Split training data: 2240 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.43, 0.435]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7487, Train Loss: 0.5285, Val Acc: 0.7028, Val Loss: 0.5485\n",
            "Restored model from best epoch 5 with val_loss: 0.548500\n",
            "NFL direct model 87/201 completed\n",
            "Original data shape: (2590, 8)\n",
            "Flattened data shape: (2590, 8)\n",
            "Split training data: 2331 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.435, 0.44]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7413, Train Loss: 0.5357, Val Acc: 0.7452, Val Loss: 0.4671\n",
            "Restored model from best epoch 3 with val_loss: 0.467140\n",
            "NFL direct model 88/201 completed\n",
            "Original data shape: (2500, 8)\n",
            "Flattened data shape: (2500, 8)\n",
            "Split training data: 2250 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.44, 0.445]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7409, Train Loss: 0.5155, Val Acc: 0.7640, Val Loss: 0.4698\n",
            "Restored model from best epoch 5 with val_loss: 0.469769\n",
            "NFL direct model 89/201 completed\n",
            "Original data shape: (2587, 8)\n",
            "Flattened data shape: (2587, 8)\n",
            "Split training data: 2328 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.445, 0.45]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 37\n",
            "Best epoch: 27, Train Acc: 0.7685, Train Loss: 0.4892, Val Acc: 0.7606, Val Loss: 0.4421\n",
            "Restored model from best epoch 27 with val_loss: 0.442082\n",
            "NFL direct model 90/201 completed\n",
            "Original data shape: (2541, 8)\n",
            "Flattened data shape: (2541, 8)\n",
            "Split training data: 2286 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.45, 0.455]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7423, Train Loss: 0.5349, Val Acc: 0.7882, Val Loss: 0.4639\n",
            "Restored model from best epoch 2 with val_loss: 0.463908\n",
            "NFL direct model 91/201 completed\n",
            "Original data shape: (2543, 8)\n",
            "Flattened data shape: (2543, 8)\n",
            "Split training data: 2288 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.455, 0.46]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7351, Train Loss: 0.5173, Val Acc: 0.7529, Val Loss: 0.4963\n",
            "Restored model from best epoch 7 with val_loss: 0.496344\n",
            "NFL direct model 92/201 completed\n",
            "Original data shape: (2621, 8)\n",
            "Flattened data shape: (2621, 8)\n",
            "Split training data: 2358 train, 263 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.46, 0.465]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.7752, Train Loss: 0.4662, Val Acc: 0.7681, Val Loss: 0.4741\n",
            "Restored model from best epoch 20 with val_loss: 0.474141\n",
            "NFL direct model 93/201 completed\n",
            "Original data shape: (2397, 8)\n",
            "Flattened data shape: (2397, 8)\n",
            "Split training data: 2157 train, 240 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.465, 0.47]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7756, Train Loss: 0.4700, Val Acc: 0.7125, Val Loss: 0.5071\n",
            "Restored model from best epoch 11 with val_loss: 0.507087\n",
            "NFL direct model 94/201 completed\n",
            "Original data shape: (7065, 8)\n",
            "Flattened data shape: (7065, 8)\n",
            "Split training data: 6358 train, 707 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.47, 0.475]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 50\n",
            "Best epoch: 40, Train Acc: 0.7925, Train Loss: 0.4380, Val Acc: 0.7652, Val Loss: 0.4758\n",
            "Restored model from best epoch 40 with val_loss: 0.475789\n",
            "NFL direct model 95/201 completed\n",
            "Original data shape: (3598, 8)\n",
            "Flattened data shape: (3598, 8)\n",
            "Split training data: 3238 train, 360 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.475, 0.48]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.7878, Train Loss: 0.4422, Val Acc: 0.7778, Val Loss: 0.4470\n",
            "Restored model from best epoch 23 with val_loss: 0.447004\n",
            "NFL direct model 96/201 completed\n",
            "Original data shape: (3810, 8)\n",
            "Flattened data shape: (3810, 8)\n",
            "Split training data: 3429 train, 381 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.48, 0.485]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7635, Train Loss: 0.4963, Val Acc: 0.7690, Val Loss: 0.4885\n",
            "Restored model from best epoch 2 with val_loss: 0.488455\n",
            "NFL direct model 97/201 completed\n",
            "Original data shape: (4338, 8)\n",
            "Flattened data shape: (4338, 8)\n",
            "Split training data: 3904 train, 434 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.485, 0.49]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.7859, Train Loss: 0.4528, Val Acc: 0.7857, Val Loss: 0.4396\n",
            "Restored model from best epoch 22 with val_loss: 0.439624\n",
            "NFL direct model 98/201 completed\n",
            "Original data shape: (5250, 8)\n",
            "Flattened data shape: (5250, 8)\n",
            "Split training data: 4725 train, 525 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.49, 0.495]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7843, Train Loss: 0.4656, Val Acc: 0.7638, Val Loss: 0.5055\n",
            "Restored model from best epoch 10 with val_loss: 0.505529\n",
            "NFL direct model 99/201 completed\n",
            "Original data shape: (6401, 8)\n",
            "Flattened data shape: (6401, 8)\n",
            "Split training data: 5760 train, 641 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.495, 0.5]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7844, Train Loss: 0.4581, Val Acc: 0.7941, Val Loss: 0.4202\n",
            "Restored model from best epoch 17 with val_loss: 0.420187\n",
            "NFL direct model 100/201 completed\n",
            "Original data shape: (11557, 8)\n",
            "Flattened data shape: (11557, 8)\n",
            "Split training data: 10401 train, 1156 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.5, 0.505]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 46\n",
            "Best epoch: 36, Train Acc: 0.7981, Train Loss: 0.4366, Val Acc: 0.7863, Val Loss: 0.4497\n",
            "Restored model from best epoch 36 with val_loss: 0.449725\n",
            "NFL direct model 101/201 completed\n",
            "Original data shape: (1400, 8)\n",
            "Flattened data shape: (1400, 8)\n",
            "Split training data: 1260 train, 140 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.505, 0.51]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7905, Train Loss: 0.4360, Val Acc: 0.7786, Val Loss: 0.3474\n",
            "Restored model from best epoch 16 with val_loss: 0.347393\n",
            "NFL direct model 102/201 completed\n",
            "Original data shape: (2371, 8)\n",
            "Flattened data shape: (2371, 8)\n",
            "Split training data: 2133 train, 238 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.51, 0.515]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7853, Train Loss: 0.4510, Val Acc: 0.8109, Val Loss: 0.4363\n",
            "Restored model from best epoch 9 with val_loss: 0.436320\n",
            "NFL direct model 103/201 completed\n",
            "Original data shape: (2083, 8)\n",
            "Flattened data shape: (2083, 8)\n",
            "Split training data: 1874 train, 209 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.515, 0.52]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7609, Train Loss: 0.5088, Val Acc: 0.7943, Val Loss: 0.4171\n",
            "Restored model from best epoch 2 with val_loss: 0.417131\n",
            "NFL direct model 104/201 completed\n",
            "Original data shape: (2354, 8)\n",
            "Flattened data shape: (2354, 8)\n",
            "Split training data: 2118 train, 236 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.52, 0.525]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7875, Train Loss: 0.4755, Val Acc: 0.7881, Val Loss: 0.4393\n",
            "Restored model from best epoch 7 with val_loss: 0.439330\n",
            "NFL direct model 105/201 completed\n",
            "Original data shape: (2510, 8)\n",
            "Flattened data shape: (2510, 8)\n",
            "Split training data: 2259 train, 251 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.525, 0.53]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7942, Train Loss: 0.4436, Val Acc: 0.8008, Val Loss: 0.4358\n",
            "Restored model from best epoch 11 with val_loss: 0.435834\n",
            "NFL direct model 106/201 completed\n",
            "Original data shape: (2346, 8)\n",
            "Flattened data shape: (2346, 8)\n",
            "Split training data: 2111 train, 235 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.53, 0.535]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 35\n",
            "Best epoch: 25, Train Acc: 0.7830, Train Loss: 0.4542, Val Acc: 0.8043, Val Loss: 0.4021\n",
            "Restored model from best epoch 25 with val_loss: 0.402069\n",
            "NFL direct model 107/201 completed\n",
            "Original data shape: (2510, 8)\n",
            "Flattened data shape: (2510, 8)\n",
            "Split training data: 2259 train, 251 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.535, 0.54]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8026, Train Loss: 0.4280, Val Acc: 0.8207, Val Loss: 0.4143\n",
            "Restored model from best epoch 12 with val_loss: 0.414344\n",
            "NFL direct model 108/201 completed\n",
            "Original data shape: (2420, 8)\n",
            "Flattened data shape: (2420, 8)\n",
            "Split training data: 2178 train, 242 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.54, 0.545]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7906, Train Loss: 0.4621, Val Acc: 0.7934, Val Loss: 0.4397\n",
            "Restored model from best epoch 16 with val_loss: 0.439685\n",
            "NFL direct model 109/201 completed\n",
            "Original data shape: (2390, 8)\n",
            "Flattened data shape: (2390, 8)\n",
            "Split training data: 2151 train, 239 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.545, 0.55]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.7875, Train Loss: 0.4696, Val Acc: 0.7908, Val Loss: 0.4621\n",
            "Restored model from best epoch 8 with val_loss: 0.462081\n",
            "NFL direct model 110/201 completed\n",
            "Original data shape: (2466, 8)\n",
            "Flattened data shape: (2466, 8)\n",
            "Split training data: 2219 train, 247 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.55, 0.555]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7841, Train Loss: 0.4707, Val Acc: 0.8097, Val Loss: 0.4257\n",
            "Restored model from best epoch 3 with val_loss: 0.425714\n",
            "NFL direct model 111/201 completed\n",
            "Original data shape: (2463, 8)\n",
            "Flattened data shape: (2463, 8)\n",
            "Split training data: 2216 train, 247 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.555, 0.56]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7956, Train Loss: 0.4465, Val Acc: 0.7895, Val Loss: 0.4371\n",
            "Restored model from best epoch 14 with val_loss: 0.437096\n",
            "NFL direct model 112/201 completed\n",
            "Original data shape: (2530, 8)\n",
            "Flattened data shape: (2530, 8)\n",
            "Split training data: 2277 train, 253 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.56, 0.565]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.7967, Train Loss: 0.4453, Val Acc: 0.8379, Val Loss: 0.3926\n",
            "Restored model from best epoch 8 with val_loss: 0.392565\n",
            "NFL direct model 113/201 completed\n",
            "Original data shape: (2486, 8)\n",
            "Flattened data shape: (2486, 8)\n",
            "Split training data: 2237 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.565, 0.57]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.8033, Train Loss: 0.4234, Val Acc: 0.8153, Val Loss: 0.3923\n",
            "Restored model from best epoch 24 with val_loss: 0.392266\n",
            "NFL direct model 114/201 completed\n",
            "Original data shape: (2557, 8)\n",
            "Flattened data shape: (2557, 8)\n",
            "Split training data: 2301 train, 256 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.57, 0.575]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8031, Train Loss: 0.4308, Val Acc: 0.7812, Val Loss: 0.4467\n",
            "Restored model from best epoch 11 with val_loss: 0.446739\n",
            "NFL direct model 115/201 completed\n",
            "Original data shape: (2557, 8)\n",
            "Flattened data shape: (2557, 8)\n",
            "Split training data: 2301 train, 256 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.575, 0.58]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7849, Train Loss: 0.4680, Val Acc: 0.7656, Val Loss: 0.4920\n",
            "Restored model from best epoch 3 with val_loss: 0.491953\n",
            "NFL direct model 116/201 completed\n",
            "Original data shape: (2486, 8)\n",
            "Flattened data shape: (2486, 8)\n",
            "Split training data: 2237 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.58, 0.585]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7939, Train Loss: 0.4433, Val Acc: 0.7390, Val Loss: 0.4760\n",
            "Restored model from best epoch 7 with val_loss: 0.476014\n",
            "NFL direct model 117/201 completed\n",
            "Original data shape: (2535, 8)\n",
            "Flattened data shape: (2535, 8)\n",
            "Split training data: 2281 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.585, 0.59]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7992, Train Loss: 0.4393, Val Acc: 0.8307, Val Loss: 0.4061\n",
            "Restored model from best epoch 9 with val_loss: 0.406110\n",
            "NFL direct model 118/201 completed\n",
            "Original data shape: (2629, 8)\n",
            "Flattened data shape: (2629, 8)\n",
            "Split training data: 2366 train, 263 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.59, 0.595]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7963, Train Loss: 0.4479, Val Acc: 0.7681, Val Loss: 0.4872\n",
            "Restored model from best epoch 9 with val_loss: 0.487224\n",
            "NFL direct model 119/201 completed\n",
            "Original data shape: (2544, 8)\n",
            "Flattened data shape: (2544, 8)\n",
            "Split training data: 2289 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.595, 0.6]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8060, Train Loss: 0.4244, Val Acc: 0.7804, Val Loss: 0.4634\n",
            "Restored model from best epoch 10 with val_loss: 0.463443\n",
            "NFL direct model 120/201 completed\n",
            "Original data shape: (2536, 8)\n",
            "Flattened data shape: (2536, 8)\n",
            "Split training data: 2282 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.6, 0.605]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7840, Train Loss: 0.4542, Val Acc: 0.7874, Val Loss: 0.4408\n",
            "Restored model from best epoch 6 with val_loss: 0.440803\n",
            "NFL direct model 121/201 completed\n",
            "Original data shape: (2572, 8)\n",
            "Flattened data shape: (2572, 8)\n",
            "Split training data: 2314 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.605, 0.61]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8068, Train Loss: 0.4182, Val Acc: 0.8062, Val Loss: 0.4396\n",
            "Restored model from best epoch 17 with val_loss: 0.439557\n",
            "NFL direct model 122/201 completed\n",
            "Original data shape: (2591, 8)\n",
            "Flattened data shape: (2591, 8)\n",
            "Split training data: 2331 train, 260 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.61, 0.615]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7765, Train Loss: 0.4715, Val Acc: 0.7923, Val Loss: 0.4483\n",
            "Restored model from best epoch 2 with val_loss: 0.448347\n",
            "NFL direct model 123/201 completed\n",
            "Original data shape: (2527, 8)\n",
            "Flattened data shape: (2527, 8)\n",
            "Split training data: 2274 train, 253 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.615, 0.62]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7801, Train Loss: 0.4585, Val Acc: 0.7510, Val Loss: 0.4869\n",
            "Restored model from best epoch 2 with val_loss: 0.486918\n",
            "NFL direct model 124/201 completed\n",
            "Original data shape: (2489, 8)\n",
            "Flattened data shape: (2489, 8)\n",
            "Split training data: 2240 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.62, 0.625]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8089, Train Loss: 0.4235, Val Acc: 0.7912, Val Loss: 0.4252\n",
            "Restored model from best epoch 14 with val_loss: 0.425199\n",
            "NFL direct model 125/201 completed\n",
            "Original data shape: (2589, 8)\n",
            "Flattened data shape: (2589, 8)\n",
            "Split training data: 2330 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.625, 0.63]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7957, Train Loss: 0.4531, Val Acc: 0.8031, Val Loss: 0.5811\n",
            "Restored model from best epoch 3 with val_loss: 0.581061\n",
            "NFL direct model 126/201 completed\n",
            "Original data shape: (2570, 8)\n",
            "Flattened data shape: (2570, 8)\n",
            "Split training data: 2313 train, 257 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.63, 0.635]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 42\n",
            "Best epoch: 32, Train Acc: 0.8258, Train Loss: 0.3796, Val Acc: 0.8288, Val Loss: 0.3690\n",
            "Restored model from best epoch 32 with val_loss: 0.368956\n",
            "NFL direct model 127/201 completed\n",
            "Original data shape: (2557, 8)\n",
            "Flattened data shape: (2557, 8)\n",
            "Split training data: 2301 train, 256 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.635, 0.64]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7736, Train Loss: 0.4785, Val Acc: 0.7539, Val Loss: 0.4774\n",
            "Restored model from best epoch 2 with val_loss: 0.477428\n",
            "NFL direct model 128/201 completed\n",
            "Original data shape: (2397, 8)\n",
            "Flattened data shape: (2397, 8)\n",
            "Split training data: 2157 train, 240 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.64, 0.645]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.8197, Train Loss: 0.3936, Val Acc: 0.7917, Val Loss: 0.4323\n",
            "Restored model from best epoch 29 with val_loss: 0.432326\n",
            "NFL direct model 129/201 completed\n",
            "Original data shape: (2609, 8)\n",
            "Flattened data shape: (2609, 8)\n",
            "Split training data: 2348 train, 261 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.645, 0.65]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8058, Train Loss: 0.4331, Val Acc: 0.7586, Val Loss: 0.5124\n",
            "Restored model from best epoch 5 with val_loss: 0.512425\n",
            "NFL direct model 130/201 completed\n",
            "Original data shape: (2528, 8)\n",
            "Flattened data shape: (2528, 8)\n",
            "Split training data: 2275 train, 253 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.65, 0.655]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.8092, Train Loss: 0.4065, Val Acc: 0.8340, Val Loss: 0.3805\n",
            "Restored model from best epoch 18 with val_loss: 0.380469\n",
            "NFL direct model 131/201 completed\n",
            "Original data shape: (2583, 8)\n",
            "Flattened data shape: (2583, 8)\n",
            "Split training data: 2324 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.655, 0.66]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8249, Train Loss: 0.3925, Val Acc: 0.8378, Val Loss: 0.3245\n",
            "Restored model from best epoch 14 with val_loss: 0.324503\n",
            "NFL direct model 132/201 completed\n",
            "Original data shape: (2571, 8)\n",
            "Flattened data shape: (2571, 8)\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.66, 0.665]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8167, Train Loss: 0.4082, Val Acc: 0.8101, Val Loss: 0.4118\n",
            "Restored model from best epoch 6 with val_loss: 0.411793\n",
            "NFL direct model 133/201 completed\n",
            "Original data shape: (2538, 8)\n",
            "Flattened data shape: (2538, 8)\n",
            "Split training data: 2284 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.665, 0.67]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8139, Train Loss: 0.3932, Val Acc: 0.8386, Val Loss: 0.3480\n",
            "Restored model from best epoch 10 with val_loss: 0.348023\n",
            "NFL direct model 134/201 completed\n",
            "Original data shape: (2475, 8)\n",
            "Flattened data shape: (2475, 8)\n",
            "Split training data: 2227 train, 248 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.67, 0.675]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.8334, Train Loss: 0.3859, Val Acc: 0.7944, Val Loss: 0.4520\n",
            "Restored model from best epoch 18 with val_loss: 0.451980\n",
            "NFL direct model 135/201 completed\n",
            "Original data shape: (2545, 8)\n",
            "Flattened data shape: (2545, 8)\n",
            "Split training data: 2290 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.675, 0.68]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 64\n",
            "Best epoch: 54, Train Acc: 0.8397, Train Loss: 0.3575, Val Acc: 0.8314, Val Loss: 0.3414\n",
            "Restored model from best epoch 54 with val_loss: 0.341441\n",
            "NFL direct model 136/201 completed\n",
            "Original data shape: (2500, 8)\n",
            "Flattened data shape: (2500, 8)\n",
            "Split training data: 2250 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.68, 0.685]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8000, Train Loss: 0.4225, Val Acc: 0.8160, Val Loss: 0.3662\n",
            "Restored model from best epoch 10 with val_loss: 0.366225\n",
            "NFL direct model 137/201 completed\n",
            "Original data shape: (2630, 8)\n",
            "Flattened data shape: (2630, 8)\n",
            "Split training data: 2367 train, 263 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.685, 0.69]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8154, Train Loss: 0.3869, Val Acc: 0.8137, Val Loss: 0.3635\n",
            "Restored model from best epoch 15 with val_loss: 0.363524\n",
            "NFL direct model 138/201 completed\n",
            "Original data shape: (2540, 8)\n",
            "Flattened data shape: (2540, 8)\n",
            "Split training data: 2286 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.69, 0.695]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8255, Train Loss: 0.3817, Val Acc: 0.7480, Val Loss: 0.4653\n",
            "Restored model from best epoch 12 with val_loss: 0.465264\n",
            "NFL direct model 139/201 completed\n",
            "Original data shape: (2535, 8)\n",
            "Flattened data shape: (2535, 8)\n",
            "Split training data: 2281 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.695, 0.7]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8146, Train Loss: 0.3911, Val Acc: 0.8465, Val Loss: 0.3612\n",
            "Restored model from best epoch 8 with val_loss: 0.361203\n",
            "NFL direct model 140/201 completed\n",
            "Original data shape: (2584, 8)\n",
            "Flattened data shape: (2584, 8)\n",
            "Split training data: 2325 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.7, 0.705]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 47\n",
            "Best epoch: 37, Train Acc: 0.8404, Train Loss: 0.3480, Val Acc: 0.8185, Val Loss: 0.3278\n",
            "Restored model from best epoch 37 with val_loss: 0.327763\n",
            "NFL direct model 141/201 completed\n",
            "Original data shape: (2483, 8)\n",
            "Flattened data shape: (2483, 8)\n",
            "Split training data: 2234 train, 249 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.705, 0.71]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8147, Train Loss: 0.3989, Val Acc: 0.8554, Val Loss: 0.3612\n",
            "Restored model from best epoch 6 with val_loss: 0.361229\n",
            "NFL direct model 142/201 completed\n",
            "Original data shape: (2473, 8)\n",
            "Flattened data shape: (2473, 8)\n",
            "Split training data: 2225 train, 248 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.71, 0.715]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8270, Train Loss: 0.3962, Val Acc: 0.8589, Val Loss: 0.3659\n",
            "Restored model from best epoch 7 with val_loss: 0.365936\n",
            "NFL direct model 143/201 completed\n",
            "Original data shape: (2578, 8)\n",
            "Flattened data shape: (2578, 8)\n",
            "Split training data: 2320 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.715, 0.72]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8091, Train Loss: 0.4191, Val Acc: 0.7907, Val Loss: 0.3868\n",
            "Restored model from best epoch 5 with val_loss: 0.386831\n",
            "NFL direct model 144/201 completed\n",
            "Original data shape: (2533, 8)\n",
            "Flattened data shape: (2533, 8)\n",
            "Split training data: 2279 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.72, 0.725]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8447, Train Loss: 0.3617, Val Acc: 0.8465, Val Loss: 0.3854\n",
            "Restored model from best epoch 14 with val_loss: 0.385377\n",
            "NFL direct model 145/201 completed\n",
            "Original data shape: (2565, 8)\n",
            "Flattened data shape: (2565, 8)\n",
            "Split training data: 2308 train, 257 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.725, 0.73]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8219, Train Loss: 0.3799, Val Acc: 0.8132, Val Loss: 0.5914\n",
            "Restored model from best epoch 11 with val_loss: 0.591372\n",
            "NFL direct model 146/201 completed\n",
            "Original data shape: (2571, 8)\n",
            "Flattened data shape: (2571, 8)\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.73, 0.735]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.8426, Train Loss: 0.3606, Val Acc: 0.8101, Val Loss: 0.3286\n",
            "Restored model from best epoch 23 with val_loss: 0.328621\n",
            "NFL direct model 147/201 completed\n",
            "Original data shape: (2522, 8)\n",
            "Flattened data shape: (2522, 8)\n",
            "Split training data: 2269 train, 253 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.735, 0.74]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8290, Train Loss: 0.3797, Val Acc: 0.8340, Val Loss: 0.3822\n",
            "Restored model from best epoch 8 with val_loss: 0.382183\n",
            "NFL direct model 148/201 completed\n",
            "Original data shape: (2362, 8)\n",
            "Flattened data shape: (2362, 8)\n",
            "Split training data: 2125 train, 237 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.74, 0.745]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8386, Train Loss: 0.3519, Val Acc: 0.8143, Val Loss: 0.3676\n",
            "Restored model from best epoch 14 with val_loss: 0.367639\n",
            "NFL direct model 149/201 completed\n",
            "Original data shape: (2260, 8)\n",
            "Flattened data shape: (2260, 8)\n",
            "Split training data: 2034 train, 226 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.745, 0.75]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8294, Train Loss: 0.3979, Val Acc: 0.7876, Val Loss: 0.4413\n",
            "Restored model from best epoch 6 with val_loss: 0.441275\n",
            "NFL direct model 150/201 completed\n",
            "Original data shape: (7304, 8)\n",
            "Flattened data shape: (7304, 8)\n",
            "Split training data: 6573 train, 731 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.75, 0.755]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 51\n",
            "Best epoch: 41, Train Acc: 0.8518, Train Loss: 0.3231, Val Acc: 0.8577, Val Loss: 0.3070\n",
            "Restored model from best epoch 41 with val_loss: 0.307025\n",
            "NFL direct model 151/201 completed\n",
            "Original data shape: (1469, 8)\n",
            "Flattened data shape: (1469, 8)\n",
            "Split training data: 1322 train, 147 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.755, 0.76]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8457, Train Loss: 0.3472, Val Acc: 0.7959, Val Loss: 0.4765\n",
            "Restored model from best epoch 7 with val_loss: 0.476494\n",
            "NFL direct model 152/201 completed\n",
            "Original data shape: (1949, 8)\n",
            "Flattened data shape: (1949, 8)\n",
            "Split training data: 1754 train, 195 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.76, 0.765]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7851, Train Loss: 0.4883, Val Acc: 0.8154, Val Loss: 0.5095\n",
            "Restored model from best epoch 2 with val_loss: 0.509480\n",
            "NFL direct model 153/201 completed\n",
            "Original data shape: (2668, 8)\n",
            "Flattened data shape: (2668, 8)\n",
            "Split training data: 2401 train, 267 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.765, 0.77]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8505, Train Loss: 0.3750, Val Acc: 0.8127, Val Loss: 0.4240\n",
            "Restored model from best epoch 3 with val_loss: 0.423996\n",
            "NFL direct model 154/201 completed\n",
            "Original data shape: (2290, 8)\n",
            "Flattened data shape: (2290, 8)\n",
            "Split training data: 2061 train, 229 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.77, 0.775]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8239, Train Loss: 0.3843, Val Acc: 0.8603, Val Loss: 0.3556\n",
            "Restored model from best epoch 13 with val_loss: 0.355552\n",
            "NFL direct model 155/201 completed\n",
            "Original data shape: (2833, 8)\n",
            "Flattened data shape: (2833, 8)\n",
            "Split training data: 2549 train, 284 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.775, 0.78]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8478, Train Loss: 0.3474, Val Acc: 0.8204, Val Loss: 0.3865\n",
            "Restored model from best epoch 11 with val_loss: 0.386538\n",
            "NFL direct model 156/201 completed\n",
            "Original data shape: (2390, 8)\n",
            "Flattened data shape: (2390, 8)\n",
            "Split training data: 2151 train, 239 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.78, 0.785]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 19, Train Acc: 0.8503, Train Loss: 0.3441, Val Acc: 0.8745, Val Loss: 0.3151\n",
            "Restored model from best epoch 19 with val_loss: 0.315092\n",
            "NFL direct model 157/201 completed\n",
            "Original data shape: (2623, 8)\n",
            "Flattened data shape: (2623, 8)\n",
            "Split training data: 2360 train, 263 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.785, 0.79]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.8564, Train Loss: 0.3309, Val Acc: 0.8137, Val Loss: 0.3509\n",
            "Restored model from best epoch 20 with val_loss: 0.350870\n",
            "NFL direct model 158/201 completed\n",
            "Original data shape: (2478, 8)\n",
            "Flattened data shape: (2478, 8)\n",
            "Split training data: 2230 train, 248 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.79, 0.795]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8650, Train Loss: 0.3222, Val Acc: 0.8145, Val Loss: 0.3725\n",
            "Restored model from best epoch 10 with val_loss: 0.372531\n",
            "NFL direct model 159/201 completed\n",
            "Original data shape: (2455, 8)\n",
            "Flattened data shape: (2455, 8)\n",
            "Split training data: 2209 train, 246 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.795, 0.8]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8370, Train Loss: 0.3599, Val Acc: 0.8211, Val Loss: 0.3590\n",
            "Restored model from best epoch 9 with val_loss: 0.358984\n",
            "NFL direct model 160/201 completed\n",
            "Original data shape: (2696, 8)\n",
            "Flattened data shape: (2696, 8)\n",
            "Split training data: 2426 train, 270 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.8, 0.805]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.8631, Train Loss: 0.3234, Val Acc: 0.8519, Val Loss: 0.3437\n",
            "Restored model from best epoch 22 with val_loss: 0.343721\n",
            "NFL direct model 161/201 completed\n",
            "Original data shape: (2586, 8)\n",
            "Flattened data shape: (2586, 8)\n",
            "Split training data: 2327 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.805, 0.81]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8354, Train Loss: 0.3755, Val Acc: 0.8649, Val Loss: 0.4649\n",
            "Restored model from best epoch 3 with val_loss: 0.464940\n",
            "NFL direct model 162/201 completed\n",
            "Original data shape: (2593, 8)\n",
            "Flattened data shape: (2593, 8)\n",
            "Split training data: 2333 train, 260 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.81, 0.815]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8543, Train Loss: 0.3486, Val Acc: 0.8385, Val Loss: 0.3750\n",
            "Restored model from best epoch 10 with val_loss: 0.374998\n",
            "NFL direct model 163/201 completed\n",
            "Original data shape: (2571, 8)\n",
            "Flattened data shape: (2571, 8)\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.815, 0.82]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8448, Train Loss: 0.3585, Val Acc: 0.8488, Val Loss: 0.2925\n",
            "Restored model from best epoch 4 with val_loss: 0.292475\n",
            "NFL direct model 164/201 completed\n",
            "Original data shape: (2622, 8)\n",
            "Flattened data shape: (2622, 8)\n",
            "Split training data: 2359 train, 263 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.82, 0.825]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8593, Train Loss: 0.3322, Val Acc: 0.8137, Val Loss: 0.4819\n",
            "Restored model from best epoch 10 with val_loss: 0.481938\n",
            "NFL direct model 165/201 completed\n",
            "Original data shape: (2499, 8)\n",
            "Flattened data shape: (2499, 8)\n",
            "Split training data: 2249 train, 250 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.825, 0.83]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8595, Train Loss: 0.3163, Val Acc: 0.8200, Val Loss: 0.4075\n",
            "Restored model from best epoch 16 with val_loss: 0.407475\n",
            "NFL direct model 166/201 completed\n",
            "Original data shape: (2510, 8)\n",
            "Flattened data shape: (2510, 8)\n",
            "Split training data: 2259 train, 251 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.83, 0.835]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8654, Train Loss: 0.3304, Val Acc: 0.8805, Val Loss: 0.3108\n",
            "Restored model from best epoch 8 with val_loss: 0.310806\n",
            "NFL direct model 167/201 completed\n",
            "Original data shape: (2539, 8)\n",
            "Flattened data shape: (2539, 8)\n",
            "Split training data: 2285 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.835, 0.84]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8604, Train Loss: 0.3145, Val Acc: 0.8976, Val Loss: 0.2821\n",
            "Restored model from best epoch 10 with val_loss: 0.282065\n",
            "NFL direct model 168/201 completed\n",
            "Original data shape: (2569, 8)\n",
            "Flattened data shape: (2569, 8)\n",
            "Split training data: 2312 train, 257 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.84, 0.845]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8698, Train Loss: 0.2991, Val Acc: 0.8833, Val Loss: 0.2637\n",
            "Restored model from best epoch 14 with val_loss: 0.263730\n",
            "NFL direct model 169/201 completed\n",
            "Original data shape: (2574, 8)\n",
            "Flattened data shape: (2574, 8)\n",
            "Split training data: 2316 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.845, 0.85]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8605, Train Loss: 0.3310, Val Acc: 0.8217, Val Loss: 0.3646\n",
            "Restored model from best epoch 9 with val_loss: 0.364607\n",
            "NFL direct model 170/201 completed\n",
            "Original data shape: (2555, 8)\n",
            "Flattened data shape: (2555, 8)\n",
            "Split training data: 2299 train, 256 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.85, 0.855]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8669, Train Loss: 0.3121, Val Acc: 0.8281, Val Loss: 0.3635\n",
            "Restored model from best epoch 12 with val_loss: 0.363504\n",
            "NFL direct model 171/201 completed\n",
            "Original data shape: (2544, 8)\n",
            "Flattened data shape: (2544, 8)\n",
            "Split training data: 2289 train, 255 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.855, 0.86]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8707, Train Loss: 0.2995, Val Acc: 0.8667, Val Loss: 0.3326\n",
            "Restored model from best epoch 16 with val_loss: 0.332602\n",
            "NFL direct model 172/201 completed\n",
            "Original data shape: (2561, 8)\n",
            "Flattened data shape: (2561, 8)\n",
            "Split training data: 2304 train, 257 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.86, 0.865]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8685, Train Loss: 0.3002, Val Acc: 0.8521, Val Loss: 0.2720\n",
            "Restored model from best epoch 14 with val_loss: 0.271993\n",
            "NFL direct model 173/201 completed\n",
            "Original data shape: (2571, 8)\n",
            "Flattened data shape: (2571, 8)\n",
            "Split training data: 2313 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.865, 0.87]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8681, Train Loss: 0.3083, Val Acc: 0.8721, Val Loss: 0.2372\n",
            "Restored model from best epoch 14 with val_loss: 0.237225\n",
            "NFL direct model 174/201 completed\n",
            "Original data shape: (2537, 8)\n",
            "Flattened data shape: (2537, 8)\n",
            "Split training data: 2283 train, 254 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.87, 0.875]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8519, Train Loss: 0.3130, Val Acc: 0.8622, Val Loss: 0.3072\n",
            "Restored model from best epoch 15 with val_loss: 0.307156\n",
            "NFL direct model 175/201 completed\n",
            "Original data shape: (2620, 8)\n",
            "Flattened data shape: (2620, 8)\n",
            "Split training data: 2358 train, 262 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.875, 0.88]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8660, Train Loss: 0.3152, Val Acc: 0.8397, Val Loss: 0.3509\n",
            "Restored model from best epoch 6 with val_loss: 0.350901\n",
            "NFL direct model 176/201 completed\n",
            "Original data shape: (2585, 8)\n",
            "Flattened data shape: (2585, 8)\n",
            "Split training data: 2326 train, 259 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.88, 0.885]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8710, Train Loss: 0.2769, Val Acc: 0.8147, Val Loss: 0.4138\n",
            "Restored model from best epoch 16 with val_loss: 0.413847\n",
            "NFL direct model 177/201 completed\n",
            "Original data shape: (2607, 8)\n",
            "Flattened data shape: (2607, 8)\n",
            "Split training data: 2346 train, 261 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.885, 0.89]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8662, Train Loss: 0.3021, Val Acc: 0.8008, Val Loss: 0.3736\n",
            "Restored model from best epoch 15 with val_loss: 0.373552\n",
            "NFL direct model 178/201 completed\n",
            "Original data shape: (2576, 8)\n",
            "Flattened data shape: (2576, 8)\n",
            "Split training data: 2318 train, 258 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.89, 0.895]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8740, Train Loss: 0.2933, Val Acc: 0.8566, Val Loss: 0.2672\n",
            "Restored model from best epoch 10 with val_loss: 0.267155\n",
            "NFL direct model 179/201 completed\n",
            "Original data shape: (2651, 8)\n",
            "Flattened data shape: (2651, 8)\n",
            "Split training data: 2385 train, 266 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.895, 0.9]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8906, Train Loss: 0.2615, Val Acc: 0.8759, Val Loss: 0.2947\n",
            "Restored model from best epoch 10 with val_loss: 0.294732\n",
            "NFL direct model 180/201 completed\n",
            "Original data shape: (2604, 8)\n",
            "Flattened data shape: (2604, 8)\n",
            "Split training data: 2343 train, 261 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.9, 0.905]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8613, Train Loss: 0.3159, Val Acc: 0.8544, Val Loss: 0.2944\n",
            "Restored model from best epoch 6 with val_loss: 0.294445\n",
            "NFL direct model 181/201 completed\n",
            "Original data shape: (2597, 8)\n",
            "Flattened data shape: (2597, 8)\n",
            "Split training data: 2337 train, 260 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.905, 0.91]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 44\n",
            "Best epoch: 34, Train Acc: 0.8849, Train Loss: 0.2391, Val Acc: 0.8538, Val Loss: 0.2698\n",
            "Restored model from best epoch 34 with val_loss: 0.269775\n",
            "NFL direct model 182/201 completed\n",
            "Original data shape: (2692, 8)\n",
            "Flattened data shape: (2692, 8)\n",
            "Split training data: 2422 train, 270 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.91, 0.915]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8782, Train Loss: 0.2738, Val Acc: 0.8741, Val Loss: 0.2623\n",
            "Restored model from best epoch 16 with val_loss: 0.262252\n",
            "NFL direct model 183/201 completed\n",
            "Original data shape: (2653, 8)\n",
            "Flattened data shape: (2653, 8)\n",
            "Split training data: 2387 train, 266 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.915, 0.92]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8919, Train Loss: 0.2405, Val Acc: 0.8421, Val Loss: 0.3889\n",
            "Restored model from best epoch 16 with val_loss: 0.388898\n",
            "NFL direct model 184/201 completed\n",
            "Original data shape: (2837, 8)\n",
            "Flattened data shape: (2837, 8)\n",
            "Split training data: 2553 train, 284 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.92, 0.925]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.8844, Train Loss: 0.2575, Val Acc: 0.8732, Val Loss: 0.2626\n",
            "Restored model from best epoch 20 with val_loss: 0.262580\n",
            "NFL direct model 185/201 completed\n",
            "Original data shape: (2961, 8)\n",
            "Flattened data shape: (2961, 8)\n",
            "Split training data: 2664 train, 297 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.925, 0.93]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8821, Train Loss: 0.2709, Val Acc: 0.8586, Val Loss: 0.3199\n",
            "Restored model from best epoch 7 with val_loss: 0.319863\n",
            "NFL direct model 186/201 completed\n",
            "Original data shape: (2893, 8)\n",
            "Flattened data shape: (2893, 8)\n",
            "Split training data: 2603 train, 290 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.93, 0.935]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8955, Train Loss: 0.2432, Val Acc: 0.8759, Val Loss: 0.2895\n",
            "Restored model from best epoch 10 with val_loss: 0.289502\n",
            "NFL direct model 187/201 completed\n",
            "Original data shape: (3014, 8)\n",
            "Flattened data shape: (3014, 8)\n",
            "Split training data: 2712 train, 302 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.935, 0.94]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.8912, Train Loss: 0.2323, Val Acc: 0.8775, Val Loss: 0.2444\n",
            "Restored model from best epoch 22 with val_loss: 0.244361\n",
            "NFL direct model 188/201 completed\n",
            "Original data shape: (3236, 8)\n",
            "Flattened data shape: (3236, 8)\n",
            "Split training data: 2912 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.94, 0.945]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8973, Train Loss: 0.2180, Val Acc: 0.8951, Val Loss: 0.2096\n",
            "Restored model from best epoch 15 with val_loss: 0.209632\n",
            "NFL direct model 189/201 completed\n",
            "Original data shape: (3264, 8)\n",
            "Flattened data shape: (3264, 8)\n",
            "Split training data: 2937 train, 327 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.945, 0.95]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.9016, Train Loss: 0.2204, Val Acc: 0.8838, Val Loss: 0.2259\n",
            "Restored model from best epoch 15 with val_loss: 0.225867\n",
            "NFL direct model 190/201 completed\n",
            "Original data shape: (3376, 8)\n",
            "Flattened data shape: (3376, 8)\n",
            "Split training data: 3038 train, 338 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.95, 0.955]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8858, Train Loss: 0.2575, Val Acc: 0.8876, Val Loss: 0.2311\n",
            "Restored model from best epoch 11 with val_loss: 0.231067\n",
            "NFL direct model 191/201 completed\n",
            "Original data shape: (3231, 8)\n",
            "Flattened data shape: (3231, 8)\n",
            "Split training data: 2907 train, 324 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.955, 0.96]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.8920, Train Loss: 0.2348, Val Acc: 0.8889, Val Loss: 0.1989\n",
            "Restored model from best epoch 22 with val_loss: 0.198920\n",
            "NFL direct model 192/201 completed\n",
            "Original data shape: (3397, 8)\n",
            "Flattened data shape: (3397, 8)\n",
            "Split training data: 3057 train, 340 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.96, 0.965]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.8979, Train Loss: 0.2278, Val Acc: 0.8853, Val Loss: 0.2434\n",
            "Restored model from best epoch 26 with val_loss: 0.243384\n",
            "NFL direct model 193/201 completed\n",
            "Original data shape: (3108, 8)\n",
            "Flattened data shape: (3108, 8)\n",
            "Split training data: 2797 train, 311 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.965, 0.97]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8949, Train Loss: 0.2302, Val Acc: 0.9003, Val Loss: 0.2349\n",
            "Restored model from best epoch 17 with val_loss: 0.234879\n",
            "NFL direct model 194/201 completed\n",
            "Original data shape: (7205, 8)\n",
            "Flattened data shape: (7205, 8)\n",
            "Split training data: 6484 train, 721 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.97, 0.975]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 53\n",
            "Best epoch: 43, Train Acc: 0.9138, Train Loss: 0.1947, Val Acc: 0.9237, Val Loss: 0.1806\n",
            "Restored model from best epoch 43 with val_loss: 0.180595\n",
            "NFL direct model 195/201 completed\n",
            "Original data shape: (3298, 8)\n",
            "Flattened data shape: (3298, 8)\n",
            "Split training data: 2968 train, 330 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.975, 0.98]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.9080, Train Loss: 0.2039, Val Acc: 0.8818, Val Loss: 0.2320\n",
            "Restored model from best epoch 29 with val_loss: 0.232049\n",
            "NFL direct model 196/201 completed\n",
            "Original data shape: (3474, 8)\n",
            "Flattened data shape: (3474, 8)\n",
            "Split training data: 3126 train, 348 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.98, 0.985]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.9082, Train Loss: 0.1894, Val Acc: 0.9224, Val Loss: 0.1928\n",
            "Restored model from best epoch 14 with val_loss: 0.192754\n",
            "NFL direct model 197/201 completed\n",
            "Original data shape: (3466, 8)\n",
            "Flattened data shape: (3466, 8)\n",
            "Split training data: 3119 train, 347 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.985, 0.99]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 19, Train Acc: 0.9224, Train Loss: 0.1826, Val Acc: 0.9049, Val Loss: 0.2187\n",
            "Restored model from best epoch 19 with val_loss: 0.218742\n",
            "NFL direct model 198/201 completed\n",
            "Original data shape: (3469, 8)\n",
            "Flattened data shape: (3469, 8)\n",
            "Split training data: 3122 train, 347 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.99, 0.995]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.9196, Train Loss: 0.1741, Val Acc: 0.9135, Val Loss: 0.2307\n",
            "Restored model from best epoch 23 with val_loss: 0.230682\n",
            "NFL direct model 199/201 completed\n",
            "Original data shape: (3440, 8)\n",
            "Flattened data shape: (3440, 8)\n",
            "Split training data: 3096 train, 344 validation\n",
            "\n",
            "Training direct prediction model for timestep range [0.995, 1.0]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.9257, Train Loss: 0.1732, Val Acc: 0.8953, Val Loss: 0.2306\n",
            "Restored model from best epoch 23 with val_loss: 0.230562\n",
            "NFL direct model 200/201 completed\n",
            "Original data shape: (4199, 8)\n",
            "Flattened data shape: (4199, 8)\n",
            "Split training data: 3779 train, 420 validation\n",
            "\n",
            "Training direct prediction model for timestep range [1.0, 1.005]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.9471, Train Loss: 0.1294, Val Acc: 0.9476, Val Loss: 0.1056\n",
            "Restored model from best epoch 22 with val_loss: 0.105633\n",
            "NFL direct model 201/201 completed\n"
          ]
        }
      ],
      "source": [
        "all_models[\"nn\"] = setup_direct_models(training_data, None, num_models=201)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing timestep: 0.0\n",
            "Timestep 0.00% : Training Loss = 0.6247, Accuracy = 0.6511, Test Loss = 0.6359, Test Accuracy = 0.6449\n",
            "Processing timestep: 0.005\n",
            "Timestep 0.50% : Training Loss = 0.6320, Accuracy = 0.6422, Test Loss = 0.6394, Test Accuracy = 0.6263\n",
            "Processing timestep: 0.01\n",
            "Timestep 1.00% : Training Loss = 0.6206, Accuracy = 0.6447, Test Loss = 0.6310, Test Accuracy = 0.6273\n",
            "Processing timestep: 0.015\n",
            "Timestep 1.50% : Training Loss = 0.6350, Accuracy = 0.6318, Test Loss = 0.6215, Test Accuracy = 0.6561\n",
            "Processing timestep: 0.02\n",
            "Timestep 2.00% : Training Loss = 0.6342, Accuracy = 0.6365, Test Loss = 0.6457, Test Accuracy = 0.6069\n",
            "Processing timestep: 0.025\n",
            "Timestep 2.50% : Training Loss = 0.6323, Accuracy = 0.6365, Test Loss = 0.6369, Test Accuracy = 0.6482\n",
            "Processing timestep: 0.03\n",
            "Timestep 3.00% : Training Loss = 0.6214, Accuracy = 0.6544, Test Loss = 0.6280, Test Accuracy = 0.6364\n",
            "Processing timestep: 0.035\n",
            "Timestep 3.50% : Training Loss = 0.6274, Accuracy = 0.6461, Test Loss = 0.6538, Test Accuracy = 0.6203\n",
            "Processing timestep: 0.04\n",
            "Timestep 4.00% : Training Loss = 0.6294, Accuracy = 0.6522, Test Loss = 0.6075, Test Accuracy = 0.6827\n",
            "Processing timestep: 0.045\n",
            "Timestep 4.50% : Training Loss = 0.6311, Accuracy = 0.6460, Test Loss = 0.6214, Test Accuracy = 0.6667\n",
            "Processing timestep: 0.05\n",
            "Timestep 5.00% : Training Loss = 0.6212, Accuracy = 0.6613, Test Loss = 0.6451, Test Accuracy = 0.6092\n",
            "Processing timestep: 0.055\n",
            "Timestep 5.50% : Training Loss = 0.6128, Accuracy = 0.6739, Test Loss = 0.6408, Test Accuracy = 0.6171\n",
            "Processing timestep: 0.06\n",
            "Timestep 6.00% : Training Loss = 0.6246, Accuracy = 0.6482, Test Loss = 0.6128, Test Accuracy = 0.6537\n",
            "Processing timestep: 0.065\n",
            "Timestep 6.50% : Training Loss = 0.6323, Accuracy = 0.6410, Test Loss = 0.6280, Test Accuracy = 0.6176\n",
            "Processing timestep: 0.07\n",
            "Timestep 7.00% : Training Loss = 0.6158, Accuracy = 0.6611, Test Loss = 0.6309, Test Accuracy = 0.6684\n",
            "Processing timestep: 0.075\n",
            "Timestep 7.50% : Training Loss = 0.6284, Accuracy = 0.6357, Test Loss = 0.5978, Test Accuracy = 0.6802\n",
            "Processing timestep: 0.08\n",
            "Timestep 8.00% : Training Loss = 0.6104, Accuracy = 0.6698, Test Loss = 0.5970, Test Accuracy = 0.7068\n",
            "Processing timestep: 0.085\n",
            "Timestep 8.50% : Training Loss = 0.6132, Accuracy = 0.6644, Test Loss = 0.6286, Test Accuracy = 0.6554\n",
            "Processing timestep: 0.09\n",
            "Timestep 9.00% : Training Loss = 0.6157, Accuracy = 0.6503, Test Loss = 0.6351, Test Accuracy = 0.6332\n",
            "Processing timestep: 0.095\n",
            "Timestep 9.50% : Training Loss = 0.6110, Accuracy = 0.6596, Test Loss = 0.6227, Test Accuracy = 0.6597\n",
            "Processing timestep: 0.1\n",
            "Timestep 10.00% : Training Loss = 0.6035, Accuracy = 0.6722, Test Loss = 0.6304, Test Accuracy = 0.6554\n",
            "Processing timestep: 0.105\n",
            "Timestep 10.50% : Training Loss = 0.5983, Accuracy = 0.6753, Test Loss = 0.6278, Test Accuracy = 0.6133\n",
            "Processing timestep: 0.11\n",
            "Timestep 11.00% : Training Loss = 0.6114, Accuracy = 0.6650, Test Loss = 0.6243, Test Accuracy = 0.6373\n",
            "Processing timestep: 0.115\n",
            "Timestep 11.50% : Training Loss = 0.5981, Accuracy = 0.6826, Test Loss = 0.5880, Test Accuracy = 0.6542\n",
            "Processing timestep: 0.12\n",
            "Timestep 12.00% : Training Loss = 0.6064, Accuracy = 0.6738, Test Loss = 0.6294, Test Accuracy = 0.6361\n",
            "Processing timestep: 0.125\n",
            "Timestep 12.50% : Training Loss = 0.5989, Accuracy = 0.6753, Test Loss = 0.6000, Test Accuracy = 0.6598\n",
            "Processing timestep: 0.13\n",
            "Timestep 13.00% : Training Loss = 0.5927, Accuracy = 0.6838, Test Loss = 0.6224, Test Accuracy = 0.6430\n",
            "Processing timestep: 0.135\n",
            "Timestep 13.50% : Training Loss = 0.6129, Accuracy = 0.6612, Test Loss = 0.5987, Test Accuracy = 0.6551\n",
            "Processing timestep: 0.14\n",
            "Timestep 14.00% : Training Loss = 0.5961, Accuracy = 0.6974, Test Loss = 0.6048, Test Accuracy = 0.6471\n",
            "Processing timestep: 0.145\n",
            "Timestep 14.50% : Training Loss = 0.5946, Accuracy = 0.6858, Test Loss = 0.5975, Test Accuracy = 0.6720\n",
            "Processing timestep: 0.15\n",
            "Timestep 15.00% : Training Loss = 0.5886, Accuracy = 0.6975, Test Loss = 0.6155, Test Accuracy = 0.6701\n",
            "Processing timestep: 0.155\n",
            "Timestep 15.50% : Training Loss = 0.5835, Accuracy = 0.6934, Test Loss = 0.6197, Test Accuracy = 0.6602\n",
            "Processing timestep: 0.16\n",
            "Timestep 16.00% : Training Loss = 0.5833, Accuracy = 0.6872, Test Loss = 0.6203, Test Accuracy = 0.6215\n",
            "Processing timestep: 0.165\n",
            "Timestep 16.50% : Training Loss = 0.6014, Accuracy = 0.6693, Test Loss = 0.6186, Test Accuracy = 0.6456\n",
            "Processing timestep: 0.17\n",
            "Timestep 17.00% : Training Loss = 0.5941, Accuracy = 0.6889, Test Loss = 0.5936, Test Accuracy = 0.6623\n",
            "Processing timestep: 0.175\n",
            "Timestep 17.50% : Training Loss = 0.6022, Accuracy = 0.6786, Test Loss = 0.6164, Test Accuracy = 0.6380\n",
            "Processing timestep: 0.18\n",
            "Timestep 18.00% : Training Loss = 0.5786, Accuracy = 0.6896, Test Loss = 0.5974, Test Accuracy = 0.6649\n",
            "Processing timestep: 0.185\n",
            "Timestep 18.50% : Training Loss = 0.5920, Accuracy = 0.6900, Test Loss = 0.5905, Test Accuracy = 0.6765\n",
            "Processing timestep: 0.19\n",
            "Timestep 19.00% : Training Loss = 0.5841, Accuracy = 0.6926, Test Loss = 0.5860, Test Accuracy = 0.6720\n",
            "Processing timestep: 0.195\n",
            "Timestep 19.50% : Training Loss = 0.5683, Accuracy = 0.7045, Test Loss = 0.5998, Test Accuracy = 0.6562\n",
            "Processing timestep: 0.2\n",
            "Timestep 20.00% : Training Loss = 0.5911, Accuracy = 0.6898, Test Loss = 0.5770, Test Accuracy = 0.6729\n",
            "Processing timestep: 0.205\n",
            "Timestep 20.50% : Training Loss = 0.5887, Accuracy = 0.6883, Test Loss = 0.5458, Test Accuracy = 0.7048\n",
            "Processing timestep: 0.21\n",
            "Timestep 21.00% : Training Loss = 0.5702, Accuracy = 0.7066, Test Loss = 0.5979, Test Accuracy = 0.6642\n",
            "Processing timestep: 0.215\n",
            "Timestep 21.50% : Training Loss = 0.5808, Accuracy = 0.6990, Test Loss = 0.5760, Test Accuracy = 0.6712\n",
            "Processing timestep: 0.22\n",
            "Timestep 22.00% : Training Loss = 0.5745, Accuracy = 0.7041, Test Loss = 0.5684, Test Accuracy = 0.6955\n",
            "Processing timestep: 0.225\n",
            "Timestep 22.50% : Training Loss = 0.5599, Accuracy = 0.7070, Test Loss = 0.6014, Test Accuracy = 0.6762\n",
            "Processing timestep: 0.23\n",
            "Timestep 23.00% : Training Loss = 0.5749, Accuracy = 0.6964, Test Loss = 0.5720, Test Accuracy = 0.6801\n",
            "Processing timestep: 0.235\n",
            "Timestep 23.50% : Training Loss = 0.5627, Accuracy = 0.7124, Test Loss = 0.5323, Test Accuracy = 0.7036\n",
            "Processing timestep: 0.24\n",
            "Timestep 24.00% : Training Loss = 0.5830, Accuracy = 0.6918, Test Loss = 0.5738, Test Accuracy = 0.6576\n",
            "Processing timestep: 0.245\n",
            "Timestep 24.50% : Training Loss = 0.5725, Accuracy = 0.6978, Test Loss = 0.5723, Test Accuracy = 0.6950\n",
            "Processing timestep: 0.25\n",
            "Timestep 25.00% : Training Loss = 0.5669, Accuracy = 0.7035, Test Loss = 0.5524, Test Accuracy = 0.7060\n",
            "Processing timestep: 0.255\n",
            "Timestep 25.50% : Training Loss = 0.5704, Accuracy = 0.6989, Test Loss = 0.5602, Test Accuracy = 0.6912\n",
            "Processing timestep: 0.26\n",
            "Timestep 26.00% : Training Loss = 0.5667, Accuracy = 0.7088, Test Loss = 0.5801, Test Accuracy = 0.6758\n",
            "Processing timestep: 0.265\n",
            "Timestep 26.50% : Training Loss = 0.5680, Accuracy = 0.6985, Test Loss = 0.5370, Test Accuracy = 0.7182\n",
            "Processing timestep: 0.27\n",
            "Timestep 27.00% : Training Loss = 0.5644, Accuracy = 0.7084, Test Loss = 0.5555, Test Accuracy = 0.6923\n",
            "Processing timestep: 0.275\n",
            "Timestep 27.50% : Training Loss = 0.5650, Accuracy = 0.6964, Test Loss = 0.5423, Test Accuracy = 0.7104\n",
            "Processing timestep: 0.28\n",
            "Timestep 28.00% : Training Loss = 0.5599, Accuracy = 0.7038, Test Loss = 0.5636, Test Accuracy = 0.7195\n",
            "Processing timestep: 0.285\n",
            "Timestep 28.50% : Training Loss = 0.5590, Accuracy = 0.7087, Test Loss = 0.5183, Test Accuracy = 0.7319\n",
            "Processing timestep: 0.29\n",
            "Timestep 29.00% : Training Loss = 0.5712, Accuracy = 0.6951, Test Loss = 0.5350, Test Accuracy = 0.7089\n",
            "Processing timestep: 0.295\n",
            "Timestep 29.50% : Training Loss = 0.5643, Accuracy = 0.6981, Test Loss = 0.5528, Test Accuracy = 0.7063\n",
            "Processing timestep: 0.3\n",
            "Timestep 30.00% : Training Loss = 0.5563, Accuracy = 0.7039, Test Loss = 0.5592, Test Accuracy = 0.6947\n",
            "Processing timestep: 0.305\n",
            "Timestep 30.50% : Training Loss = 0.5539, Accuracy = 0.7128, Test Loss = 0.5730, Test Accuracy = 0.6848\n",
            "Processing timestep: 0.31\n",
            "Timestep 31.00% : Training Loss = 0.5480, Accuracy = 0.7166, Test Loss = 0.5432, Test Accuracy = 0.7195\n",
            "Processing timestep: 0.315\n",
            "Timestep 31.50% : Training Loss = 0.5667, Accuracy = 0.6979, Test Loss = 0.5897, Test Accuracy = 0.6824\n",
            "Processing timestep: 0.32\n",
            "Timestep 32.00% : Training Loss = 0.5523, Accuracy = 0.7096, Test Loss = 0.5244, Test Accuracy = 0.7318\n",
            "Processing timestep: 0.325\n",
            "Timestep 32.50% : Training Loss = 0.5554, Accuracy = 0.7131, Test Loss = 0.5403, Test Accuracy = 0.7062\n",
            "Processing timestep: 0.33\n",
            "Timestep 33.00% : Training Loss = 0.5533, Accuracy = 0.7087, Test Loss = 0.5199, Test Accuracy = 0.7251\n",
            "Processing timestep: 0.335\n",
            "Timestep 33.50% : Training Loss = 0.5361, Accuracy = 0.7250, Test Loss = 0.5292, Test Accuracy = 0.7287\n",
            "Processing timestep: 0.34\n",
            "Timestep 34.00% : Training Loss = 0.5356, Accuracy = 0.7236, Test Loss = 0.5352, Test Accuracy = 0.7105\n",
            "Processing timestep: 0.345\n",
            "Timestep 34.50% : Training Loss = 0.5294, Accuracy = 0.7283, Test Loss = 0.5255, Test Accuracy = 0.7194\n",
            "Processing timestep: 0.35\n",
            "Timestep 35.00% : Training Loss = 0.5416, Accuracy = 0.7167, Test Loss = 0.5358, Test Accuracy = 0.7177\n",
            "Processing timestep: 0.355\n",
            "Timestep 35.50% : Training Loss = 0.5420, Accuracy = 0.7162, Test Loss = 0.5290, Test Accuracy = 0.7364\n",
            "Processing timestep: 0.36\n",
            "Timestep 36.00% : Training Loss = 0.5490, Accuracy = 0.7203, Test Loss = 0.5434, Test Accuracy = 0.7246\n",
            "Processing timestep: 0.365\n",
            "Timestep 36.50% : Training Loss = 0.5385, Accuracy = 0.7324, Test Loss = 0.5180, Test Accuracy = 0.7249\n",
            "Processing timestep: 0.37\n",
            "Timestep 37.00% : Training Loss = 0.5577, Accuracy = 0.7191, Test Loss = 0.5458, Test Accuracy = 0.7131\n",
            "Processing timestep: 0.375\n",
            "Timestep 37.50% : Training Loss = 0.5302, Accuracy = 0.7327, Test Loss = 0.5387, Test Accuracy = 0.7172\n",
            "Processing timestep: 0.38\n",
            "Timestep 38.00% : Training Loss = 0.5201, Accuracy = 0.7381, Test Loss = 0.5271, Test Accuracy = 0.7063\n",
            "Processing timestep: 0.385\n",
            "Timestep 38.50% : Training Loss = 0.5404, Accuracy = 0.7207, Test Loss = 0.5309, Test Accuracy = 0.7203\n",
            "Processing timestep: 0.39\n",
            "Timestep 39.00% : Training Loss = 0.5293, Accuracy = 0.7298, Test Loss = 0.5443, Test Accuracy = 0.7067\n",
            "Processing timestep: 0.395\n",
            "Timestep 39.50% : Training Loss = 0.5395, Accuracy = 0.7239, Test Loss = 0.5154, Test Accuracy = 0.7435\n",
            "Processing timestep: 0.4\n",
            "Timestep 40.00% : Training Loss = 0.5411, Accuracy = 0.7236, Test Loss = 0.5438, Test Accuracy = 0.7116\n",
            "Processing timestep: 0.405\n",
            "Timestep 40.50% : Training Loss = 0.5175, Accuracy = 0.7490, Test Loss = 0.4871, Test Accuracy = 0.7784\n",
            "Processing timestep: 0.41\n",
            "Timestep 41.00% : Training Loss = 0.5444, Accuracy = 0.7181, Test Loss = 0.5132, Test Accuracy = 0.7506\n",
            "Processing timestep: 0.415\n",
            "Timestep 41.50% : Training Loss = 0.5297, Accuracy = 0.7421, Test Loss = 0.5161, Test Accuracy = 0.7246\n",
            "Processing timestep: 0.42\n",
            "Timestep 42.00% : Training Loss = 0.5417, Accuracy = 0.7244, Test Loss = 0.5611, Test Accuracy = 0.6829\n",
            "Processing timestep: 0.425\n",
            "Timestep 42.50% : Training Loss = 0.5170, Accuracy = 0.7451, Test Loss = 0.5426, Test Accuracy = 0.7409\n",
            "Processing timestep: 0.43\n",
            "Timestep 43.00% : Training Loss = 0.5135, Accuracy = 0.7513, Test Loss = 0.5299, Test Accuracy = 0.7193\n",
            "Processing timestep: 0.435\n",
            "Timestep 43.50% : Training Loss = 0.5193, Accuracy = 0.7474, Test Loss = 0.5058, Test Accuracy = 0.7352\n",
            "Processing timestep: 0.44\n",
            "Timestep 44.00% : Training Loss = 0.5100, Accuracy = 0.7525, Test Loss = 0.5365, Test Accuracy = 0.7200\n",
            "Processing timestep: 0.445\n",
            "Timestep 44.50% : Training Loss = 0.5214, Accuracy = 0.7425, Test Loss = 0.5260, Test Accuracy = 0.7378\n",
            "Processing timestep: 0.45\n",
            "Timestep 45.00% : Training Loss = 0.5094, Accuracy = 0.7517, Test Loss = 0.5468, Test Accuracy = 0.7225\n",
            "Processing timestep: 0.455\n",
            "Timestep 45.50% : Training Loss = 0.5251, Accuracy = 0.7390, Test Loss = 0.5267, Test Accuracy = 0.7277\n",
            "Processing timestep: 0.46\n",
            "Timestep 46.00% : Training Loss = 0.5057, Accuracy = 0.7566, Test Loss = 0.4830, Test Accuracy = 0.7843\n",
            "Processing timestep: 0.465\n",
            "Timestep 46.50% : Training Loss = 0.4858, Accuracy = 0.7678, Test Loss = 0.5288, Test Accuracy = 0.7611\n",
            "Processing timestep: 0.47\n",
            "Timestep 47.00% : Training Loss = 0.5052, Accuracy = 0.7537, Test Loss = 0.5057, Test Accuracy = 0.7462\n",
            "Processing timestep: 0.475\n",
            "Timestep 47.50% : Training Loss = 0.4889, Accuracy = 0.7688, Test Loss = 0.4984, Test Accuracy = 0.7426\n",
            "Processing timestep: 0.48\n",
            "Timestep 48.00% : Training Loss = 0.4851, Accuracy = 0.7631, Test Loss = 0.4928, Test Accuracy = 0.7570\n",
            "Processing timestep: 0.485\n",
            "Timestep 48.50% : Training Loss = 0.4822, Accuracy = 0.7643, Test Loss = 0.4907, Test Accuracy = 0.7727\n",
            "Processing timestep: 0.49\n",
            "Timestep 49.00% : Training Loss = 0.4778, Accuracy = 0.7822, Test Loss = 0.5161, Test Accuracy = 0.7525\n",
            "Processing timestep: 0.495\n",
            "Timestep 49.50% : Training Loss = 0.4780, Accuracy = 0.7737, Test Loss = 0.4550, Test Accuracy = 0.7950\n",
            "Processing timestep: 0.5\n",
            "Timestep 50.00% : Training Loss = 0.4717, Accuracy = 0.7762, Test Loss = 0.4475, Test Accuracy = 0.8057\n",
            "Processing timestep: 0.505\n",
            "Timestep 50.50% : Training Loss = 0.4425, Accuracy = 0.7840, Test Loss = 0.5292, Test Accuracy = 0.7905\n",
            "Processing timestep: 0.51\n",
            "Timestep 51.00% : Training Loss = 0.4502, Accuracy = 0.7851, Test Loss = 0.4787, Test Accuracy = 0.8006\n",
            "Processing timestep: 0.515\n",
            "Timestep 51.50% : Training Loss = 0.4602, Accuracy = 0.7904, Test Loss = 0.4553, Test Accuracy = 0.7955\n",
            "Processing timestep: 0.52\n",
            "Timestep 52.00% : Training Loss = 0.4700, Accuracy = 0.7750, Test Loss = 0.4501, Test Accuracy = 0.8136\n",
            "Processing timestep: 0.525\n",
            "Timestep 52.50% : Training Loss = 0.4434, Accuracy = 0.7947, Test Loss = 0.4562, Test Accuracy = 0.8117\n",
            "Processing timestep: 0.53\n",
            "Timestep 53.00% : Training Loss = 0.4652, Accuracy = 0.7778, Test Loss = 0.4936, Test Accuracy = 0.7699\n",
            "Processing timestep: 0.535\n",
            "Timestep 53.50% : Training Loss = 0.4349, Accuracy = 0.7965, Test Loss = 0.4340, Test Accuracy = 0.8276\n",
            "Processing timestep: 0.54\n",
            "Timestep 54.00% : Training Loss = 0.4513, Accuracy = 0.7876, Test Loss = 0.5110, Test Accuracy = 0.7631\n",
            "Processing timestep: 0.545\n",
            "Timestep 54.50% : Training Loss = 0.4663, Accuracy = 0.7834, Test Loss = 0.4862, Test Accuracy = 0.7799\n",
            "Processing timestep: 0.55\n",
            "Timestep 55.00% : Training Loss = 0.4376, Accuracy = 0.7968, Test Loss = 0.4525, Test Accuracy = 0.8162\n",
            "Processing timestep: 0.555\n",
            "Timestep 55.50% : Training Loss = 0.4559, Accuracy = 0.7874, Test Loss = 0.4449, Test Accuracy = 0.8081\n",
            "Processing timestep: 0.56\n",
            "Timestep 56.00% : Training Loss = 0.4331, Accuracy = 0.8033, Test Loss = 0.4504, Test Accuracy = 0.8000\n",
            "Processing timestep: 0.565\n",
            "Timestep 56.50% : Training Loss = 0.4409, Accuracy = 0.7927, Test Loss = 0.4593, Test Accuracy = 0.7721\n",
            "Processing timestep: 0.57\n",
            "Timestep 57.00% : Training Loss = 0.4439, Accuracy = 0.7943, Test Loss = 0.4368, Test Accuracy = 0.8021\n",
            "Processing timestep: 0.575\n",
            "Timestep 57.50% : Training Loss = 0.4527, Accuracy = 0.7892, Test Loss = 0.4815, Test Accuracy = 0.7839\n",
            "Processing timestep: 0.58\n",
            "Timestep 58.00% : Training Loss = 0.4457, Accuracy = 0.7866, Test Loss = 0.4516, Test Accuracy = 0.7909\n",
            "Processing timestep: 0.585\n",
            "Timestep 58.50% : Training Loss = 0.4464, Accuracy = 0.7925, Test Loss = 0.4110, Test Accuracy = 0.8241\n",
            "Processing timestep: 0.59\n",
            "Timestep 59.00% : Training Loss = 0.4574, Accuracy = 0.7816, Test Loss = 0.4617, Test Accuracy = 0.7975\n",
            "Processing timestep: 0.595\n",
            "Timestep 59.50% : Training Loss = 0.4352, Accuracy = 0.7909, Test Loss = 0.4705, Test Accuracy = 0.7723\n",
            "Processing timestep: 0.6\n",
            "Timestep 60.00% : Training Loss = 0.4446, Accuracy = 0.7847, Test Loss = 0.4578, Test Accuracy = 0.7953\n",
            "Processing timestep: 0.605\n",
            "Timestep 60.50% : Training Loss = 0.4483, Accuracy = 0.7900, Test Loss = 0.4460, Test Accuracy = 0.7850\n",
            "Processing timestep: 0.61\n",
            "Timestep 61.00% : Training Loss = 0.4360, Accuracy = 0.7925, Test Loss = 0.4497, Test Accuracy = 0.7918\n",
            "Processing timestep: 0.615\n",
            "Timestep 61.50% : Training Loss = 0.4229, Accuracy = 0.7946, Test Loss = 0.4360, Test Accuracy = 0.7947\n",
            "Processing timestep: 0.62\n",
            "Timestep 62.00% : Training Loss = 0.4431, Accuracy = 0.7962, Test Loss = 0.4527, Test Accuracy = 0.7834\n",
            "Processing timestep: 0.625\n",
            "Timestep 62.50% : Training Loss = 0.4335, Accuracy = 0.8027, Test Loss = 0.4499, Test Accuracy = 0.7918\n",
            "Processing timestep: 0.63\n",
            "Timestep 63.00% : Training Loss = 0.4229, Accuracy = 0.8013, Test Loss = 0.4313, Test Accuracy = 0.8031\n",
            "Processing timestep: 0.635\n",
            "Timestep 63.50% : Training Loss = 0.4298, Accuracy = 0.8003, Test Loss = 0.4461, Test Accuracy = 0.7812\n",
            "Processing timestep: 0.64\n",
            "Timestep 64.00% : Training Loss = 0.4195, Accuracy = 0.8095, Test Loss = 0.4704, Test Accuracy = 0.7722\n",
            "Processing timestep: 0.645\n",
            "Timestep 64.50% : Training Loss = 0.4453, Accuracy = 0.7916, Test Loss = 0.4233, Test Accuracy = 0.8112\n",
            "Processing timestep: 0.65\n",
            "Timestep 65.00% : Training Loss = 0.4247, Accuracy = 0.7989, Test Loss = 0.5006, Test Accuracy = 0.7632\n",
            "Processing timestep: 0.655\n",
            "Timestep 65.50% : Training Loss = 0.4046, Accuracy = 0.8123, Test Loss = 0.4547, Test Accuracy = 0.7784\n",
            "Processing timestep: 0.66\n",
            "Timestep 66.00% : Training Loss = 0.4177, Accuracy = 0.8101, Test Loss = 0.4248, Test Accuracy = 0.8005\n",
            "Processing timestep: 0.665\n",
            "Timestep 66.50% : Training Loss = 0.3911, Accuracy = 0.8164, Test Loss = 0.4505, Test Accuracy = 0.7769\n",
            "Processing timestep: 0.67\n",
            "Timestep 67.00% : Training Loss = 0.4100, Accuracy = 0.8184, Test Loss = 0.4352, Test Accuracy = 0.8145\n",
            "Processing timestep: 0.675\n",
            "Timestep 67.50% : Training Loss = 0.4214, Accuracy = 0.8040, Test Loss = 0.4403, Test Accuracy = 0.7775\n",
            "Processing timestep: 0.68\n",
            "Timestep 68.00% : Training Loss = 0.4163, Accuracy = 0.8132, Test Loss = 0.4251, Test Accuracy = 0.7813\n",
            "Processing timestep: 0.685\n",
            "Timestep 68.50% : Training Loss = 0.4027, Accuracy = 0.8161, Test Loss = 0.4586, Test Accuracy = 0.7722\n",
            "Processing timestep: 0.69\n",
            "Timestep 69.00% : Training Loss = 0.4038, Accuracy = 0.8110, Test Loss = 0.4114, Test Accuracy = 0.7848\n",
            "Processing timestep: 0.695\n",
            "Timestep 69.50% : Training Loss = 0.3941, Accuracy = 0.8208, Test Loss = 0.3935, Test Accuracy = 0.7979\n",
            "Processing timestep: 0.7\n",
            "Timestep 70.00% : Training Loss = 0.4052, Accuracy = 0.8060, Test Loss = 0.3987, Test Accuracy = 0.8144\n",
            "Processing timestep: 0.705\n",
            "Timestep 70.50% : Training Loss = 0.3997, Accuracy = 0.8137, Test Loss = 0.3904, Test Accuracy = 0.8070\n",
            "Processing timestep: 0.71\n",
            "Timestep 71.00% : Training Loss = 0.3957, Accuracy = 0.8259, Test Loss = 0.4048, Test Accuracy = 0.8086\n",
            "Processing timestep: 0.715\n",
            "Timestep 71.50% : Training Loss = 0.3991, Accuracy = 0.8152, Test Loss = 0.4554, Test Accuracy = 0.7623\n",
            "Processing timestep: 0.72\n",
            "Timestep 72.00% : Training Loss = 0.3885, Accuracy = 0.8226, Test Loss = 0.3742, Test Accuracy = 0.8368\n",
            "Processing timestep: 0.725\n",
            "Timestep 72.50% : Training Loss = 0.3876, Accuracy = 0.8183, Test Loss = 0.3971, Test Accuracy = 0.8130\n",
            "Processing timestep: 0.73\n",
            "Timestep 73.00% : Training Loss = 0.3788, Accuracy = 0.8252, Test Loss = 0.4301, Test Accuracy = 0.8083\n",
            "Processing timestep: 0.735\n",
            "Timestep 73.50% : Training Loss = 0.3841, Accuracy = 0.8283, Test Loss = 0.4151, Test Accuracy = 0.8127\n",
            "Processing timestep: 0.74\n",
            "Timestep 74.00% : Training Loss = 0.3687, Accuracy = 0.8356, Test Loss = 0.4167, Test Accuracy = 0.8338\n",
            "Processing timestep: 0.745\n",
            "Timestep 74.50% : Training Loss = 0.3873, Accuracy = 0.8324, Test Loss = 0.4080, Test Accuracy = 0.8142\n",
            "Processing timestep: 0.75\n",
            "Timestep 75.00% : Training Loss = 0.3837, Accuracy = 0.8260, Test Loss = 0.3790, Test Accuracy = 0.8184\n",
            "Processing timestep: 0.755\n",
            "Timestep 75.50% : Training Loss = 0.3486, Accuracy = 0.8462, Test Loss = 0.3743, Test Accuracy = 0.8371\n",
            "Processing timestep: 0.76\n",
            "Timestep 76.00% : Training Loss = 0.3629, Accuracy = 0.8388, Test Loss = 0.3501, Test Accuracy = 0.8430\n",
            "Processing timestep: 0.765\n",
            "Timestep 76.50% : Training Loss = 0.3429, Accuracy = 0.8509, Test Loss = 0.3863, Test Accuracy = 0.8204\n",
            "Processing timestep: 0.77\n",
            "Timestep 77.00% : Training Loss = 0.3782, Accuracy = 0.8309, Test Loss = 0.3993, Test Accuracy = 0.8052\n",
            "Processing timestep: 0.775\n",
            "Timestep 77.50% : Training Loss = 0.3670, Accuracy = 0.8306, Test Loss = 0.3449, Test Accuracy = 0.8518\n",
            "Processing timestep: 0.78\n",
            "Timestep 78.00% : Training Loss = 0.3583, Accuracy = 0.8410, Test Loss = 0.4167, Test Accuracy = 0.8134\n",
            "Processing timestep: 0.785\n",
            "Timestep 78.50% : Training Loss = 0.3519, Accuracy = 0.8461, Test Loss = 0.4022, Test Accuracy = 0.8223\n",
            "Processing timestep: 0.79\n",
            "Timestep 79.00% : Training Loss = 0.3359, Accuracy = 0.8566, Test Loss = 0.3332, Test Accuracy = 0.8683\n",
            "Processing timestep: 0.795\n",
            "Timestep 79.50% : Training Loss = 0.3693, Accuracy = 0.8351, Test Loss = 0.3927, Test Accuracy = 0.8320\n",
            "Processing timestep: 0.8\n",
            "Timestep 80.00% : Training Loss = 0.3430, Accuracy = 0.8529, Test Loss = 0.3550, Test Accuracy = 0.8617\n",
            "Processing timestep: 0.805\n",
            "Timestep 80.50% : Training Loss = 0.3437, Accuracy = 0.8494, Test Loss = 0.3494, Test Accuracy = 0.8505\n",
            "Processing timestep: 0.81\n",
            "Timestep 81.00% : Training Loss = 0.3435, Accuracy = 0.8525, Test Loss = 0.3915, Test Accuracy = 0.8149\n",
            "Processing timestep: 0.815\n",
            "Timestep 81.50% : Training Loss = 0.3398, Accuracy = 0.8481, Test Loss = 0.3782, Test Accuracy = 0.8290\n",
            "Processing timestep: 0.82\n",
            "Timestep 82.00% : Training Loss = 0.3451, Accuracy = 0.8429, Test Loss = 0.3803, Test Accuracy = 0.8173\n",
            "Processing timestep: 0.825\n",
            "Timestep 82.50% : Training Loss = 0.3447, Accuracy = 0.8456, Test Loss = 0.3780, Test Accuracy = 0.8347\n",
            "Processing timestep: 0.83\n",
            "Timestep 83.00% : Training Loss = 0.3269, Accuracy = 0.8561, Test Loss = 0.3474, Test Accuracy = 0.8302\n",
            "Processing timestep: 0.835\n",
            "Timestep 83.50% : Training Loss = 0.3220, Accuracy = 0.8582, Test Loss = 0.3067, Test Accuracy = 0.8793\n",
            "Processing timestep: 0.84\n",
            "Timestep 84.00% : Training Loss = 0.3110, Accuracy = 0.8598, Test Loss = 0.3261, Test Accuracy = 0.8446\n",
            "Processing timestep: 0.845\n",
            "Timestep 84.50% : Training Loss = 0.3251, Accuracy = 0.8523, Test Loss = 0.3571, Test Accuracy = 0.8398\n",
            "Processing timestep: 0.85\n",
            "Timestep 85.00% : Training Loss = 0.3180, Accuracy = 0.8581, Test Loss = 0.3506, Test Accuracy = 0.8385\n",
            "Processing timestep: 0.855\n",
            "Timestep 85.50% : Training Loss = 0.3097, Accuracy = 0.8673, Test Loss = 0.4255, Test Accuracy = 0.7984\n",
            "Processing timestep: 0.86\n",
            "Timestep 86.00% : Training Loss = 0.3092, Accuracy = 0.8594, Test Loss = 0.3212, Test Accuracy = 0.8571\n",
            "Processing timestep: 0.865\n",
            "Timestep 86.50% : Training Loss = 0.3188, Accuracy = 0.8618, Test Loss = 0.3035, Test Accuracy = 0.8627\n",
            "Processing timestep: 0.87\n",
            "Timestep 87.00% : Training Loss = 0.3145, Accuracy = 0.8553, Test Loss = 0.3875, Test Accuracy = 0.7979\n",
            "Processing timestep: 0.875\n",
            "Timestep 87.50% : Training Loss = 0.3164, Accuracy = 0.8509, Test Loss = 0.2791, Test Accuracy = 0.8855\n",
            "Processing timestep: 0.88\n",
            "Timestep 88.00% : Training Loss = 0.2938, Accuracy = 0.8621, Test Loss = 0.3355, Test Accuracy = 0.8557\n",
            "Processing timestep: 0.885\n",
            "Timestep 88.50% : Training Loss = 0.3168, Accuracy = 0.8497, Test Loss = 0.3483, Test Accuracy = 0.8265\n",
            "Processing timestep: 0.89\n",
            "Timestep 89.00% : Training Loss = 0.2952, Accuracy = 0.8661, Test Loss = 0.3741, Test Accuracy = 0.8295\n",
            "Processing timestep: 0.895\n",
            "Timestep 89.50% : Training Loss = 0.2672, Accuracy = 0.8802, Test Loss = 0.2793, Test Accuracy = 0.8819\n",
            "Processing timestep: 0.9\n",
            "Timestep 90.00% : Training Loss = 0.3140, Accuracy = 0.8545, Test Loss = 0.3407, Test Accuracy = 0.8440\n",
            "Processing timestep: 0.905\n",
            "Timestep 90.50% : Training Loss = 0.2782, Accuracy = 0.8686, Test Loss = 0.3151, Test Accuracy = 0.8590\n",
            "Processing timestep: 0.91\n",
            "Timestep 91.00% : Training Loss = 0.2890, Accuracy = 0.8698, Test Loss = 0.2976, Test Accuracy = 0.8639\n",
            "Processing timestep: 0.915\n",
            "Timestep 91.50% : Training Loss = 0.2506, Accuracy = 0.8882, Test Loss = 0.3142, Test Accuracy = 0.8643\n",
            "Processing timestep: 0.92\n",
            "Timestep 92.00% : Training Loss = 0.2808, Accuracy = 0.8706, Test Loss = 0.3114, Test Accuracy = 0.8474\n",
            "Processing timestep: 0.925\n",
            "Timestep 92.50% : Training Loss = 0.2736, Accuracy = 0.8748, Test Loss = 0.2535, Test Accuracy = 0.8787\n",
            "Processing timestep: 0.93\n",
            "Timestep 93.00% : Training Loss = 0.2672, Accuracy = 0.8853, Test Loss = 0.2548, Test Accuracy = 0.8871\n",
            "Processing timestep: 0.935\n",
            "Timestep 93.50% : Training Loss = 0.2578, Accuracy = 0.8852, Test Loss = 0.3258, Test Accuracy = 0.8543\n",
            "Processing timestep: 0.94\n",
            "Timestep 94.00% : Training Loss = 0.2436, Accuracy = 0.8916, Test Loss = 0.2619, Test Accuracy = 0.8889\n",
            "Processing timestep: 0.945\n",
            "Timestep 94.50% : Training Loss = 0.2516, Accuracy = 0.8929, Test Loss = 0.2877, Test Accuracy = 0.8571\n",
            "Processing timestep: 0.95\n",
            "Timestep 95.00% : Training Loss = 0.2627, Accuracy = 0.8794, Test Loss = 0.3173, Test Accuracy = 0.8560\n",
            "Processing timestep: 0.955\n",
            "Timestep 95.50% : Training Loss = 0.2567, Accuracy = 0.8831, Test Loss = 0.2682, Test Accuracy = 0.8845\n",
            "Processing timestep: 0.96\n",
            "Timestep 96.00% : Training Loss = 0.2748, Accuracy = 0.8808, Test Loss = 0.2964, Test Accuracy = 0.8647\n",
            "Processing timestep: 0.965\n",
            "Timestep 96.50% : Training Loss = 0.2560, Accuracy = 0.8811, Test Loss = 0.2525, Test Accuracy = 0.8801\n",
            "Processing timestep: 0.97\n",
            "Timestep 97.00% : Training Loss = 0.2560, Accuracy = 0.8870, Test Loss = 0.2582, Test Accuracy = 0.8751\n",
            "Processing timestep: 0.975\n",
            "Timestep 97.50% : Training Loss = 0.2617, Accuracy = 0.8901, Test Loss = 0.2466, Test Accuracy = 0.8869\n",
            "Processing timestep: 0.98\n",
            "Timestep 98.00% : Training Loss = 0.2299, Accuracy = 0.9048, Test Loss = 0.2629, Test Accuracy = 0.8582\n",
            "Processing timestep: 0.985\n",
            "Timestep 98.50% : Training Loss = 0.2322, Accuracy = 0.9005, Test Loss = 0.2432, Test Accuracy = 0.8750\n",
            "Processing timestep: 0.99\n",
            "Timestep 99.00% : Training Loss = 0.2624, Accuracy = 0.8843, Test Loss = 0.2339, Test Accuracy = 0.8887\n",
            "Processing timestep: 0.995\n",
            "Timestep 99.50% : Training Loss = 0.2542, Accuracy = 0.8895, Test Loss = 0.2334, Test Accuracy = 0.8953\n",
            "Processing timestep: 1.0\n",
            "Timestep 100.00% : Training Loss = 0.1918, Accuracy = 0.9274, Test Loss = 0.1534, Test Accuracy = 0.9460\n"
          ]
        }
      ],
      "source": [
        "other_features = [\n",
        "            \"type.id\",             # Play type (categorical)\n",
        "            \"home_has_possession\", # Binary indicator\n",
        "            \"end.down\",            # Down number (1-4, discrete)\n",
        "            \"home_timeouts_left\",  # Discrete count (0-3)\n",
        "            \"away_timeouts_left\",  # Discrete count (0-3)\n",
        "        ]\n",
        "numeric_features = [\n",
        "    \"score_difference\",\n",
        "    \"relative_strength\", \n",
        "    \"end.yardsToEndzone\", \n",
        "    \"end.distance\", \n",
        "    \"field_position_shift\"\n",
        "]\n",
        "other_features = [\n",
        "            \"home_has_possession\", # Binary indicator\n",
        "            \"end.down\",            # Down number (1-4, discrete)\n",
        "            \"home_timeouts_left\",  # Discrete count (0-3)\n",
        "            \"away_timeouts_left\",  # Discrete count (0-3)\n",
        "        ]\n",
        "numeric_features = [\n",
        "    \"score_difference\",\n",
        "    \"relative_strength\", \n",
        "    \"end.yardsToEndzone\", \n",
        "    \"end.distance\", \n",
        "]\n",
        "lr_numeric_features= [\n",
        "    \"score_difference\",\n",
        "    \"relative_strength\"\n",
        "]\n",
        "lr_other_features = [\n",
        "   \"home_has_possession\" \n",
        "]\n",
        "lr_features = [\"relative_strength\", \"score_difference\", \"home_has_possession\"]\n",
        "all_models[\"logistic\"] = setup_logistic_regression_models(training_data, None, lr_numeric_features, lr_other_features, lr_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestep 0.00%(Calibrated): Training Loss = 0.3555, Accuracy = 0.6445, Validation Loss = 0.2111, Validation Accuracy = 0.6628\n",
            "Timestep 0.50%(Calibrated): Training Loss = 0.3509, Accuracy = 0.6491, Validation Loss = 0.2097, Validation Accuracy = 0.6435\n",
            "Timestep 1.00%(Calibrated): Training Loss = 0.3489, Accuracy = 0.6511, Validation Loss = 0.2024, Validation Accuracy = 0.6795\n",
            "Timestep 1.50%(Calibrated): Training Loss = 0.3550, Accuracy = 0.6450, Validation Loss = 0.2138, Validation Accuracy = 0.6603\n",
            "Timestep 2.00%(Calibrated): Training Loss = 0.3669, Accuracy = 0.6331, Validation Loss = 0.2176, Validation Accuracy = 0.6395\n",
            "Timestep 2.50%(Calibrated): Training Loss = 0.3581, Accuracy = 0.6419, Validation Loss = 0.2084, Validation Accuracy = 0.6589\n",
            "Timestep 3.00%(Calibrated): Training Loss = 0.3469, Accuracy = 0.6531, Validation Loss = 0.2024, Validation Accuracy = 0.6737\n",
            "Timestep 3.50%(Calibrated): Training Loss = 0.3494, Accuracy = 0.6506, Validation Loss = 0.2160, Validation Accuracy = 0.6346\n",
            "Timestep 4.00%(Calibrated): Training Loss = 0.3534, Accuracy = 0.6466, Validation Loss = 0.2077, Validation Accuracy = 0.6650\n",
            "Timestep 4.50%(Calibrated): Training Loss = 0.3452, Accuracy = 0.6548, Validation Loss = 0.2054, Validation Accuracy = 0.6825\n",
            "Timestep 5.00%(Calibrated): Training Loss = 0.3622, Accuracy = 0.6378, Validation Loss = 0.2055, Validation Accuracy = 0.6596\n",
            "Timestep 5.50%(Calibrated): Training Loss = 0.3478, Accuracy = 0.6522, Validation Loss = 0.2096, Validation Accuracy = 0.6638\n",
            "Timestep 6.00%(Calibrated): Training Loss = 0.3530, Accuracy = 0.6470, Validation Loss = 0.2016, Validation Accuracy = 0.6739\n",
            "Timestep 6.50%(Calibrated): Training Loss = 0.3260, Accuracy = 0.6740, Validation Loss = 0.2177, Validation Accuracy = 0.6308\n",
            "Timestep 7.00%(Calibrated): Training Loss = 0.3470, Accuracy = 0.6530, Validation Loss = 0.1985, Validation Accuracy = 0.6962\n",
            "Timestep 7.50%(Calibrated): Training Loss = 0.3456, Accuracy = 0.6544, Validation Loss = 0.2031, Validation Accuracy = 0.6634\n",
            "Timestep 8.00%(Calibrated): Training Loss = 0.3171, Accuracy = 0.6829, Validation Loss = 0.2004, Validation Accuracy = 0.6855\n",
            "Timestep 8.50%(Calibrated): Training Loss = 0.3499, Accuracy = 0.6501, Validation Loss = 0.1939, Validation Accuracy = 0.6925\n",
            "Timestep 9.00%(Calibrated): Training Loss = 0.3342, Accuracy = 0.6658, Validation Loss = 0.2042, Validation Accuracy = 0.6737\n",
            "Timestep 9.50%(Calibrated): Training Loss = 0.3280, Accuracy = 0.6720, Validation Loss = 0.2107, Validation Accuracy = 0.6677\n",
            "Timestep 10.00%(Calibrated): Training Loss = 0.3145, Accuracy = 0.6855, Validation Loss = 0.1990, Validation Accuracy = 0.6897\n",
            "Timestep 10.50%(Calibrated): Training Loss = 0.3422, Accuracy = 0.6578, Validation Loss = 0.1940, Validation Accuracy = 0.6811\n",
            "Timestep 11.00%(Calibrated): Training Loss = 0.3437, Accuracy = 0.6563, Validation Loss = 0.2025, Validation Accuracy = 0.6854\n",
            "Timestep 11.50%(Calibrated): Training Loss = 0.3162, Accuracy = 0.6838, Validation Loss = 0.1918, Validation Accuracy = 0.6989\n",
            "Timestep 12.00%(Calibrated): Training Loss = 0.3133, Accuracy = 0.6867, Validation Loss = 0.2051, Validation Accuracy = 0.6750\n",
            "Timestep 12.50%(Calibrated): Training Loss = 0.3157, Accuracy = 0.6843, Validation Loss = 0.1936, Validation Accuracy = 0.6882\n",
            "Timestep 13.00%(Calibrated): Training Loss = 0.3232, Accuracy = 0.6768, Validation Loss = 0.1945, Validation Accuracy = 0.6898\n",
            "Timestep 13.50%(Calibrated): Training Loss = 0.3349, Accuracy = 0.6651, Validation Loss = 0.1994, Validation Accuracy = 0.6939\n",
            "Timestep 14.00%(Calibrated): Training Loss = 0.3002, Accuracy = 0.6998, Validation Loss = 0.1907, Validation Accuracy = 0.6998\n",
            "Timestep 14.50%(Calibrated): Training Loss = 0.3150, Accuracy = 0.6850, Validation Loss = 0.1898, Validation Accuracy = 0.6848\n",
            "Timestep 15.00%(Calibrated): Training Loss = 0.2938, Accuracy = 0.7062, Validation Loss = 0.1897, Validation Accuracy = 0.7121\n",
            "Timestep 15.50%(Calibrated): Training Loss = 0.3099, Accuracy = 0.6901, Validation Loss = 0.1973, Validation Accuracy = 0.6951\n",
            "Timestep 16.00%(Calibrated): Training Loss = 0.3371, Accuracy = 0.6629, Validation Loss = 0.2032, Validation Accuracy = 0.6713\n",
            "Timestep 16.50%(Calibrated): Training Loss = 0.3539, Accuracy = 0.6461, Validation Loss = 0.2020, Validation Accuracy = 0.6667\n",
            "Timestep 17.00%(Calibrated): Training Loss = 0.3214, Accuracy = 0.6786, Validation Loss = 0.1954, Validation Accuracy = 0.6864\n",
            "Timestep 17.50%(Calibrated): Training Loss = 0.3213, Accuracy = 0.6787, Validation Loss = 0.1928, Validation Accuracy = 0.6917\n",
            "Timestep 18.00%(Calibrated): Training Loss = 0.3170, Accuracy = 0.6830, Validation Loss = 0.1884, Validation Accuracy = 0.7206\n",
            "Timestep 18.50%(Calibrated): Training Loss = 0.3096, Accuracy = 0.6904, Validation Loss = 0.1895, Validation Accuracy = 0.7111\n",
            "Timestep 19.00%(Calibrated): Training Loss = 0.3086, Accuracy = 0.6914, Validation Loss = 0.1871, Validation Accuracy = 0.7097\n",
            "Timestep 19.50%(Calibrated): Training Loss = 0.2966, Accuracy = 0.7034, Validation Loss = 0.1843, Validation Accuracy = 0.7071\n",
            "Timestep 20.00%(Calibrated): Training Loss = 0.2968, Accuracy = 0.7032, Validation Loss = 0.1883, Validation Accuracy = 0.7101\n",
            "Timestep 20.50%(Calibrated): Training Loss = 0.3034, Accuracy = 0.6966, Validation Loss = 0.1893, Validation Accuracy = 0.6954\n",
            "Timestep 21.00%(Calibrated): Training Loss = 0.2977, Accuracy = 0.7023, Validation Loss = 0.1732, Validation Accuracy = 0.7239\n",
            "Timestep 21.50%(Calibrated): Training Loss = 0.2905, Accuracy = 0.7095, Validation Loss = 0.1858, Validation Accuracy = 0.7084\n",
            "Timestep 22.00%(Calibrated): Training Loss = 0.2834, Accuracy = 0.7166, Validation Loss = 0.1741, Validation Accuracy = 0.7386\n",
            "Timestep 22.50%(Calibrated): Training Loss = 0.2759, Accuracy = 0.7241, Validation Loss = 0.1780, Validation Accuracy = 0.7300\n",
            "Timestep 23.00%(Calibrated): Training Loss = 0.2952, Accuracy = 0.7048, Validation Loss = 0.1783, Validation Accuracy = 0.7242\n",
            "Timestep 23.50%(Calibrated): Training Loss = 0.2696, Accuracy = 0.7304, Validation Loss = 0.1743, Validation Accuracy = 0.7276\n",
            "Timestep 24.00%(Calibrated): Training Loss = 0.2990, Accuracy = 0.7010, Validation Loss = 0.1816, Validation Accuracy = 0.7222\n",
            "Timestep 24.50%(Calibrated): Training Loss = 0.2941, Accuracy = 0.7059, Validation Loss = 0.1691, Validation Accuracy = 0.7478\n",
            "Completed 50/201 timesteps\n",
            "Timestep 25.00%(Calibrated): Training Loss = 0.2840, Accuracy = 0.7160, Validation Loss = 0.1740, Validation Accuracy = 0.7351\n",
            "Timestep 25.50%(Calibrated): Training Loss = 0.2740, Accuracy = 0.7260, Validation Loss = 0.1744, Validation Accuracy = 0.7155\n",
            "Timestep 26.00%(Calibrated): Training Loss = 0.2916, Accuracy = 0.7084, Validation Loss = 0.1728, Validation Accuracy = 0.7207\n",
            "Timestep 26.50%(Calibrated): Training Loss = 0.2942, Accuracy = 0.7058, Validation Loss = 0.1655, Validation Accuracy = 0.7470\n",
            "Timestep 27.00%(Calibrated): Training Loss = 0.2786, Accuracy = 0.7214, Validation Loss = 0.1717, Validation Accuracy = 0.7299\n",
            "Timestep 27.50%(Calibrated): Training Loss = 0.2823, Accuracy = 0.7177, Validation Loss = 0.1720, Validation Accuracy = 0.7374\n",
            "Timestep 28.00%(Calibrated): Training Loss = 0.2890, Accuracy = 0.7110, Validation Loss = 0.1753, Validation Accuracy = 0.7325\n",
            "Timestep 28.50%(Calibrated): Training Loss = 0.2948, Accuracy = 0.7052, Validation Loss = 0.1622, Validation Accuracy = 0.7475\n",
            "Timestep 29.00%(Calibrated): Training Loss = 0.3054, Accuracy = 0.6946, Validation Loss = 0.1761, Validation Accuracy = 0.7180\n",
            "Timestep 29.50%(Calibrated): Training Loss = 0.2918, Accuracy = 0.7082, Validation Loss = 0.1695, Validation Accuracy = 0.7206\n",
            "Timestep 30.00%(Calibrated): Training Loss = 0.2708, Accuracy = 0.7292, Validation Loss = 0.1772, Validation Accuracy = 0.7109\n",
            "Timestep 30.50%(Calibrated): Training Loss = 0.2918, Accuracy = 0.7082, Validation Loss = 0.1763, Validation Accuracy = 0.7080\n",
            "Timestep 31.00%(Calibrated): Training Loss = 0.2703, Accuracy = 0.7297, Validation Loss = 0.1736, Validation Accuracy = 0.7259\n",
            "Timestep 31.50%(Calibrated): Training Loss = 0.2939, Accuracy = 0.7061, Validation Loss = 0.1830, Validation Accuracy = 0.6987\n",
            "Timestep 32.00%(Calibrated): Training Loss = 0.2760, Accuracy = 0.7240, Validation Loss = 0.1680, Validation Accuracy = 0.7312\n",
            "Timestep 32.50%(Calibrated): Training Loss = 0.2626, Accuracy = 0.7374, Validation Loss = 0.1740, Validation Accuracy = 0.7217\n",
            "Timestep 33.00%(Calibrated): Training Loss = 0.2820, Accuracy = 0.7180, Validation Loss = 0.1649, Validation Accuracy = 0.7316\n",
            "Timestep 33.50%(Calibrated): Training Loss = 0.2572, Accuracy = 0.7428, Validation Loss = 0.1726, Validation Accuracy = 0.7252\n",
            "Timestep 34.00%(Calibrated): Training Loss = 0.2649, Accuracy = 0.7351, Validation Loss = 0.1653, Validation Accuracy = 0.7382\n",
            "Timestep 34.50%(Calibrated): Training Loss = 0.2656, Accuracy = 0.7344, Validation Loss = 0.1581, Validation Accuracy = 0.7550\n",
            "Timestep 35.00%(Calibrated): Training Loss = 0.2699, Accuracy = 0.7301, Validation Loss = 0.1702, Validation Accuracy = 0.7326\n",
            "Timestep 35.50%(Calibrated): Training Loss = 0.2828, Accuracy = 0.7172, Validation Loss = 0.1649, Validation Accuracy = 0.7457\n",
            "Timestep 36.00%(Calibrated): Training Loss = 0.2740, Accuracy = 0.7260, Validation Loss = 0.1639, Validation Accuracy = 0.7492\n",
            "Timestep 36.50%(Calibrated): Training Loss = 0.2580, Accuracy = 0.7420, Validation Loss = 0.1690, Validation Accuracy = 0.7361\n",
            "Timestep 37.00%(Calibrated): Training Loss = 0.2678, Accuracy = 0.7322, Validation Loss = 0.1697, Validation Accuracy = 0.7391\n",
            "Timestep 37.50%(Calibrated): Training Loss = 0.2550, Accuracy = 0.7450, Validation Loss = 0.1676, Validation Accuracy = 0.7423\n",
            "Timestep 38.00%(Calibrated): Training Loss = 0.2434, Accuracy = 0.7566, Validation Loss = 0.1628, Validation Accuracy = 0.7397\n",
            "Timestep 38.50%(Calibrated): Training Loss = 0.2678, Accuracy = 0.7322, Validation Loss = 0.1634, Validation Accuracy = 0.7433\n",
            "Timestep 39.00%(Calibrated): Training Loss = 0.2652, Accuracy = 0.7348, Validation Loss = 0.1674, Validation Accuracy = 0.7392\n",
            "Timestep 39.50%(Calibrated): Training Loss = 0.2610, Accuracy = 0.7390, Validation Loss = 0.1625, Validation Accuracy = 0.7500\n",
            "Timestep 40.00%(Calibrated): Training Loss = 0.2576, Accuracy = 0.7424, Validation Loss = 0.1735, Validation Accuracy = 0.7250\n",
            "Timestep 40.50%(Calibrated): Training Loss = 0.2341, Accuracy = 0.7659, Validation Loss = 0.1513, Validation Accuracy = 0.7774\n",
            "Timestep 41.00%(Calibrated): Training Loss = 0.2706, Accuracy = 0.7294, Validation Loss = 0.1590, Validation Accuracy = 0.7573\n",
            "Timestep 41.50%(Calibrated): Training Loss = 0.2479, Accuracy = 0.7521, Validation Loss = 0.1577, Validation Accuracy = 0.7560\n",
            "Timestep 42.00%(Calibrated): Training Loss = 0.2523, Accuracy = 0.7477, Validation Loss = 0.1737, Validation Accuracy = 0.7066\n",
            "Timestep 42.50%(Calibrated): Training Loss = 0.2453, Accuracy = 0.7547, Validation Loss = 0.1635, Validation Accuracy = 0.7667\n",
            "Timestep 43.00%(Calibrated): Training Loss = 0.2369, Accuracy = 0.7631, Validation Loss = 0.1609, Validation Accuracy = 0.7544\n",
            "Timestep 43.50%(Calibrated): Training Loss = 0.2333, Accuracy = 0.7667, Validation Loss = 0.1603, Validation Accuracy = 0.7531\n",
            "Timestep 44.00%(Calibrated): Training Loss = 0.2400, Accuracy = 0.7600, Validation Loss = 0.1699, Validation Accuracy = 0.7328\n",
            "Timestep 44.50%(Calibrated): Training Loss = 0.2412, Accuracy = 0.7588, Validation Loss = 0.1619, Validation Accuracy = 0.7573\n",
            "Timestep 45.00%(Calibrated): Training Loss = 0.2625, Accuracy = 0.7375, Validation Loss = 0.1579, Validation Accuracy = 0.7610\n",
            "Timestep 45.50%(Calibrated): Training Loss = 0.2653, Accuracy = 0.7347, Validation Loss = 0.1641, Validation Accuracy = 0.7374\n",
            "Timestep 46.00%(Calibrated): Training Loss = 0.2438, Accuracy = 0.7562, Validation Loss = 0.1432, Validation Accuracy = 0.7988\n",
            "Timestep 46.50%(Calibrated): Training Loss = 0.2337, Accuracy = 0.7663, Validation Loss = 0.1507, Validation Accuracy = 0.7833\n",
            "Timestep 47.00%(Calibrated): Training Loss = 0.2291, Accuracy = 0.7709, Validation Loss = 0.1570, Validation Accuracy = 0.7578\n",
            "Timestep 47.50%(Calibrated): Training Loss = 0.2294, Accuracy = 0.7706, Validation Loss = 0.1515, Validation Accuracy = 0.7678\n",
            "Timestep 48.00%(Calibrated): Training Loss = 0.2142, Accuracy = 0.7858, Validation Loss = 0.1494, Validation Accuracy = 0.7744\n",
            "Timestep 48.50%(Calibrated): Training Loss = 0.2210, Accuracy = 0.7790, Validation Loss = 0.1464, Validation Accuracy = 0.7742\n",
            "Timestep 49.00%(Calibrated): Training Loss = 0.2022, Accuracy = 0.7978, Validation Loss = 0.1612, Validation Accuracy = 0.7601\n",
            "Timestep 49.50%(Calibrated): Training Loss = 0.2152, Accuracy = 0.7848, Validation Loss = 0.1425, Validation Accuracy = 0.7920\n",
            "Completed 100/201 timesteps\n",
            "Timestep 50.00%(Calibrated): Training Loss = 0.2057, Accuracy = 0.7943, Validation Loss = 0.1415, Validation Accuracy = 0.7997\n",
            "Timestep 50.50%(Calibrated): Training Loss = 0.2048, Accuracy = 0.7952, Validation Loss = 0.1468, Validation Accuracy = 0.7829\n",
            "Timestep 51.00%(Calibrated): Training Loss = 0.2115, Accuracy = 0.7885, Validation Loss = 0.1452, Validation Accuracy = 0.7993\n",
            "Timestep 51.50%(Calibrated): Training Loss = 0.2010, Accuracy = 0.7990, Validation Loss = 0.1363, Validation Accuracy = 0.8061\n",
            "Timestep 52.00%(Calibrated): Training Loss = 0.2249, Accuracy = 0.7751, Validation Loss = 0.1340, Validation Accuracy = 0.8115\n",
            "Timestep 52.50%(Calibrated): Training Loss = 0.1987, Accuracy = 0.8013, Validation Loss = 0.1435, Validation Accuracy = 0.7946\n",
            "Timestep 53.00%(Calibrated): Training Loss = 0.2263, Accuracy = 0.7737, Validation Loss = 0.1547, Validation Accuracy = 0.7700\n",
            "Timestep 53.50%(Calibrated): Training Loss = 0.2019, Accuracy = 0.7981, Validation Loss = 0.1320, Validation Accuracy = 0.8217\n",
            "Timestep 54.00%(Calibrated): Training Loss = 0.2022, Accuracy = 0.7978, Validation Loss = 0.1539, Validation Accuracy = 0.7719\n",
            "Timestep 54.50%(Calibrated): Training Loss = 0.2137, Accuracy = 0.7863, Validation Loss = 0.1467, Validation Accuracy = 0.7860\n",
            "Timestep 55.00%(Calibrated): Training Loss = 0.1893, Accuracy = 0.8107, Validation Loss = 0.1391, Validation Accuracy = 0.8120\n",
            "Timestep 55.50%(Calibrated): Training Loss = 0.2041, Accuracy = 0.7959, Validation Loss = 0.1397, Validation Accuracy = 0.7922\n",
            "Timestep 56.00%(Calibrated): Training Loss = 0.1961, Accuracy = 0.8039, Validation Loss = 0.1408, Validation Accuracy = 0.8009\n",
            "Timestep 56.50%(Calibrated): Training Loss = 0.1958, Accuracy = 0.8042, Validation Loss = 0.1488, Validation Accuracy = 0.7749\n",
            "Timestep 57.00%(Calibrated): Training Loss = 0.2045, Accuracy = 0.7955, Validation Loss = 0.1368, Validation Accuracy = 0.8094\n",
            "Timestep 57.50%(Calibrated): Training Loss = 0.2071, Accuracy = 0.7929, Validation Loss = 0.1456, Validation Accuracy = 0.7812\n",
            "Timestep 58.00%(Calibrated): Training Loss = 0.2092, Accuracy = 0.7908, Validation Loss = 0.1388, Validation Accuracy = 0.7830\n",
            "Timestep 58.50%(Calibrated): Training Loss = 0.2041, Accuracy = 0.7959, Validation Loss = 0.1357, Validation Accuracy = 0.8091\n",
            "Timestep 59.00%(Calibrated): Training Loss = 0.1989, Accuracy = 0.8011, Validation Loss = 0.1493, Validation Accuracy = 0.7888\n",
            "Timestep 59.50%(Calibrated): Training Loss = 0.2060, Accuracy = 0.7940, Validation Loss = 0.1384, Validation Accuracy = 0.8035\n",
            "Timestep 60.00%(Calibrated): Training Loss = 0.2056, Accuracy = 0.7944, Validation Loss = 0.1455, Validation Accuracy = 0.7918\n",
            "Timestep 60.50%(Calibrated): Training Loss = 0.1960, Accuracy = 0.8040, Validation Loss = 0.1393, Validation Accuracy = 0.7900\n",
            "Timestep 61.00%(Calibrated): Training Loss = 0.1951, Accuracy = 0.8049, Validation Loss = 0.1406, Validation Accuracy = 0.7978\n",
            "Timestep 61.50%(Calibrated): Training Loss = 0.1931, Accuracy = 0.8069, Validation Loss = 0.1384, Validation Accuracy = 0.8022\n",
            "Timestep 62.00%(Calibrated): Training Loss = 0.1977, Accuracy = 0.8023, Validation Loss = 0.1381, Validation Accuracy = 0.7994\n",
            "Timestep 62.50%(Calibrated): Training Loss = 0.1839, Accuracy = 0.8161, Validation Loss = 0.1405, Validation Accuracy = 0.8117\n",
            "Timestep 63.00%(Calibrated): Training Loss = 0.1920, Accuracy = 0.8080, Validation Loss = 0.1405, Validation Accuracy = 0.7978\n",
            "Timestep 63.50%(Calibrated): Training Loss = 0.1987, Accuracy = 0.8013, Validation Loss = 0.1361, Validation Accuracy = 0.8016\n",
            "Timestep 64.00%(Calibrated): Training Loss = 0.1825, Accuracy = 0.8175, Validation Loss = 0.1476, Validation Accuracy = 0.7767\n",
            "Timestep 64.50%(Calibrated): Training Loss = 0.1927, Accuracy = 0.8073, Validation Loss = 0.1444, Validation Accuracy = 0.7917\n",
            "Timestep 65.00%(Calibrated): Training Loss = 0.1957, Accuracy = 0.8043, Validation Loss = 0.1523, Validation Accuracy = 0.7706\n",
            "Timestep 65.50%(Calibrated): Training Loss = 0.1766, Accuracy = 0.8234, Validation Loss = 0.1479, Validation Accuracy = 0.7740\n",
            "Timestep 66.00%(Calibrated): Training Loss = 0.1831, Accuracy = 0.8169, Validation Loss = 0.1343, Validation Accuracy = 0.8040\n",
            "Timestep 66.50%(Calibrated): Training Loss = 0.1797, Accuracy = 0.8203, Validation Loss = 0.1351, Validation Accuracy = 0.8079\n",
            "Timestep 67.00%(Calibrated): Training Loss = 0.1713, Accuracy = 0.8287, Validation Loss = 0.1335, Validation Accuracy = 0.8191\n",
            "Timestep 67.50%(Calibrated): Training Loss = 0.1855, Accuracy = 0.8145, Validation Loss = 0.1354, Validation Accuracy = 0.7975\n",
            "Timestep 68.00%(Calibrated): Training Loss = 0.1915, Accuracy = 0.8085, Validation Loss = 0.1252, Validation Accuracy = 0.8144\n",
            "Timestep 68.50%(Calibrated): Training Loss = 0.1826, Accuracy = 0.8174, Validation Loss = 0.1352, Validation Accuracy = 0.8009\n",
            "Timestep 69.00%(Calibrated): Training Loss = 0.1769, Accuracy = 0.8231, Validation Loss = 0.1293, Validation Accuracy = 0.8063\n",
            "Timestep 69.50%(Calibrated): Training Loss = 0.1731, Accuracy = 0.8269, Validation Loss = 0.1308, Validation Accuracy = 0.8155\n",
            "Timestep 70.00%(Calibrated): Training Loss = 0.2100, Accuracy = 0.7900, Validation Loss = 0.1263, Validation Accuracy = 0.8065\n",
            "Timestep 70.50%(Calibrated): Training Loss = 0.1740, Accuracy = 0.8260, Validation Loss = 0.1258, Validation Accuracy = 0.8180\n",
            "Timestep 71.00%(Calibrated): Training Loss = 0.1737, Accuracy = 0.8263, Validation Loss = 0.1283, Validation Accuracy = 0.8126\n",
            "Timestep 71.50%(Calibrated): Training Loss = 0.1676, Accuracy = 0.8324, Validation Loss = 0.1366, Validation Accuracy = 0.7969\n",
            "Timestep 72.00%(Calibrated): Training Loss = 0.1727, Accuracy = 0.8273, Validation Loss = 0.1167, Validation Accuracy = 0.8438\n",
            "Timestep 72.50%(Calibrated): Training Loss = 0.1695, Accuracy = 0.8305, Validation Loss = 0.1313, Validation Accuracy = 0.8069\n",
            "Timestep 73.00%(Calibrated): Training Loss = 0.1691, Accuracy = 0.8309, Validation Loss = 0.1282, Validation Accuracy = 0.8196\n",
            "Timestep 73.50%(Calibrated): Training Loss = 0.1597, Accuracy = 0.8403, Validation Loss = 0.1340, Validation Accuracy = 0.8051\n",
            "Timestep 74.00%(Calibrated): Training Loss = 0.1604, Accuracy = 0.8396, Validation Loss = 0.1237, Validation Accuracy = 0.8223\n",
            "Timestep 74.50%(Calibrated): Training Loss = 0.1699, Accuracy = 0.8301, Validation Loss = 0.1273, Validation Accuracy = 0.8212\n",
            "Completed 150/201 timesteps\n",
            "Timestep 75.00%(Calibrated): Training Loss = 0.1605, Accuracy = 0.8395, Validation Loss = 0.1231, Validation Accuracy = 0.8209\n",
            "Timestep 75.50%(Calibrated): Training Loss = 0.1290, Accuracy = 0.8710, Validation Loss = 0.1077, Validation Accuracy = 0.8451\n",
            "Timestep 76.00%(Calibrated): Training Loss = 0.1561, Accuracy = 0.8439, Validation Loss = 0.1062, Validation Accuracy = 0.8484\n",
            "Timestep 76.50%(Calibrated): Training Loss = 0.1414, Accuracy = 0.8586, Validation Loss = 0.1206, Validation Accuracy = 0.8306\n",
            "Timestep 77.00%(Calibrated): Training Loss = 0.1631, Accuracy = 0.8369, Validation Loss = 0.1287, Validation Accuracy = 0.8098\n",
            "Timestep 77.50%(Calibrated): Training Loss = 0.1483, Accuracy = 0.8517, Validation Loss = 0.1169, Validation Accuracy = 0.8336\n",
            "Timestep 78.00%(Calibrated): Training Loss = 0.1529, Accuracy = 0.8471, Validation Loss = 0.1313, Validation Accuracy = 0.8043\n",
            "Timestep 78.50%(Calibrated): Training Loss = 0.1500, Accuracy = 0.8500, Validation Loss = 0.1204, Validation Accuracy = 0.8277\n",
            "Timestep 79.00%(Calibrated): Training Loss = 0.1356, Accuracy = 0.8644, Validation Loss = 0.1089, Validation Accuracy = 0.8548\n",
            "Timestep 79.50%(Calibrated): Training Loss = 0.1651, Accuracy = 0.8349, Validation Loss = 0.1195, Validation Accuracy = 0.8306\n",
            "Timestep 80.00%(Calibrated): Training Loss = 0.1320, Accuracy = 0.8680, Validation Loss = 0.1138, Validation Accuracy = 0.8457\n",
            "Timestep 80.50%(Calibrated): Training Loss = 0.1408, Accuracy = 0.8592, Validation Loss = 0.1067, Validation Accuracy = 0.8501\n",
            "Timestep 81.00%(Calibrated): Training Loss = 0.1394, Accuracy = 0.8606, Validation Loss = 0.1081, Validation Accuracy = 0.8428\n",
            "Timestep 81.50%(Calibrated): Training Loss = 0.1400, Accuracy = 0.8600, Validation Loss = 0.1197, Validation Accuracy = 0.8227\n",
            "Timestep 82.00%(Calibrated): Training Loss = 0.1607, Accuracy = 0.8393, Validation Loss = 0.1028, Validation Accuracy = 0.8430\n",
            "Timestep 82.50%(Calibrated): Training Loss = 0.1483, Accuracy = 0.8517, Validation Loss = 0.1151, Validation Accuracy = 0.8336\n",
            "Timestep 83.00%(Calibrated): Training Loss = 0.1424, Accuracy = 0.8576, Validation Loss = 0.1031, Validation Accuracy = 0.8471\n",
            "Timestep 83.50%(Calibrated): Training Loss = 0.1350, Accuracy = 0.8650, Validation Loss = 0.0900, Validation Accuracy = 0.8709\n",
            "Timestep 84.00%(Calibrated): Training Loss = 0.1516, Accuracy = 0.8484, Validation Loss = 0.0966, Validation Accuracy = 0.8631\n",
            "Timestep 84.50%(Calibrated): Training Loss = 0.1440, Accuracy = 0.8560, Validation Loss = 0.1054, Validation Accuracy = 0.8463\n",
            "Timestep 85.00%(Calibrated): Training Loss = 0.1326, Accuracy = 0.8674, Validation Loss = 0.1041, Validation Accuracy = 0.8560\n",
            "Timestep 85.50%(Calibrated): Training Loss = 0.1546, Accuracy = 0.8454, Validation Loss = 0.1122, Validation Accuracy = 0.8286\n",
            "Timestep 86.00%(Calibrated): Training Loss = 0.1318, Accuracy = 0.8682, Validation Loss = 0.0985, Validation Accuracy = 0.8518\n",
            "Timestep 86.50%(Calibrated): Training Loss = 0.1260, Accuracy = 0.8740, Validation Loss = 0.0901, Validation Accuracy = 0.8818\n",
            "Timestep 87.00%(Calibrated): Training Loss = 0.1446, Accuracy = 0.8554, Validation Loss = 0.1074, Validation Accuracy = 0.8378\n",
            "Timestep 87.50%(Calibrated): Training Loss = 0.1384, Accuracy = 0.8616, Validation Loss = 0.0908, Validation Accuracy = 0.8702\n",
            "Timestep 88.00%(Calibrated): Training Loss = 0.1305, Accuracy = 0.8695, Validation Loss = 0.1032, Validation Accuracy = 0.8547\n",
            "Timestep 88.50%(Calibrated): Training Loss = 0.1427, Accuracy = 0.8573, Validation Loss = 0.1026, Validation Accuracy = 0.8420\n",
            "Timestep 89.00%(Calibrated): Training Loss = 0.1320, Accuracy = 0.8680, Validation Loss = 0.1042, Validation Accuracy = 0.8432\n",
            "Timestep 89.50%(Calibrated): Training Loss = 0.1112, Accuracy = 0.8888, Validation Loss = 0.0897, Validation Accuracy = 0.8839\n",
            "Timestep 90.00%(Calibrated): Training Loss = 0.1403, Accuracy = 0.8597, Validation Loss = 0.0925, Validation Accuracy = 0.8618\n",
            "Timestep 90.50%(Calibrated): Training Loss = 0.1310, Accuracy = 0.8690, Validation Loss = 0.0909, Validation Accuracy = 0.8585\n",
            "Timestep 91.00%(Calibrated): Training Loss = 0.1367, Accuracy = 0.8633, Validation Loss = 0.0889, Validation Accuracy = 0.8692\n",
            "Timestep 91.50%(Calibrated): Training Loss = 0.1146, Accuracy = 0.8854, Validation Loss = 0.0894, Validation Accuracy = 0.8765\n",
            "Timestep 92.00%(Calibrated): Training Loss = 0.1302, Accuracy = 0.8698, Validation Loss = 0.0916, Validation Accuracy = 0.8690\n",
            "Timestep 92.50%(Calibrated): Training Loss = 0.1171, Accuracy = 0.8829, Validation Loss = 0.0878, Validation Accuracy = 0.8745\n",
            "Timestep 93.00%(Calibrated): Training Loss = 0.1111, Accuracy = 0.8889, Validation Loss = 0.0856, Validation Accuracy = 0.8743\n",
            "Timestep 93.50%(Calibrated): Training Loss = 0.1119, Accuracy = 0.8881, Validation Loss = 0.0899, Validation Accuracy = 0.8793\n",
            "Timestep 94.00%(Calibrated): Training Loss = 0.1030, Accuracy = 0.8970, Validation Loss = 0.0754, Validation Accuracy = 0.8900\n",
            "Timestep 94.50%(Calibrated): Training Loss = 0.1083, Accuracy = 0.8917, Validation Loss = 0.0761, Validation Accuracy = 0.8860\n",
            "Timestep 95.00%(Calibrated): Training Loss = 0.1157, Accuracy = 0.8843, Validation Loss = 0.0871, Validation Accuracy = 0.8673\n",
            "Timestep 95.50%(Calibrated): Training Loss = 0.1222, Accuracy = 0.8778, Validation Loss = 0.0773, Validation Accuracy = 0.8800\n",
            "Timestep 96.00%(Calibrated): Training Loss = 0.1158, Accuracy = 0.8842, Validation Loss = 0.0949, Validation Accuracy = 0.8612\n",
            "Timestep 96.50%(Calibrated): Training Loss = 0.1261, Accuracy = 0.8739, Validation Loss = 0.0755, Validation Accuracy = 0.8906\n",
            "Timestep 97.00%(Calibrated): Training Loss = 0.0961, Accuracy = 0.9039, Validation Loss = 0.0848, Validation Accuracy = 0.8724\n",
            "Timestep 97.50%(Calibrated): Training Loss = 0.1007, Accuracy = 0.8993, Validation Loss = 0.0889, Validation Accuracy = 0.8752\n",
            "Timestep 98.00%(Calibrated): Training Loss = 0.0964, Accuracy = 0.9036, Validation Loss = 0.0723, Validation Accuracy = 0.8999\n",
            "Timestep 98.50%(Calibrated): Training Loss = 0.1031, Accuracy = 0.8969, Validation Loss = 0.0677, Validation Accuracy = 0.8973\n",
            "Timestep 99.00%(Calibrated): Training Loss = 0.1111, Accuracy = 0.8889, Validation Loss = 0.0680, Validation Accuracy = 0.9136\n",
            "Timestep 99.50%(Calibrated): Training Loss = 0.0965, Accuracy = 0.9035, Validation Loss = 0.0715, Validation Accuracy = 0.9000\n",
            "Completed 200/201 timesteps\n",
            "Timestep 100.00%(Calibrated): Training Loss = 0.0778, Accuracy = 0.9222, Validation Loss = 0.0398, Validation Accuracy = 0.9410\n",
            "Completed 201/201 timesteps\n"
          ]
        }
      ],
      "source": [
        "all_models[\"xgboost\"] = setup_xgboost_models(training_data, None, numeric_features, other_features, features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['lstm', 'nn', 'logistic', 'xgboost'])\n",
            "Generating predictions for timestep 0.0\n",
            "Generating predictions for timestep 0.005\n",
            "Generating predictions for timestep 0.01\n",
            "Generating predictions for timestep 0.015\n",
            "Generating predictions for timestep 0.02\n",
            "Generating predictions for timestep 0.025\n",
            "Generating predictions for timestep 0.03\n",
            "Generating predictions for timestep 0.035\n",
            "Generating predictions for timestep 0.04\n",
            "Generating predictions for timestep 0.045\n",
            "Generating predictions for timestep 0.05\n",
            "Generating predictions for timestep 0.055\n",
            "Generating predictions for timestep 0.06\n",
            "Generating predictions for timestep 0.065\n",
            "Generating predictions for timestep 0.07\n",
            "Generating predictions for timestep 0.075\n",
            "Generating predictions for timestep 0.08\n",
            "Generating predictions for timestep 0.085\n",
            "Generating predictions for timestep 0.09\n",
            "Generating predictions for timestep 0.095\n",
            "Generating predictions for timestep 0.1\n",
            "Generating predictions for timestep 0.105\n",
            "Generating predictions for timestep 0.11\n",
            "Generating predictions for timestep 0.115\n",
            "Generating predictions for timestep 0.12\n",
            "Generating predictions for timestep 0.125\n",
            "Generating predictions for timestep 0.13\n",
            "Generating predictions for timestep 0.135\n",
            "Generating predictions for timestep 0.14\n",
            "Generating predictions for timestep 0.145\n",
            "Generating predictions for timestep 0.15\n",
            "Generating predictions for timestep 0.155\n",
            "Generating predictions for timestep 0.16\n",
            "Generating predictions for timestep 0.165\n",
            "Generating predictions for timestep 0.17\n",
            "Generating predictions for timestep 0.175\n",
            "Generating predictions for timestep 0.18\n",
            "Generating predictions for timestep 0.185\n",
            "Generating predictions for timestep 0.19\n",
            "Generating predictions for timestep 0.195\n",
            "Generating predictions for timestep 0.2\n",
            "Generating predictions for timestep 0.205\n",
            "Generating predictions for timestep 0.21\n",
            "Generating predictions for timestep 0.215\n",
            "Generating predictions for timestep 0.22\n",
            "Generating predictions for timestep 0.225\n",
            "Generating predictions for timestep 0.23\n",
            "Generating predictions for timestep 0.235\n",
            "Generating predictions for timestep 0.24\n",
            "Generating predictions for timestep 0.245\n",
            "Generating predictions for timestep 0.25\n",
            "Generating predictions for timestep 0.255\n",
            "Generating predictions for timestep 0.26\n",
            "Generating predictions for timestep 0.265\n",
            "Generating predictions for timestep 0.27\n",
            "Generating predictions for timestep 0.275\n",
            "Generating predictions for timestep 0.28\n",
            "Generating predictions for timestep 0.285\n",
            "Generating predictions for timestep 0.29\n",
            "Generating predictions for timestep 0.295\n",
            "Generating predictions for timestep 0.3\n",
            "Generating predictions for timestep 0.305\n",
            "Generating predictions for timestep 0.31\n",
            "Generating predictions for timestep 0.315\n",
            "Generating predictions for timestep 0.32\n",
            "Generating predictions for timestep 0.325\n",
            "Generating predictions for timestep 0.33\n",
            "Generating predictions for timestep 0.335\n",
            "Generating predictions for timestep 0.34\n",
            "Generating predictions for timestep 0.345\n",
            "Generating predictions for timestep 0.35\n",
            "Generating predictions for timestep 0.355\n",
            "Generating predictions for timestep 0.36\n",
            "Generating predictions for timestep 0.365\n",
            "Generating predictions for timestep 0.37\n",
            "Generating predictions for timestep 0.375\n",
            "Generating predictions for timestep 0.38\n",
            "Generating predictions for timestep 0.385\n",
            "Generating predictions for timestep 0.39\n",
            "Generating predictions for timestep 0.395\n",
            "Generating predictions for timestep 0.4\n",
            "Generating predictions for timestep 0.405\n",
            "Generating predictions for timestep 0.41\n",
            "Generating predictions for timestep 0.415\n",
            "Generating predictions for timestep 0.42\n",
            "Generating predictions for timestep 0.425\n",
            "Generating predictions for timestep 0.43\n",
            "Generating predictions for timestep 0.435\n",
            "Generating predictions for timestep 0.44\n",
            "Generating predictions for timestep 0.445\n",
            "Generating predictions for timestep 0.45\n",
            "Generating predictions for timestep 0.455\n",
            "Generating predictions for timestep 0.46\n",
            "Generating predictions for timestep 0.465\n",
            "Generating predictions for timestep 0.47\n",
            "Generating predictions for timestep 0.475\n",
            "Generating predictions for timestep 0.48\n",
            "Generating predictions for timestep 0.485\n",
            "Generating predictions for timestep 0.49\n",
            "Generating predictions for timestep 0.495\n",
            "Generating predictions for timestep 0.5\n",
            "Generating predictions for timestep 0.505\n",
            "Generating predictions for timestep 0.51\n",
            "Generating predictions for timestep 0.515\n",
            "Generating predictions for timestep 0.52\n",
            "Generating predictions for timestep 0.525\n",
            "Generating predictions for timestep 0.53\n",
            "Generating predictions for timestep 0.535\n",
            "Generating predictions for timestep 0.54\n",
            "Generating predictions for timestep 0.545\n",
            "Generating predictions for timestep 0.55\n",
            "Generating predictions for timestep 0.555\n",
            "Generating predictions for timestep 0.56\n",
            "Generating predictions for timestep 0.565\n",
            "Generating predictions for timestep 0.57\n",
            "Generating predictions for timestep 0.575\n",
            "Generating predictions for timestep 0.58\n",
            "Generating predictions for timestep 0.585\n",
            "Generating predictions for timestep 0.59\n",
            "Generating predictions for timestep 0.595\n",
            "Generating predictions for timestep 0.6\n",
            "Generating predictions for timestep 0.605\n",
            "Generating predictions for timestep 0.61\n",
            "Generating predictions for timestep 0.615\n",
            "Generating predictions for timestep 0.62\n",
            "Generating predictions for timestep 0.625\n",
            "Generating predictions for timestep 0.63\n",
            "Generating predictions for timestep 0.635\n",
            "Generating predictions for timestep 0.64\n",
            "Generating predictions for timestep 0.645\n",
            "Generating predictions for timestep 0.65\n",
            "Generating predictions for timestep 0.655\n",
            "Generating predictions for timestep 0.66\n",
            "Generating predictions for timestep 0.665\n",
            "Generating predictions for timestep 0.67\n",
            "Generating predictions for timestep 0.675\n",
            "Generating predictions for timestep 0.68\n",
            "Generating predictions for timestep 0.685\n",
            "Generating predictions for timestep 0.69\n",
            "Generating predictions for timestep 0.695\n",
            "Generating predictions for timestep 0.7\n",
            "Generating predictions for timestep 0.705\n",
            "Generating predictions for timestep 0.71\n",
            "Generating predictions for timestep 0.715\n",
            "Generating predictions for timestep 0.72\n",
            "Generating predictions for timestep 0.725\n",
            "Generating predictions for timestep 0.73\n",
            "Generating predictions for timestep 0.735\n",
            "Generating predictions for timestep 0.74\n",
            "Generating predictions for timestep 0.745\n",
            "Generating predictions for timestep 0.75\n",
            "Generating predictions for timestep 0.755\n",
            "Generating predictions for timestep 0.76\n",
            "Generating predictions for timestep 0.765\n",
            "Generating predictions for timestep 0.77\n",
            "Generating predictions for timestep 0.775\n",
            "Generating predictions for timestep 0.78\n",
            "Generating predictions for timestep 0.785\n",
            "Generating predictions for timestep 0.79\n",
            "Generating predictions for timestep 0.795\n",
            "Generating predictions for timestep 0.8\n",
            "Generating predictions for timestep 0.805\n",
            "Generating predictions for timestep 0.81\n",
            "Generating predictions for timestep 0.815\n",
            "Generating predictions for timestep 0.82\n",
            "Generating predictions for timestep 0.825\n",
            "Generating predictions for timestep 0.83\n",
            "Generating predictions for timestep 0.835\n",
            "Generating predictions for timestep 0.84\n",
            "Generating predictions for timestep 0.845\n",
            "Generating predictions for timestep 0.85\n",
            "Generating predictions for timestep 0.855\n",
            "Generating predictions for timestep 0.86\n",
            "Generating predictions for timestep 0.865\n",
            "Generating predictions for timestep 0.87\n",
            "Generating predictions for timestep 0.875\n",
            "Generating predictions for timestep 0.88\n",
            "Generating predictions for timestep 0.885\n",
            "Generating predictions for timestep 0.89\n",
            "Generating predictions for timestep 0.895\n",
            "Generating predictions for timestep 0.9\n",
            "Generating predictions for timestep 0.905\n",
            "Generating predictions for timestep 0.91\n",
            "Generating predictions for timestep 0.915\n",
            "Generating predictions for timestep 0.92\n",
            "Generating predictions for timestep 0.925\n",
            "Generating predictions for timestep 0.93\n",
            "Generating predictions for timestep 0.935\n",
            "Generating predictions for timestep 0.94\n",
            "Generating predictions for timestep 0.945\n",
            "Generating predictions for timestep 0.95\n",
            "Generating predictions for timestep 0.955\n",
            "Generating predictions for timestep 0.96\n",
            "Generating predictions for timestep 0.965\n",
            "Generating predictions for timestep 0.97\n",
            "Generating predictions for timestep 0.975\n",
            "Generating predictions for timestep 0.98\n",
            "Generating predictions for timestep 0.985\n",
            "Generating predictions for timestep 0.99\n",
            "Generating predictions for timestep 0.995\n",
            "Generating predictions for timestep 1.0\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "print(all_models.keys())\n",
        "all_models_order = [\"xgboost\", \"nn\", \"logistic\", \"lstm\"] # Strict ordering of models\n",
        "# all_models_order = [\"xgboost\", \"nn\", \"logistic\"] # Strict ordering of models\n",
        "\n",
        "def generate_ensemble_matrix(models, all_models_order, data_dict_seq):\n",
        "    \"\"\"Generate predictions from a specific model type on given data\"\"\"\n",
        "    predictions = {}\n",
        "    # predictions:\n",
        "        # timestep:\n",
        "            # \"predictions\": [model_1_predictions, model_2_predictions, ..., model_n_predictions, \n",
        "            # model_1_predictions_seq, model_2_predictions_seq, ..., model_n_predictions_seq],\n",
        "            # \"y_true\": y_true\n",
        "    for timestep in data_dict_seq:\n",
        "        print(f\"Generating predictions for timestep {timestep}\")\n",
        "        # For each entry, take the last array from the \"rows\" list and pair with its label\n",
        "        non_sequential_data_for_timestep = [{\"rows\": entry[\"rows\"][-1], \"label\": entry[\"label\"]} for entry in data_dict_seq[timestep]]\n",
        "        X = np.array([row[\"rows\"] for row in non_sequential_data_for_timestep])\n",
        "        y = np.array([row[\"label\"] for row in non_sequential_data_for_timestep])\n",
        "        X_seq = np.array([row[\"rows\"] for row in data_dict_seq[timestep]])\n",
        "        predictions[timestep] = {\"predictions\": [], \"y_true\": []}\n",
        "        for i in range(len(X)):\n",
        "            predictions[timestep][\"predictions\"].append(np.array([\n",
        "                models[model][timestep].predict_proba(np.expand_dims(X_seq[i], axis=0))[:, 1].item() if model == \"lstm\" else models[model][timestep].predict_proba(np.expand_dims(X[i], axis=0))[:, 1].item()\n",
        "                for model in all_models_order\n",
        "            ]))\n",
        "            predictions[timestep][\"y_true\"].append(y[i])\n",
        "        predictions[timestep][\"y_true\"] = np.array(predictions[timestep][\"y_true\"])\n",
        "        predictions[timestep][\"predictions\"] = np.array(predictions[timestep][\"predictions\"])\n",
        "    return predictions\n",
        "\n",
        "ensemble_matrices = generate_ensemble_matrix(all_models, all_models_order, ensemble_data_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LogisticRegressionMetaModel:\n",
        "    def __init__(self):\n",
        "        self.meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.meta_model.fit(X, y)\n",
        "        if X_val is not None and y_val is not None:\n",
        "            self.meta_model.fit(X_val, y_val)\n",
        "    def predict(self, X):\n",
        "        return 1 if self.meta_model.predict_proba(X)[:, 1] > 0.5 else 0\n",
        "    def predict_proba(self, X):\n",
        "        return self.meta_model.predict_proba(X)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class SimpleMetaNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleMetaNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class NeuralNetworkMetaModel(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, input_dim=None, lr=0.01, epochs=30, batch_size=32, device=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        if self.input_dim is None:\n",
        "            self.input_dim = X.shape[1]\n",
        "        self.model = SimpleMetaNN(self.input_dim).to(self.device)\n",
        "        criterion = nn.BCELoss()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(self.device)\n",
        "        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        self.model.train()\n",
        "        for epoch in range(self.epochs):\n",
        "            for xb, yb in loader:\n",
        "                optimizer.zero_grad()\n",
        "                preds = self.model(xb)\n",
        "                loss = criterion(preds, yb)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).cpu().numpy().flatten()\n",
        "        return (probs > 0.5).astype(int)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).cpu().numpy().flatten()\n",
        "        return np.column_stack([1 - probs, probs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training meta-model for timestep 0.0\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2252, 'nn': 0.7748, 'logistic': 0.0, 'lstm': 0.0} (score: 0.216800)\n",
            "Training meta-model for timestep 0.005\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0798, 'nn': 0.899, 'logistic': 0.0213, 'lstm': 0.0} (score: 0.226594)\n",
            "Training meta-model for timestep 0.01\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1907, 'nn': 0.8093, 'logistic': 0.0, 'lstm': 0.0} (score: 0.214287)\n",
            "Training meta-model for timestep 0.015\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.42, 'nn': 0.58, 'logistic': 0.0, 'lstm': 0.0} (score: 0.215387)\n",
            "Training meta-model for timestep 0.02\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.213600)\n",
            "Training meta-model for timestep 0.025\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1773, 'nn': 0.8227, 'logistic': 0.0, 'lstm': 0.0} (score: 0.215629)\n",
            "Training meta-model for timestep 0.03\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.6402, 'logistic': 0.0, 'lstm': 0.3598} (score: 0.210007)\n",
            "Training meta-model for timestep 0.035\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2583, 'nn': 0.7417, 'logistic': 0.0, 'lstm': 0.0} (score: 0.215512)\n",
            "Training meta-model for timestep 0.04\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0186, 'nn': 0.9814, 'logistic': 0.0, 'lstm': 0.0} (score: 0.216713)\n",
            "Training meta-model for timestep 0.045\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.220211)\n",
            "Training meta-model for timestep 0.05\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0684, 'nn': 0.9316, 'logistic': 0.0, 'lstm': 0.0} (score: 0.217233)\n",
            "Training meta-model for timestep 0.055\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3611, 'nn': 0.6389, 'logistic': 0.0, 'lstm': 0.0} (score: 0.209207)\n",
            "Training meta-model for timestep 0.06\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4569, 'nn': 0.5431, 'logistic': 0.0, 'lstm': 0.0} (score: 0.214645)\n",
            "Training meta-model for timestep 0.065\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2721, 'nn': 0.7279, 'logistic': 0.0, 'lstm': 0.0} (score: 0.215532)\n",
            "Training meta-model for timestep 0.07\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.212789)\n",
            "Training meta-model for timestep 0.075\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5497, 'nn': 0.4503, 'logistic': 0.0, 'lstm': 0.0} (score: 0.212308)\n",
            "Training meta-model for timestep 0.08\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.210576)\n",
            "Training meta-model for timestep 0.085\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.189604)\n",
            "Training meta-model for timestep 0.09\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.201351)\n",
            "Training meta-model for timestep 0.095\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.195665)\n",
            "Training meta-model for timestep 0.1\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.5625, 'logistic': 0.0, 'lstm': 0.4375} (score: 0.200175)\n",
            "Training meta-model for timestep 0.105\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0638, 'nn': 0.9362, 'logistic': 0.0, 'lstm': 0.0} (score: 0.194057)\n",
            "Training meta-model for timestep 0.11\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.204546)\n",
            "Training meta-model for timestep 0.115\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.193042)\n",
            "Training meta-model for timestep 0.12\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.014, 'nn': 0.986, 'logistic': 0.0, 'lstm': 0.0} (score: 0.190896)\n",
            "Training meta-model for timestep 0.125\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.198992)\n",
            "Training meta-model for timestep 0.13\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1541, 'nn': 0.4613, 'logistic': 0.0, 'lstm': 0.3846} (score: 0.196227)\n",
            "Training meta-model for timestep 0.135\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.4807, 'logistic': 0.0, 'lstm': 0.5193} (score: 0.197298)\n",
            "Training meta-model for timestep 0.14\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.009, 'nn': 0.991, 'logistic': 0.0, 'lstm': 0.0} (score: 0.201303)\n",
            "Training meta-model for timestep 0.145\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0321, 'nn': 0.9679, 'logistic': 0.0, 'lstm': 0.0} (score: 0.205661)\n",
            "Training meta-model for timestep 0.15\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0451, 'nn': 0.9549, 'logistic': 0.0, 'lstm': 0.0} (score: 0.191572)\n",
            "Training meta-model for timestep 0.155\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1015, 'nn': 0.748, 'logistic': 0.0, 'lstm': 0.1505} (score: 0.184032)\n",
            "Training meta-model for timestep 0.16\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.184029)\n",
            "Training meta-model for timestep 0.165\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.199475)\n",
            "Training meta-model for timestep 0.17\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.185458)\n",
            "Training meta-model for timestep 0.175\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.9143, 'logistic': 0.0, 'lstm': 0.0857} (score: 0.202478)\n",
            "Training meta-model for timestep 0.18\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8248, 'logistic': 0.0, 'lstm': 0.1752} (score: 0.192963)\n",
            "Training meta-model for timestep 0.185\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.195129)\n",
            "Training meta-model for timestep 0.19\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0849, 'nn': 0.7252, 'logistic': 0.0, 'lstm': 0.19} (score: 0.199204)\n",
            "Training meta-model for timestep 0.195\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1405, 'nn': 0.8595, 'logistic': 0.0, 'lstm': 0.0} (score: 0.184368)\n",
            "Training meta-model for timestep 0.2\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0015, 'nn': 0.9985, 'logistic': 0.0, 'lstm': 0.0} (score: 0.186408)\n",
            "Training meta-model for timestep 0.205\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.5234, 'logistic': 0.0, 'lstm': 0.4766} (score: 0.193350)\n",
            "Training meta-model for timestep 0.21\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1548, 'nn': 0.4505, 'logistic': 0.0, 'lstm': 0.3947} (score: 0.194573)\n",
            "Training meta-model for timestep 0.215\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3369, 'nn': 0.359, 'logistic': 0.0, 'lstm': 0.304} (score: 0.198210)\n",
            "Training meta-model for timestep 0.22\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1095, 'nn': 0.1327, 'logistic': 0.0, 'lstm': 0.7579} (score: 0.186287)\n",
            "Training meta-model for timestep 0.225\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1542, 'nn': 0.8458, 'logistic': 0.0, 'lstm': 0.0} (score: 0.182548)\n",
            "Training meta-model for timestep 0.23\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.201382)\n",
            "Training meta-model for timestep 0.235\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2133, 'nn': 0.0791, 'logistic': 0.0, 'lstm': 0.7076} (score: 0.188660)\n",
            "Training meta-model for timestep 0.24\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5718, 'nn': 0.4282, 'logistic': 0.0, 'lstm': 0.0} (score: 0.192964)\n",
            "Training meta-model for timestep 0.245\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2138, 'nn': 0.7862, 'logistic': 0.0, 'lstm': 0.0} (score: 0.198478)\n",
            "Training meta-model for timestep 0.25\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.148765)\n",
            "Training meta-model for timestep 0.255\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8655, 'logistic': 0.0, 'lstm': 0.1345} (score: 0.169332)\n",
            "Training meta-model for timestep 0.26\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.179227)\n",
            "Training meta-model for timestep 0.265\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.7819, 'logistic': 0.0, 'lstm': 0.2181} (score: 0.184143)\n",
            "Training meta-model for timestep 0.27\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.158412)\n",
            "Training meta-model for timestep 0.275\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.6191, 'logistic': 0.0, 'lstm': 0.3809} (score: 0.181177)\n",
            "Training meta-model for timestep 0.28\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0361, 'nn': 0.4733, 'logistic': 0.0, 'lstm': 0.4906} (score: 0.189028)\n",
            "Training meta-model for timestep 0.285\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1563, 'nn': 0.8437, 'logistic': 0.0, 'lstm': 0.0} (score: 0.179428)\n",
            "Training meta-model for timestep 0.29\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.186050)\n",
            "Training meta-model for timestep 0.295\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.169495)\n",
            "Training meta-model for timestep 0.3\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0249, 'nn': 0.8817, 'logistic': 0.0, 'lstm': 0.0934} (score: 0.184170)\n",
            "Training meta-model for timestep 0.305\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0493, 'nn': 0.7349, 'logistic': 0.0, 'lstm': 0.2158} (score: 0.191180)\n",
            "Training meta-model for timestep 0.31\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.170308)\n",
            "Training meta-model for timestep 0.315\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.166879)\n",
            "Training meta-model for timestep 0.32\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2999, 'nn': 0.3367, 'logistic': 0.0, 'lstm': 0.3633} (score: 0.192983)\n",
            "Training meta-model for timestep 0.325\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.185753)\n",
            "Training meta-model for timestep 0.33\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.179857)\n",
            "Training meta-model for timestep 0.335\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3104, 'nn': 0.3538, 'logistic': 0.0, 'lstm': 0.3358} (score: 0.178813)\n",
            "Training meta-model for timestep 0.34\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.165695)\n",
            "Training meta-model for timestep 0.345\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.175755)\n",
            "Training meta-model for timestep 0.35\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.164758)\n",
            "Training meta-model for timestep 0.355\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.9406, 'logistic': 0.0, 'lstm': 0.0594} (score: 0.182912)\n",
            "Training meta-model for timestep 0.36\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0961, 'nn': 0.9039, 'logistic': 0.0, 'lstm': 0.0} (score: 0.176165)\n",
            "Training meta-model for timestep 0.365\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.171465)\n",
            "Training meta-model for timestep 0.37\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0309, 'nn': 0.9691, 'logistic': 0.0, 'lstm': 0.0} (score: 0.189313)\n",
            "Training meta-model for timestep 0.375\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3945, 'nn': 0.0, 'logistic': 0.0, 'lstm': 0.6055} (score: 0.178338)\n",
            "Training meta-model for timestep 0.38\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.175586)\n",
            "Training meta-model for timestep 0.385\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.151006)\n",
            "Training meta-model for timestep 0.39\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.162903)\n",
            "Training meta-model for timestep 0.395\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.175666)\n",
            "Training meta-model for timestep 0.4\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.169508)\n",
            "Training meta-model for timestep 0.405\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.158852)\n",
            "Training meta-model for timestep 0.41\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.5144, 'logistic': 0.0, 'lstm': 0.4856} (score: 0.191113)\n",
            "Training meta-model for timestep 0.415\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8705, 'logistic': 0.0, 'lstm': 0.1295} (score: 0.179152)\n",
            "Training meta-model for timestep 0.42\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0191, 'nn': 0.9809, 'logistic': 0.0, 'lstm': 0.0} (score: 0.183818)\n",
            "Training meta-model for timestep 0.425\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.7594, 'logistic': 0.0, 'lstm': 0.2406} (score: 0.170779)\n",
            "Training meta-model for timestep 0.43\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.332, 'nn': 0.0539, 'logistic': 0.0, 'lstm': 0.6141} (score: 0.175540)\n",
            "Training meta-model for timestep 0.435\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1456, 'nn': 0.4891, 'logistic': 0.0, 'lstm': 0.3653} (score: 0.179900)\n",
            "Training meta-model for timestep 0.44\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.025, 'nn': 0.975, 'logistic': 0.0, 'lstm': 0.0} (score: 0.167091)\n",
            "Training meta-model for timestep 0.445\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.167886)\n",
            "Training meta-model for timestep 0.45\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8458, 'logistic': 0.0, 'lstm': 0.1542} (score: 0.170081)\n",
            "Training meta-model for timestep 0.455\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.167222)\n",
            "Training meta-model for timestep 0.46\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.152399)\n",
            "Training meta-model for timestep 0.465\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.183, 'nn': 0.817, 'logistic': 0.0, 'lstm': 0.0} (score: 0.165272)\n",
            "Training meta-model for timestep 0.47\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.141272)\n",
            "Training meta-model for timestep 0.475\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.153277)\n",
            "Training meta-model for timestep 0.48\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2575, 'nn': 0.2851, 'logistic': 0.0, 'lstm': 0.4574} (score: 0.158555)\n",
            "Training meta-model for timestep 0.485\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.146696)\n",
            "Training meta-model for timestep 0.49\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3101, 'nn': 0.6899, 'logistic': 0.0, 'lstm': 0.0} (score: 0.152033)\n",
            "Training meta-model for timestep 0.495\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0497, 'nn': 0.9503, 'logistic': 0.0, 'lstm': 0.0} (score: 0.149506)\n",
            "Training meta-model for timestep 0.5\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1622, 'nn': 0.8378, 'logistic': 0.0, 'lstm': 0.0} (score: 0.151780)\n",
            "Training meta-model for timestep 0.505\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.9998, 'logistic': 0.0, 'lstm': 0.0002} (score: 0.137626)\n",
            "Training meta-model for timestep 0.51\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.149466)\n",
            "Training meta-model for timestep 0.515\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4394, 'nn': 0.1244, 'logistic': 0.0, 'lstm': 0.4362} (score: 0.164757)\n",
            "Training meta-model for timestep 0.52\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0991, 'nn': 0.9009, 'logistic': 0.0, 'lstm': 0.0} (score: 0.167593)\n",
            "Training meta-model for timestep 0.525\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3318, 'nn': 0.6682, 'logistic': 0.0, 'lstm': 0.0} (score: 0.156039)\n",
            "Training meta-model for timestep 0.53\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.158406)\n",
            "Training meta-model for timestep 0.535\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.154179)\n",
            "Training meta-model for timestep 0.54\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0106, 'nn': 0.9894, 'logistic': 0.0, 'lstm': 0.0} (score: 0.147468)\n",
            "Training meta-model for timestep 0.545\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0426, 'nn': 0.9574, 'logistic': 0.0, 'lstm': 0.0} (score: 0.169470)\n",
            "Training meta-model for timestep 0.55\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1277, 'nn': 0.4414, 'logistic': 0.0, 'lstm': 0.4309} (score: 0.163448)\n",
            "Training meta-model for timestep 0.555\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2608, 'nn': 0.7392, 'logistic': 0.0, 'lstm': 0.0} (score: 0.157008)\n",
            "Training meta-model for timestep 0.56\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0267, 'nn': 0.4626, 'logistic': 0.0, 'lstm': 0.5107} (score: 0.142963)\n",
            "Training meta-model for timestep 0.565\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1291, 'nn': 0.8709, 'logistic': 0.0, 'lstm': 0.0} (score: 0.147484)\n",
            "Training meta-model for timestep 0.57\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8622, 'logistic': 0.0, 'lstm': 0.1378} (score: 0.152935)\n",
            "Training meta-model for timestep 0.575\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8004, 'logistic': 0.0, 'lstm': 0.1996} (score: 0.164181)\n",
            "Training meta-model for timestep 0.58\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.196, 'nn': 0.6082, 'logistic': 0.0, 'lstm': 0.1958} (score: 0.152434)\n",
            "Training meta-model for timestep 0.585\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.71, 'logistic': 0.0, 'lstm': 0.29} (score: 0.150534)\n",
            "Training meta-model for timestep 0.59\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2073, 'nn': 0.7927, 'logistic': 0.0, 'lstm': 0.0} (score: 0.158784)\n",
            "Training meta-model for timestep 0.595\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1809, 'nn': 0.8191, 'logistic': 0.0, 'lstm': 0.0} (score: 0.144592)\n",
            "Training meta-model for timestep 0.6\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0386, 'nn': 0.2166, 'logistic': 0.0, 'lstm': 0.7448} (score: 0.156160)\n",
            "Training meta-model for timestep 0.605\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0083, 'nn': 0.9917, 'logistic': 0.0, 'lstm': 0.0} (score: 0.149593)\n",
            "Training meta-model for timestep 0.61\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1178, 'nn': 0.0, 'logistic': 0.0, 'lstm': 0.8822} (score: 0.144727)\n",
            "Training meta-model for timestep 0.615\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3117, 'nn': 0.3666, 'logistic': 0.0, 'lstm': 0.3217} (score: 0.152938)\n",
            "Training meta-model for timestep 0.62\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0696, 'nn': 0.5999, 'logistic': 0.0, 'lstm': 0.3305} (score: 0.153130)\n",
            "Training meta-model for timestep 0.625\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0092, 'nn': 0.4272, 'logistic': 0.0, 'lstm': 0.5636} (score: 0.147225)\n",
            "Training meta-model for timestep 0.63\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.125473)\n",
            "Training meta-model for timestep 0.635\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4048, 'nn': 0.5952, 'logistic': 0.0, 'lstm': 0.0} (score: 0.146760)\n",
            "Training meta-model for timestep 0.64\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.133792)\n",
            "Training meta-model for timestep 0.645\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2163, 'nn': 0.7837, 'logistic': 0.0, 'lstm': 0.0} (score: 0.152986)\n",
            "Training meta-model for timestep 0.65\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0206, 'nn': 0.9367, 'logistic': 0.0, 'lstm': 0.0427} (score: 0.139264)\n",
            "Training meta-model for timestep 0.655\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.131180)\n",
            "Training meta-model for timestep 0.66\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0543, 'nn': 0.918, 'logistic': 0.0, 'lstm': 0.0277} (score: 0.152382)\n",
            "Training meta-model for timestep 0.665\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.9123, 'logistic': 0.0, 'lstm': 0.0877} (score: 0.127752)\n",
            "Training meta-model for timestep 0.67\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.7035, 'logistic': 0.0, 'lstm': 0.2965} (score: 0.140273)\n",
            "Training meta-model for timestep 0.675\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.128628)\n",
            "Training meta-model for timestep 0.68\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8246, 'logistic': 0.0, 'lstm': 0.1754} (score: 0.147329)\n",
            "Training meta-model for timestep 0.685\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.130874)\n",
            "Training meta-model for timestep 0.69\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.9875, 'logistic': 0.0, 'lstm': 0.0125} (score: 0.125525)\n",
            "Training meta-model for timestep 0.695\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1284, 'nn': 0.8716, 'logistic': 0.0, 'lstm': 0.0} (score: 0.132965)\n",
            "Training meta-model for timestep 0.7\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.121239)\n",
            "Training meta-model for timestep 0.705\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2431, 'nn': 0.3813, 'logistic': 0.0, 'lstm': 0.3756} (score: 0.138782)\n",
            "Training meta-model for timestep 0.71\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0881, 'nn': 0.4144, 'logistic': 0.0, 'lstm': 0.4975} (score: 0.134535)\n",
            "Training meta-model for timestep 0.715\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4457, 'nn': 0.5543, 'logistic': 0.0, 'lstm': 0.0} (score: 0.148332)\n",
            "Training meta-model for timestep 0.72\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.120715)\n",
            "Training meta-model for timestep 0.725\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.047, 'nn': 0.953, 'logistic': 0.0, 'lstm': 0.0} (score: 0.129204)\n",
            "Training meta-model for timestep 0.73\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.069, 'nn': 0.8405, 'logistic': 0.0, 'lstm': 0.0904} (score: 0.131619)\n",
            "Training meta-model for timestep 0.735\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.6928, 'logistic': 0.0, 'lstm': 0.3072} (score: 0.132790)\n",
            "Training meta-model for timestep 0.74\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0375, 'nn': 0.9625, 'logistic': 0.0, 'lstm': 0.0} (score: 0.123261)\n",
            "Training meta-model for timestep 0.745\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1669, 'nn': 0.5076, 'logistic': 0.0, 'lstm': 0.3255} (score: 0.140230)\n",
            "Training meta-model for timestep 0.75\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.109416)\n",
            "Training meta-model for timestep 0.755\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2473, 'nn': 0.7527, 'logistic': 0.0, 'lstm': 0.0} (score: 0.124224)\n",
            "Training meta-model for timestep 0.76\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4237, 'nn': 0.5004, 'logistic': 0.0, 'lstm': 0.0759} (score: 0.130184)\n",
            "Training meta-model for timestep 0.765\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0434, 'nn': 0.5773, 'logistic': 0.0, 'lstm': 0.3794} (score: 0.115582)\n",
            "Training meta-model for timestep 0.77\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.133401)\n",
            "Training meta-model for timestep 0.775\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0463, 'nn': 0.7292, 'logistic': 0.0, 'lstm': 0.2245} (score: 0.129258)\n",
            "Training meta-model for timestep 0.78\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1051, 'nn': 0.8949, 'logistic': 0.0, 'lstm': 0.0} (score: 0.118390)\n",
            "Training meta-model for timestep 0.785\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8907, 'logistic': 0.0, 'lstm': 0.1093} (score: 0.110779)\n",
            "Training meta-model for timestep 0.79\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0093, 'nn': 0.9234, 'logistic': 0.0, 'lstm': 0.0672} (score: 0.108227)\n",
            "Training meta-model for timestep 0.795\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.126351)\n",
            "Training meta-model for timestep 0.8\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.107342)\n",
            "Training meta-model for timestep 0.805\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.5683, 'logistic': 0.0, 'lstm': 0.4317} (score: 0.116698)\n",
            "Training meta-model for timestep 0.81\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.114016)\n",
            "Training meta-model for timestep 0.815\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.4079, 'logistic': 0.0, 'lstm': 0.5921} (score: 0.114896)\n",
            "Training meta-model for timestep 0.82\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.119265)\n",
            "Training meta-model for timestep 0.825\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.106056)\n",
            "Training meta-model for timestep 0.83\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.106102)\n",
            "Training meta-model for timestep 0.835\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.107049)\n",
            "Training meta-model for timestep 0.84\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.107906)\n",
            "Training meta-model for timestep 0.845\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.9468, 'logistic': 0.0, 'lstm': 0.0532} (score: 0.101639)\n",
            "Training meta-model for timestep 0.85\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.911, 'logistic': 0.0, 'lstm': 0.089} (score: 0.114558)\n",
            "Training meta-model for timestep 0.855\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.102368)\n",
            "Training meta-model for timestep 0.86\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.099241)\n",
            "Training meta-model for timestep 0.865\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.092579)\n",
            "Training meta-model for timestep 0.87\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.104366)\n",
            "Training meta-model for timestep 0.875\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.110494)\n",
            "Training meta-model for timestep 0.88\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.092312)\n",
            "Training meta-model for timestep 0.885\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.104595)\n",
            "Training meta-model for timestep 0.89\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.084885)\n",
            "Training meta-model for timestep 0.895\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.5514, 'logistic': 0.0, 'lstm': 0.4486} (score: 0.077291)\n",
            "Training meta-model for timestep 0.9\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.507, 'logistic': 0.0, 'lstm': 0.493} (score: 0.094455)\n",
            "Training meta-model for timestep 0.905\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.081272)\n",
            "Training meta-model for timestep 0.91\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.7122, 'logistic': 0.0, 'lstm': 0.2878} (score: 0.093446)\n",
            "Training meta-model for timestep 0.915\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.7239, 'logistic': 0.0, 'lstm': 0.2761} (score: 0.074722)\n",
            "Training meta-model for timestep 0.92\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.074329)\n",
            "Training meta-model for timestep 0.925\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.3213, 'logistic': 0.0, 'lstm': 0.6787} (score: 0.089463)\n",
            "Training meta-model for timestep 0.93\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0143, 'nn': 0.9757, 'logistic': 0.0, 'lstm': 0.01} (score: 0.080428)\n",
            "Training meta-model for timestep 0.935\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.076603)\n",
            "Training meta-model for timestep 0.94\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.082386)\n",
            "Training meta-model for timestep 0.945\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8809, 'logistic': 0.0, 'lstm': 0.1191} (score: 0.076736)\n",
            "Training meta-model for timestep 0.95\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8482, 'logistic': 0.0, 'lstm': 0.1518} (score: 0.084408)\n",
            "Training meta-model for timestep 0.955\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.893, 'logistic': 0.0, 'lstm': 0.107} (score: 0.081132)\n",
            "Training meta-model for timestep 0.96\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.077643)\n",
            "Training meta-model for timestep 0.965\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.080978)\n",
            "Training meta-model for timestep 0.97\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.057472)\n",
            "Training meta-model for timestep 0.975\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.057066)\n",
            "Training meta-model for timestep 0.98\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.8301, 'logistic': 0.0, 'lstm': 0.1699} (score: 0.062229)\n",
            "Training meta-model for timestep 0.985\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.049887)\n",
            "Training meta-model for timestep 0.99\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.045246)\n",
            "Training meta-model for timestep 0.995\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 1.0, 'logistic': 0.0, 'lstm': 0.0} (score: 0.045924)\n",
            "Training meta-model for timestep 1.0\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.7173, 'logistic': 0.0, 'lstm': 0.2827} (score: 0.032591)\n"
          ]
        }
      ],
      "source": [
        "def setup_meta_models(ensemble_matrices, all_models, all_models_order, strategy='meta_model', meta_model=None):\n",
        "    models = {}\n",
        "    for timestep in ensemble_matrices:\n",
        "        print(f\"Training meta-model for timestep {timestep}\")\n",
        "        ensemble_matrix = ensemble_matrices[timestep]\n",
        "        x_train = ensemble_matrix[\"predictions\"]\n",
        "        y_train = ensemble_matrix[\"y_true\"]\n",
        "        all_models_for_timestep = {model_name: all_models[model_name][timestep] for model_name in all_models_order}\n",
        "        models[timestep] = EnsemblePredictor(all_models_for_timestep, all_models_order, features, strategy, meta_model)\n",
        "        models[timestep].train_ensemble(x_train, y_train, objective='brier')\n",
        "    return models\n",
        "\n",
        "ensemble_models = setup_meta_models(ensemble_matrices, all_models, all_models_order, strategy='weighted_average', meta_model=LogisticRegressionMetaModel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestep 0.00%: Accuracy = 0.6775, Brier Score = 0.2275\n",
            "Timestep 0.50%: Accuracy = 0.6900, Brier Score = 0.2156\n",
            "Timestep 1.00%: Accuracy = 0.7153, Brier Score = 0.2130\n",
            "Timestep 1.50%: Accuracy = 0.6993, Brier Score = 0.2146\n",
            "Timestep 2.00%: Accuracy = 0.6886, Brier Score = 0.2233\n",
            "Timestep 2.50%: Accuracy = 0.6825, Brier Score = 0.2097\n",
            "Timestep 3.00%: Accuracy = 0.6885, Brier Score = 0.2099\n",
            "Timestep 3.50%: Accuracy = 0.6824, Brier Score = 0.2197\n",
            "Timestep 4.00%: Accuracy = 0.6399, Brier Score = 0.2225\n",
            "Timestep 4.50%: Accuracy = 0.6720, Brier Score = 0.2138\n",
            "Timestep 5.00%: Accuracy = 0.7522, Brier Score = 0.2018\n",
            "Timestep 5.50%: Accuracy = 0.6703, Brier Score = 0.2198\n",
            "Timestep 6.00%: Accuracy = 0.7147, Brier Score = 0.2167\n",
            "Timestep 6.50%: Accuracy = 0.6617, Brier Score = 0.2253\n",
            "Timestep 7.00%: Accuracy = 0.6183, Brier Score = 0.2294\n",
            "Timestep 7.50%: Accuracy = 0.7105, Brier Score = 0.2143\n",
            "Timestep 8.00%: Accuracy = 0.7193, Brier Score = 0.1988\n",
            "Timestep 8.50%: Accuracy = 0.6976, Brier Score = 0.2075\n",
            "Timestep 9.00%: Accuracy = 0.6546, Brier Score = 0.2267\n",
            "Timestep 9.50%: Accuracy = 0.6415, Brier Score = 0.2167\n",
            "Timestep 10.00%: Accuracy = 0.6516, Brier Score = 0.2198\n",
            "Timestep 10.50%: Accuracy = 0.6579, Brier Score = 0.2106\n",
            "Timestep 11.00%: Accuracy = 0.6590, Brier Score = 0.2124\n",
            "Timestep 11.50%: Accuracy = 0.6657, Brier Score = 0.2126\n",
            "Timestep 12.00%: Accuracy = 0.6903, Brier Score = 0.2115\n",
            "Timestep 12.50%: Accuracy = 0.6467, Brier Score = 0.2208\n",
            "Timestep 13.00%: Accuracy = 0.6761, Brier Score = 0.2127\n",
            "Timestep 13.50%: Accuracy = 0.6497, Brier Score = 0.2190\n",
            "Timestep 14.00%: Accuracy = 0.6903, Brier Score = 0.1957\n",
            "Timestep 14.50%: Accuracy = 0.6847, Brier Score = 0.2042\n",
            "Timestep 15.00%: Accuracy = 0.6204, Brier Score = 0.2188\n",
            "Timestep 15.50%: Accuracy = 0.6698, Brier Score = 0.2026\n",
            "Timestep 16.00%: Accuracy = 0.6805, Brier Score = 0.2122\n",
            "Timestep 16.50%: Accuracy = 0.6743, Brier Score = 0.2153\n",
            "Timestep 17.00%: Accuracy = 0.6429, Brier Score = 0.2127\n",
            "Timestep 17.50%: Accuracy = 0.6092, Brier Score = 0.2267\n",
            "Timestep 18.00%: Accuracy = 0.6528, Brier Score = 0.2055\n",
            "Timestep 18.50%: Accuracy = 0.6518, Brier Score = 0.2159\n",
            "Timestep 19.00%: Accuracy = 0.6431, Brier Score = 0.2172\n",
            "Timestep 19.50%: Accuracy = 0.6627, Brier Score = 0.2023\n",
            "Timestep 20.00%: Accuracy = 0.6685, Brier Score = 0.2040\n",
            "Timestep 20.50%: Accuracy = 0.6531, Brier Score = 0.2084\n",
            "Timestep 21.00%: Accuracy = 0.6773, Brier Score = 0.1944\n",
            "Timestep 21.50%: Accuracy = 0.6391, Brier Score = 0.2116\n",
            "Timestep 22.00%: Accuracy = 0.6707, Brier Score = 0.2002\n",
            "Timestep 22.50%: Accuracy = 0.6544, Brier Score = 0.2140\n",
            "Timestep 23.00%: Accuracy = 0.6836, Brier Score = 0.2014\n",
            "Timestep 23.50%: Accuracy = 0.6452, Brier Score = 0.2080\n",
            "Timestep 24.00%: Accuracy = 0.6145, Brier Score = 0.2204\n",
            "Timestep 24.50%: Accuracy = 0.6266, Brier Score = 0.2136\n",
            "Timestep 25.00%: Accuracy = 0.6277, Brier Score = 0.2308\n",
            "Timestep 25.50%: Accuracy = 0.6126, Brier Score = 0.2304\n",
            "Timestep 26.00%: Accuracy = 0.6471, Brier Score = 0.2125\n",
            "Timestep 26.50%: Accuracy = 0.6584, Brier Score = 0.2082\n",
            "Timestep 27.00%: Accuracy = 0.6520, Brier Score = 0.2191\n",
            "Timestep 27.50%: Accuracy = 0.6573, Brier Score = 0.2017\n",
            "Timestep 28.00%: Accuracy = 0.6625, Brier Score = 0.1985\n",
            "Timestep 28.50%: Accuracy = 0.6499, Brier Score = 0.2133\n",
            "Timestep 29.00%: Accuracy = 0.7059, Brier Score = 0.1912\n",
            "Timestep 29.50%: Accuracy = 0.7052, Brier Score = 0.1901\n",
            "Timestep 30.00%: Accuracy = 0.6732, Brier Score = 0.1953\n",
            "Timestep 30.50%: Accuracy = 0.6803, Brier Score = 0.1957\n",
            "Timestep 31.00%: Accuracy = 0.6833, Brier Score = 0.1980\n",
            "Timestep 31.50%: Accuracy = 0.6978, Brier Score = 0.2040\n",
            "Timestep 32.00%: Accuracy = 0.6704, Brier Score = 0.1917\n",
            "Timestep 32.50%: Accuracy = 0.6435, Brier Score = 0.2060\n",
            "Timestep 33.00%: Accuracy = 0.6611, Brier Score = 0.1979\n",
            "Timestep 33.50%: Accuracy = 0.6531, Brier Score = 0.1978\n",
            "Timestep 34.00%: Accuracy = 0.6784, Brier Score = 0.1963\n",
            "Timestep 34.50%: Accuracy = 0.7182, Brier Score = 0.1794\n",
            "Timestep 35.00%: Accuracy = 0.7049, Brier Score = 0.1881\n",
            "Timestep 35.50%: Accuracy = 0.7155, Brier Score = 0.1878\n",
            "Timestep 36.00%: Accuracy = 0.7202, Brier Score = 0.1765\n",
            "Timestep 36.50%: Accuracy = 0.7109, Brier Score = 0.1877\n",
            "Timestep 37.00%: Accuracy = 0.7164, Brier Score = 0.1770\n",
            "Timestep 37.50%: Accuracy = 0.7199, Brier Score = 0.1835\n",
            "Timestep 38.00%: Accuracy = 0.7360, Brier Score = 0.1665\n",
            "Timestep 38.50%: Accuracy = 0.6916, Brier Score = 0.1940\n",
            "Timestep 39.00%: Accuracy = 0.7251, Brier Score = 0.1725\n",
            "Timestep 39.50%: Accuracy = 0.7396, Brier Score = 0.1709\n",
            "Timestep 40.00%: Accuracy = 0.7222, Brier Score = 0.1764\n",
            "Timestep 40.50%: Accuracy = 0.7528, Brier Score = 0.1639\n",
            "Timestep 41.00%: Accuracy = 0.7514, Brier Score = 0.1761\n",
            "Timestep 41.50%: Accuracy = 0.7692, Brier Score = 0.1670\n",
            "Timestep 42.00%: Accuracy = 0.7619, Brier Score = 0.1848\n",
            "Timestep 42.50%: Accuracy = 0.7882, Brier Score = 0.1626\n",
            "Timestep 43.00%: Accuracy = 0.7781, Brier Score = 0.1681\n",
            "Timestep 43.50%: Accuracy = 0.7742, Brier Score = 0.1572\n",
            "Timestep 44.00%: Accuracy = 0.7683, Brier Score = 0.1663\n",
            "Timestep 44.50%: Accuracy = 0.7557, Brier Score = 0.1684\n",
            "Timestep 45.00%: Accuracy = 0.7799, Brier Score = 0.1569\n",
            "Timestep 45.50%: Accuracy = 0.7600, Brier Score = 0.1703\n",
            "Timestep 46.00%: Accuracy = 0.7598, Brier Score = 0.1702\n",
            "Timestep 46.50%: Accuracy = 0.8071, Brier Score = 0.1401\n",
            "Timestep 47.00%: Accuracy = 0.7587, Brier Score = 0.1670\n",
            "Timestep 47.50%: Accuracy = 0.7617, Brier Score = 0.1632\n",
            "Timestep 48.00%: Accuracy = 0.7856, Brier Score = 0.1517\n",
            "Timestep 48.50%: Accuracy = 0.7838, Brier Score = 0.1569\n",
            "Timestep 49.00%: Accuracy = 0.7956, Brier Score = 0.1473\n",
            "Timestep 49.50%: Accuracy = 0.7687, Brier Score = 0.1615\n",
            "Timestep 50.00%: Accuracy = 0.7602, Brier Score = 0.1641\n",
            "Timestep 50.50%: Accuracy = 0.7607, Brier Score = 0.1639\n",
            "Timestep 51.00%: Accuracy = 0.7527, Brier Score = 0.1621\n",
            "Timestep 51.50%: Accuracy = 0.7508, Brier Score = 0.1582\n",
            "Timestep 52.00%: Accuracy = 0.7859, Brier Score = 0.1399\n",
            "Timestep 52.50%: Accuracy = 0.7676, Brier Score = 0.1592\n",
            "Timestep 53.00%: Accuracy = 0.7493, Brier Score = 0.1612\n",
            "Timestep 53.50%: Accuracy = 0.7662, Brier Score = 0.1617\n",
            "Timestep 54.00%: Accuracy = 0.7708, Brier Score = 0.1557\n",
            "Timestep 54.50%: Accuracy = 0.7697, Brier Score = 0.1482\n",
            "Timestep 55.00%: Accuracy = 0.7754, Brier Score = 0.1505\n",
            "Timestep 55.50%: Accuracy = 0.7273, Brier Score = 0.1632\n",
            "Timestep 56.00%: Accuracy = 0.7574, Brier Score = 0.1597\n",
            "Timestep 56.50%: Accuracy = 0.7538, Brier Score = 0.1495\n",
            "Timestep 57.00%: Accuracy = 0.7500, Brier Score = 0.1619\n",
            "Timestep 57.50%: Accuracy = 0.7820, Brier Score = 0.1418\n",
            "Timestep 58.00%: Accuracy = 0.7972, Brier Score = 0.1365\n",
            "Timestep 58.50%: Accuracy = 0.7983, Brier Score = 0.1436\n",
            "Timestep 59.00%: Accuracy = 0.7895, Brier Score = 0.1472\n",
            "Timestep 59.50%: Accuracy = 0.8047, Brier Score = 0.1446\n",
            "Timestep 60.00%: Accuracy = 0.8121, Brier Score = 0.1329\n",
            "Timestep 60.50%: Accuracy = 0.7514, Brier Score = 0.1532\n",
            "Timestep 61.00%: Accuracy = 0.7874, Brier Score = 0.1464\n",
            "Timestep 61.50%: Accuracy = 0.7915, Brier Score = 0.1348\n",
            "Timestep 62.00%: Accuracy = 0.7661, Brier Score = 0.1461\n",
            "Timestep 62.50%: Accuracy = 0.8011, Brier Score = 0.1335\n",
            "Timestep 63.00%: Accuracy = 0.7893, Brier Score = 0.1362\n",
            "Timestep 63.50%: Accuracy = 0.8237, Brier Score = 0.1334\n",
            "Timestep 64.00%: Accuracy = 0.7970, Brier Score = 0.1385\n",
            "Timestep 64.50%: Accuracy = 0.8017, Brier Score = 0.1411\n",
            "Timestep 65.00%: Accuracy = 0.7867, Brier Score = 0.1412\n",
            "Timestep 65.50%: Accuracy = 0.8201, Brier Score = 0.1253\n",
            "Timestep 66.00%: Accuracy = 0.8012, Brier Score = 0.1332\n",
            "Timestep 66.50%: Accuracy = 0.8047, Brier Score = 0.1289\n",
            "Timestep 67.00%: Accuracy = 0.8146, Brier Score = 0.1240\n",
            "Timestep 67.50%: Accuracy = 0.7758, Brier Score = 0.1501\n",
            "Timestep 68.00%: Accuracy = 0.8274, Brier Score = 0.1148\n",
            "Timestep 68.50%: Accuracy = 0.7829, Brier Score = 0.1345\n",
            "Timestep 69.00%: Accuracy = 0.7946, Brier Score = 0.1299\n",
            "Timestep 69.50%: Accuracy = 0.8225, Brier Score = 0.1170\n",
            "Timestep 70.00%: Accuracy = 0.8112, Brier Score = 0.1376\n",
            "Timestep 70.50%: Accuracy = 0.8329, Brier Score = 0.1100\n",
            "Timestep 71.00%: Accuracy = 0.8193, Brier Score = 0.1123\n",
            "Timestep 71.50%: Accuracy = 0.8258, Brier Score = 0.1123\n",
            "Timestep 72.00%: Accuracy = 0.8297, Brier Score = 0.1202\n",
            "Timestep 72.50%: Accuracy = 0.8205, Brier Score = 0.1122\n",
            "Timestep 73.00%: Accuracy = 0.8413, Brier Score = 0.1151\n",
            "Timestep 73.50%: Accuracy = 0.8304, Brier Score = 0.1205\n",
            "Timestep 74.00%: Accuracy = 0.8299, Brier Score = 0.1217\n",
            "Timestep 74.50%: Accuracy = 0.8279, Brier Score = 0.1203\n",
            "Timestep 75.00%: Accuracy = 0.8246, Brier Score = 0.1196\n",
            "Timestep 75.50%: Accuracy = 0.8442, Brier Score = 0.1064\n",
            "Timestep 76.00%: Accuracy = 0.8581, Brier Score = 0.1056\n",
            "Timestep 76.50%: Accuracy = 0.8464, Brier Score = 0.0985\n",
            "Timestep 77.00%: Accuracy = 0.8250, Brier Score = 0.1131\n",
            "Timestep 77.50%: Accuracy = 0.8276, Brier Score = 0.1143\n",
            "Timestep 78.00%: Accuracy = 0.8377, Brier Score = 0.1130\n",
            "Timestep 78.50%: Accuracy = 0.8487, Brier Score = 0.1128\n",
            "Timestep 79.00%: Accuracy = 0.8491, Brier Score = 0.1041\n",
            "Timestep 79.50%: Accuracy = 0.8239, Brier Score = 0.1172\n",
            "Timestep 80.00%: Accuracy = 0.8583, Brier Score = 0.1110\n",
            "Timestep 80.50%: Accuracy = 0.8580, Brier Score = 0.1130\n",
            "Timestep 81.00%: Accuracy = 0.8333, Brier Score = 0.1059\n",
            "Timestep 81.50%: Accuracy = 0.8504, Brier Score = 0.1022\n",
            "Timestep 82.00%: Accuracy = 0.8772, Brier Score = 0.0900\n",
            "Timestep 82.50%: Accuracy = 0.8663, Brier Score = 0.1010\n",
            "Timestep 83.00%: Accuracy = 0.8729, Brier Score = 0.0912\n",
            "Timestep 83.50%: Accuracy = 0.8680, Brier Score = 0.0849\n",
            "Timestep 84.00%: Accuracy = 0.8630, Brier Score = 0.0978\n",
            "Timestep 84.50%: Accuracy = 0.8438, Brier Score = 0.1012\n",
            "Timestep 85.00%: Accuracy = 0.8592, Brier Score = 0.0953\n",
            "Timestep 85.50%: Accuracy = 0.8516, Brier Score = 0.0994\n",
            "Timestep 86.00%: Accuracy = 0.8929, Brier Score = 0.0759\n",
            "Timestep 86.50%: Accuracy = 0.8725, Brier Score = 0.0837\n",
            "Timestep 87.00%: Accuracy = 0.8839, Brier Score = 0.0893\n",
            "Timestep 87.50%: Accuracy = 0.8791, Brier Score = 0.0877\n",
            "Timestep 88.00%: Accuracy = 0.8860, Brier Score = 0.0822\n",
            "Timestep 88.50%: Accuracy = 0.8989, Brier Score = 0.0815\n",
            "Timestep 89.00%: Accuracy = 0.8805, Brier Score = 0.0846\n",
            "Timestep 89.50%: Accuracy = 0.8919, Brier Score = 0.0799\n",
            "Timestep 90.00%: Accuracy = 0.8736, Brier Score = 0.0893\n",
            "Timestep 90.50%: Accuracy = 0.8480, Brier Score = 0.1017\n",
            "Timestep 91.00%: Accuracy = 0.8701, Brier Score = 0.0883\n",
            "Timestep 91.50%: Accuracy = 0.9096, Brier Score = 0.0744\n",
            "Timestep 92.00%: Accuracy = 0.8730, Brier Score = 0.0911\n",
            "Timestep 92.50%: Accuracy = 0.8792, Brier Score = 0.0814\n",
            "Timestep 93.00%: Accuracy = 0.8338, Brier Score = 0.1070\n",
            "Timestep 93.50%: Accuracy = 0.8792, Brier Score = 0.0897\n",
            "Timestep 94.00%: Accuracy = 0.8826, Brier Score = 0.0836\n",
            "Timestep 94.50%: Accuracy = 0.8874, Brier Score = 0.0823\n",
            "Timestep 95.00%: Accuracy = 0.8696, Brier Score = 0.0841\n",
            "Timestep 95.50%: Accuracy = 0.8720, Brier Score = 0.0926\n",
            "Timestep 96.00%: Accuracy = 0.8547, Brier Score = 0.0950\n",
            "Timestep 96.50%: Accuracy = 0.9076, Brier Score = 0.0721\n",
            "Timestep 97.00%: Accuracy = 0.8661, Brier Score = 0.0937\n",
            "Timestep 97.50%: Accuracy = 0.8696, Brier Score = 0.0961\n",
            "Timestep 98.00%: Accuracy = 0.8900, Brier Score = 0.0839\n",
            "Timestep 98.50%: Accuracy = 0.8982, Brier Score = 0.0721\n",
            "Timestep 99.00%: Accuracy = 0.8804, Brier Score = 0.0756\n",
            "Timestep 99.50%: Accuracy = 0.8697, Brier Score = 0.0938\n",
            "Timestep 100.00%: Accuracy = 0.9085, Brier Score = 0.0659\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary Statistics:\n",
            "Average Accuracy: 0.7616  0.0827\n",
            "Average Brier Score: 0.1568  0.0477\n",
            "Best Accuracy: 0.9096 at timestep 91.50%\n",
            "Best Brier Score: 0.0659 at timestep 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Test accuracy and Brier score of model for each timestep on test data and plot\n",
        "accuracies = []\n",
        "brier_scores = []\n",
        "timesteps = []\n",
        "def brier_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "for timestep, i in zip(ensemble_models, test_data.keys()):\n",
        "    model = ensemble_models[timestep]\n",
        "    # Convert test data to array\n",
        "    y_test = np.array([row[\"label\"] for row in test_data_seq[i]])\n",
        "    X_test = np.array([row[\"rows\"] for row in test_data_seq[i]])\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    \n",
        "    # Calculate Brier score\n",
        "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probability predictions\n",
        "    brier_score = brier_loss(y_test, y_test_pred_proba)\n",
        "    \n",
        "    print(f\"Timestep {timestep:.2%}: Accuracy = {accuracy:.4f}, Brier Score = {brier_score:.4f}\")\n",
        "    accuracies.append(accuracy)\n",
        "    brier_scores.append(brier_score)\n",
        "    timesteps.append(timestep)\n",
        "\n",
        "# Create subplots for both metrics\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot accuracy\n",
        "ax1.plot(timesteps, accuracies, 'b-', linewidth=2, marker='o', markersize=3)\n",
        "ax1.set_xlabel(\"Timestep\")\n",
        "ax1.set_ylabel(\"Accuracy\")\n",
        "ax1.set_title(\"Test Accuracy vs Timestep\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([min(accuracies) * 0.95, max(accuracies) * 1.05])\n",
        "\n",
        "# Plot Brier score\n",
        "ax2.plot(timesteps, brier_scores, 'r-', linewidth=2, marker='s', markersize=3)\n",
        "ax2.set_xlabel(\"Timestep\")\n",
        "ax2.set_ylabel(\"Brier Score\")\n",
        "ax2.set_title(\"Test Brier Score vs Timestep\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim([min(brier_scores) * 0.95, max(brier_scores) * 1.05])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\nSummary Statistics:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}  {np.std(accuracies):.4f}\")\n",
        "print(f\"Average Brier Score: {np.mean(brier_scores):.4f}  {np.std(brier_scores):.4f}\")\n",
        "print(f\"Best Accuracy: {max(accuracies):.4f} at timestep {timesteps[np.argmax(accuracies)]:.2%}\")\n",
        "print(f\"Best Brier Score: {min(brier_scores):.4f} at timestep {timesteps[np.argmin(brier_scores)]:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.90517624, 0.09482376]])"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ensemble_models[0.975]\n",
        "features = [\"relative_strength\", \"score_difference\", \"home_has_possession\", \"end.down\", \"end.distance\", \"end.yardsToEndzone\",  \"home_timeouts_left\", \"away_timeouts_left\"]\n",
        "data_point = [[0.5, -4, 1, 1, 1, 1, 1, 1], [0.5, -4, 1, 1, 1, 1, 1, 1], [0.5, -4, 1, 1, 1, 1, 1, 1], [0.5, -4, 1, 1, 1, 1, 1, 1], [0.5, -4, 1, 1, 1, 1, 1, 1]]\n",
        "model.predict_proba(np.array([data_point]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name:  xgboost\n",
            "(2, 5, 11)\n",
            "(2, 11)\n",
            "[[0.         1.        ]\n",
            " [0.19230769 0.80769231]]\n",
            "Model name:  nn\n",
            "(2, 5, 11)\n",
            "(2, 11)\n",
            "[[1. 0.]\n",
            " [1. 0.]]\n",
            "Model name:  logistic\n",
            "(2, 5, 11)\n",
            "(2, 11)\n",
            "[[0. 1.]\n",
            " [0. 1.]]\n",
            "Model name:  lstm\n",
            "(2, 5, 11)\n",
            "[[0.79934996 0.20065005]\n",
            " [0.7205218  0.27947822]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.48275698, 0.51724302],\n",
              "       [0.44681822, 0.55318178]])"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ensemble_models[0]\n",
        "model.predict_proba(np.arange(110).reshape(2, 5, 11))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2024\n",
            "Processed file:  game_401671629.csv\n",
            "Processed file:  game_401671601.csv\n",
            "Processed file:  game_401671826.csv\n",
            "Processed file:  game_401671832.csv\n",
            "Processed file:  game_401671749.csv\n",
            "Processed file:  game_401671775.csv\n",
            "Processed file:  game_401671761.csv\n",
            "Processed file:  game_401671760.csv\n",
            "Processed file:  game_401671774.csv\n",
            "Processed file:  game_401671748.csv\n",
            "Processed file:  game_401671833.csv\n",
            "Processed file:  game_401671827.csv\n",
            "Processed file:  game_401671600.csv\n",
            "Processed file:  game_401671628.csv\n",
            "Processed file:  game_401671616.csv\n",
            "Processed file:  game_401671831.csv\n",
            "Processed file:  game_401671825.csv\n",
            "Processed file:  game_401671819.csv\n",
            "Processed file:  game_401671762.csv\n",
            "Processed file:  game_401671776.csv\n",
            "Processed file:  game_401671789.csv\n",
            "Processed file:  game_401671788.csv\n",
            "Processed file:  game_401671777.csv\n",
            "Processed file:  game_401671763.csv\n",
            "Processed file:  game_401671818.csv\n",
            "Processed file:  game_401671824.csv\n",
            "Processed file:  game_401671830.csv\n",
            "Processed file:  game_401671617.csv\n",
            "Processed file:  game_401671808.csv\n",
            "Processed file:  game_401671834.csv\n",
            "Processed file:  game_401671820.csv\n",
            "Processed file:  game_401671767.csv\n",
            "Processed file:  game_401671773.csv\n",
            "Processed file:  game_401671798.csv\n",
            "Processed file:  game_401671799.csv\n",
            "Processed file:  game_401671772.csv\n",
            "Processed file:  game_401671766.csv\n",
            "Processed file:  game_401671821.csv\n",
            "Processed file:  game_401671835.csv\n",
            "Processed file:  game_401671809.csv\n",
            "Processed file:  game_401671638.csv\n",
            "Processed file:  game_401671823.csv\n",
            "Processed file:  game_401671837.csv\n",
            "Processed file:  game_401671599.csv\n",
            "Processed file:  game_401671770.csv\n",
            "Processed file:  game_401671764.csv\n",
            "Processed file:  game_401671758.csv\n",
            "Processed file:  game_401671759.csv\n",
            "Processed file:  game_401671765.csv\n",
            "Processed file:  game_401671771.csv\n",
            "Processed file:  game_401671836.csv\n",
            "Processed file:  game_401671822.csv\n",
            "Processed file:  game_401671639.csv\n",
            "Processed file:  game_401671662.csv\n",
            "Processed file:  game_401671676.csv\n",
            "Processed file:  game_401671845.csv\n",
            "Processed file:  game_401671851.csv\n",
            "Processed file:  game_401671689.csv\n",
            "Processed file:  game_401671716.csv\n",
            "Processed file:  game_401671702.csv\n",
            "Processed file:  game_401671703.csv\n",
            "Processed file:  game_401671717.csv\n",
            "Processed file:  game_401671688.csv\n",
            "Processed file:  game_401671850.csv\n",
            "Processed file:  game_401671844.csv\n",
            "Processed file:  game_401671677.csv\n",
            "Processed file:  game_401671663.csv\n",
            "Processed file:  game_401671649.csv\n",
            "Processed file:  game_401671675.csv\n",
            "Processed file:  game_401671661.csv\n",
            "Processed file:  game_401671852.csv\n",
            "Processed file:  game_401671846.csv\n",
            "Processed file:  game_401671729.csv\n",
            "Processed file:  game_401671701.csv\n",
            "Processed file:  game_401671715.csv\n",
            "Processed file:  game_401671714.csv\n",
            "Processed file:  game_401671700.csv\n",
            "Processed file:  game_401671728.csv\n",
            "Processed file:  game_401671489.csv\n",
            "Processed file:  game_401671847.csv\n",
            "Processed file:  game_401671853.csv\n",
            "Processed file:  game_401671660.csv\n",
            "Processed file:  game_401671674.csv\n",
            "Processed file:  game_401671648.csv\n",
            "Processed file:  game_401671670.csv\n",
            "Processed file:  game_401671664.csv\n",
            "Processed file:  game_401671658.csv\n",
            "Processed file:  game_401671857.csv\n",
            "Processed file:  game_401671843.csv\n",
            "Processed file:  game_401671704.csv\n",
            "Processed file:  game_401671710.csv\n",
            "Processed file:  game_401671738.csv\n",
            "Processed file:  game_401671739.csv\n",
            "Processed file:  game_401671711.csv\n",
            "Processed file:  game_401671705.csv\n",
            "Processed file:  game_401671842.csv\n",
            "Processed file:  game_401671856.csv\n",
            "Processed file:  game_401671659.csv\n",
            "Processed file:  game_401671665.csv\n",
            "Processed file:  game_401671671.csv\n",
            "Processed file:  game_401671667.csv\n",
            "Processed file:  game_401671673.csv\n",
            "Processed file:  game_401671868.csv\n",
            "Processed file:  game_401671840.csv\n",
            "Processed file:  game_401671698.csv\n",
            "Processed file:  game_401671854.csv\n",
            "Processed file:  game_401671713.csv\n",
            "Processed file:  game_401671707.csv\n",
            "Processed file:  game_401671706.csv\n",
            "Processed file:  game_401671712.csv\n",
            "Processed file:  game_401671855.csv\n",
            "Processed file:  game_401671699.csv\n",
            "Processed file:  game_401671841.csv\n",
            "Processed file:  game_401671869.csv\n",
            "Processed file:  game_401671672.csv\n",
            "Processed file:  game_401671666.csv\n",
            "Processed file:  game_401671643.csv\n",
            "Processed file:  game_401671657.csv\n",
            "Processed file:  game_401671864.csv\n",
            "Processed file:  game_401671870.csv\n",
            "Processed file:  game_401671858.csv\n",
            "Processed file:  game_401671680.csv\n",
            "Processed file:  game_401671694.csv\n",
            "Processed file:  game_401671737.csv\n",
            "Processed file:  game_401671723.csv\n",
            "Processed file:  game_401671722.csv\n",
            "Processed file:  game_401671736.csv\n",
            "Processed file:  game_401671695.csv\n",
            "Processed file:  game_401671681.csv\n",
            "Processed file:  game_401671859.csv\n",
            "Processed file:  game_401671871.csv\n",
            "Processed file:  game_401671865.csv\n",
            "Processed file:  game_401671656.csv\n",
            "Processed file:  game_401671642.csv\n",
            "Processed file:  game_401671668.csv\n",
            "Processed file:  game_401671654.csv\n",
            "Processed file:  game_401671640.csv\n",
            "Processed file:  game_401671873.csv\n",
            "Processed file:  game_401671867.csv\n",
            "Processed file:  game_401671697.csv\n",
            "Processed file:  game_401671683.csv\n",
            "Processed file:  game_401671495.csv\n",
            "Processed file:  game_401671708.csv\n",
            "Processed file:  game_401671720.csv\n",
            "Processed file:  game_401671734.csv\n",
            "Processed file:  game_401671735.csv\n",
            "Processed file:  game_401671721.csv\n",
            "Processed file:  game_401671709.csv\n",
            "Processed file:  game_401671494.csv\n",
            "Processed file:  game_401671682.csv\n",
            "Processed file:  game_401671696.csv\n",
            "Processed file:  game_401671866.csv\n",
            "Processed file:  game_401671872.csv\n",
            "Processed file:  game_401671641.csv\n",
            "Processed file:  game_401671655.csv\n",
            "Processed file:  game_401671669.csv\n",
            "Processed file:  game_401671651.csv\n",
            "Processed file:  game_401671645.csv\n",
            "Processed file:  game_401671679.csv\n",
            "Processed file:  game_401671692.csv\n",
            "Processed file:  game_401671686.csv\n",
            "Processed file:  game_401671876.csv\n",
            "Processed file:  game_401671862.csv\n",
            "Processed file:  game_401671490.csv\n",
            "Processed file:  game_401671725.csv\n",
            "Processed file:  game_401671731.csv\n",
            "Processed file:  game_401671719.csv\n",
            "Processed file:  game_401671718.csv\n",
            "Processed file:  game_401671730.csv\n",
            "Processed file:  game_401671724.csv\n",
            "Processed file:  game_401671491.csv\n",
            "Processed file:  game_401671863.csv\n",
            "Processed file:  game_401671877.csv\n",
            "Processed file:  game_401671687.csv\n",
            "Processed file:  game_401671693.csv\n",
            "Processed file:  game_401671678.csv\n",
            "Processed file:  game_401671644.csv\n",
            "Processed file:  game_401671650.csv\n",
            "Processed file:  game_401671646.csv\n",
            "Processed file:  game_401671652.csv\n",
            "Processed file:  game_401671685.csv\n",
            "Processed file:  game_401671849.csv\n",
            "Processed file:  game_401671691.csv\n",
            "Processed file:  game_401671861.csv\n",
            "Processed file:  game_401671875.csv\n",
            "Processed file:  game_401671493.csv\n",
            "Processed file:  game_401671732.csv\n",
            "Processed file:  game_401671726.csv\n",
            "Processed file:  game_401671727.csv\n",
            "Processed file:  game_401671733.csv\n",
            "Processed file:  game_401671492.csv\n",
            "Processed file:  game_401671874.csv\n",
            "Processed file:  game_401671860.csv\n",
            "Processed file:  game_401671690.csv\n",
            "Processed file:  game_401671848.csv\n",
            "Processed file:  game_401671684.csv\n",
            "Processed file:  game_401671653.csv\n",
            "Processed file:  game_401671647.csv\n",
            "Processed file:  game_401671620.csv\n",
            "Processed file:  game_401671634.csv\n",
            "Processed file:  game_401671807.csv\n",
            "Processed file:  game_401671813.csv\n",
            "Processed file:  game_401671768.csv\n",
            "Processed file:  game_401671754.csv\n",
            "Processed file:  game_401671740.csv\n",
            "Processed file:  game_401671797.csv\n",
            "Processed file:  game_401671783.csv\n",
            "Processed file:  game_401671782.csv\n",
            "Processed file:  game_401671796.csv\n",
            "Processed file:  game_401671741.csv\n",
            "Processed file:  game_401671755.csv\n",
            "Processed file:  game_401671769.csv\n",
            "Processed file:  game_401671812.csv\n",
            "Processed file:  game_401671806.csv\n",
            "Processed file:  game_401671635.csv\n",
            "Processed file:  game_401671621.csv\n",
            "Processed file:  game_401671637.csv\n",
            "Processed file:  game_401671623.csv\n",
            "Processed file:  game_401671810.csv\n",
            "Processed file:  game_401671804.csv\n",
            "Processed file:  game_401671838.csv\n",
            "Processed file:  game_401671743.csv\n",
            "Processed file:  game_401671757.csv\n",
            "Processed file:  game_401671780.csv\n",
            "Processed file:  game_401671794.csv\n",
            "Processed file:  game_401671795.csv\n",
            "Processed file:  game_401671781.csv\n",
            "Processed file:  game_401671756.csv\n",
            "Processed file:  game_401671742.csv\n",
            "Processed file:  game_401671839.csv\n",
            "Processed file:  game_401671805.csv\n",
            "Processed file:  game_401671811.csv\n",
            "Processed file:  game_401671622.csv\n",
            "Processed file:  game_401671636.csv\n",
            "Processed file:  game_401671632.csv\n",
            "Processed file:  game_401671626.csv\n",
            "Processed file:  game_401671829.csv\n",
            "Processed file:  game_401671815.csv\n",
            "Processed file:  game_401671801.csv\n",
            "Processed file:  game_401671746.csv\n",
            "Processed file:  game_401671752.csv\n",
            "Processed file:  game_401671785.csv\n",
            "Processed file:  game_401671791.csv\n",
            "Processed file:  game_401671790.csv\n",
            "Processed file:  game_401671784.csv\n",
            "Processed file:  game_401671753.csv\n",
            "Processed file:  game_401671747.csv\n",
            "Processed file:  game_401671800.csv\n",
            "Processed file:  game_401671814.csv\n",
            "Processed file:  game_401671828.csv\n",
            "Processed file:  game_401671627.csv\n",
            "Processed file:  game_401671633.csv\n",
            "Processed file:  game_401671625.csv\n",
            "Processed file:  game_401671631.csv\n",
            "Processed file:  game_401671619.csv\n",
            "Processed file:  game_401671802.csv\n",
            "Processed file:  game_401671816.csv\n",
            "Processed file:  game_401671751.csv\n",
            "Processed file:  game_401671745.csv\n",
            "Processed file:  game_401671779.csv\n",
            "Processed file:  game_401671792.csv\n",
            "Processed file:  game_401671786.csv\n",
            "Processed file:  game_401671787.csv\n",
            "Processed file:  game_401671793.csv\n",
            "Processed file:  game_401671778.csv\n",
            "Processed file:  game_401671744.csv\n",
            "Processed file:  game_401671750.csv\n",
            "Processed file:  game_401671817.csv\n",
            "Processed file:  game_401671803.csv\n",
            "Processed file:  game_401671618.csv\n",
            "Processed file:  game_401671630.csv\n",
            "Processed file:  game_401671624.csv\n"
          ]
        }
      ],
      "source": [
        "# Write predictions to csv file\n",
        "from process_data import write_predictions\n",
        "write_predictions(ensemble_models, interpolated_dir, [2024], 4, features, replace_nan_val = 0, phat_b = \"ensemble_phat_b_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0.3927 -33.       0.      -1.      10.       0.       3.       3.    ]\n",
            " [  0.3927 -33.       0.       1.      10.      70.       3.       3.    ]\n",
            " [  0.3927 -33.       1.       2.       7.      67.       3.       3.    ]\n",
            " [  0.3927 -33.       1.       2.       7.      67.       3.       3.    ]\n",
            " [  0.3927 -33.       1.       2.       7.      67.       3.       3.    ]]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "can only convert an array of size 1 to a Python scalar",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[161], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[module_name]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprocess_data\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mprocess_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massess_differences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/notebooks/process_data.py:405\u001b[0m, in \u001b[0;36massess_differences\u001b[0;34m(models, data, timestep, loss, threshold)\u001b[0m\n\u001b[1;32m    401\u001b[0m     diff \u001b[38;5;241m=\u001b[39m loss_val_1 \u001b[38;5;241m-\u001b[39m loss_val_2\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(diff) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[1;32m    403\u001b[0m         entries_above_threshold\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry\u001b[39m\u001b[38;5;124m\"\u001b[39m: entry,\n\u001b[0;32m--> 405\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    406\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff\u001b[39m\u001b[38;5;124m\"\u001b[39m: diff\n\u001b[1;32m    407\u001b[0m         })\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Convert entries to a table format\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entries_above_threshold:\n",
            "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
          ]
        }
      ],
      "source": [
        "modules_to_reload = [\n",
        "    \"process_data\"\n",
        "]\n",
        "\n",
        "for module_name in modules_to_reload:\n",
        "    if module_name in sys.modules:\n",
        "        del sys.modules[module_name]\n",
        "import process_data\n",
        "process_data.assess_differences(ensemble_models, test_data_seq, 0.95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied '/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024' to '/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/test_7/ensemble_model_testing_2'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the ancestor directory and the parent directory\n",
        "src_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Adjust the number of \"../\" as needed\n",
        "dest_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
        "\n",
        "# Specify the file or directory to copy from the ancestor directory\n",
        "source = os.path.join(src_dir, \"dataset_interpolated_fixed\", \"2024\")  # Replace with the actual name\n",
        "destination = os.path.join(dest_dir, \"test_7\", \"ensemble_model_testing_2\")  # Replace with the desired name\n",
        "\n",
        "# Perform the copy operation\n",
        "if os.path.exists(source):\n",
        "    if os.path.isdir(source):\n",
        "        shutil.copytree(source, destination)\n",
        "    else:\n",
        "        shutil.copy2(source, destination)\n",
        "    print(f\"Copied '{source}' to '{destination}'\")\n",
        "else:\n",
        "    print(f\"Source '{source}' does not exist\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NFL_env (3.9.13)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
