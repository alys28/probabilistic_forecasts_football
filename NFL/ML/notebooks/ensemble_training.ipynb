{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensemble training (1 year of testing, 2 years of validation, the rest is training)\n",
        "    # Learned weights on validation data (Constrained optimization)\n",
        "    # Meta-learning using an other ML model\n",
        "\n",
        "# Models used:\n",
        "# - XGBoost\n",
        "# - Neural Network\n",
        "# - Logistic Regression\n",
        "# - LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML\n"
          ]
        }
      ],
      "source": [
        "# Set up paths and load data\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "sys.path.append(parent_dir)\n",
        "print(parent_dir)\n",
        "\n",
        "interpolated_dir = os.path.join(parent_dir, \"dataset_interpolated_fixed\")\n",
        "# features = [\"game_completed\", \"relative_strength\", \"score_difference\", \"type.id\", \"home_has_possession\", \"end.down\", \"end.yardsToEndzone\", \"end.distance\", \"field_position_shift\", \"home_timeouts_left\", \"away_timeouts_left\"]\n",
        "features = [\"relative_strength\", \"score_difference\", \"home_has_possession\", \"end.down\", \"end.distance\", \"end.yardsToEndzone\",  \"home_timeouts_left\", \"away_timeouts_left\"]\n",
        "# Import necessary modules\n",
        "from sklearn.metrics import brier_score_loss, accuracy_score, log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.optimize import minimize\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "  Processing 254 CSV files in parallel with 8 workers...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Completed processing 2017\n",
            "Loading data for 2019\n",
            "  Processing 256 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2019\n",
            "Loading data for 2021\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2021\n",
            "Loading data for 2020\n",
            "  Processing 255 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2020\n",
            "Loading data for 2018\n",
            "  Processing 255 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2018\n",
            "Loading data for 2016\n",
            "  Processing 254 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2016\n",
            "Loading data for 2022\n",
            "  Processing 271 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n"
          ]
        }
      ],
      "source": [
        "# Load data for ensemble training\n",
        "import process_data\n",
        "training_data = process_data.load_data(interpolated_dir, \n",
        "                                       years = [2016, 2017, 2018, 2019, 2020, 2021], \n",
        "                                       history_length = 0, \n",
        "                                       features = features, \n",
        "                                       label_feature = \"home_win\")\n",
        "\n",
        "ensemble_data = process_data.load_data(interpolated_dir, \n",
        "                                         years = [2022, 2023], \n",
        "                                         history_length = 0, \n",
        "                                         features = features, \n",
        "                                         label_feature = \"home_win\",\n",
        "                                         train = True\n",
        "                                         )\n",
        "\n",
        "test_data = process_data.load_data(interpolated_dir, \n",
        "                                   years = [2024],\n",
        "                                   history_length = 0, \n",
        "                                   features = features, \n",
        "                                   label_feature = \"home_win\",\n",
        "                                   train = False\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "  Processing 254 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2017\n",
            "Loading data for 2019\n",
            "  Processing 256 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2019\n",
            "Loading data for 2021\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2021\n",
            "Loading data for 2020\n",
            "  Processing 255 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2020\n",
            "Loading data for 2018\n",
            "  Processing 255 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2018\n",
            "Loading data for 2016\n",
            "  Processing 254 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2016\n",
            "Loading data for 2022\n",
            "  Processing 271 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2022\n",
            "Loading data for 2024\n",
            "skipping  2024\n",
            "Loading data for 2023\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n",
            "Loading data for 2022\n",
            "skipping  2022\n",
            "Loading data for 2024\n",
            "  Processing 272 CSV files in parallel with 8 workers...\n",
            "  Completed processing 2024\n",
            "Loading data for 2023\n",
            "skipping  2023\n",
            "Loading data for .DS_Store\n",
            "Loading data for 2017\n",
            "skipping  2017\n",
            "Loading data for 2019\n",
            "skipping  2019\n",
            "Loading data for 2021\n",
            "skipping  2021\n",
            "Loading data for 2020\n",
            "skipping  2020\n",
            "Loading data for 2018\n",
            "skipping  2018\n",
            "Loading data for 2016\n",
            "skipping  2016\n"
          ]
        }
      ],
      "source": [
        "\n",
        "training_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                       years = [2016, 2017, 2018, 2019, 2020, 2021], \n",
        "                                       history_length = 4, \n",
        "                                       features = features, \n",
        "                                       label_feature = \"home_win\",\n",
        "                                       train = True\n",
        "                                       )\n",
        "\n",
        "ensemble_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                         years = [2022, 2023], \n",
        "                                         history_length = 4, \n",
        "                                         features = features, \n",
        "                                         label_feature = \"home_win\",\n",
        "                                         train = True\n",
        "                                         )\n",
        "\n",
        "test_data_seq = process_data.load_data(interpolated_dir, \n",
        "                                   years = [2024],\n",
        "                                   history_length = 4, \n",
        "                                   features = features, \n",
        "                                   label_feature = \"home_win\",\n",
        "                                   train = False\n",
        "                                   )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "class EnsemblePredictor:\n",
        "    \"\"\"\n",
        "    Ensemble predictor class, one per timestep\n",
        "    \"\"\"\n",
        "    def __init__(self, all_models, all_models_order, all_features, strategy='meta_model', meta_model=None):\n",
        "        self.all_models = all_models\n",
        "        self.all_models_order = all_models_order\n",
        "        self.strategy = strategy\n",
        "        self.all_features = all_features\n",
        "        if self.strategy != 'meta_model' and self.strategy != 'weighted_average':\n",
        "            raise ValueError(\"Invalid strategy\")\n",
        "        if meta_model is None and self.strategy == 'meta_model':\n",
        "            raise ValueError(\"Meta model is required for meta_model strategy\")\n",
        "        self.meta_model = meta_model\n",
        "        self.ensemble_weights = None # Will be a 1D array of shape (n_models,) once trained\n",
        " \n",
        "    def train_ensemble(self, x_train, y_train, objective='brier'):\n",
        "        \"\"\"\n",
        "        Train the ensemble for a single timestep using validation data.\n",
        "        \"\"\"\n",
        "        print(f\"Training ensemble for this timestep...\")\n",
        "        if self.strategy == 'weighted_average':\n",
        "            self.optimize_ensemble_weights(x_train, y_train, objective)\n",
        "        elif self.strategy == 'meta_model':\n",
        "            self.train_meta_model(x_train, y_train)\n",
        "\n",
        "    def optimize_ensemble_weights(self, x_train, y_train, objective='brier'):\n",
        "        \"\"\"\n",
        "        Optimize ensemble weights for a single timestep using validation data.\n",
        "        \"\"\"\n",
        "        print(f\"Optimizing ensemble weights for this timestep...\")\n",
        "\n",
        "        n_models = x_train.shape[1]\n",
        "\n",
        "        def objective_function(weights):\n",
        "            weights = weights / np.sum(weights)  # Normalize weights\n",
        "            ensemble_preds = np.dot(x_train, weights)\n",
        "\n",
        "            if objective == 'brier':\n",
        "                ensemble_preds = np.clip(ensemble_preds, 1e-15, 1-1e-15)\n",
        "                return brier_score_loss(y_train, ensemble_preds)\n",
        "            elif objective == 'logloss':\n",
        "                # Clip predictions to avoid log(0)\n",
        "                ensemble_preds = np.clip(ensemble_preds, 1e-15, 1-1e-15)\n",
        "                return log_loss(y_train, ensemble_preds)\n",
        "            elif objective == 'accuracy':\n",
        "                return -accuracy_score(y_train, ensemble_preds > 0.5)  # Negative for minimization\n",
        "\n",
        "        # Constraints: weights sum to 1 and are non-negative\n",
        "        constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
        "        bounds = [(0, 1) for _ in range(n_models)]\n",
        "\n",
        "        # Initialize with equal weights\n",
        "        initial_weights = np.ones(n_models) / n_models\n",
        "\n",
        "        result = minimize(objective_function, initial_weights,\n",
        "                          method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "\n",
        "        if result.success:\n",
        "            self.ensemble_weights = result.x\n",
        "            print(f\"  Optimized weights: {dict(zip(self.all_models_order, result.x.round(4)))} (score: {result.fun:.6f})\")\n",
        "        else:\n",
        "            print(f\"  Optimization failed, using equal weights\")\n",
        "            self.ensemble_weights = initial_weights\n",
        "\n",
        "        return self.ensemble_weights\n",
        "\n",
        "    def train_meta_model(self, x_train, y_train):\n",
        "        \"\"\"\n",
        "        Train a meta-model for a single timestep to predict based on base model outputs.\n",
        "        \"\"\"\n",
        "        X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "        # Train meta-model: input=base_model_predictions, output=final_prediction\n",
        "        self.meta_model.fit(X_train, y_train.reshape(-1, 1))\n",
        "\n",
        "        # Test the meta-model's prediction capability\n",
        "        meta_predictions = self.meta_model.predict_proba(X_val)[:, 1]\n",
        "        meta_accuracy = accuracy_score(y_val, meta_predictions > 0.5)\n",
        "        meta_brier = brier_score_loss(y_val, meta_predictions)\n",
        "\n",
        "        print(f\"  Meta-model trained on {len(X_train)} samples\")\n",
        "        print(f\"    Validation Meta-model accuracy: {meta_accuracy:.4f}, Validation Brier score: {meta_brier:.4f}\")\n",
        "\n",
        "        return self.meta_model\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probability of the positive class for a given input\n",
        "        \"\"\"\n",
        "        # Generate predictions from each individual model\n",
        "        # Convert X to a 3D array of shape (n_samples, n_history, n_features)\n",
        "        predictions = [] # Will be a 2D array of shape (n_samples, n_models)\n",
        "        for i, model_name in enumerate(self.all_models_order):\n",
        "            model = self.all_models[model_name]\n",
        "            # print(\"Model name: \", model_name)\n",
        "            if model_name == \"lstm\":\n",
        "                # print(X.shape)\n",
        "                pred = model.predict_proba(X)\n",
        "                # print(pred)\n",
        "                predictions.append(pred[:, 1])\n",
        "            else:\n",
        "                # print(X.shape)\n",
        "                x = np.array([X[i][-1] for i in range(X.shape[0])]) if len(X.shape) == 3 else np.array([X[-1]])\n",
        "                # print(x.shape)\n",
        "                pred = model.predict_proba(x)\n",
        "                # print(pred)\n",
        "                predictions.append(pred[:, 1]) # Will be a 1D array of shape (n_samples,) for each model\n",
        "        predictions = np.array(predictions) # Will be a 2D array of shape (n_models, n_samples)\n",
        "        predictions = predictions.T # Reshape to be a 2D array of shape (n_samples, n_models)\n",
        "        if self.strategy == 'weighted_average':\n",
        "            return np.dot(predictions, self.ensemble_weights)\n",
        "        elif self.strategy == 'meta_model':\n",
        "            return self.meta_model.predict_proba(predictions)[:, 1]\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probability of the positive class for a given input\n",
        "        \"\"\"\n",
        "        pred = self.predict(X).flatten()\n",
        "        return np.column_stack([1 - pred, pred])\n",
        "\n",
        "    def predict_proba_single(self, X):\n",
        "        preds = self.predict_proba(X)\n",
        "        return preds[:, 1]\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        Score the ensemble for a given input\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "        y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "        return np.mean(y_pred_labels == y)\n",
        "    \n",
        "    def SHAP_analysis(self, X_test, X_train, plot = True):\n",
        "        \"\"\"\n",
        "        Model interpretability with SHAP values\n",
        "        \"\"\"\n",
        "        feature_names = self.all_features\n",
        "        masker = shap.maskers.Independent(X_train[:10])\n",
        "        explainer = shap.Explainer(self.predict_proba_single, masker, feature_names=self.all_features)\n",
        "        shap_values = explainer(X_test)\n",
        "        if plot:\n",
        "            shap.plots.bar(shap_values)\n",
        "        return shap_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload modules\n",
        "modules_to_reload = [\n",
        "    'models.xg_boost',\n",
        "    'models.direct_prediction_network_lstm',\n",
        "    'models.direct_prediction_network',\n",
        "    'models.logistic_regression',\n",
        "    'models.Model'\n",
        "    'models.DL_Model'\n",
        "]\n",
        "\n",
        "for module_name in modules_to_reload:\n",
        "    if module_name in sys.modules:\n",
        "        del sys.modules[module_name]\n",
        "from models.xg_boost import setup_xgboost_models\n",
        "from models.direct_prediction_network_lstm import setup_direct_lstm_models\n",
        "from models.direct_prediction_network import setup_direct_models\n",
        "from models.logistic_regression import setup_logistic_regression_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split training data: 2484 train, 277 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.0, 0.005]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.6630, Train Loss: 0.2148, Val Acc: 0.6606, Val Loss: 0.2097\n",
            "Restored model from best epoch 16 with val_loss: 0.209741\n",
            "NFL LSTM model 1/201 completed\n",
            "Split training data: 881 train, 98 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.005, 0.01]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 2/201 completed\n",
            "Split training data: 1634 train, 182 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.01, 0.015]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.6646, Train Loss: 0.2079, Val Acc: 0.6923, Val Loss: 0.1946\n",
            "Restored model from best epoch 18 with val_loss: 0.194615\n",
            "NFL LSTM model 3/201 completed\n",
            "Split training data: 1382 train, 154 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.015, 0.02]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.6476, Train Loss: 0.2220, Val Acc: 0.7013, Val Loss: 0.1955\n",
            "Restored model from best epoch 18 with val_loss: 0.195494\n",
            "NFL LSTM model 4/201 completed\n",
            "Split training data: 1546 train, 172 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.02, 0.025]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.6488, Train Loss: 0.2195, Val Acc: 0.6628, Val Loss: 0.2248\n",
            "Restored model from best epoch 11 with val_loss: 0.224768\n",
            "NFL LSTM model 5/201 completed\n",
            "Split training data: 1594 train, 178 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.025, 0.03]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.6455, Train Loss: 0.2249, Val Acc: 0.6798, Val Loss: 0.2050\n",
            "Restored model from best epoch 6 with val_loss: 0.204983\n",
            "NFL LSTM model 6/201 completed\n",
            "Split training data: 1516 train, 169 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.03, 0.035]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.6748, Train Loss: 0.2094, Val Acc: 0.6627, Val Loss: 0.2023\n",
            "Restored model from best epoch 20 with val_loss: 0.202338\n",
            "NFL LSTM model 7/201 completed\n",
            "Split training data: 1646 train, 183 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.035, 0.04]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 8/201 completed\n",
            "Split training data: 1568 train, 175 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.04, 0.045]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.6747, Train Loss: 0.2120, Val Acc: 0.6857, Val Loss: 0.1940\n",
            "Restored model from best epoch 22 with val_loss: 0.193954\n",
            "NFL LSTM model 9/201 completed\n",
            "Split training data: 1678 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.045, 0.05]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.6633, Train Loss: 0.2181, Val Acc: 0.7326, Val Loss: 0.1921\n",
            "Restored model from best epoch 11 with val_loss: 0.192059\n",
            "NFL LSTM model 10/201 completed\n",
            "Split training data: 1630 train, 182 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.05, 0.055]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.6571, Train Loss: 0.2160, Val Acc: 0.6484, Val Loss: 0.2170\n",
            "Restored model from best epoch 15 with val_loss: 0.217027\n",
            "NFL LSTM model 11/201 completed\n",
            "Split training data: 1573 train, 175 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.055, 0.06]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.6643, Train Loss: 0.2185, Val Acc: 0.6800, Val Loss: 0.2144\n",
            "Restored model from best epoch 9 with val_loss: 0.214371\n",
            "NFL LSTM model 12/201 completed\n",
            "Split training data: 1708 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.06, 0.065]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6639, Train Loss: 0.2177, Val Acc: 0.6368, Val Loss: 0.2211\n",
            "Restored model from best epoch 3 with val_loss: 0.221071\n",
            "NFL LSTM model 13/201 completed\n",
            "Split training data: 1642 train, 183 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.065, 0.07]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.6553, Train Loss: 0.2188, Val Acc: 0.6667, Val Loss: 0.2030\n",
            "Restored model from best epoch 9 with val_loss: 0.202977\n",
            "NFL LSTM model 14/201 completed\n",
            "Split training data: 1677 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.07, 0.075]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.6696, Train Loss: 0.2105, Val Acc: 0.7326, Val Loss: 0.1798\n",
            "Restored model from best epoch 20 with val_loss: 0.179754\n",
            "NFL LSTM model 15/201 completed\n",
            "Split training data: 1629 train, 181 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.075, 0.08]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 16/201 completed\n",
            "Split training data: 1692 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.08, 0.085]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7021, Train Loss: 0.2041, Val Acc: 0.7181, Val Loss: 0.1824\n",
            "Restored model from best epoch 12 with val_loss: 0.182371\n",
            "NFL LSTM model 17/201 completed\n",
            "Split training data: 1711 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.085, 0.09]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 18/201 completed\n",
            "Split training data: 1618 train, 180 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.09, 0.095]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6477, Train Loss: 0.2225, Val Acc: 0.6667, Val Loss: 0.2213\n",
            "Restored model from best epoch 5 with val_loss: 0.221271\n",
            "NFL LSTM model 19/201 completed\n",
            "Split training data: 1692 train, 189 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.095, 0.1]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6655, Train Loss: 0.2160, Val Acc: 0.6085, Val Loss: 0.2357\n",
            "Restored model from best epoch 5 with val_loss: 0.235739\n",
            "NFL LSTM model 20/201 completed\n",
            "Split training data: 1663 train, 185 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.1, 0.105]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 21/201 completed\n",
            "Split training data: 1647 train, 184 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.105, 0.11]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 22/201 completed\n",
            "Split training data: 1702 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.11, 0.115]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.6722, Train Loss: 0.2130, Val Acc: 0.6737, Val Loss: 0.2110\n",
            "Restored model from best epoch 8 with val_loss: 0.211011\n",
            "NFL LSTM model 23/201 completed\n",
            "Split training data: 1637 train, 182 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.115, 0.12]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.6976, Train Loss: 0.2012, Val Acc: 0.6978, Val Loss: 0.2003\n",
            "Restored model from best epoch 15 with val_loss: 0.200279\n",
            "NFL LSTM model 24/201 completed\n",
            "Split training data: 1696 train, 189 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.12, 0.125]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.6869, Train Loss: 0.2100, Val Acc: 0.6772, Val Loss: 0.2038\n",
            "Restored model from best epoch 5 with val_loss: 0.203780\n",
            "NFL LSTM model 25/201 completed\n",
            "Split training data: 1709 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.125, 0.13]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.6940, Train Loss: 0.2053, Val Acc: 0.6789, Val Loss: 0.2166\n",
            "Restored model from best epoch 4 with val_loss: 0.216604\n",
            "NFL LSTM model 26/201 completed\n",
            "Split training data: 1688 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.13, 0.135]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6771, Train Loss: 0.2081, Val Acc: 0.6436, Val Loss: 0.2104\n",
            "Restored model from best epoch 3 with val_loss: 0.210375\n",
            "NFL LSTM model 27/201 completed\n",
            "Split training data: 1660 train, 185 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.135, 0.14]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 28/201 completed\n",
            "Split training data: 1610 train, 179 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.14, 0.145]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.7155, Train Loss: 0.1960, Val Acc: 0.7151, Val Loss: 0.1951\n",
            "Restored model from best epoch 16 with val_loss: 0.195057\n",
            "NFL LSTM model 29/201 completed\n",
            "Split training data: 1654 train, 184 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.145, 0.15]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.6911, Train Loss: 0.2025, Val Acc: 0.7446, Val Loss: 0.1761\n",
            "Restored model from best epoch 14 with val_loss: 0.176067\n",
            "NFL LSTM model 30/201 completed\n",
            "Split training data: 1715 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.15, 0.155]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 31/201 completed\n",
            "Split training data: 1576 train, 176 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.155, 0.16]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.7030, Train Loss: 0.1992, Val Acc: 0.6875, Val Loss: 0.2073\n",
            "Restored model from best epoch 13 with val_loss: 0.207280\n",
            "NFL LSTM model 32/201 completed\n",
            "Split training data: 1760 train, 196 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.16, 0.165]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.7125, Train Loss: 0.1930, Val Acc: 0.7245, Val Loss: 0.1937\n",
            "Restored model from best epoch 16 with val_loss: 0.193667\n",
            "NFL LSTM model 33/201 completed\n",
            "Split training data: 1605 train, 179 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.165, 0.17]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.7028, Train Loss: 0.1977, Val Acc: 0.6872, Val Loss: 0.1996\n",
            "Restored model from best epoch 17 with val_loss: 0.199568\n",
            "NFL LSTM model 34/201 completed\n",
            "Split training data: 1659 train, 185 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.17, 0.175]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.7034, Train Loss: 0.1959, Val Acc: 0.7243, Val Loss: 0.1876\n",
            "Restored model from best epoch 10 with val_loss: 0.187604\n",
            "NFL LSTM model 35/201 completed\n",
            "Split training data: 1723 train, 192 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.175, 0.18]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.6790, Train Loss: 0.2061, Val Acc: 0.7292, Val Loss: 0.1849\n",
            "Restored model from best epoch 9 with val_loss: 0.184918\n",
            "NFL LSTM model 36/201 completed\n",
            "Split training data: 1614 train, 180 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.18, 0.185]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.7088, Train Loss: 0.1945, Val Acc: 0.7444, Val Loss: 0.1784\n",
            "Restored model from best epoch 15 with val_loss: 0.178374\n",
            "NFL LSTM model 37/201 completed\n",
            "Split training data: 1669 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.185, 0.19]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.7052, Train Loss: 0.1977, Val Acc: 0.7849, Val Loss: 0.1602\n",
            "Restored model from best epoch 24 with val_loss: 0.160158\n",
            "NFL LSTM model 38/201 completed\n",
            "Split training data: 1615 train, 180 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.19, 0.195]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 39/201 completed\n",
            "Split training data: 1681 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.195, 0.2]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 40/201 completed\n",
            "Split training data: 1637 train, 182 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.2, 0.205]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.7123, Train Loss: 0.1888, Val Acc: 0.6593, Val Loss: 0.2081\n",
            "Restored model from best epoch 18 with val_loss: 0.208110\n",
            "NFL LSTM model 41/201 completed\n",
            "Split training data: 1653 train, 184 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.205, 0.21]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.6999, Train Loss: 0.1961, Val Acc: 0.7065, Val Loss: 0.1876\n",
            "Restored model from best epoch 13 with val_loss: 0.187581\n",
            "NFL LSTM model 42/201 completed\n",
            "Split training data: 1749 train, 195 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.21, 0.215]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.7050, Train Loss: 0.1852, Val Acc: 0.7077, Val Loss: 0.2032\n",
            "Restored model from best epoch 19 with val_loss: 0.203235\n",
            "NFL LSTM model 43/201 completed\n",
            "Split training data: 1578 train, 176 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.215, 0.22]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7009, Train Loss: 0.1957, Val Acc: 0.7273, Val Loss: 0.1868\n",
            "Restored model from best epoch 7 with val_loss: 0.186767\n",
            "NFL LSTM model 44/201 completed\n",
            "Split training data: 1689 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.22, 0.225]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 45/201 completed\n",
            "Split training data: 1708 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.225, 0.23]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 46/201 completed\n",
            "Split training data: 1597 train, 178 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.23, 0.235]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7132, Train Loss: 0.1877, Val Acc: 0.7191, Val Loss: 0.1954\n",
            "Restored model from best epoch 8 with val_loss: 0.195371\n",
            "NFL LSTM model 47/201 completed\n",
            "Split training data: 1715 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.235, 0.24]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 48/201 completed\n",
            "Split training data: 1620 train, 180 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.24, 0.245]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 24, Train Acc: 0.6920, Train Loss: 0.1954, Val Acc: 0.7389, Val Loss: 0.1715\n",
            "Restored model from best epoch 24 with val_loss: 0.171539\n",
            "NFL LSTM model 49/201 completed\n",
            "Split training data: 1519 train, 169 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.245, 0.25]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.7011, Train Loss: 0.1951, Val Acc: 0.7041, Val Loss: 0.1953\n",
            "Restored model from best epoch 9 with val_loss: 0.195348\n",
            "NFL LSTM model 50/201 completed\n",
            "Split training data: 4953 train, 551 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.25, 0.255]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 51/201 completed\n",
            "Split training data: 983 train, 110 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.255, 0.26]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.7152, Train Loss: 0.1886, Val Acc: 0.6909, Val Loss: 0.1887\n",
            "Restored model from best epoch 9 with val_loss: 0.188662\n",
            "NFL LSTM model 52/201 completed\n",
            "Split training data: 1296 train, 144 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.26, 0.265]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.7130, Train Loss: 0.1879, Val Acc: 0.7708, Val Loss: 0.1587\n",
            "Restored model from best epoch 18 with val_loss: 0.158660\n",
            "NFL LSTM model 53/201 completed\n",
            "Split training data: 1745 train, 194 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.265, 0.27]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 54/201 completed\n",
            "Split training data: 1559 train, 174 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.27, 0.275]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7178, Train Loss: 0.1896, Val Acc: 0.7011, Val Loss: 0.1810\n",
            "Restored model from best epoch 8 with val_loss: 0.181048\n",
            "NFL LSTM model 55/201 completed\n",
            "Split training data: 1774 train, 198 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.275, 0.28]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.7193, Train Loss: 0.1828, Val Acc: 0.6818, Val Loss: 0.2045\n",
            "Restored model from best epoch 25 with val_loss: 0.204488\n",
            "NFL LSTM model 56/201 completed\n",
            "Split training data: 1539 train, 171 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.28, 0.285]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.7109, Train Loss: 0.1903, Val Acc: 0.7427, Val Loss: 0.1781\n",
            "Restored model from best epoch 9 with val_loss: 0.178072\n",
            "NFL LSTM model 57/201 completed\n",
            "Split training data: 1782 train, 199 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.285, 0.29]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.6925, Train Loss: 0.1988, Val Acc: 0.6884, Val Loss: 0.2071\n",
            "Restored model from best epoch 3 with val_loss: 0.207059\n",
            "NFL LSTM model 58/201 completed\n",
            "Split training data: 1626 train, 181 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.29, 0.295]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 59/201 completed\n",
            "Split training data: 1681 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.295, 0.3]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.7412, Train Loss: 0.1803, Val Acc: 0.7326, Val Loss: 0.1812\n",
            "Restored model from best epoch 20 with val_loss: 0.181178\n",
            "NFL LSTM model 60/201 completed\n",
            "Split training data: 1700 train, 189 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.3, 0.305]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 61/201 completed\n",
            "Split training data: 1585 train, 177 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.305, 0.31]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7268, Train Loss: 0.1846, Val Acc: 0.7401, Val Loss: 0.1869\n",
            "Restored model from best epoch 11 with val_loss: 0.186864\n",
            "NFL LSTM model 62/201 completed\n",
            "Split training data: 1708 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.31, 0.315]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 63/201 completed\n",
            "Split training data: 1676 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.315, 0.32]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 64/201 completed\n",
            "Split training data: 1692 train, 189 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.32, 0.325]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.7506, Train Loss: 0.1702, Val Acc: 0.7989, Val Loss: 0.1546\n",
            "Restored model from best epoch 17 with val_loss: 0.154559\n",
            "NFL LSTM model 65/201 completed\n",
            "Split training data: 1621 train, 181 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.325, 0.33]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7279, Train Loss: 0.1886, Val Acc: 0.6906, Val Loss: 0.1858\n",
            "Restored model from best epoch 4 with val_loss: 0.185807\n",
            "NFL LSTM model 66/201 completed\n",
            "Split training data: 1678 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.33, 0.335]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 67/201 completed\n",
            "Split training data: 1708 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.335, 0.34]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 68/201 completed\n",
            "Split training data: 1650 train, 184 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.34, 0.345]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 69/201 completed\n",
            "Split training data: 1734 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.345, 0.35]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 8\n",
            "Best epoch: 3, Train Acc: 0.7163, Train Loss: 0.1897, Val Acc: 0.7565, Val Loss: 0.1680\n",
            "Restored model from best epoch 3 with val_loss: 0.168002\n",
            "NFL LSTM model 70/201 completed\n",
            "Split training data: 1699 train, 189 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.35, 0.355]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 71/201 completed\n",
            "Split training data: 1688 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.355, 0.36]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.7382, Train Loss: 0.1793, Val Acc: 0.7713, Val Loss: 0.1665\n",
            "Restored model from best epoch 11 with val_loss: 0.166467\n",
            "NFL LSTM model 72/201 completed\n",
            "Split training data: 1653 train, 184 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.36, 0.365]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.7356, Train Loss: 0.1825, Val Acc: 0.7609, Val Loss: 0.1559\n",
            "Restored model from best epoch 17 with val_loss: 0.155866\n",
            "NFL LSTM model 73/201 completed\n",
            "Split training data: 1719 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.365, 0.37]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 74/201 completed\n",
            "Split training data: 1631 train, 182 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.37, 0.375]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 75/201 completed\n",
            "Split training data: 1696 train, 189 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.375, 0.38]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.7583, Train Loss: 0.1708, Val Acc: 0.7513, Val Loss: 0.1696\n",
            "Restored model from best epoch 10 with val_loss: 0.169574\n",
            "NFL LSTM model 76/201 completed\n",
            "Split training data: 1652 train, 184 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.38, 0.385]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.7669, Train Loss: 0.1679, Val Acc: 0.7283, Val Loss: 0.1682\n",
            "Restored model from best epoch 13 with val_loss: 0.168206\n",
            "NFL LSTM model 77/201 completed\n",
            "Split training data: 1660 train, 185 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.385, 0.39]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.7747, Train Loss: 0.1580, Val Acc: 0.7514, Val Loss: 0.1747\n",
            "Restored model from best epoch 22 with val_loss: 0.174669\n",
            "NFL LSTM model 78/201 completed\n",
            "Split training data: 1664 train, 185 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.39, 0.395]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.7590, Train Loss: 0.1683, Val Acc: 0.7351, Val Loss: 0.1735\n",
            "Restored model from best epoch 18 with val_loss: 0.173473\n",
            "NFL LSTM model 79/201 completed\n",
            "Split training data: 1710 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.395, 0.4]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 80/201 completed\n",
            "Split training data: 1670 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.4, 0.405]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7204, Train Loss: 0.1911, Val Acc: 0.6989, Val Loss: 0.1981\n",
            "Restored model from best epoch 4 with val_loss: 0.198094\n",
            "NFL LSTM model 81/201 completed\n",
            "Split training data: 1587 train, 177 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.405, 0.41]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.7732, Train Loss: 0.1566, Val Acc: 0.7627, Val Loss: 0.1718\n",
            "Restored model from best epoch 20 with val_loss: 0.171837\n",
            "NFL LSTM model 82/201 completed\n",
            "Split training data: 1732 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.41, 0.415]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.7494, Train Loss: 0.1772, Val Acc: 0.7513, Val Loss: 0.1555\n",
            "Restored model from best epoch 9 with val_loss: 0.155477\n",
            "NFL LSTM model 83/201 completed\n",
            "Split training data: 1669 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.415, 0.42]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.7400, Train Loss: 0.1717, Val Acc: 0.7527, Val Loss: 0.1738\n",
            "Restored model from best epoch 8 with val_loss: 0.173827\n",
            "NFL LSTM model 84/201 completed\n",
            "Split training data: 1720 train, 192 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.42, 0.425]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 85/201 completed\n",
            "Split training data: 1678 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.425, 0.43]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7503, Train Loss: 0.1687, Val Acc: 0.7112, Val Loss: 0.1878\n",
            "Restored model from best epoch 12 with val_loss: 0.187765\n",
            "NFL LSTM model 86/201 completed\n",
            "Split training data: 1671 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.43, 0.435]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.7672, Train Loss: 0.1639, Val Acc: 0.6828, Val Loss: 0.1865\n",
            "Restored model from best epoch 14 with val_loss: 0.186503\n",
            "NFL LSTM model 87/201 completed\n",
            "Split training data: 1731 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.435, 0.44]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 9\n",
            "Best epoch: 4, Train Acc: 0.7475, Train Loss: 0.1782, Val Acc: 0.7772, Val Loss: 0.1986\n",
            "Restored model from best epoch 4 with val_loss: 0.198608\n",
            "NFL LSTM model 88/201 completed\n",
            "Split training data: 1637 train, 182 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.44, 0.445]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 89/201 completed\n",
            "Split training data: 1709 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.445, 0.45]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7642, Train Loss: 0.1645, Val Acc: 0.7737, Val Loss: 0.1499\n",
            "Restored model from best epoch 6 with val_loss: 0.149920\n",
            "NFL LSTM model 90/201 completed\n",
            "Split training data: 1690 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.45, 0.455]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.7621, Train Loss: 0.1637, Val Acc: 0.7394, Val Loss: 0.1720\n",
            "Restored model from best epoch 12 with val_loss: 0.171951\n",
            "NFL LSTM model 91/201 completed\n",
            "Split training data: 1691 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.455, 0.46]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.7564, Train Loss: 0.1653, Val Acc: 0.7340, Val Loss: 0.1797\n",
            "Restored model from best epoch 14 with val_loss: 0.179700\n",
            "NFL LSTM model 92/201 completed\n",
            "Split training data: 1723 train, 192 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.46, 0.465]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 93/201 completed\n",
            "Split training data: 1616 train, 180 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.465, 0.47]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 94/201 completed\n",
            "Split training data: 4663 train, 519 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.47, 0.475]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 95/201 completed\n",
            "Split training data: 2369 train, 264 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.475, 0.48]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 96/201 completed\n",
            "Split training data: 2547 train, 284 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.48, 0.485]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.7966, Train Loss: 0.1464, Val Acc: 0.7852, Val Loss: 0.1527\n",
            "Restored model from best epoch 21 with val_loss: 0.152698\n",
            "NFL LSTM model 97/201 completed\n",
            "Split training data: 2877 train, 320 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.485, 0.49]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 98/201 completed\n",
            "Split training data: 3471 train, 386 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.49, 0.495]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 99/201 completed\n",
            "Split training data: 4170 train, 464 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.495, 0.5]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 100/201 completed\n",
            "Split training data: 7587 train, 843 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.5, 0.505]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8039, Train Loss: 0.1426, Val Acc: 0.7900, Val Loss: 0.1430\n",
            "Restored model from best epoch 9 with val_loss: 0.143048\n",
            "NFL LSTM model 101/201 completed\n",
            "Split training data: 983 train, 110 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.505, 0.51]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8057, Train Loss: 0.1426, Val Acc: 0.7455, Val Loss: 0.1606\n",
            "Restored model from best epoch 7 with val_loss: 0.160596\n",
            "NFL LSTM model 102/201 completed\n",
            "Split training data: 1591 train, 177 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.51, 0.515]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.8083, Train Loss: 0.1396, Val Acc: 0.7797, Val Loss: 0.1648\n",
            "Restored model from best epoch 18 with val_loss: 0.164845\n",
            "NFL LSTM model 103/201 completed\n",
            "Split training data: 1379 train, 154 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.515, 0.52]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8296, Train Loss: 0.1300, Val Acc: 0.8247, Val Loss: 0.1379\n",
            "Restored model from best epoch 22 with val_loss: 0.137936\n",
            "NFL LSTM model 104/201 completed\n",
            "Split training data: 1559 train, 174 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.52, 0.525]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8063, Train Loss: 0.1423, Val Acc: 0.8333, Val Loss: 0.1239\n",
            "Restored model from best epoch 17 with val_loss: 0.123918\n",
            "NFL LSTM model 105/201 completed\n",
            "Split training data: 1647 train, 184 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.525, 0.53]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 106/201 completed\n",
            "Split training data: 1584 train, 177 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.53, 0.535]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.7879, Train Loss: 0.1485, Val Acc: 0.8023, Val Loss: 0.1490\n",
            "Restored model from best epoch 16 with val_loss: 0.149014\n",
            "NFL LSTM model 107/201 completed\n",
            "Split training data: 1665 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.535, 0.54]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8192, Train Loss: 0.1350, Val Acc: 0.8118, Val Loss: 0.1294\n",
            "Restored model from best epoch 8 with val_loss: 0.129354\n",
            "NFL LSTM model 108/201 completed\n",
            "Split training data: 1599 train, 178 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.54, 0.545]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.7955, Train Loss: 0.1512, Val Acc: 0.7921, Val Loss: 0.1549\n",
            "Restored model from best epoch 6 with val_loss: 0.154905\n",
            "NFL LSTM model 109/201 completed\n",
            "Split training data: 1595 train, 178 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.545, 0.55]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.7944, Train Loss: 0.1463, Val Acc: 0.7697, Val Loss: 0.1664\n",
            "Restored model from best epoch 5 with val_loss: 0.166384\n",
            "NFL LSTM model 110/201 completed\n",
            "Split training data: 1640 train, 183 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.55, 0.555]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.8329, Train Loss: 0.1299, Val Acc: 0.7814, Val Loss: 0.1500\n",
            "Restored model from best epoch 16 with val_loss: 0.150003\n",
            "NFL LSTM model 111/201 completed\n",
            "Split training data: 1621 train, 181 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.555, 0.56]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.8118, Train Loss: 0.1371, Val Acc: 0.8232, Val Loss: 0.1178\n",
            "Restored model from best epoch 20 with val_loss: 0.117802\n",
            "NFL LSTM model 112/201 completed\n",
            "Split training data: 1639 train, 183 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.56, 0.565]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 113/201 completed\n",
            "Split training data: 1677 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.565, 0.57]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 114/201 completed\n",
            "Split training data: 1705 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.57, 0.575]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8123, Train Loss: 0.1409, Val Acc: 0.8158, Val Loss: 0.1384\n",
            "Restored model from best epoch 6 with val_loss: 0.138398\n",
            "NFL LSTM model 115/201 completed\n",
            "Split training data: 1701 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.575, 0.58]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 116/201 completed\n",
            "Split training data: 1615 train, 180 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.58, 0.585]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.7963, Train Loss: 0.1443, Val Acc: 0.8556, Val Loss: 0.1123\n",
            "Restored model from best epoch 7 with val_loss: 0.112327\n",
            "NFL LSTM model 117/201 completed\n",
            "Split training data: 1638 train, 182 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.585, 0.59]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8156, Train Loss: 0.1383, Val Acc: 0.8187, Val Loss: 0.1368\n",
            "Restored model from best epoch 6 with val_loss: 0.136782\n",
            "NFL LSTM model 118/201 completed\n",
            "Split training data: 1734 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.59, 0.595]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8097, Train Loss: 0.1410, Val Acc: 0.7565, Val Loss: 0.1500\n",
            "Restored model from best epoch 6 with val_loss: 0.149965\n",
            "NFL LSTM model 119/201 completed\n",
            "Split training data: 1705 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.595, 0.6]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 120/201 completed\n",
            "Split training data: 1667 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.6, 0.605]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8158, Train Loss: 0.1301, Val Acc: 0.8226, Val Loss: 0.1207\n",
            "Restored model from best epoch 22 with val_loss: 0.120718\n",
            "NFL LSTM model 121/201 completed\n",
            "Split training data: 1710 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.605, 0.61]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.8000, Train Loss: 0.1400, Val Acc: 0.7801, Val Loss: 0.1475\n",
            "Restored model from best epoch 5 with val_loss: 0.147482\n",
            "NFL LSTM model 122/201 completed\n",
            "Split training data: 1722 train, 192 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.61, 0.615]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.8159, Train Loss: 0.1344, Val Acc: 0.8125, Val Loss: 0.1242\n",
            "Restored model from best epoch 14 with val_loss: 0.124215\n",
            "NFL LSTM model 123/201 completed\n",
            "Split training data: 1683 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.615, 0.62]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8271, Train Loss: 0.1271, Val Acc: 0.8075, Val Loss: 0.1333\n",
            "Restored model from best epoch 22 with val_loss: 0.133344\n",
            "NFL LSTM model 124/201 completed\n",
            "Split training data: 1670 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.62, 0.625]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 125/201 completed\n",
            "Split training data: 1734 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.625, 0.63]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 126/201 completed\n",
            "Split training data: 1679 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.63, 0.635]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8154, Train Loss: 0.1298, Val Acc: 0.8396, Val Loss: 0.1196\n",
            "Restored model from best epoch 15 with val_loss: 0.119646\n",
            "NFL LSTM model 127/201 completed\n",
            "Split training data: 1671 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.635, 0.64]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8282, Train Loss: 0.1267, Val Acc: 0.7957, Val Loss: 0.1391\n",
            "Restored model from best epoch 21 with val_loss: 0.139093\n",
            "NFL LSTM model 128/201 completed\n",
            "Split training data: 1600 train, 178 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.64, 0.645]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8125, Train Loss: 0.1322, Val Acc: 0.8034, Val Loss: 0.1425\n",
            "Restored model from best epoch 6 with val_loss: 0.142463\n",
            "NFL LSTM model 129/201 completed\n",
            "Split training data: 1738 train, 194 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.645, 0.65]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8147, Train Loss: 0.1338, Val Acc: 0.8454, Val Loss: 0.1046\n",
            "Restored model from best epoch 21 with val_loss: 0.104600\n",
            "NFL LSTM model 130/201 completed\n",
            "Split training data: 1681 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.65, 0.655]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 131/201 completed\n",
            "Split training data: 1713 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.655, 0.66]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.8342, Train Loss: 0.1234, Val Acc: 0.8534, Val Loss: 0.1202\n",
            "Restored model from best epoch 18 with val_loss: 0.120238\n",
            "NFL LSTM model 132/201 completed\n",
            "Split training data: 1717 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.66, 0.665]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 133/201 completed\n",
            "Split training data: 1679 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.665, 0.67]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.8362, Train Loss: 0.1246, Val Acc: 0.8342, Val Loss: 0.1228\n",
            "Restored model from best epoch 13 with val_loss: 0.122775\n",
            "NFL LSTM model 134/201 completed\n",
            "Split training data: 1689 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.67, 0.675]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8283, Train Loss: 0.1291, Val Acc: 0.8404, Val Loss: 0.1197\n",
            "Restored model from best epoch 6 with val_loss: 0.119702\n",
            "NFL LSTM model 135/201 completed\n",
            "Split training data: 1639 train, 183 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.675, 0.68]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8371, Train Loss: 0.1226, Val Acc: 0.8470, Val Loss: 0.1078\n",
            "Restored model from best epoch 22 with val_loss: 0.107770\n",
            "NFL LSTM model 136/201 completed\n",
            "Split training data: 1665 train, 185 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.68, 0.685]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8258, Train Loss: 0.1291, Val Acc: 0.8703, Val Loss: 0.1065\n",
            "Restored model from best epoch 11 with val_loss: 0.106487\n",
            "NFL LSTM model 137/201 completed\n",
            "Split training data: 1733 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.685, 0.69]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 138/201 completed\n",
            "Split training data: 1687 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.69, 0.695]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.8346, Train Loss: 0.1229, Val Acc: 0.8564, Val Loss: 0.1155\n",
            "Restored model from best epoch 13 with val_loss: 0.115458\n",
            "NFL LSTM model 139/201 completed\n",
            "Split training data: 1664 train, 185 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.695, 0.7]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 17, Train Acc: 0.8606, Train Loss: 0.1082, Val Acc: 0.8162, Val Loss: 0.1324\n",
            "Restored model from best epoch 17 with val_loss: 0.132421\n",
            "NFL LSTM model 140/201 completed\n",
            "Split training data: 1711 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.7, 0.705]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8317, Train Loss: 0.1281, Val Acc: 0.8586, Val Loss: 0.1168\n",
            "Restored model from best epoch 8 with val_loss: 0.116802\n",
            "NFL LSTM model 141/201 completed\n",
            "Split training data: 1638 train, 182 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.705, 0.71]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8321, Train Loss: 0.1216, Val Acc: 0.8132, Val Loss: 0.1265\n",
            "Restored model from best epoch 10 with val_loss: 0.126457\n",
            "NFL LSTM model 142/201 completed\n",
            "Split training data: 1639 train, 183 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.71, 0.715]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8487, Train Loss: 0.1173, Val Acc: 0.8033, Val Loss: 0.1325\n",
            "Restored model from best epoch 11 with val_loss: 0.132544\n",
            "NFL LSTM model 143/201 completed\n",
            "Split training data: 1706 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.715, 0.72]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8236, Train Loss: 0.1217, Val Acc: 0.8263, Val Loss: 0.1214\n",
            "Restored model from best epoch 21 with val_loss: 0.121363\n",
            "NFL LSTM model 144/201 completed\n",
            "Split training data: 1688 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.72, 0.725]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 145/201 completed\n",
            "Split training data: 1735 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.725, 0.73]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8421, Train Loss: 0.1159, Val Acc: 0.8497, Val Loss: 0.1186\n",
            "Restored model from best epoch 21 with val_loss: 0.118628\n",
            "NFL LSTM model 146/201 completed\n",
            "Split training data: 1721 train, 192 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.73, 0.735]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 9, Train Acc: 0.8431, Train Loss: 0.1159, Val Acc: 0.7969, Val Loss: 0.1469\n",
            "Restored model from best epoch 9 with val_loss: 0.146910\n",
            "NFL LSTM model 147/201 completed\n",
            "Split training data: 1666 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.735, 0.74]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.8523, Train Loss: 0.1122, Val Acc: 0.8817, Val Loss: 0.0998\n",
            "Restored model from best epoch 25 with val_loss: 0.099775\n",
            "NFL LSTM model 148/201 completed\n",
            "Split training data: 1551 train, 173 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.74, 0.745]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8433, Train Loss: 0.1181, Val Acc: 0.8324, Val Loss: 0.1217\n",
            "Restored model from best epoch 8 with val_loss: 0.121743\n",
            "NFL LSTM model 149/201 completed\n",
            "Split training data: 1493 train, 166 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.745, 0.75]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.8607, Train Loss: 0.1062, Val Acc: 0.8313, Val Loss: 0.0966\n",
            "Restored model from best epoch 25 with val_loss: 0.096643\n",
            "NFL LSTM model 150/201 completed\n",
            "Split training data: 4825 train, 537 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.75, 0.755]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 25, Train Acc: 0.8551, Train Loss: 0.1053, Val Acc: 0.8752, Val Loss: 0.0956\n",
            "Restored model from best epoch 25 with val_loss: 0.095561\n",
            "NFL LSTM model 151/201 completed\n",
            "Split training data: 993 train, 111 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.755, 0.76]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.8741, Train Loss: 0.0962, Val Acc: 0.9099, Val Loss: 0.0660\n",
            "Restored model from best epoch 20 with val_loss: 0.065998\n",
            "NFL LSTM model 152/201 completed\n",
            "Split training data: 1325 train, 148 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.76, 0.765]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8679, Train Loss: 0.1022, Val Acc: 0.8649, Val Loss: 0.1059\n",
            "Restored model from best epoch 15 with val_loss: 0.105942\n",
            "NFL LSTM model 153/201 completed\n",
            "Split training data: 1746 train, 194 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.765, 0.77]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 154/201 completed\n",
            "Split training data: 1511 train, 168 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.77, 0.775]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 155/201 completed\n",
            "Split training data: 1859 train, 207 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.775, 0.78]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8628, Train Loss: 0.0990, Val Acc: 0.8309, Val Loss: 0.1173\n",
            "Restored model from best epoch 15 with val_loss: 0.117301\n",
            "NFL LSTM model 156/201 completed\n",
            "Split training data: 1592 train, 177 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.78, 0.785]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 11, Train Acc: 0.8505, Train Loss: 0.1097, Val Acc: 0.8531, Val Loss: 0.1116\n",
            "Restored model from best epoch 11 with val_loss: 0.111632\n",
            "NFL LSTM model 157/201 completed\n",
            "Split training data: 1737 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.785, 0.79]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8526, Train Loss: 0.1092, Val Acc: 0.8653, Val Loss: 0.0915\n",
            "Restored model from best epoch 21 with val_loss: 0.091540\n",
            "NFL LSTM model 158/201 completed\n",
            "Split training data: 1630 train, 182 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.79, 0.795]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.8663, Train Loss: 0.1043, Val Acc: 0.8187, Val Loss: 0.1355\n",
            "Restored model from best epoch 5 with val_loss: 0.135526\n",
            "NFL LSTM model 159/201 completed\n",
            "Split training data: 1611 train, 179 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.795, 0.8]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.8349, Train Loss: 0.1199, Val Acc: 0.8324, Val Loss: 0.1281\n",
            "Restored model from best epoch 5 with val_loss: 0.128118\n",
            "NFL LSTM model 160/201 completed\n",
            "Split training data: 1800 train, 200 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.8, 0.805]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8561, Train Loss: 0.1086, Val Acc: 0.8550, Val Loss: 0.0934\n",
            "Restored model from best epoch 7 with val_loss: 0.093383\n",
            "NFL LSTM model 161/201 completed\n",
            "Split training data: 1728 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.805, 0.81]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.8634, Train Loss: 0.1013, Val Acc: 0.8756, Val Loss: 0.0787\n",
            "Restored model from best epoch 13 with val_loss: 0.078683\n",
            "NFL LSTM model 162/201 completed\n",
            "Split training data: 1706 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.81, 0.815]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.8658, Train Loss: 0.0991, Val Acc: 0.8579, Val Loss: 0.1051\n",
            "Restored model from best epoch 13 with val_loss: 0.105130\n",
            "NFL LSTM model 163/201 completed\n",
            "Split training data: 1681 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.815, 0.82]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8501, Train Loss: 0.1134, Val Acc: 0.8877, Val Loss: 0.0850\n",
            "Restored model from best epoch 6 with val_loss: 0.084954\n",
            "NFL LSTM model 164/201 completed\n",
            "Split training data: 1755 train, 195 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.82, 0.825]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8587, Train Loss: 0.1077, Val Acc: 0.8974, Val Loss: 0.0828\n",
            "Restored model from best epoch 6 with val_loss: 0.082792\n",
            "NFL LSTM model 165/201 completed\n",
            "Split training data: 1619 train, 180 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.825, 0.83]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 166/201 completed\n",
            "Split training data: 1687 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.83, 0.835]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.8637, Train Loss: 0.0980, Val Acc: 0.8723, Val Loss: 0.0953\n",
            "Restored model from best epoch 19 with val_loss: 0.095328\n",
            "NFL LSTM model 167/201 completed\n",
            "Split training data: 1695 train, 189 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.835, 0.84]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8814, Train Loss: 0.0932, Val Acc: 0.8730, Val Loss: 0.0904\n",
            "Restored model from best epoch 7 with val_loss: 0.090368\n",
            "NFL LSTM model 168/201 completed\n",
            "Split training data: 1687 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.84, 0.845]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8820, Train Loss: 0.0929, Val Acc: 0.8670, Val Loss: 0.0951\n",
            "Restored model from best epoch 7 with val_loss: 0.095061\n",
            "NFL LSTM model 169/201 completed\n",
            "Split training data: 1717 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.845, 0.85]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8526, Train Loss: 0.1064, Val Acc: 0.8586, Val Loss: 0.1017\n",
            "Restored model from best epoch 8 with val_loss: 0.101665\n",
            "NFL LSTM model 170/201 completed\n",
            "Split training data: 1709 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.85, 0.855]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 171/201 completed\n",
            "Split training data: 1665 train, 186 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.855, 0.86]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8805, Train Loss: 0.0884, Val Acc: 0.8925, Val Loss: 0.0847\n",
            "Restored model from best epoch 22 with val_loss: 0.084704\n",
            "NFL LSTM model 172/201 completed\n",
            "Split training data: 1709 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.86, 0.865]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 20, Train Acc: 0.8853, Train Loss: 0.0871, Val Acc: 0.8579, Val Loss: 0.1030\n",
            "Restored model from best epoch 20 with val_loss: 0.102958\n",
            "NFL LSTM model 173/201 completed\n",
            "Split training data: 1679 train, 187 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.865, 0.87]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 21, Train Acc: 0.8803, Train Loss: 0.0876, Val Acc: 0.9037, Val Loss: 0.0677\n",
            "Restored model from best epoch 21 with val_loss: 0.067677\n",
            "NFL LSTM model 174/201 completed\n",
            "Split training data: 1686 train, 188 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.87, 0.875]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8701, Train Loss: 0.0971, Val Acc: 0.8298, Val Loss: 0.1171\n",
            "Restored model from best epoch 10 with val_loss: 0.117091\n",
            "NFL LSTM model 175/201 completed\n",
            "Split training data: 1739 train, 194 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.875, 0.88]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.8798, Train Loss: 0.0870, Val Acc: 0.8866, Val Loss: 0.0937\n",
            "Restored model from best epoch 15 with val_loss: 0.093725\n",
            "NFL LSTM model 176/201 completed\n",
            "Split training data: 1704 train, 190 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.88, 0.885]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 8, Train Acc: 0.8668, Train Loss: 0.0987, Val Acc: 0.8947, Val Loss: 0.0755\n",
            "Restored model from best epoch 8 with val_loss: 0.075474\n",
            "NFL LSTM model 177/201 completed\n",
            "Split training data: 1711 train, 191 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.885, 0.89]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 18, Train Acc: 0.8656, Train Loss: 0.0932, Val Acc: 0.8639, Val Loss: 0.0960\n",
            "Restored model from best epoch 18 with val_loss: 0.095977\n",
            "NFL LSTM model 178/201 completed\n",
            "Split training data: 1736 train, 193 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.89, 0.895]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 179/201 completed\n",
            "Split training data: 1753 train, 195 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.895, 0.9]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8928, Train Loss: 0.0823, Val Acc: 0.8821, Val Loss: 0.0765\n",
            "Restored model from best epoch 12 with val_loss: 0.076456\n",
            "NFL LSTM model 180/201 completed\n",
            "Split training data: 1698 train, 189 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.9, 0.905]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 10\n",
            "Best epoch: 5, Train Acc: 0.8581, Train Loss: 0.1040, Val Acc: 0.8519, Val Loss: 0.1117\n",
            "Restored model from best epoch 5 with val_loss: 0.111697\n",
            "NFL LSTM model 181/201 completed\n",
            "Split training data: 1741 train, 194 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.905, 0.91]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8897, Train Loss: 0.0813, Val Acc: 0.8763, Val Loss: 0.0865\n",
            "Restored model from best epoch 12 with val_loss: 0.086548\n",
            "NFL LSTM model 182/201 completed\n",
            "Split training data: 1769 train, 197 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.91, 0.915]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 6, Train Acc: 0.8898, Train Loss: 0.0886, Val Acc: 0.8629, Val Loss: 0.1030\n",
            "Restored model from best epoch 6 with val_loss: 0.102989\n",
            "NFL LSTM model 183/201 completed\n",
            "Split training data: 1763 train, 196 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.915, 0.92]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 22, Train Acc: 0.8985, Train Loss: 0.0787, Val Acc: 0.8929, Val Loss: 0.0648\n",
            "Restored model from best epoch 22 with val_loss: 0.064795\n",
            "NFL LSTM model 184/201 completed\n",
            "Split training data: 1872 train, 208 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.92, 0.925]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.8953, Train Loss: 0.0830, Val Acc: 0.8654, Val Loss: 0.0966\n",
            "Restored model from best epoch 10 with val_loss: 0.096640\n",
            "NFL LSTM model 185/201 completed\n",
            "Split training data: 1945 train, 217 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.925, 0.93]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 7, Train Acc: 0.8946, Train Loss: 0.0830, Val Acc: 0.8756, Val Loss: 0.0887\n",
            "Restored model from best epoch 7 with val_loss: 0.088678\n",
            "NFL LSTM model 186/201 completed\n",
            "Split training data: 1921 train, 214 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.93, 0.935]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 187/201 completed\n",
            "Split training data: 2052 train, 228 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.935, 0.94]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8918, Train Loss: 0.0795, Val Acc: 0.9123, Val Loss: 0.0768\n",
            "Restored model from best epoch 12 with val_loss: 0.076786\n",
            "NFL LSTM model 188/201 completed\n",
            "Split training data: 2202 train, 245 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.94, 0.945]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 15, Train Acc: 0.9164, Train Loss: 0.0639, Val Acc: 0.8980, Val Loss: 0.0845\n",
            "Restored model from best epoch 15 with val_loss: 0.084457\n",
            "NFL LSTM model 189/201 completed\n",
            "Split training data: 2198 train, 245 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.945, 0.95]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.9026, Train Loss: 0.0737, Val Acc: 0.9347, Val Loss: 0.0472\n",
            "Restored model from best epoch 12 with val_loss: 0.047201\n",
            "NFL LSTM model 190/201 completed\n",
            "Split training data: 2246 train, 250 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.95, 0.955]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 191/201 completed\n",
            "Split training data: 2124 train, 236 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.955, 0.96]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 192/201 completed\n",
            "Split training data: 2258 train, 251 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.96, 0.965]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 12, Train Acc: 0.8924, Train Loss: 0.0786, Val Acc: 0.8845, Val Loss: 0.0738\n",
            "Restored model from best epoch 12 with val_loss: 0.073841\n",
            "NFL LSTM model 193/201 completed\n",
            "Split training data: 2055 train, 229 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.965, 0.97]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 10, Train Acc: 0.9017, Train Loss: 0.0764, Val Acc: 0.9170, Val Loss: 0.0485\n",
            "Restored model from best epoch 10 with val_loss: 0.048453\n",
            "NFL LSTM model 194/201 completed\n",
            "Split training data: 4770 train, 531 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.97, 0.975]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 16, Train Acc: 0.9086, Train Loss: 0.0673, Val Acc: 0.8964, Val Loss: 0.0808\n",
            "Restored model from best epoch 16 with val_loss: 0.080768\n",
            "NFL LSTM model 195/201 completed\n",
            "Split training data: 2214 train, 247 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.975, 0.98]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 14, Train Acc: 0.9088, Train Loss: 0.0724, Val Acc: 0.8947, Val Loss: 0.0822\n",
            "Restored model from best epoch 14 with val_loss: 0.082190\n",
            "NFL LSTM model 196/201 completed\n",
            "Split training data: 2312 train, 257 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.98, 0.985]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 13, Train Acc: 0.9122, Train Loss: 0.0675, Val Acc: 0.9261, Val Loss: 0.0510\n",
            "Restored model from best epoch 13 with val_loss: 0.050984\n",
            "NFL LSTM model 197/201 completed\n",
            "Split training data: 2234 train, 249 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.985, 0.99]\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 19, Train Acc: 0.9261, Train Loss: 0.0537, Val Acc: 0.9076, Val Loss: 0.0698\n",
            "Restored model from best epoch 19 with val_loss: 0.069815\n",
            "NFL LSTM model 198/201 completed\n",
            "Split training data: 2293 train, 255 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.99, 0.995]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 199/201 completed\n",
            "Split training data: 2268 train, 252 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [0.995, 1.0]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 200/201 completed\n",
            "Split training data: 2799 train, 312 validation\n",
            "\n",
            "Training direct prediction LSTM model for timestep range [1.0, 1.005]\n",
            "Starting training on device: cpu\n",
            "NFL LSTM model 201/201 completed\n"
          ]
        }
      ],
      "source": [
        "all_models[\"lstm\"] = setup_direct_lstm_models(training_data_seq, None, num_models=201)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Range [0.000, 0.005): 2484 train, 277 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 48\n",
            "Best epoch: 38, Train Acc: 0.6973, Train Loss: 0.5747, Val Acc: 0.7040, Val Loss: 0.5565\n",
            "Restored model from best epoch 38 with val_loss: 0.556524\n",
            "NFL direct model 1/200 completed\n",
            "Range [0.005, 0.010): 881 train, 98 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 38\n",
            "Best epoch: 28, Train Acc: 0.6958, Train Loss: 0.5708, Val Acc: 0.6939, Val Loss: 0.6093\n",
            "Restored model from best epoch 28 with val_loss: 0.609255\n",
            "NFL direct model 2/200 completed\n",
            "Range [0.010, 0.015): 1634 train, 182 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.6524, Train Loss: 0.6185, Val Acc: 0.7143, Val Loss: 0.5677\n",
            "Restored model from best epoch 2 with val_loss: 0.567706\n",
            "NFL direct model 3/200 completed\n",
            "Range [0.015, 0.020): 1382 train, 154 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.6766, Train Loss: 0.6111, Val Acc: 0.6948, Val Loss: 0.5723\n",
            "Restored model from best epoch 10 with val_loss: 0.572290\n",
            "NFL direct model 4/200 completed\n",
            "Range [0.020, 0.025): 1546 train, 172 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.6442, Train Loss: 0.6350, Val Acc: 0.6337, Val Loss: 0.5962\n",
            "Restored model from best epoch 8 with val_loss: 0.596204\n",
            "NFL direct model 5/200 completed\n",
            "Range [0.025, 0.030): 1594 train, 178 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6575, Train Loss: 0.6249, Val Acc: 0.6517, Val Loss: 0.6105\n",
            "Restored model from best epoch 6 with val_loss: 0.610529\n",
            "NFL direct model 6/200 completed\n",
            "Range [0.030, 0.035): 1516 train, 169 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.6722, Train Loss: 0.6023, Val Acc: 0.6509, Val Loss: 0.6475\n",
            "Restored model from best epoch 14 with val_loss: 0.647476\n",
            "NFL direct model 7/200 completed\n",
            "Range [0.035, 0.040): 1646 train, 183 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6719, Train Loss: 0.6165, Val Acc: 0.6175, Val Loss: 0.6469\n",
            "Restored model from best epoch 7 with val_loss: 0.646944\n",
            "NFL direct model 8/200 completed\n",
            "Range [0.040, 0.045): 1568 train, 175 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6626, Train Loss: 0.6156, Val Acc: 0.6686, Val Loss: 0.5946\n",
            "Restored model from best epoch 4 with val_loss: 0.594578\n",
            "NFL direct model 9/200 completed\n",
            "Range [0.045, 0.050): 1678 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6657, Train Loss: 0.6201, Val Acc: 0.7166, Val Loss: 0.5744\n",
            "Restored model from best epoch 4 with val_loss: 0.574442\n",
            "NFL direct model 10/200 completed\n",
            "Range [0.050, 0.055): 1630 train, 182 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.6706, Train Loss: 0.6013, Val Acc: 0.6319, Val Loss: 0.6287\n",
            "Restored model from best epoch 14 with val_loss: 0.628733\n",
            "NFL direct model 11/200 completed\n",
            "Range [0.055, 0.060): 1573 train, 175 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.6872, Train Loss: 0.5943, Val Acc: 0.6743, Val Loss: 0.5952\n",
            "Restored model from best epoch 14 with val_loss: 0.595216\n",
            "NFL direct model 12/200 completed\n",
            "Range [0.060, 0.065): 1708 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6833, Train Loss: 0.5974, Val Acc: 0.6632, Val Loss: 0.6452\n",
            "Restored model from best epoch 4 with val_loss: 0.645242\n",
            "NFL direct model 13/200 completed\n",
            "Range [0.065, 0.070): 1642 train, 183 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6705, Train Loss: 0.6139, Val Acc: 0.6995, Val Loss: 0.5854\n",
            "Restored model from best epoch 4 with val_loss: 0.585398\n",
            "NFL direct model 14/200 completed\n",
            "Range [0.070, 0.075): 1677 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.6887, Train Loss: 0.5924, Val Acc: 0.7166, Val Loss: 0.5776\n",
            "Restored model from best epoch 11 with val_loss: 0.577626\n",
            "NFL direct model 15/200 completed\n",
            "Range [0.075, 0.080): 1629 train, 181 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.6599, Train Loss: 0.6085, Val Acc: 0.7403, Val Loss: 0.5490\n",
            "Restored model from best epoch 6 with val_loss: 0.548964\n",
            "NFL direct model 16/200 completed\n",
            "Range [0.080, 0.085): 1692 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7021, Train Loss: 0.5789, Val Acc: 0.7234, Val Loss: 0.5561\n",
            "Restored model from best epoch 10 with val_loss: 0.556071\n",
            "NFL direct model 17/200 completed\n",
            "Range [0.085, 0.090): 1711 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.6861, Train Loss: 0.5972, Val Acc: 0.6859, Val Loss: 0.5942\n",
            "Restored model from best epoch 7 with val_loss: 0.594213\n",
            "NFL direct model 18/200 completed\n",
            "Range [0.090, 0.095): 1618 train, 180 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.6638, Train Loss: 0.6247, Val Acc: 0.6667, Val Loss: 0.6267\n",
            "Restored model from best epoch 2 with val_loss: 0.626682\n",
            "NFL direct model 19/200 completed\n",
            "Range [0.095, 0.100): 1692 train, 189 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.6838, Train Loss: 0.5898, Val Acc: 0.6561, Val Loss: 0.6174\n",
            "Restored model from best epoch 8 with val_loss: 0.617371\n",
            "NFL direct model 20/200 completed\n",
            "Range [0.100, 0.105): 1663 train, 185 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.6753, Train Loss: 0.6025, Val Acc: 0.6973, Val Loss: 0.5913\n",
            "Restored model from best epoch 4 with val_loss: 0.591311\n",
            "NFL direct model 21/200 completed\n",
            "Range [0.105, 0.110): 1647 train, 184 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7037, Train Loss: 0.5738, Val Acc: 0.6739, Val Loss: 0.5964\n",
            "Restored model from best epoch 11 with val_loss: 0.596386\n",
            "NFL direct model 22/200 completed\n",
            "Range [0.110, 0.115): 1702 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.6968, Train Loss: 0.5875, Val Acc: 0.6789, Val Loss: 0.5933\n",
            "Restored model from best epoch 10 with val_loss: 0.593278\n",
            "NFL direct model 23/200 completed\n",
            "Range [0.115, 0.120): 1637 train, 182 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.7135, Train Loss: 0.5596, Val Acc: 0.7582, Val Loss: 0.5313\n",
            "Restored model from best epoch 20 with val_loss: 0.531334\n",
            "NFL direct model 24/200 completed\n",
            "Range [0.120, 0.125): 1696 train, 189 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 29\n",
            "Best epoch: 19, Train Acc: 0.7152, Train Loss: 0.5639, Val Acc: 0.6984, Val Loss: 0.5830\n",
            "Restored model from best epoch 19 with val_loss: 0.583025\n",
            "NFL direct model 25/200 completed\n",
            "Range [0.125, 0.130): 1709 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7045, Train Loss: 0.5833, Val Acc: 0.6526, Val Loss: 0.6091\n",
            "Restored model from best epoch 3 with val_loss: 0.609074\n",
            "NFL direct model 26/200 completed\n",
            "Range [0.130, 0.135): 1688 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.6914, Train Loss: 0.5690, Val Acc: 0.6330, Val Loss: 0.6212\n",
            "Restored model from best epoch 5 with val_loss: 0.621210\n",
            "NFL direct model 27/200 completed\n",
            "Range [0.135, 0.140): 1660 train, 185 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.6958, Train Loss: 0.5718, Val Acc: 0.6919, Val Loss: 0.6011\n",
            "Restored model from best epoch 11 with val_loss: 0.601083\n",
            "NFL direct model 28/200 completed\n",
            "Range [0.140, 0.145): 1610 train, 179 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7062, Train Loss: 0.5808, Val Acc: 0.6983, Val Loss: 0.5853\n",
            "Restored model from best epoch 3 with val_loss: 0.585271\n",
            "NFL direct model 29/200 completed\n",
            "Range [0.145, 0.150): 1654 train, 184 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 41\n",
            "Best epoch: 31, Train Acc: 0.7527, Train Loss: 0.5026, Val Acc: 0.8043, Val Loss: 0.4922\n",
            "Restored model from best epoch 31 with val_loss: 0.492205\n",
            "NFL direct model 30/200 completed\n",
            "Range [0.150, 0.155): 1715 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.7306, Train Loss: 0.5412, Val Acc: 0.7696, Val Loss: 0.5097\n",
            "Restored model from best epoch 24 with val_loss: 0.509665\n",
            "NFL direct model 31/200 completed\n",
            "Range [0.155, 0.160): 1576 train, 176 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7049, Train Loss: 0.5675, Val Acc: 0.6648, Val Loss: 0.5961\n",
            "Restored model from best epoch 5 with val_loss: 0.596118\n",
            "NFL direct model 32/200 completed\n",
            "Range [0.160, 0.165): 1760 train, 196 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7125, Train Loss: 0.5780, Val Acc: 0.7347, Val Loss: 0.5016\n",
            "Restored model from best epoch 5 with val_loss: 0.501586\n",
            "NFL direct model 33/200 completed\n",
            "Range [0.165, 0.170): 1605 train, 179 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.6835, Train Loss: 0.5962, Val Acc: 0.7095, Val Loss: 0.5652\n",
            "Restored model from best epoch 5 with val_loss: 0.565151\n",
            "NFL direct model 34/200 completed\n",
            "Range [0.170, 0.175): 1659 train, 185 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.6401, Train Loss: 0.6447, Val Acc: 0.6757, Val Loss: 0.5860\n",
            "Restored model from best epoch 1 with val_loss: 0.585971\n",
            "NFL direct model 35/200 completed\n",
            "Range [0.175, 0.180): 1723 train, 192 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.6831, Train Loss: 0.5858, Val Acc: 0.7344, Val Loss: 0.5615\n",
            "Restored model from best epoch 5 with val_loss: 0.561536\n",
            "NFL direct model 36/200 completed\n",
            "Range [0.180, 0.185): 1614 train, 180 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7274, Train Loss: 0.5384, Val Acc: 0.7167, Val Loss: 0.5302\n",
            "Restored model from best epoch 16 with val_loss: 0.530195\n",
            "NFL direct model 37/200 completed\n",
            "Range [0.185, 0.190): 1669 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.7280, Train Loss: 0.5338, Val Acc: 0.7204, Val Loss: 0.5447\n",
            "Restored model from best epoch 15 with val_loss: 0.544746\n",
            "NFL direct model 38/200 completed\n",
            "Range [0.190, 0.195): 1615 train, 180 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.6904, Train Loss: 0.5861, Val Acc: 0.7333, Val Loss: 0.5409\n",
            "Restored model from best epoch 2 with val_loss: 0.540928\n",
            "NFL direct model 39/200 completed\n",
            "Range [0.195, 0.200): 1681 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.7371, Train Loss: 0.5094, Val Acc: 0.7380, Val Loss: 0.5029\n",
            "Restored model from best epoch 22 with val_loss: 0.502922\n",
            "NFL direct model 40/200 completed\n",
            "Range [0.200, 0.205): 1637 train, 182 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.7208, Train Loss: 0.5486, Val Acc: 0.7363, Val Loss: 0.5257\n",
            "Restored model from best epoch 13 with val_loss: 0.525671\n",
            "NFL direct model 41/200 completed\n",
            "Range [0.205, 0.210): 1653 train, 184 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7278, Train Loss: 0.5453, Val Acc: 0.7120, Val Loss: 0.5718\n",
            "Restored model from best epoch 9 with val_loss: 0.571833\n",
            "NFL direct model 42/200 completed\n",
            "Range [0.210, 0.215): 1749 train, 195 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 35\n",
            "Best epoch: 25, Train Acc: 0.7484, Train Loss: 0.5155, Val Acc: 0.7128, Val Loss: 0.6127\n",
            "Restored model from best epoch 25 with val_loss: 0.612683\n",
            "NFL direct model 43/200 completed\n",
            "Range [0.215, 0.220): 1578 train, 176 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7167, Train Loss: 0.5480, Val Acc: 0.7102, Val Loss: 0.5453\n",
            "Restored model from best epoch 9 with val_loss: 0.545265\n",
            "NFL direct model 44/200 completed\n",
            "Range [0.220, 0.225): 1689 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7288, Train Loss: 0.5227, Val Acc: 0.7394, Val Loss: 0.5126\n",
            "Restored model from best epoch 16 with val_loss: 0.512648\n",
            "NFL direct model 45/200 completed\n",
            "Range [0.225, 0.230): 1708 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7172, Train Loss: 0.5559, Val Acc: 0.7263, Val Loss: 0.5241\n",
            "Restored model from best epoch 7 with val_loss: 0.524054\n",
            "NFL direct model 46/200 completed\n",
            "Range [0.230, 0.235): 1597 train, 178 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7138, Train Loss: 0.5285, Val Acc: 0.7472, Val Loss: 0.5172\n",
            "Restored model from best epoch 9 with val_loss: 0.517221\n",
            "NFL direct model 47/200 completed\n",
            "Range [0.235, 0.240): 1715 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7382, Train Loss: 0.5310, Val Acc: 0.6911, Val Loss: 0.5689\n",
            "Restored model from best epoch 9 with val_loss: 0.568898\n",
            "NFL direct model 48/200 completed\n",
            "Range [0.240, 0.245): 1620 train, 180 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.6296, Train Loss: 0.6418, Val Acc: 0.6778, Val Loss: 0.6176\n",
            "Restored model from best epoch 1 with val_loss: 0.617589\n",
            "NFL direct model 49/200 completed\n",
            "Range [0.245, 0.250): 1519 train, 169 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 61\n",
            "Best epoch: 51, Train Acc: 0.7979, Train Loss: 0.4356, Val Acc: 0.7278, Val Loss: 0.5163\n",
            "Restored model from best epoch 51 with val_loss: 0.516339\n",
            "NFL direct model 50/200 completed\n",
            "Range [0.250, 0.255): 4953 train, 551 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 51\n",
            "Best epoch: 41, Train Acc: 0.7886, Train Loss: 0.4414, Val Acc: 0.7278, Val Loss: 0.5192\n",
            "Restored model from best epoch 41 with val_loss: 0.519158\n",
            "NFL direct model 51/200 completed\n",
            "Range [0.255, 0.260): 983 train, 110 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7050, Train Loss: 0.5560, Val Acc: 0.7182, Val Loss: 0.5290\n",
            "Restored model from best epoch 4 with val_loss: 0.529005\n",
            "NFL direct model 52/200 completed\n",
            "Range [0.260, 0.265): 1296 train, 144 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7014, Train Loss: 0.5824, Val Acc: 0.7431, Val Loss: 0.5718\n",
            "Restored model from best epoch 2 with val_loss: 0.571754\n",
            "NFL direct model 53/200 completed\n",
            "Range [0.265, 0.270): 1745 train, 194 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.7358, Train Loss: 0.5421, Val Acc: 0.7268, Val Loss: 0.5182\n",
            "Restored model from best epoch 5 with val_loss: 0.518190\n",
            "NFL direct model 54/200 completed\n",
            "Range [0.270, 0.275): 1559 train, 174 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7530, Train Loss: 0.5194, Val Acc: 0.7241, Val Loss: 0.5655\n",
            "Restored model from best epoch 14 with val_loss: 0.565539\n",
            "NFL direct model 55/200 completed\n",
            "Range [0.275, 0.280): 1774 train, 198 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7249, Train Loss: 0.5247, Val Acc: 0.6768, Val Loss: 0.5518\n",
            "Restored model from best epoch 12 with val_loss: 0.551814\n",
            "NFL direct model 56/200 completed\n",
            "Range [0.280, 0.285): 1539 train, 171 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7297, Train Loss: 0.5398, Val Acc: 0.7427, Val Loss: 0.5160\n",
            "Restored model from best epoch 9 with val_loss: 0.515953\n",
            "NFL direct model 57/200 completed\n",
            "Range [0.285, 0.290): 1782 train, 199 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7469, Train Loss: 0.5012, Val Acc: 0.7487, Val Loss: 0.4831\n",
            "Restored model from best epoch 14 with val_loss: 0.483120\n",
            "NFL direct model 58/200 completed\n",
            "Range [0.290, 0.295): 1626 train, 181 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.7362, Train Loss: 0.5259, Val Acc: 0.7348, Val Loss: 0.4896\n",
            "Restored model from best epoch 13 with val_loss: 0.489604\n",
            "NFL direct model 59/200 completed\n",
            "Range [0.295, 0.300): 1681 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.7674, Train Loss: 0.4921, Val Acc: 0.7487, Val Loss: 0.5296\n",
            "Restored model from best epoch 20 with val_loss: 0.529578\n",
            "NFL direct model 60/200 completed\n",
            "Range [0.300, 0.305): 1700 train, 189 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.7371, Train Loss: 0.5023, Val Acc: 0.7725, Val Loss: 0.5053\n",
            "Restored model from best epoch 14 with val_loss: 0.505277\n",
            "NFL direct model 61/200 completed\n",
            "Range [0.305, 0.310): 1585 train, 177 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.7413, Train Loss: 0.5163, Val Acc: 0.7006, Val Loss: 0.5653\n",
            "Restored model from best epoch 9 with val_loss: 0.565318\n",
            "NFL direct model 62/200 completed\n",
            "Range [0.310, 0.315): 1708 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.7693, Train Loss: 0.4796, Val Acc: 0.7158, Val Loss: 0.5341\n",
            "Restored model from best epoch 18 with val_loss: 0.534054\n",
            "NFL direct model 63/200 completed\n",
            "Range [0.315, 0.320): 1676 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.7309, Train Loss: 0.5373, Val Acc: 0.7433, Val Loss: 0.5509\n",
            "Restored model from best epoch 10 with val_loss: 0.550925\n",
            "NFL direct model 64/200 completed\n",
            "Range [0.320, 0.325): 1692 train, 189 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7571, Train Loss: 0.4884, Val Acc: 0.7513, Val Loss: 0.4922\n",
            "Restored model from best epoch 11 with val_loss: 0.492179\n",
            "NFL direct model 65/200 completed\n",
            "Range [0.325, 0.330): 1621 train, 181 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7551, Train Loss: 0.5103, Val Acc: 0.7017, Val Loss: 0.5693\n",
            "Restored model from best epoch 7 with val_loss: 0.569339\n",
            "NFL direct model 66/200 completed\n",
            "Range [0.330, 0.335): 1678 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.7712, Train Loss: 0.4725, Val Acc: 0.7273, Val Loss: 0.5099\n",
            "Restored model from best epoch 20 with val_loss: 0.509908\n",
            "NFL direct model 67/200 completed\n",
            "Range [0.335, 0.340): 1708 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7576, Train Loss: 0.4946, Val Acc: 0.7526, Val Loss: 0.5339\n",
            "Restored model from best epoch 11 with val_loss: 0.533883\n",
            "NFL direct model 68/200 completed\n",
            "Range [0.340, 0.345): 1650 train, 184 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.7752, Train Loss: 0.4695, Val Acc: 0.7446, Val Loss: 0.4694\n",
            "Restored model from best epoch 22 with val_loss: 0.469419\n",
            "NFL direct model 69/200 completed\n",
            "Range [0.345, 0.350): 1734 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7347, Train Loss: 0.5567, Val Acc: 0.7254, Val Loss: 0.4971\n",
            "Restored model from best epoch 2 with val_loss: 0.497131\n",
            "NFL direct model 70/200 completed\n",
            "Range [0.350, 0.355): 1699 train, 189 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7722, Train Loss: 0.4704, Val Acc: 0.7354, Val Loss: 0.4846\n",
            "Restored model from best epoch 16 with val_loss: 0.484585\n",
            "NFL direct model 71/200 completed\n",
            "Range [0.355, 0.360): 1688 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7601, Train Loss: 0.4968, Val Acc: 0.7394, Val Loss: 0.5019\n",
            "Restored model from best epoch 12 with val_loss: 0.501938\n",
            "NFL direct model 72/200 completed\n",
            "Range [0.360, 0.365): 1653 train, 184 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7381, Train Loss: 0.5356, Val Acc: 0.7500, Val Loss: 0.4938\n",
            "Restored model from best epoch 3 with val_loss: 0.493823\n",
            "NFL direct model 73/200 completed\n",
            "Range [0.365, 0.370): 1719 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7510, Train Loss: 0.5194, Val Acc: 0.7906, Val Loss: 0.4762\n",
            "Restored model from best epoch 2 with val_loss: 0.476206\n",
            "NFL direct model 74/200 completed\n",
            "Range [0.370, 0.375): 1631 train, 182 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7505, Train Loss: 0.5100, Val Acc: 0.7473, Val Loss: 0.5163\n",
            "Restored model from best epoch 4 with val_loss: 0.516294\n",
            "NFL direct model 75/200 completed\n",
            "Range [0.375, 0.380): 1696 train, 189 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.7742, Train Loss: 0.4694, Val Acc: 0.7143, Val Loss: 0.5108\n",
            "Restored model from best epoch 16 with val_loss: 0.510817\n",
            "NFL direct model 76/200 completed\n",
            "Range [0.380, 0.385): 1652 train, 184 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.7791, Train Loss: 0.4776, Val Acc: 0.7228, Val Loss: 0.4938\n",
            "Restored model from best epoch 13 with val_loss: 0.493792\n",
            "NFL direct model 77/200 completed\n",
            "Range [0.385, 0.390): 1660 train, 185 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.7608, Train Loss: 0.4939, Val Acc: 0.7514, Val Loss: 0.5121\n",
            "Restored model from best epoch 7 with val_loss: 0.512092\n",
            "NFL direct model 78/200 completed\n",
            "Range [0.390, 0.395): 1664 train, 185 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.7500, Train Loss: 0.5066, Val Acc: 0.7351, Val Loss: 0.5018\n",
            "Restored model from best epoch 6 with val_loss: 0.501798\n",
            "NFL direct model 79/200 completed\n",
            "Range [0.395, 0.400): 1710 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.7842, Train Loss: 0.4484, Val Acc: 0.6895, Val Loss: 0.5173\n",
            "Restored model from best epoch 24 with val_loss: 0.517286\n",
            "NFL direct model 80/200 completed\n",
            "Range [0.400, 0.405): 1670 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.7503, Train Loss: 0.5065, Val Acc: 0.6882, Val Loss: 0.5413\n",
            "Restored model from best epoch 8 with val_loss: 0.541310\n",
            "NFL direct model 81/200 completed\n",
            "Range [0.405, 0.410): 1587 train, 177 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7706, Train Loss: 0.4924, Val Acc: 0.7345, Val Loss: 0.5505\n",
            "Restored model from best epoch 3 with val_loss: 0.550526\n",
            "NFL direct model 82/200 completed\n",
            "Range [0.410, 0.415): 1732 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7454, Train Loss: 0.5326, Val Acc: 0.7098, Val Loss: 0.4663\n",
            "Restored model from best epoch 2 with val_loss: 0.466268\n",
            "NFL direct model 83/200 completed\n",
            "Range [0.415, 0.420): 1669 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.7729, Train Loss: 0.4788, Val Acc: 0.7742, Val Loss: 0.4576\n",
            "Restored model from best epoch 11 with val_loss: 0.457602\n",
            "NFL direct model 84/200 completed\n",
            "Range [0.420, 0.425): 1720 train, 192 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.6715, Train Loss: 0.6077, Val Acc: 0.6875, Val Loss: 0.5688\n",
            "Restored model from best epoch 1 with val_loss: 0.568807\n",
            "NFL direct model 85/200 completed\n",
            "Range [0.425, 0.430): 1678 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.7706, Train Loss: 0.5067, Val Acc: 0.7219, Val Loss: 0.5375\n",
            "Restored model from best epoch 4 with val_loss: 0.537461\n",
            "NFL direct model 86/200 completed\n",
            "Range [0.430, 0.435): 1671 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 38\n",
            "Best epoch: 28, Train Acc: 0.7971, Train Loss: 0.4422, Val Acc: 0.7258, Val Loss: 0.5133\n",
            "Restored model from best epoch 28 with val_loss: 0.513290\n",
            "NFL direct model 87/200 completed\n",
            "Range [0.435, 0.440): 1731 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.6869, Train Loss: 0.6147, Val Acc: 0.8031, Val Loss: 0.6403\n",
            "Restored model from best epoch 1 with val_loss: 0.640308\n",
            "NFL direct model 88/200 completed\n",
            "Range [0.440, 0.445): 1637 train, 182 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 38\n",
            "Best epoch: 28, Train Acc: 0.8045, Train Loss: 0.4308, Val Acc: 0.7637, Val Loss: 0.4529\n",
            "Restored model from best epoch 28 with val_loss: 0.452855\n",
            "NFL direct model 89/200 completed\n",
            "Range [0.445, 0.450): 1709 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.8104, Train Loss: 0.4181, Val Acc: 0.7579, Val Loss: 0.4804\n",
            "Restored model from best epoch 22 with val_loss: 0.480385\n",
            "NFL direct model 90/200 completed\n",
            "Range [0.450, 0.455): 1690 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7479, Train Loss: 0.5157, Val Acc: 0.7872, Val Loss: 0.4939\n",
            "Restored model from best epoch 3 with val_loss: 0.493930\n",
            "NFL direct model 91/200 completed\n",
            "Range [0.455, 0.460): 1691 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 34\n",
            "Best epoch: 24, Train Acc: 0.7871, Train Loss: 0.4577, Val Acc: 0.7128, Val Loss: 0.4816\n",
            "Restored model from best epoch 24 with val_loss: 0.481619\n",
            "NFL direct model 92/200 completed\n",
            "Range [0.460, 0.465): 1723 train, 192 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.7882, Train Loss: 0.4415, Val Acc: 0.7917, Val Loss: 0.4374\n",
            "Restored model from best epoch 12 with val_loss: 0.437425\n",
            "NFL direct model 93/200 completed\n",
            "Range [0.465, 0.470): 1616 train, 180 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.7970, Train Loss: 0.4256, Val Acc: 0.8222, Val Loss: 0.3917\n",
            "Restored model from best epoch 17 with val_loss: 0.391677\n",
            "NFL direct model 94/200 completed\n",
            "Range [0.470, 0.475): 4663 train, 519 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7783, Train Loss: 0.4708, Val Acc: 0.7746, Val Loss: 0.4442\n",
            "Restored model from best epoch 2 with val_loss: 0.444162\n",
            "NFL direct model 95/200 completed\n",
            "Range [0.475, 0.480): 2369 train, 264 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.8088, Train Loss: 0.3844, Val Acc: 0.8030, Val Loss: 0.4123\n",
            "Restored model from best epoch 22 with val_loss: 0.412287\n",
            "NFL direct model 96/200 completed\n",
            "Range [0.480, 0.485): 2547 train, 284 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 25\n",
            "Best epoch: 15, Train Acc: 0.8084, Train Loss: 0.4188, Val Acc: 0.7993, Val Loss: 0.4502\n",
            "Restored model from best epoch 15 with val_loss: 0.450173\n",
            "NFL direct model 97/200 completed\n",
            "Range [0.485, 0.490): 2877 train, 320 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.8092, Train Loss: 0.3907, Val Acc: 0.8000, Val Loss: 0.4262\n",
            "Restored model from best epoch 23 with val_loss: 0.426244\n",
            "NFL direct model 98/200 completed\n",
            "Range [0.490, 0.495): 3471 train, 386 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7842, Train Loss: 0.4766, Val Acc: 0.7953, Val Loss: 0.4195\n",
            "Restored model from best epoch 3 with val_loss: 0.419520\n",
            "NFL direct model 99/200 completed\n",
            "Range [0.495, 0.500): 4170 train, 464 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 44\n",
            "Best epoch: 34, Train Acc: 0.8314, Train Loss: 0.3692, Val Acc: 0.7931, Val Loss: 0.4106\n",
            "Restored model from best epoch 34 with val_loss: 0.410630\n",
            "NFL direct model 100/200 completed\n",
            "Range [0.500, 0.505): 7587 train, 843 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 44\n",
            "Best epoch: 34, Train Acc: 0.8231, Train Loss: 0.3874, Val Acc: 0.7711, Val Loss: 0.4574\n",
            "Restored model from best epoch 34 with val_loss: 0.457446\n",
            "NFL direct model 101/200 completed\n",
            "Range [0.505, 0.510): 983 train, 110 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7813, Train Loss: 0.5024, Val Acc: 0.7727, Val Loss: 0.4633\n",
            "Restored model from best epoch 2 with val_loss: 0.463348\n",
            "NFL direct model 102/200 completed\n",
            "Range [0.510, 0.515): 1591 train, 177 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8127, Train Loss: 0.4211, Val Acc: 0.7288, Val Loss: 0.5169\n",
            "Restored model from best epoch 6 with val_loss: 0.516933\n",
            "NFL direct model 103/200 completed\n",
            "Range [0.515, 0.520): 1379 train, 154 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8151, Train Loss: 0.4256, Val Acc: 0.8312, Val Loss: 0.4133\n",
            "Restored model from best epoch 6 with val_loss: 0.413258\n",
            "NFL direct model 104/200 completed\n",
            "Range [0.520, 0.525): 1559 train, 174 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7845, Train Loss: 0.4526, Val Acc: 0.8161, Val Loss: 0.3882\n",
            "Restored model from best epoch 3 with val_loss: 0.388238\n",
            "NFL direct model 105/200 completed\n",
            "Range [0.525, 0.530): 1647 train, 184 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8154, Train Loss: 0.4297, Val Acc: 0.8207, Val Loss: 0.3709\n",
            "Restored model from best epoch 5 with val_loss: 0.370902\n",
            "NFL direct model 106/200 completed\n",
            "Range [0.530, 0.535): 1584 train, 177 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.7898, Train Loss: 0.4347, Val Acc: 0.7910, Val Loss: 0.4287\n",
            "Restored model from best epoch 13 with val_loss: 0.428741\n",
            "NFL direct model 107/200 completed\n",
            "Range [0.535, 0.540): 1665 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8240, Train Loss: 0.3909, Val Acc: 0.8118, Val Loss: 0.3715\n",
            "Restored model from best epoch 8 with val_loss: 0.371514\n",
            "NFL direct model 108/200 completed\n",
            "Range [0.540, 0.545): 1599 train, 178 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.7967, Train Loss: 0.4439, Val Acc: 0.7472, Val Loss: 0.5056\n",
            "Restored model from best epoch 3 with val_loss: 0.505633\n",
            "NFL direct model 109/200 completed\n",
            "Range [0.545, 0.550): 1595 train, 178 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8194, Train Loss: 0.4170, Val Acc: 0.7640, Val Loss: 0.4430\n",
            "Restored model from best epoch 12 with val_loss: 0.442979\n",
            "NFL direct model 110/200 completed\n",
            "Range [0.550, 0.555): 1640 train, 183 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8329, Train Loss: 0.3827, Val Acc: 0.8142, Val Loss: 0.3818\n",
            "Restored model from best epoch 17 with val_loss: 0.381803\n",
            "NFL direct model 111/200 completed\n",
            "Range [0.555, 0.560): 1621 train, 181 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8205, Train Loss: 0.4052, Val Acc: 0.8122, Val Loss: 0.4003\n",
            "Restored model from best epoch 13 with val_loss: 0.400321\n",
            "NFL direct model 112/200 completed\n",
            "Range [0.560, 0.565): 1639 train, 183 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8194, Train Loss: 0.3997, Val Acc: 0.7923, Val Loss: 0.4565\n",
            "Restored model from best epoch 11 with val_loss: 0.456458\n",
            "NFL direct model 113/200 completed\n",
            "Range [0.565, 0.570): 1677 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 37\n",
            "Best epoch: 27, Train Acc: 0.8283, Train Loss: 0.3752, Val Acc: 0.8396, Val Loss: 0.3808\n",
            "Restored model from best epoch 27 with val_loss: 0.380808\n",
            "NFL direct model 114/200 completed\n",
            "Range [0.570, 0.575): 1705 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8065, Train Loss: 0.4272, Val Acc: 0.8105, Val Loss: 0.3904\n",
            "Restored model from best epoch 3 with val_loss: 0.390382\n",
            "NFL direct model 115/200 completed\n",
            "Range [0.575, 0.580): 1701 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8048, Train Loss: 0.4111, Val Acc: 0.8000, Val Loss: 0.4215\n",
            "Restored model from best epoch 11 with val_loss: 0.421544\n",
            "NFL direct model 116/200 completed\n",
            "Range [0.580, 0.585): 1615 train, 180 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8105, Train Loss: 0.4173, Val Acc: 0.8167, Val Loss: 0.3799\n",
            "Restored model from best epoch 11 with val_loss: 0.379884\n",
            "NFL direct model 117/200 completed\n",
            "Range [0.585, 0.590): 1638 train, 182 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8211, Train Loss: 0.4121, Val Acc: 0.8077, Val Loss: 0.4329\n",
            "Restored model from best epoch 7 with val_loss: 0.432903\n",
            "NFL direct model 118/200 completed\n",
            "Range [0.590, 0.595): 1734 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8126, Train Loss: 0.4142, Val Acc: 0.7720, Val Loss: 0.3650\n",
            "Restored model from best epoch 10 with val_loss: 0.365044\n",
            "NFL direct model 119/200 completed\n",
            "Range [0.595, 0.600): 1705 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8088, Train Loss: 0.4205, Val Acc: 0.8000, Val Loss: 0.4491\n",
            "Restored model from best epoch 5 with val_loss: 0.449060\n",
            "NFL direct model 120/200 completed\n",
            "Range [0.600, 0.605): 1667 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.7912, Train Loss: 0.4565, Val Acc: 0.7688, Val Loss: 0.4451\n",
            "Restored model from best epoch 2 with val_loss: 0.445104\n",
            "NFL direct model 121/200 completed\n",
            "Range [0.605, 0.610): 1710 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8187, Train Loss: 0.3927, Val Acc: 0.8010, Val Loss: 0.4122\n",
            "Restored model from best epoch 8 with val_loss: 0.412224\n",
            "NFL direct model 122/200 completed\n",
            "Range [0.610, 0.615): 1722 train, 192 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8188, Train Loss: 0.3927, Val Acc: 0.7708, Val Loss: 0.4071\n",
            "Restored model from best epoch 16 with val_loss: 0.407051\n",
            "NFL direct model 123/200 completed\n",
            "Range [0.615, 0.620): 1683 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 38\n",
            "Best epoch: 28, Train Acc: 0.8485, Train Loss: 0.3458, Val Acc: 0.8235, Val Loss: 0.3564\n",
            "Restored model from best epoch 28 with val_loss: 0.356375\n",
            "NFL direct model 124/200 completed\n",
            "Range [0.620, 0.625): 1670 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.8305, Train Loss: 0.3778, Val Acc: 0.8118, Val Loss: 0.3779\n",
            "Restored model from best epoch 26 with val_loss: 0.377892\n",
            "NFL direct model 125/200 completed\n",
            "Range [0.625, 0.630): 1734 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8328, Train Loss: 0.3855, Val Acc: 0.7565, Val Loss: 0.4264\n",
            "Restored model from best epoch 14 with val_loss: 0.426401\n",
            "NFL direct model 126/200 completed\n",
            "Range [0.630, 0.635): 1679 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 11\n",
            "Best epoch: 1, Train Acc: 0.7600, Train Loss: 0.5371, Val Acc: 0.8128, Val Loss: 0.4291\n",
            "Restored model from best epoch 1 with val_loss: 0.429116\n",
            "NFL direct model 127/200 completed\n",
            "Range [0.635, 0.640): 1671 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8085, Train Loss: 0.4200, Val Acc: 0.8011, Val Loss: 0.4130\n",
            "Restored model from best epoch 5 with val_loss: 0.413036\n",
            "NFL direct model 128/200 completed\n",
            "Range [0.640, 0.645): 1600 train, 178 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8331, Train Loss: 0.3821, Val Acc: 0.7921, Val Loss: 0.4341\n",
            "Restored model from best epoch 11 with val_loss: 0.434124\n",
            "NFL direct model 129/200 completed\n",
            "Range [0.645, 0.650): 1738 train, 194 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 50\n",
            "Best epoch: 40, Train Acc: 0.8475, Train Loss: 0.3397, Val Acc: 0.8351, Val Loss: 0.3644\n",
            "Restored model from best epoch 40 with val_loss: 0.364405\n",
            "NFL direct model 130/200 completed\n",
            "Range [0.650, 0.655): 1681 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8281, Train Loss: 0.3731, Val Acc: 0.8075, Val Loss: 0.3966\n",
            "Restored model from best epoch 13 with val_loss: 0.396576\n",
            "NFL direct model 131/200 completed\n",
            "Range [0.655, 0.660): 1713 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.8506, Train Loss: 0.3440, Val Acc: 0.8063, Val Loss: 0.4037\n",
            "Restored model from best epoch 16 with val_loss: 0.403675\n",
            "NFL direct model 132/200 completed\n",
            "Range [0.660, 0.665): 1717 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 52\n",
            "Best epoch: 42, Train Acc: 0.8626, Train Loss: 0.3056, Val Acc: 0.8377, Val Loss: 0.2918\n",
            "Restored model from best epoch 42 with val_loss: 0.291767\n",
            "NFL direct model 133/200 completed\n",
            "Range [0.665, 0.670): 1679 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.8505, Train Loss: 0.3335, Val Acc: 0.8021, Val Loss: 0.3848\n",
            "Restored model from best epoch 23 with val_loss: 0.384764\n",
            "NFL direct model 134/200 completed\n",
            "Range [0.670, 0.675): 1689 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8271, Train Loss: 0.3957, Val Acc: 0.8511, Val Loss: 0.3742\n",
            "Restored model from best epoch 3 with val_loss: 0.374215\n",
            "NFL direct model 135/200 completed\n",
            "Range [0.675, 0.680): 1639 train, 183 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8347, Train Loss: 0.3753, Val Acc: 0.8361, Val Loss: 0.3316\n",
            "Restored model from best epoch 7 with val_loss: 0.331567\n",
            "NFL direct model 136/200 completed\n",
            "Range [0.680, 0.685): 1665 train, 185 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8078, Train Loss: 0.4025, Val Acc: 0.8162, Val Loss: 0.3793\n",
            "Restored model from best epoch 3 with val_loss: 0.379337\n",
            "NFL direct model 137/200 completed\n",
            "Range [0.685, 0.690): 1733 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8177, Train Loss: 0.3980, Val Acc: 0.8446, Val Loss: 0.3897\n",
            "Restored model from best epoch 4 with val_loss: 0.389736\n",
            "NFL direct model 138/200 completed\n",
            "Range [0.690, 0.695): 1687 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8263, Train Loss: 0.4014, Val Acc: 0.8138, Val Loss: 0.4270\n",
            "Restored model from best epoch 3 with val_loss: 0.426997\n",
            "NFL direct model 139/200 completed\n",
            "Range [0.695, 0.700): 1664 train, 185 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8504, Train Loss: 0.3379, Val Acc: 0.8432, Val Loss: 0.3472\n",
            "Restored model from best epoch 13 with val_loss: 0.347171\n",
            "NFL direct model 140/200 completed\n",
            "Range [0.700, 0.705): 1711 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8457, Train Loss: 0.3463, Val Acc: 0.7958, Val Loss: 0.4348\n",
            "Restored model from best epoch 11 with val_loss: 0.434756\n",
            "NFL direct model 141/200 completed\n",
            "Range [0.705, 0.710): 1638 train, 182 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 35\n",
            "Best epoch: 25, Train Acc: 0.8608, Train Loss: 0.3066, Val Acc: 0.8516, Val Loss: 0.2955\n",
            "Restored model from best epoch 25 with val_loss: 0.295533\n",
            "NFL direct model 142/200 completed\n",
            "Range [0.710, 0.715): 1639 train, 183 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8487, Train Loss: 0.3428, Val Acc: 0.7760, Val Loss: 0.4507\n",
            "Restored model from best epoch 9 with val_loss: 0.450687\n",
            "NFL direct model 143/200 completed\n",
            "Range [0.715, 0.720): 1706 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8458, Train Loss: 0.3468, Val Acc: 0.8316, Val Loss: 0.3632\n",
            "Restored model from best epoch 9 with val_loss: 0.363218\n",
            "NFL direct model 144/200 completed\n",
            "Range [0.720, 0.725): 1688 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 28\n",
            "Best epoch: 18, Train Acc: 0.8643, Train Loss: 0.3069, Val Acc: 0.8564, Val Loss: 0.3270\n",
            "Restored model from best epoch 18 with val_loss: 0.327035\n",
            "NFL direct model 145/200 completed\n",
            "Range [0.725, 0.730): 1735 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8455, Train Loss: 0.3397, Val Acc: 0.8446, Val Loss: 0.3947\n",
            "Restored model from best epoch 12 with val_loss: 0.394703\n",
            "NFL direct model 146/200 completed\n",
            "Range [0.730, 0.735): 1721 train, 192 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8466, Train Loss: 0.3478, Val Acc: 0.7812, Val Loss: 0.4216\n",
            "Restored model from best epoch 8 with val_loss: 0.421632\n",
            "NFL direct model 147/200 completed\n",
            "Range [0.735, 0.740): 1666 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8505, Train Loss: 0.3270, Val Acc: 0.8441, Val Loss: 0.3560\n",
            "Restored model from best epoch 14 with val_loss: 0.356004\n",
            "NFL direct model 148/200 completed\n",
            "Range [0.740, 0.745): 1551 train, 173 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8536, Train Loss: 0.3472, Val Acc: 0.8324, Val Loss: 0.3354\n",
            "Restored model from best epoch 9 with val_loss: 0.335361\n",
            "NFL direct model 149/200 completed\n",
            "Range [0.745, 0.750): 1493 train, 166 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8513, Train Loss: 0.3663, Val Acc: 0.8554, Val Loss: 0.3262\n",
            "Restored model from best epoch 7 with val_loss: 0.326216\n",
            "NFL direct model 150/200 completed\n",
            "Range [0.750, 0.755): 4825 train, 537 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 46\n",
            "Best epoch: 36, Train Acc: 0.8939, Train Loss: 0.2375, Val Acc: 0.8678, Val Loss: 0.3062\n",
            "Restored model from best epoch 36 with val_loss: 0.306150\n",
            "NFL direct model 151/200 completed\n",
            "Range [0.755, 0.760): 993 train, 111 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 35\n",
            "Best epoch: 25, Train Acc: 0.8862, Train Loss: 0.2624, Val Acc: 0.9099, Val Loss: 0.2069\n",
            "Restored model from best epoch 25 with val_loss: 0.206866\n",
            "NFL direct model 152/200 completed\n",
            "Range [0.760, 0.765): 1325 train, 148 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.8664, Train Loss: 0.3074, Val Acc: 0.8378, Val Loss: 0.4060\n",
            "Restored model from best epoch 9 with val_loss: 0.406049\n",
            "NFL direct model 153/200 completed\n",
            "Range [0.765, 0.770): 1746 train, 194 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 49\n",
            "Best epoch: 39, Train Acc: 0.8837, Train Loss: 0.2671, Val Acc: 0.8299, Val Loss: 0.2889\n",
            "Restored model from best epoch 39 with val_loss: 0.288910\n",
            "NFL direct model 154/200 completed\n",
            "Range [0.770, 0.775): 1511 train, 168 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 22\n",
            "Best epoch: 12, Train Acc: 0.8564, Train Loss: 0.3219, Val Acc: 0.8452, Val Loss: 0.3560\n",
            "Restored model from best epoch 12 with val_loss: 0.355997\n",
            "NFL direct model 155/200 completed\n",
            "Range [0.775, 0.780): 1859 train, 207 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8553, Train Loss: 0.3298, Val Acc: 0.8551, Val Loss: 0.3793\n",
            "Restored model from best epoch 3 with val_loss: 0.379305\n",
            "NFL direct model 156/200 completed\n",
            "Range [0.780, 0.785): 1592 train, 177 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 30\n",
            "Best epoch: 20, Train Acc: 0.8631, Train Loss: 0.2947, Val Acc: 0.8418, Val Loss: 0.3566\n",
            "Restored model from best epoch 20 with val_loss: 0.356627\n",
            "NFL direct model 157/200 completed\n",
            "Range [0.785, 0.790): 1737 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.8492, Train Loss: 0.3183, Val Acc: 0.8446, Val Loss: 0.2709\n",
            "Restored model from best epoch 11 with val_loss: 0.270862\n",
            "NFL direct model 158/200 completed\n",
            "Range [0.790, 0.795): 1630 train, 182 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8699, Train Loss: 0.3257, Val Acc: 0.8352, Val Loss: 0.3517\n",
            "Restored model from best epoch 3 with val_loss: 0.351721\n",
            "NFL direct model 159/200 completed\n",
            "Range [0.795, 0.800): 1611 train, 179 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8510, Train Loss: 0.3074, Val Acc: 0.8101, Val Loss: 0.3665\n",
            "Restored model from best epoch 10 with val_loss: 0.366504\n",
            "NFL direct model 160/200 completed\n",
            "Range [0.800, 0.805): 1800 train, 200 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 69\n",
            "Best epoch: 59, Train Acc: 0.9100, Train Loss: 0.2121, Val Acc: 0.8900, Val Loss: 0.2380\n",
            "Restored model from best epoch 59 with val_loss: 0.237975\n",
            "NFL direct model 161/200 completed\n",
            "Range [0.805, 0.810): 1728 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8727, Train Loss: 0.2963, Val Acc: 0.8446, Val Loss: 0.2591\n",
            "Restored model from best epoch 10 with val_loss: 0.259065\n",
            "NFL direct model 162/200 completed\n",
            "Range [0.810, 0.815): 1706 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8564, Train Loss: 0.3458, Val Acc: 0.8579, Val Loss: 0.3371\n",
            "Restored model from best epoch 3 with val_loss: 0.337062\n",
            "NFL direct model 163/200 completed\n",
            "Range [0.815, 0.820): 1681 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 33\n",
            "Best epoch: 23, Train Acc: 0.8822, Train Loss: 0.2661, Val Acc: 0.8610, Val Loss: 0.2563\n",
            "Restored model from best epoch 23 with val_loss: 0.256277\n",
            "NFL direct model 164/200 completed\n",
            "Range [0.820, 0.825): 1755 train, 195 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.8393, Train Loss: 0.3635, Val Acc: 0.8872, Val Loss: 0.3267\n",
            "Restored model from best epoch 2 with val_loss: 0.326651\n",
            "NFL direct model 165/200 completed\n",
            "Range [0.825, 0.830): 1619 train, 180 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 23\n",
            "Best epoch: 13, Train Acc: 0.8796, Train Loss: 0.2829, Val Acc: 0.8167, Val Loss: 0.3361\n",
            "Restored model from best epoch 13 with val_loss: 0.336124\n",
            "NFL direct model 166/200 completed\n",
            "Range [0.830, 0.835): 1687 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8720, Train Loss: 0.2982, Val Acc: 0.8723, Val Loss: 0.3112\n",
            "Restored model from best epoch 10 with val_loss: 0.311220\n",
            "NFL direct model 167/200 completed\n",
            "Range [0.835, 0.840): 1695 train, 189 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8838, Train Loss: 0.2982, Val Acc: 0.8836, Val Loss: 0.3012\n",
            "Restored model from best epoch 4 with val_loss: 0.301188\n",
            "NFL direct model 168/200 completed\n",
            "Range [0.840, 0.845): 1687 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8868, Train Loss: 0.2704, Val Acc: 0.8457, Val Loss: 0.3490\n",
            "Restored model from best epoch 7 with val_loss: 0.349037\n",
            "NFL direct model 169/200 completed\n",
            "Range [0.845, 0.850): 1717 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 13\n",
            "Best epoch: 3, Train Acc: 0.8422, Train Loss: 0.3844, Val Acc: 0.8743, Val Loss: 0.3133\n",
            "Restored model from best epoch 3 with val_loss: 0.313299\n",
            "NFL direct model 170/200 completed\n",
            "Range [0.850, 0.855): 1709 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 42\n",
            "Best epoch: 32, Train Acc: 0.9029, Train Loss: 0.2162, Val Acc: 0.9263, Val Loss: 0.2087\n",
            "Restored model from best epoch 32 with val_loss: 0.208749\n",
            "NFL direct model 171/200 completed\n",
            "Range [0.855, 0.860): 1665 train, 186 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8733, Train Loss: 0.2956, Val Acc: 0.8602, Val Loss: 0.2923\n",
            "Restored model from best epoch 4 with val_loss: 0.292285\n",
            "NFL direct model 172/200 completed\n",
            "Range [0.860, 0.865): 1709 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 17\n",
            "Best epoch: 7, Train Acc: 0.8853, Train Loss: 0.2828, Val Acc: 0.8474, Val Loss: 0.3262\n",
            "Restored model from best epoch 7 with val_loss: 0.326249\n",
            "NFL direct model 173/200 completed\n",
            "Range [0.865, 0.870): 1679 train, 187 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 27\n",
            "Best epoch: 17, Train Acc: 0.8904, Train Loss: 0.2662, Val Acc: 0.8930, Val Loss: 0.1932\n",
            "Restored model from best epoch 17 with val_loss: 0.193168\n",
            "NFL direct model 174/200 completed\n",
            "Range [0.870, 0.875): 1686 train, 188 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.8434, Train Loss: 0.3501, Val Acc: 0.8245, Val Loss: 0.3292\n",
            "Restored model from best epoch 2 with val_loss: 0.329222\n",
            "NFL direct model 175/200 completed\n",
            "Range [0.875, 0.880): 1739 train, 194 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8867, Train Loss: 0.2770, Val Acc: 0.8814, Val Loss: 0.2148\n",
            "Restored model from best epoch 10 with val_loss: 0.214770\n",
            "NFL direct model 176/200 completed\n",
            "Range [0.880, 0.885): 1704 train, 190 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.8638, Train Loss: 0.3032, Val Acc: 0.8368, Val Loss: 0.2952\n",
            "Restored model from best epoch 4 with val_loss: 0.295207\n",
            "NFL direct model 177/200 completed\n",
            "Range [0.885, 0.890): 1711 train, 191 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8778, Train Loss: 0.2641, Val Acc: 0.8586, Val Loss: 0.3031\n",
            "Restored model from best epoch 14 with val_loss: 0.303063\n",
            "NFL direct model 178/200 completed\n",
            "Range [0.890, 0.895): 1736 train, 193 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 41\n",
            "Best epoch: 31, Train Acc: 0.9038, Train Loss: 0.2269, Val Acc: 0.8964, Val Loss: 0.1706\n",
            "Restored model from best epoch 31 with val_loss: 0.170635\n",
            "NFL direct model 179/200 completed\n",
            "Range [0.895, 0.900): 1753 train, 195 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.8899, Train Loss: 0.2502, Val Acc: 0.8615, Val Loss: 0.2142\n",
            "Restored model from best epoch 10 with val_loss: 0.214227\n",
            "NFL direct model 180/200 completed\n",
            "Range [0.900, 0.905): 1698 train, 189 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 24\n",
            "Best epoch: 14, Train Acc: 0.8887, Train Loss: 0.2574, Val Acc: 0.8413, Val Loss: 0.3574\n",
            "Restored model from best epoch 14 with val_loss: 0.357425\n",
            "NFL direct model 181/200 completed\n",
            "Range [0.905, 0.910): 1741 train, 194 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.8690, Train Loss: 0.3337, Val Acc: 0.8660, Val Loss: 0.2906\n",
            "Restored model from best epoch 2 with val_loss: 0.290570\n",
            "NFL direct model 182/200 completed\n",
            "Range [0.910, 0.915): 1769 train, 197 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8932, Train Loss: 0.2519, Val Acc: 0.8731, Val Loss: 0.3064\n",
            "Restored model from best epoch 5 with val_loss: 0.306438\n",
            "NFL direct model 183/200 completed\n",
            "Range [0.915, 0.920): 1763 train, 196 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 41\n",
            "Best epoch: 31, Train Acc: 0.9212, Train Loss: 0.1835, Val Acc: 0.9286, Val Loss: 0.1187\n",
            "Restored model from best epoch 31 with val_loss: 0.118665\n",
            "NFL direct model 184/200 completed\n",
            "Range [0.920, 0.925): 1872 train, 208 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 36\n",
            "Best epoch: 26, Train Acc: 0.9087, Train Loss: 0.2060, Val Acc: 0.8990, Val Loss: 0.2100\n",
            "Restored model from best epoch 26 with val_loss: 0.209952\n",
            "NFL direct model 185/200 completed\n",
            "Range [0.925, 0.930): 1945 train, 217 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 26\n",
            "Best epoch: 16, Train Acc: 0.9039, Train Loss: 0.2149, Val Acc: 0.8571, Val Loss: 0.2547\n",
            "Restored model from best epoch 16 with val_loss: 0.254737\n",
            "NFL direct model 186/200 completed\n",
            "Range [0.930, 0.935): 1921 train, 214 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 32\n",
            "Best epoch: 22, Train Acc: 0.9089, Train Loss: 0.2166, Val Acc: 0.8972, Val Loss: 0.2361\n",
            "Restored model from best epoch 22 with val_loss: 0.236104\n",
            "NFL direct model 187/200 completed\n",
            "Range [0.935, 0.940): 2052 train, 228 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 18\n",
            "Best epoch: 8, Train Acc: 0.8977, Train Loss: 0.2322, Val Acc: 0.8684, Val Loss: 0.2647\n",
            "Restored model from best epoch 8 with val_loss: 0.264735\n",
            "NFL direct model 188/200 completed\n",
            "Range [0.940, 0.945): 2202 train, 245 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 19\n",
            "Best epoch: 9, Train Acc: 0.9178, Train Loss: 0.1947, Val Acc: 0.8816, Val Loss: 0.2286\n",
            "Restored model from best epoch 9 with val_loss: 0.228633\n",
            "NFL direct model 189/200 completed\n",
            "Range [0.945, 0.950): 2198 train, 245 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.8958, Train Loss: 0.2339, Val Acc: 0.9306, Val Loss: 0.2060\n",
            "Restored model from best epoch 5 with val_loss: 0.205955\n",
            "NFL direct model 190/200 completed\n",
            "Range [0.950, 0.955): 2246 train, 250 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 12\n",
            "Best epoch: 2, Train Acc: 0.8727, Train Loss: 0.3083, Val Acc: 0.9160, Val Loss: 0.1884\n",
            "Restored model from best epoch 2 with val_loss: 0.188388\n",
            "NFL direct model 191/200 completed\n",
            "Range [0.955, 0.960): 2124 train, 236 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.9237, Train Loss: 0.1708, Val Acc: 0.8814, Val Loss: 0.2176\n",
            "Restored model from best epoch 29 with val_loss: 0.217577\n",
            "NFL direct model 192/200 completed\n",
            "Range [0.960, 0.965): 2258 train, 251 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.8942, Train Loss: 0.2387, Val Acc: 0.8884, Val Loss: 0.2577\n",
            "Restored model from best epoch 6 with val_loss: 0.257698\n",
            "NFL direct model 193/200 completed\n",
            "Range [0.965, 0.970): 2055 train, 229 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 21\n",
            "Best epoch: 11, Train Acc: 0.9056, Train Loss: 0.2043, Val Acc: 0.9214, Val Loss: 0.1908\n",
            "Restored model from best epoch 11 with val_loss: 0.190842\n",
            "NFL direct model 194/200 completed\n",
            "Range [0.970, 0.975): 4770 train, 531 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 40\n",
            "Best epoch: 30, Train Acc: 0.9252, Train Loss: 0.1662, Val Acc: 0.9322, Val Loss: 0.1789\n",
            "Restored model from best epoch 30 with val_loss: 0.178921\n",
            "NFL direct model 195/200 completed\n",
            "Range [0.975, 0.980): 2214 train, 247 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 16\n",
            "Best epoch: 6, Train Acc: 0.9047, Train Loss: 0.2416, Val Acc: 0.8988, Val Loss: 0.2208\n",
            "Restored model from best epoch 6 with val_loss: 0.220802\n",
            "NFL direct model 196/200 completed\n",
            "Range [0.980, 0.985): 2312 train, 257 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 14\n",
            "Best epoch: 4, Train Acc: 0.9087, Train Loss: 0.2148, Val Acc: 0.8911, Val Loss: 0.2012\n",
            "Restored model from best epoch 4 with val_loss: 0.201197\n",
            "NFL direct model 197/200 completed\n",
            "Range [0.985, 0.990): 2234 train, 249 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 15\n",
            "Best epoch: 5, Train Acc: 0.9230, Train Loss: 0.1886, Val Acc: 0.8956, Val Loss: 0.2812\n",
            "Restored model from best epoch 5 with val_loss: 0.281246\n",
            "NFL direct model 198/200 completed\n",
            "Range [0.990, 0.995): 2293 train, 255 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 20\n",
            "Best epoch: 10, Train Acc: 0.9158, Train Loss: 0.1999, Val Acc: 0.8784, Val Loss: 0.2419\n",
            "Restored model from best epoch 10 with val_loss: 0.241934\n",
            "NFL direct model 199/200 completed\n",
            "Range [0.995, 1.000): 5067 train, 564 validation\n",
            "Starting training on device: cpu\n",
            "Early stopping at epoch 39\n",
            "Best epoch: 29, Train Acc: 0.9566, Train Loss: 0.1051, Val Acc: 0.9592, Val Loss: 0.1237\n",
            "Restored model from best epoch 29 with val_loss: 0.123710\n",
            "NFL direct model 200/200 completed\n"
          ]
        }
      ],
      "source": [
        "all_models[\"nn\"] = setup_direct_models(training_data, None, num_models=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing timestep: 0.0\n",
            "Timestep 0.00% : Training Loss = 0.6133, Accuracy = 0.6624, Test Loss = 0.6287, Test Accuracy = 0.6627\n",
            "Processing timestep: 0.005\n",
            "Timestep 0.50% : Training Loss = 0.6185, Accuracy = 0.6538, Test Loss = 0.6533, Test Accuracy = 0.5646\n",
            "Processing timestep: 0.01\n",
            "Timestep 1.00% : Training Loss = 0.6060, Accuracy = 0.6669, Test Loss = 0.6422, Test Accuracy = 0.6117\n",
            "Processing timestep: 0.015\n",
            "Timestep 1.50% : Training Loss = 0.6319, Accuracy = 0.6383, Test Loss = 0.6166, Test Accuracy = 0.6494\n",
            "Processing timestep: 0.02\n",
            "Timestep 2.00% : Training Loss = 0.6238, Accuracy = 0.6527, Test Loss = 0.6472, Test Accuracy = 0.6124\n",
            "Processing timestep: 0.025\n",
            "Timestep 2.50% : Training Loss = 0.6299, Accuracy = 0.6467, Test Loss = 0.6151, Test Accuracy = 0.6617\n",
            "Processing timestep: 0.03\n",
            "Timestep 3.00% : Training Loss = 0.6101, Accuracy = 0.6620, Test Loss = 0.6515, Test Accuracy = 0.5850\n",
            "Processing timestep: 0.035\n",
            "Timestep 3.50% : Training Loss = 0.6223, Accuracy = 0.6512, Test Loss = 0.6458, Test Accuracy = 0.5927\n",
            "Processing timestep: 0.04\n",
            "Timestep 4.00% : Training Loss = 0.6126, Accuracy = 0.6597, Test Loss = 0.6181, Test Accuracy = 0.6794\n",
            "Processing timestep: 0.045\n",
            "Timestep 4.50% : Training Loss = 0.6164, Accuracy = 0.6568, Test Loss = 0.6235, Test Accuracy = 0.6536\n",
            "Processing timestep: 0.05\n",
            "Timestep 5.00% : Training Loss = 0.6096, Accuracy = 0.6740, Test Loss = 0.6479, Test Accuracy = 0.5993\n",
            "Processing timestep: 0.055\n",
            "Timestep 5.50% : Training Loss = 0.6116, Accuracy = 0.6795, Test Loss = 0.6310, Test Accuracy = 0.6502\n",
            "Processing timestep: 0.06\n",
            "Timestep 6.00% : Training Loss = 0.6122, Accuracy = 0.6646, Test Loss = 0.6127, Test Accuracy = 0.6351\n",
            "Processing timestep: 0.065\n",
            "Timestep 6.50% : Training Loss = 0.6231, Accuracy = 0.6570, Test Loss = 0.6294, Test Accuracy = 0.6314\n",
            "Processing timestep: 0.07\n",
            "Timestep 7.00% : Training Loss = 0.6029, Accuracy = 0.6856, Test Loss = 0.6397, Test Accuracy = 0.6429\n",
            "Processing timestep: 0.075\n",
            "Timestep 7.50% : Training Loss = 0.6198, Accuracy = 0.6554, Test Loss = 0.6002, Test Accuracy = 0.6949\n",
            "Processing timestep: 0.08\n",
            "Timestep 8.00% : Training Loss = 0.6006, Accuracy = 0.6865, Test Loss = 0.5930, Test Accuracy = 0.6879\n",
            "Processing timestep: 0.085\n",
            "Timestep 8.50% : Training Loss = 0.6131, Accuracy = 0.6665, Test Loss = 0.6305, Test Accuracy = 0.6469\n",
            "Processing timestep: 0.09\n",
            "Timestep 9.00% : Training Loss = 0.6115, Accuracy = 0.6715, Test Loss = 0.6378, Test Accuracy = 0.6037\n",
            "Processing timestep: 0.095\n",
            "Timestep 9.50% : Training Loss = 0.6173, Accuracy = 0.6740, Test Loss = 0.6142, Test Accuracy = 0.6360\n",
            "Processing timestep: 0.1\n",
            "Timestep 10.00% : Training Loss = 0.5926, Accuracy = 0.6879, Test Loss = 0.6219, Test Accuracy = 0.6331\n",
            "Processing timestep: 0.105\n",
            "Timestep 10.50% : Training Loss = 0.5950, Accuracy = 0.6825, Test Loss = 0.6184, Test Accuracy = 0.6218\n",
            "Processing timestep: 0.11\n",
            "Timestep 11.00% : Training Loss = 0.6027, Accuracy = 0.6859, Test Loss = 0.6347, Test Accuracy = 0.6232\n",
            "Processing timestep: 0.115\n",
            "Timestep 11.50% : Training Loss = 0.5829, Accuracy = 0.6966, Test Loss = 0.6097, Test Accuracy = 0.6374\n",
            "Processing timestep: 0.12\n",
            "Timestep 12.00% : Training Loss = 0.5996, Accuracy = 0.6792, Test Loss = 0.6441, Test Accuracy = 0.6254\n",
            "Processing timestep: 0.125\n",
            "Timestep 12.50% : Training Loss = 0.5799, Accuracy = 0.6927, Test Loss = 0.5926, Test Accuracy = 0.6667\n",
            "Processing timestep: 0.13\n",
            "Timestep 13.00% : Training Loss = 0.5831, Accuracy = 0.6913, Test Loss = 0.6435, Test Accuracy = 0.6348\n",
            "Processing timestep: 0.135\n",
            "Timestep 13.50% : Training Loss = 0.6003, Accuracy = 0.6786, Test Loss = 0.6089, Test Accuracy = 0.6534\n",
            "Processing timestep: 0.14\n",
            "Timestep 14.00% : Training Loss = 0.5802, Accuracy = 0.6967, Test Loss = 0.6203, Test Accuracy = 0.6468\n",
            "Processing timestep: 0.145\n",
            "Timestep 14.50% : Training Loss = 0.5798, Accuracy = 0.6946, Test Loss = 0.5903, Test Accuracy = 0.6848\n",
            "Processing timestep: 0.15\n",
            "Timestep 15.00% : Training Loss = 0.5805, Accuracy = 0.6981, Test Loss = 0.6163, Test Accuracy = 0.6818\n",
            "Processing timestep: 0.155\n",
            "Timestep 15.50% : Training Loss = 0.5891, Accuracy = 0.6911, Test Loss = 0.6102, Test Accuracy = 0.6578\n",
            "Processing timestep: 0.16\n",
            "Timestep 16.00% : Training Loss = 0.5708, Accuracy = 0.6974, Test Loss = 0.6386, Test Accuracy = 0.6190\n",
            "Processing timestep: 0.165\n",
            "Timestep 16.50% : Training Loss = 0.5953, Accuracy = 0.6821, Test Loss = 0.6130, Test Accuracy = 0.6418\n",
            "Processing timestep: 0.17\n",
            "Timestep 17.00% : Training Loss = 0.5757, Accuracy = 0.7033, Test Loss = 0.6126, Test Accuracy = 0.6498\n",
            "Processing timestep: 0.175\n",
            "Timestep 17.50% : Training Loss = 0.5923, Accuracy = 0.6878, Test Loss = 0.6039, Test Accuracy = 0.6667\n",
            "Processing timestep: 0.18\n",
            "Timestep 18.00% : Training Loss = 0.5713, Accuracy = 0.6988, Test Loss = 0.6057, Test Accuracy = 0.6741\n",
            "Processing timestep: 0.185\n",
            "Timestep 18.50% : Training Loss = 0.5819, Accuracy = 0.7062, Test Loss = 0.5970, Test Accuracy = 0.6703\n",
            "Processing timestep: 0.19\n",
            "Timestep 19.00% : Training Loss = 0.5629, Accuracy = 0.7187, Test Loss = 0.5982, Test Accuracy = 0.6741\n",
            "Processing timestep: 0.195\n",
            "Timestep 19.50% : Training Loss = 0.5584, Accuracy = 0.7190, Test Loss = 0.6260, Test Accuracy = 0.6477\n",
            "Processing timestep: 0.2\n",
            "Timestep 20.00% : Training Loss = 0.5818, Accuracy = 0.7038, Test Loss = 0.5893, Test Accuracy = 0.6520\n",
            "Processing timestep: 0.205\n",
            "Timestep 20.50% : Training Loss = 0.5747, Accuracy = 0.6951, Test Loss = 0.5460, Test Accuracy = 0.7138\n",
            "Processing timestep: 0.21\n",
            "Timestep 21.00% : Training Loss = 0.5536, Accuracy = 0.7155, Test Loss = 0.6112, Test Accuracy = 0.6404\n",
            "Processing timestep: 0.215\n",
            "Timestep 21.50% : Training Loss = 0.5675, Accuracy = 0.7121, Test Loss = 0.5658, Test Accuracy = 0.6856\n",
            "Processing timestep: 0.22\n",
            "Timestep 22.00% : Training Loss = 0.5631, Accuracy = 0.7210, Test Loss = 0.5929, Test Accuracy = 0.6702\n",
            "Processing timestep: 0.225\n",
            "Timestep 22.50% : Training Loss = 0.5546, Accuracy = 0.7223, Test Loss = 0.5990, Test Accuracy = 0.6702\n",
            "Processing timestep: 0.23\n",
            "Timestep 23.00% : Training Loss = 0.5446, Accuracy = 0.7281, Test Loss = 0.5903, Test Accuracy = 0.6442\n",
            "Processing timestep: 0.235\n",
            "Timestep 23.50% : Training Loss = 0.5528, Accuracy = 0.7216, Test Loss = 0.5265, Test Accuracy = 0.7028\n",
            "Processing timestep: 0.24\n",
            "Timestep 24.00% : Training Loss = 0.5764, Accuracy = 0.7020, Test Loss = 0.5921, Test Accuracy = 0.6593\n",
            "Processing timestep: 0.245\n",
            "Timestep 24.50% : Training Loss = 0.5562, Accuracy = 0.7162, Test Loss = 0.5803, Test Accuracy = 0.6850\n",
            "Processing timestep: 0.25\n",
            "Timestep 25.00% : Training Loss = 0.5478, Accuracy = 0.7174, Test Loss = 0.5613, Test Accuracy = 0.6937\n",
            "Processing timestep: 0.255\n",
            "Timestep 25.50% : Training Loss = 0.5607, Accuracy = 0.7008, Test Loss = 0.5414, Test Accuracy = 0.7317\n",
            "Processing timestep: 0.26\n",
            "Timestep 26.00% : Training Loss = 0.5597, Accuracy = 0.7132, Test Loss = 0.5567, Test Accuracy = 0.6944\n",
            "Processing timestep: 0.265\n",
            "Timestep 26.50% : Training Loss = 0.5482, Accuracy = 0.7172, Test Loss = 0.5423, Test Accuracy = 0.7010\n",
            "Processing timestep: 0.27\n",
            "Timestep 27.00% : Training Loss = 0.5439, Accuracy = 0.7203, Test Loss = 0.5616, Test Accuracy = 0.6962\n",
            "Processing timestep: 0.275\n",
            "Timestep 27.50% : Training Loss = 0.5514, Accuracy = 0.6999, Test Loss = 0.5663, Test Accuracy = 0.6892\n",
            "Processing timestep: 0.28\n",
            "Timestep 28.00% : Training Loss = 0.5505, Accuracy = 0.7123, Test Loss = 0.5512, Test Accuracy = 0.7276\n",
            "Processing timestep: 0.285\n",
            "Timestep 28.50% : Training Loss = 0.5402, Accuracy = 0.7255, Test Loss = 0.5488, Test Accuracy = 0.6879\n",
            "Processing timestep: 0.29\n",
            "Timestep 29.00% : Training Loss = 0.5465, Accuracy = 0.7160, Test Loss = 0.5542, Test Accuracy = 0.7022\n",
            "Processing timestep: 0.295\n",
            "Timestep 29.50% : Training Loss = 0.5427, Accuracy = 0.7101, Test Loss = 0.5574, Test Accuracy = 0.7011\n",
            "Processing timestep: 0.3\n",
            "Timestep 30.00% : Training Loss = 0.5498, Accuracy = 0.7128, Test Loss = 0.5485, Test Accuracy = 0.7113\n",
            "Processing timestep: 0.305\n",
            "Timestep 30.50% : Training Loss = 0.5273, Accuracy = 0.7241, Test Loss = 0.5839, Test Accuracy = 0.6868\n",
            "Processing timestep: 0.31\n",
            "Timestep 31.00% : Training Loss = 0.5342, Accuracy = 0.7210, Test Loss = 0.5668, Test Accuracy = 0.6982\n",
            "Processing timestep: 0.315\n",
            "Timestep 31.50% : Training Loss = 0.5656, Accuracy = 0.6974, Test Loss = 0.5679, Test Accuracy = 0.6857\n",
            "Processing timestep: 0.32\n",
            "Timestep 32.00% : Training Loss = 0.5226, Accuracy = 0.7284, Test Loss = 0.5307, Test Accuracy = 0.7350\n",
            "Processing timestep: 0.325\n",
            "Timestep 32.50% : Training Loss = 0.5310, Accuracy = 0.7231, Test Loss = 0.5409, Test Accuracy = 0.7269\n",
            "Processing timestep: 0.33\n",
            "Timestep 33.00% : Training Loss = 0.5228, Accuracy = 0.7306, Test Loss = 0.5405, Test Accuracy = 0.7107\n",
            "Processing timestep: 0.335\n",
            "Timestep 33.50% : Training Loss = 0.5227, Accuracy = 0.7353, Test Loss = 0.5464, Test Accuracy = 0.7333\n",
            "Processing timestep: 0.34\n",
            "Timestep 34.00% : Training Loss = 0.5182, Accuracy = 0.7311, Test Loss = 0.5559, Test Accuracy = 0.6993\n",
            "Processing timestep: 0.345\n",
            "Timestep 34.50% : Training Loss = 0.5013, Accuracy = 0.7483, Test Loss = 0.5367, Test Accuracy = 0.7172\n",
            "Processing timestep: 0.35\n",
            "Timestep 35.00% : Training Loss = 0.5125, Accuracy = 0.7425, Test Loss = 0.5532, Test Accuracy = 0.7148\n",
            "Processing timestep: 0.355\n",
            "Timestep 35.50% : Training Loss = 0.5240, Accuracy = 0.7371, Test Loss = 0.5304, Test Accuracy = 0.7305\n",
            "Processing timestep: 0.36\n",
            "Timestep 36.00% : Training Loss = 0.5377, Accuracy = 0.7322, Test Loss = 0.5641, Test Accuracy = 0.7065\n",
            "Processing timestep: 0.365\n",
            "Timestep 36.50% : Training Loss = 0.5046, Accuracy = 0.7566, Test Loss = 0.5342, Test Accuracy = 0.7178\n",
            "Processing timestep: 0.37\n",
            "Timestep 37.00% : Training Loss = 0.5423, Accuracy = 0.7287, Test Loss = 0.5245, Test Accuracy = 0.7426\n",
            "Processing timestep: 0.375\n",
            "Timestep 37.50% : Training Loss = 0.5048, Accuracy = 0.7385, Test Loss = 0.5683, Test Accuracy = 0.7032\n",
            "Processing timestep: 0.38\n",
            "Timestep 38.00% : Training Loss = 0.4993, Accuracy = 0.7481, Test Loss = 0.5301, Test Accuracy = 0.7065\n",
            "Processing timestep: 0.385\n",
            "Timestep 38.50% : Training Loss = 0.5144, Accuracy = 0.7251, Test Loss = 0.5341, Test Accuracy = 0.7329\n",
            "Processing timestep: 0.39\n",
            "Timestep 39.00% : Training Loss = 0.5117, Accuracy = 0.7416, Test Loss = 0.5434, Test Accuracy = 0.6942\n",
            "Processing timestep: 0.395\n",
            "Timestep 39.50% : Training Loss = 0.5093, Accuracy = 0.7331, Test Loss = 0.5412, Test Accuracy = 0.7439\n",
            "Processing timestep: 0.4\n",
            "Timestep 40.00% : Training Loss = 0.5276, Accuracy = 0.7254, Test Loss = 0.5279, Test Accuracy = 0.7240\n",
            "Processing timestep: 0.405\n",
            "Timestep 40.50% : Training Loss = 0.4864, Accuracy = 0.7685, Test Loss = 0.5135, Test Accuracy = 0.7623\n",
            "Processing timestep: 0.41\n",
            "Timestep 41.00% : Training Loss = 0.5160, Accuracy = 0.7366, Test Loss = 0.4958, Test Accuracy = 0.7647\n",
            "Processing timestep: 0.415\n",
            "Timestep 41.50% : Training Loss = 0.5051, Accuracy = 0.7532, Test Loss = 0.5266, Test Accuracy = 0.7133\n",
            "Processing timestep: 0.42\n",
            "Timestep 42.00% : Training Loss = 0.5148, Accuracy = 0.7372, Test Loss = 0.5635, Test Accuracy = 0.7003\n",
            "Processing timestep: 0.425\n",
            "Timestep 42.50% : Training Loss = 0.4982, Accuracy = 0.7615, Test Loss = 0.5329, Test Accuracy = 0.7464\n",
            "Processing timestep: 0.43\n",
            "Timestep 43.00% : Training Loss = 0.4855, Accuracy = 0.7586, Test Loss = 0.5691, Test Accuracy = 0.6918\n",
            "Processing timestep: 0.435\n",
            "Timestep 43.50% : Training Loss = 0.4997, Accuracy = 0.7651, Test Loss = 0.5083, Test Accuracy = 0.7266\n",
            "Processing timestep: 0.44\n",
            "Timestep 44.00% : Training Loss = 0.4959, Accuracy = 0.7529, Test Loss = 0.5434, Test Accuracy = 0.7179\n",
            "Processing timestep: 0.445\n",
            "Timestep 44.50% : Training Loss = 0.4828, Accuracy = 0.7615, Test Loss = 0.5553, Test Accuracy = 0.7228\n",
            "Processing timestep: 0.45\n",
            "Timestep 45.00% : Training Loss = 0.4917, Accuracy = 0.7638, Test Loss = 0.5643, Test Accuracy = 0.6986\n",
            "Processing timestep: 0.455\n",
            "Timestep 45.50% : Training Loss = 0.5026, Accuracy = 0.7633, Test Loss = 0.5454, Test Accuracy = 0.6986\n",
            "Processing timestep: 0.46\n",
            "Timestep 46.00% : Training Loss = 0.4815, Accuracy = 0.7683, Test Loss = 0.5009, Test Accuracy = 0.7604\n",
            "Processing timestep: 0.465\n",
            "Timestep 46.50% : Training Loss = 0.4657, Accuracy = 0.7844, Test Loss = 0.5217, Test Accuracy = 0.7481\n",
            "Processing timestep: 0.47\n",
            "Timestep 47.00% : Training Loss = 0.4767, Accuracy = 0.7791, Test Loss = 0.5130, Test Accuracy = 0.7378\n",
            "Processing timestep: 0.475\n",
            "Timestep 47.50% : Training Loss = 0.4504, Accuracy = 0.7846, Test Loss = 0.4974, Test Accuracy = 0.7494\n",
            "Processing timestep: 0.48\n",
            "Timestep 48.00% : Training Loss = 0.4597, Accuracy = 0.7826, Test Loss = 0.5159, Test Accuracy = 0.7482\n",
            "Processing timestep: 0.485\n",
            "Timestep 48.50% : Training Loss = 0.4567, Accuracy = 0.7810, Test Loss = 0.5220, Test Accuracy = 0.7542\n",
            "Processing timestep: 0.49\n",
            "Timestep 49.00% : Training Loss = 0.4547, Accuracy = 0.7944, Test Loss = 0.5418, Test Accuracy = 0.7478\n",
            "Processing timestep: 0.495\n",
            "Timestep 49.50% : Training Loss = 0.4498, Accuracy = 0.7974, Test Loss = 0.4963, Test Accuracy = 0.7787\n",
            "Processing timestep: 0.5\n",
            "Timestep 50.00% : Training Loss = 0.4400, Accuracy = 0.7971, Test Loss = 0.4642, Test Accuracy = 0.7945\n",
            "Processing timestep: 0.505\n",
            "Timestep 50.50% : Training Loss = 0.4263, Accuracy = 0.8030, Test Loss = 0.5205, Test Accuracy = 0.7927\n",
            "Processing timestep: 0.51\n",
            "Timestep 51.00% : Training Loss = 0.4323, Accuracy = 0.8003, Test Loss = 0.4765, Test Accuracy = 0.7857\n",
            "Processing timestep: 0.515\n",
            "Timestep 51.50% : Training Loss = 0.4254, Accuracy = 0.8143, Test Loss = 0.4570, Test Accuracy = 0.8000\n",
            "Processing timestep: 0.52\n",
            "Timestep 52.00% : Training Loss = 0.4384, Accuracy = 0.7984, Test Loss = 0.4669, Test Accuracy = 0.8038\n",
            "Processing timestep: 0.525\n",
            "Timestep 52.50% : Training Loss = 0.4124, Accuracy = 0.8136, Test Loss = 0.4527, Test Accuracy = 0.8073\n",
            "Processing timestep: 0.53\n",
            "Timestep 53.00% : Training Loss = 0.4473, Accuracy = 0.7901, Test Loss = 0.4821, Test Accuracy = 0.7736\n",
            "Processing timestep: 0.535\n",
            "Timestep 53.50% : Training Loss = 0.3969, Accuracy = 0.8296, Test Loss = 0.4564, Test Accuracy = 0.8094\n",
            "Processing timestep: 0.54\n",
            "Timestep 54.00% : Training Loss = 0.4331, Accuracy = 0.8033, Test Loss = 0.5236, Test Accuracy = 0.7416\n",
            "Processing timestep: 0.545\n",
            "Timestep 54.50% : Training Loss = 0.4268, Accuracy = 0.8162, Test Loss = 0.5196, Test Accuracy = 0.7519\n",
            "Processing timestep: 0.55\n",
            "Timestep 55.00% : Training Loss = 0.4046, Accuracy = 0.8244, Test Loss = 0.4607, Test Accuracy = 0.8066\n",
            "Processing timestep: 0.555\n",
            "Timestep 55.50% : Training Loss = 0.4349, Accuracy = 0.8040, Test Loss = 0.4281, Test Accuracy = 0.8118\n",
            "Processing timestep: 0.56\n",
            "Timestep 56.00% : Training Loss = 0.4118, Accuracy = 0.8191, Test Loss = 0.4645, Test Accuracy = 0.7847\n",
            "Processing timestep: 0.565\n",
            "Timestep 56.50% : Training Loss = 0.4152, Accuracy = 0.8087, Test Loss = 0.4731, Test Accuracy = 0.7643\n",
            "Processing timestep: 0.57\n",
            "Timestep 57.00% : Training Loss = 0.4131, Accuracy = 0.8199, Test Loss = 0.4550, Test Accuracy = 0.7789\n",
            "Processing timestep: 0.575\n",
            "Timestep 57.50% : Training Loss = 0.4199, Accuracy = 0.8090, Test Loss = 0.4873, Test Accuracy = 0.7570\n",
            "Processing timestep: 0.58\n",
            "Timestep 58.00% : Training Loss = 0.4181, Accuracy = 0.8039, Test Loss = 0.4583, Test Accuracy = 0.7593\n",
            "Processing timestep: 0.585\n",
            "Timestep 58.50% : Training Loss = 0.4226, Accuracy = 0.8177, Test Loss = 0.4146, Test Accuracy = 0.8095\n",
            "Processing timestep: 0.59\n",
            "Timestep 59.00% : Training Loss = 0.4232, Accuracy = 0.8039, Test Loss = 0.4803, Test Accuracy = 0.7793\n",
            "Processing timestep: 0.595\n",
            "Timestep 59.50% : Training Loss = 0.4191, Accuracy = 0.8099, Test Loss = 0.4733, Test Accuracy = 0.7825\n",
            "Processing timestep: 0.6\n",
            "Timestep 60.00% : Training Loss = 0.4103, Accuracy = 0.8032, Test Loss = 0.4653, Test Accuracy = 0.7806\n",
            "Processing timestep: 0.605\n",
            "Timestep 60.50% : Training Loss = 0.4177, Accuracy = 0.8093, Test Loss = 0.4705, Test Accuracy = 0.7587\n",
            "Processing timestep: 0.61\n",
            "Timestep 61.00% : Training Loss = 0.4051, Accuracy = 0.8167, Test Loss = 0.4750, Test Accuracy = 0.7569\n",
            "Processing timestep: 0.615\n",
            "Timestep 61.50% : Training Loss = 0.3894, Accuracy = 0.8232, Test Loss = 0.4518, Test Accuracy = 0.7687\n",
            "Processing timestep: 0.62\n",
            "Timestep 62.00% : Training Loss = 0.4128, Accuracy = 0.8161, Test Loss = 0.4622, Test Accuracy = 0.7778\n",
            "Processing timestep: 0.625\n",
            "Timestep 62.50% : Training Loss = 0.4109, Accuracy = 0.8180, Test Loss = 0.4680, Test Accuracy = 0.7759\n",
            "Processing timestep: 0.63\n",
            "Timestep 63.00% : Training Loss = 0.3945, Accuracy = 0.8172, Test Loss = 0.4634, Test Accuracy = 0.7714\n",
            "Processing timestep: 0.635\n",
            "Timestep 63.50% : Training Loss = 0.4047, Accuracy = 0.8232, Test Loss = 0.4709, Test Accuracy = 0.7455\n",
            "Processing timestep: 0.64\n",
            "Timestep 64.00% : Training Loss = 0.3950, Accuracy = 0.8246, Test Loss = 0.4950, Test Accuracy = 0.7566\n",
            "Processing timestep: 0.645\n",
            "Timestep 64.50% : Training Loss = 0.4142, Accuracy = 0.8069, Test Loss = 0.4438, Test Accuracy = 0.7966\n",
            "Processing timestep: 0.65\n",
            "Timestep 65.00% : Training Loss = 0.4006, Accuracy = 0.8084, Test Loss = 0.5308, Test Accuracy = 0.7509\n",
            "Processing timestep: 0.655\n",
            "Timestep 65.50% : Training Loss = 0.3773, Accuracy = 0.8288, Test Loss = 0.4688, Test Accuracy = 0.7552\n",
            "Processing timestep: 0.66\n",
            "Timestep 66.00% : Training Loss = 0.3754, Accuracy = 0.8316, Test Loss = 0.4601, Test Accuracy = 0.7770\n",
            "Processing timestep: 0.665\n",
            "Timestep 66.50% : Training Loss = 0.3761, Accuracy = 0.8241, Test Loss = 0.4728, Test Accuracy = 0.7464\n",
            "Processing timestep: 0.67\n",
            "Timestep 67.00% : Training Loss = 0.3827, Accuracy = 0.8357, Test Loss = 0.4279, Test Accuracy = 0.7943\n",
            "Processing timestep: 0.675\n",
            "Timestep 67.50% : Training Loss = 0.3795, Accuracy = 0.8307, Test Loss = 0.4417, Test Accuracy = 0.7518\n",
            "Processing timestep: 0.68\n",
            "Timestep 68.00% : Training Loss = 0.3854, Accuracy = 0.8289, Test Loss = 0.4193, Test Accuracy = 0.7770\n",
            "Processing timestep: 0.685\n",
            "Timestep 68.50% : Training Loss = 0.3746, Accuracy = 0.8345, Test Loss = 0.4936, Test Accuracy = 0.7509\n",
            "Processing timestep: 0.69\n",
            "Timestep 69.00% : Training Loss = 0.3870, Accuracy = 0.8330, Test Loss = 0.4129, Test Accuracy = 0.7730\n",
            "Processing timestep: 0.695\n",
            "Timestep 69.50% : Training Loss = 0.3638, Accuracy = 0.8351, Test Loss = 0.4061, Test Accuracy = 0.7986\n",
            "Processing timestep: 0.7\n",
            "Timestep 70.00% : Training Loss = 0.3804, Accuracy = 0.8255, Test Loss = 0.4022, Test Accuracy = 0.8042\n",
            "Processing timestep: 0.705\n",
            "Timestep 70.50% : Training Loss = 0.3608, Accuracy = 0.8384, Test Loss = 0.4118, Test Accuracy = 0.7912\n",
            "Processing timestep: 0.71\n",
            "Timestep 71.00% : Training Loss = 0.3684, Accuracy = 0.8391, Test Loss = 0.4025, Test Accuracy = 0.7883\n",
            "Processing timestep: 0.715\n",
            "Timestep 71.50% : Training Loss = 0.3583, Accuracy = 0.8386, Test Loss = 0.4593, Test Accuracy = 0.7579\n",
            "Processing timestep: 0.72\n",
            "Timestep 72.00% : Training Loss = 0.3502, Accuracy = 0.8482, Test Loss = 0.4178, Test Accuracy = 0.8191\n",
            "Processing timestep: 0.725\n",
            "Timestep 72.50% : Training Loss = 0.3573, Accuracy = 0.8370, Test Loss = 0.4256, Test Accuracy = 0.7862\n",
            "Processing timestep: 0.73\n",
            "Timestep 73.00% : Training Loss = 0.3493, Accuracy = 0.8352, Test Loss = 0.4458, Test Accuracy = 0.8014\n",
            "Processing timestep: 0.735\n",
            "Timestep 73.50% : Training Loss = 0.3498, Accuracy = 0.8450, Test Loss = 0.4313, Test Accuracy = 0.7842\n",
            "Processing timestep: 0.74\n",
            "Timestep 74.00% : Training Loss = 0.3464, Accuracy = 0.8491, Test Loss = 0.3831, Test Accuracy = 0.8456\n",
            "Processing timestep: 0.745\n",
            "Timestep 74.50% : Training Loss = 0.3412, Accuracy = 0.8518, Test Loss = 0.4414, Test Accuracy = 0.7912\n",
            "Processing timestep: 0.75\n",
            "Timestep 75.00% : Training Loss = 0.3428, Accuracy = 0.8440, Test Loss = 0.3864, Test Accuracy = 0.8112\n",
            "Processing timestep: 0.755\n",
            "Timestep 75.50% : Training Loss = 0.3133, Accuracy = 0.8635, Test Loss = 0.3804, Test Accuracy = 0.8313\n",
            "Processing timestep: 0.76\n",
            "Timestep 76.00% : Training Loss = 0.3310, Accuracy = 0.8578, Test Loss = 0.3683, Test Accuracy = 0.8416\n",
            "Processing timestep: 0.765\n",
            "Timestep 76.50% : Training Loss = 0.3183, Accuracy = 0.8642, Test Loss = 0.4103, Test Accuracy = 0.8213\n",
            "Processing timestep: 0.77\n",
            "Timestep 77.00% : Training Loss = 0.3345, Accuracy = 0.8542, Test Loss = 0.4234, Test Accuracy = 0.7937\n",
            "Processing timestep: 0.775\n",
            "Timestep 77.50% : Training Loss = 0.3292, Accuracy = 0.8514, Test Loss = 0.3341, Test Accuracy = 0.8452\n",
            "Processing timestep: 0.78\n",
            "Timestep 78.00% : Training Loss = 0.3344, Accuracy = 0.8596, Test Loss = 0.4053, Test Accuracy = 0.8195\n",
            "Processing timestep: 0.785\n",
            "Timestep 78.50% : Training Loss = 0.3266, Accuracy = 0.8549, Test Loss = 0.4105, Test Accuracy = 0.8172\n",
            "Processing timestep: 0.79\n",
            "Timestep 79.00% : Training Loss = 0.3060, Accuracy = 0.8747, Test Loss = 0.3366, Test Accuracy = 0.8676\n",
            "Processing timestep: 0.795\n",
            "Timestep 79.50% : Training Loss = 0.3429, Accuracy = 0.8442, Test Loss = 0.3519, Test Accuracy = 0.8476\n",
            "Processing timestep: 0.8\n",
            "Timestep 80.00% : Training Loss = 0.3123, Accuracy = 0.8688, Test Loss = 0.3696, Test Accuracy = 0.8467\n",
            "Processing timestep: 0.805\n",
            "Timestep 80.50% : Training Loss = 0.3115, Accuracy = 0.8634, Test Loss = 0.3798, Test Accuracy = 0.8339\n",
            "Processing timestep: 0.81\n",
            "Timestep 81.00% : Training Loss = 0.3083, Accuracy = 0.8703, Test Loss = 0.3939, Test Accuracy = 0.8000\n",
            "Processing timestep: 0.815\n",
            "Timestep 81.50% : Training Loss = 0.3082, Accuracy = 0.8633, Test Loss = 0.3891, Test Accuracy = 0.8185\n",
            "Processing timestep: 0.82\n",
            "Timestep 82.00% : Training Loss = 0.3043, Accuracy = 0.8678, Test Loss = 0.3611, Test Accuracy = 0.8294\n",
            "Processing timestep: 0.825\n",
            "Timestep 82.50% : Training Loss = 0.3175, Accuracy = 0.8600, Test Loss = 0.3553, Test Accuracy = 0.8593\n",
            "Processing timestep: 0.83\n",
            "Timestep 83.00% : Training Loss = 0.2966, Accuracy = 0.8675, Test Loss = 0.3455, Test Accuracy = 0.8369\n",
            "Processing timestep: 0.835\n",
            "Timestep 83.50% : Training Loss = 0.2837, Accuracy = 0.8782, Test Loss = 0.2882, Test Accuracy = 0.8834\n",
            "Processing timestep: 0.84\n",
            "Timestep 84.00% : Training Loss = 0.2766, Accuracy = 0.8788, Test Loss = 0.3191, Test Accuracy = 0.8475\n",
            "Processing timestep: 0.845\n",
            "Timestep 84.50% : Training Loss = 0.3115, Accuracy = 0.8637, Test Loss = 0.3615, Test Accuracy = 0.8118\n",
            "Processing timestep: 0.85\n",
            "Timestep 85.00% : Training Loss = 0.2806, Accuracy = 0.8755, Test Loss = 0.3713, Test Accuracy = 0.8211\n",
            "Processing timestep: 0.855\n",
            "Timestep 85.50% : Training Loss = 0.2776, Accuracy = 0.8798, Test Loss = 0.3571, Test Accuracy = 0.8237\n",
            "Processing timestep: 0.86\n",
            "Timestep 86.00% : Training Loss = 0.2771, Accuracy = 0.8674, Test Loss = 0.3419, Test Accuracy = 0.8421\n",
            "Processing timestep: 0.865\n",
            "Timestep 86.50% : Training Loss = 0.2845, Accuracy = 0.8733, Test Loss = 0.2939, Test Accuracy = 0.8750\n",
            "Processing timestep: 0.87\n",
            "Timestep 87.00% : Training Loss = 0.2870, Accuracy = 0.8687, Test Loss = 0.3981, Test Accuracy = 0.7766\n",
            "Processing timestep: 0.875\n",
            "Timestep 87.50% : Training Loss = 0.2850, Accuracy = 0.8740, Test Loss = 0.2695, Test Accuracy = 0.8862\n",
            "Processing timestep: 0.88\n",
            "Timestep 88.00% : Training Loss = 0.2691, Accuracy = 0.8745, Test Loss = 0.3528, Test Accuracy = 0.8456\n",
            "Processing timestep: 0.885\n",
            "Timestep 88.50% : Training Loss = 0.2865, Accuracy = 0.8620, Test Loss = 0.3333, Test Accuracy = 0.8462\n",
            "Processing timestep: 0.89\n",
            "Timestep 89.00% : Training Loss = 0.2852, Accuracy = 0.8725, Test Loss = 0.3789, Test Accuracy = 0.8069\n",
            "Processing timestep: 0.895\n",
            "Timestep 89.50% : Training Loss = 0.2621, Accuracy = 0.8834, Test Loss = 0.2464, Test Accuracy = 0.8908\n",
            "Processing timestep: 0.9\n",
            "Timestep 90.00% : Training Loss = 0.2978, Accuracy = 0.8609, Test Loss = 0.3496, Test Accuracy = 0.8345\n",
            "Processing timestep: 0.905\n",
            "Timestep 90.50% : Training Loss = 0.2558, Accuracy = 0.8850, Test Loss = 0.2957, Test Accuracy = 0.8591\n",
            "Processing timestep: 0.91\n",
            "Timestep 91.00% : Training Loss = 0.2575, Accuracy = 0.8839, Test Loss = 0.2932, Test Accuracy = 0.8576\n",
            "Processing timestep: 0.915\n",
            "Timestep 91.50% : Training Loss = 0.2490, Accuracy = 0.8883, Test Loss = 0.2806, Test Accuracy = 0.8844\n",
            "Processing timestep: 0.92\n",
            "Timestep 92.00% : Training Loss = 0.2714, Accuracy = 0.8733, Test Loss = 0.3027, Test Accuracy = 0.8526\n",
            "Processing timestep: 0.925\n",
            "Timestep 92.50% : Training Loss = 0.2514, Accuracy = 0.8911, Test Loss = 0.2519, Test Accuracy = 0.8769\n",
            "Processing timestep: 0.93\n",
            "Timestep 93.00% : Training Loss = 0.2468, Accuracy = 0.8991, Test Loss = 0.2574, Test Accuracy = 0.8723\n",
            "Processing timestep: 0.935\n",
            "Timestep 93.50% : Training Loss = 0.2497, Accuracy = 0.8865, Test Loss = 0.3070, Test Accuracy = 0.8684\n",
            "Processing timestep: 0.94\n",
            "Timestep 94.00% : Training Loss = 0.2217, Accuracy = 0.9028, Test Loss = 0.2574, Test Accuracy = 0.8913\n",
            "Processing timestep: 0.945\n",
            "Timestep 94.50% : Training Loss = 0.2262, Accuracy = 0.9037, Test Loss = 0.2788, Test Accuracy = 0.8692\n",
            "Processing timestep: 0.95\n",
            "Timestep 95.00% : Training Loss = 0.2431, Accuracy = 0.8864, Test Loss = 0.3146, Test Accuracy = 0.8640\n",
            "Processing timestep: 0.955\n",
            "Timestep 95.50% : Training Loss = 0.2434, Accuracy = 0.8903, Test Loss = 0.2350, Test Accuracy = 0.9040\n",
            "Processing timestep: 0.96\n",
            "Timestep 96.00% : Training Loss = 0.2529, Accuracy = 0.8856, Test Loss = 0.2712, Test Accuracy = 0.8806\n",
            "Processing timestep: 0.965\n",
            "Timestep 96.50% : Training Loss = 0.2322, Accuracy = 0.8939, Test Loss = 0.2354, Test Accuracy = 0.8805\n",
            "Processing timestep: 0.97\n",
            "Timestep 97.00% : Training Loss = 0.2404, Accuracy = 0.8981, Test Loss = 0.2511, Test Accuracy = 0.8857\n",
            "Processing timestep: 0.975\n",
            "Timestep 97.50% : Training Loss = 0.2512, Accuracy = 0.8986, Test Loss = 0.2465, Test Accuracy = 0.8892\n",
            "Processing timestep: 0.98\n",
            "Timestep 98.00% : Training Loss = 0.2031, Accuracy = 0.9249, Test Loss = 0.2723, Test Accuracy = 0.8523\n",
            "Processing timestep: 0.985\n",
            "Timestep 98.50% : Training Loss = 0.2257, Accuracy = 0.9071, Test Loss = 0.2366, Test Accuracy = 0.8794\n",
            "Processing timestep: 0.99\n",
            "Timestep 99.00% : Training Loss = 0.2461, Accuracy = 0.8952, Test Loss = 0.2404, Test Accuracy = 0.8721\n",
            "Processing timestep: 0.995\n",
            "Timestep 99.50% : Training Loss = 0.2403, Accuracy = 0.9076, Test Loss = 0.2389, Test Accuracy = 0.8757\n",
            "Processing timestep: 1.0\n",
            "Timestep 100.00% : Training Loss = 0.1846, Accuracy = 0.9319, Test Loss = 0.1630, Test Accuracy = 0.9443\n"
          ]
        }
      ],
      "source": [
        "other_features = [\n",
        "            \"type.id\",             # Play type (categorical)\n",
        "            \"home_has_possession\", # Binary indicator\n",
        "            \"end.down\",            # Down number (1-4, discrete)\n",
        "            \"home_timeouts_left\",  # Discrete count (0-3)\n",
        "            \"away_timeouts_left\",  # Discrete count (0-3)\n",
        "        ]\n",
        "numeric_features = [\n",
        "    \"score_difference\",\n",
        "    \"relative_strength\", \n",
        "    \"end.yardsToEndzone\", \n",
        "    \"end.distance\", \n",
        "    \"field_position_shift\"\n",
        "]\n",
        "other_features = [\n",
        "            \"home_has_possession\", # Binary indicator\n",
        "            \"end.down\",            # Down number (1-4, discrete)\n",
        "            \"home_timeouts_left\",  # Discrete count (0-3)\n",
        "            \"away_timeouts_left\",  # Discrete count (0-3)\n",
        "        ]\n",
        "numeric_features = [\n",
        "    \"score_difference\",\n",
        "    \"relative_strength\", \n",
        "    \"end.yardsToEndzone\", \n",
        "    \"end.distance\", \n",
        "]\n",
        "lr_numeric_features= [\n",
        "    \"score_difference\",\n",
        "    \"relative_strength\"\n",
        "]\n",
        "lr_other_features = [\n",
        "   \"home_has_possession\" \n",
        "]\n",
        "lr_features = [\"relative_strength\", \"score_difference\", \"home_has_possession\"]\n",
        "all_models[\"logistic\"] = setup_logistic_regression_models(training_data, None, lr_numeric_features, lr_other_features, lr_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestep 0.00%(Calibrated): Training Loss = 0.3184, Accuracy = 0.6816, Validation Loss = 0.2112, Validation Accuracy = 0.6599\n",
            "Timestep 0.50%(Calibrated): Training Loss = 0.3243, Accuracy = 0.6757, Validation Loss = 0.2069, Validation Accuracy = 0.6531\n",
            "Timestep 1.00%(Calibrated): Training Loss = 0.3363, Accuracy = 0.6637, Validation Loss = 0.2045, Validation Accuracy = 0.6806\n",
            "Timestep 1.50%(Calibrated): Training Loss = 0.3455, Accuracy = 0.6545, Validation Loss = 0.2131, Validation Accuracy = 0.6667\n",
            "Timestep 2.00%(Calibrated): Training Loss = 0.3339, Accuracy = 0.6661, Validation Loss = 0.2159, Validation Accuracy = 0.6512\n",
            "Timestep 2.50%(Calibrated): Training Loss = 0.3416, Accuracy = 0.6584, Validation Loss = 0.2106, Validation Accuracy = 0.6659\n",
            "Timestep 3.00%(Calibrated): Training Loss = 0.3246, Accuracy = 0.6754, Validation Loss = 0.2034, Validation Accuracy = 0.6706\n",
            "Timestep 3.50%(Calibrated): Training Loss = 0.3559, Accuracy = 0.6441, Validation Loss = 0.2184, Validation Accuracy = 0.6441\n",
            "Timestep 4.00%(Calibrated): Training Loss = 0.3366, Accuracy = 0.6634, Validation Loss = 0.2085, Validation Accuracy = 0.6697\n",
            "Timestep 4.50%(Calibrated): Training Loss = 0.3326, Accuracy = 0.6674, Validation Loss = 0.2043, Validation Accuracy = 0.6831\n",
            "Timestep 5.00%(Calibrated): Training Loss = 0.3377, Accuracy = 0.6623, Validation Loss = 0.2109, Validation Accuracy = 0.6402\n",
            "Timestep 5.50%(Calibrated): Training Loss = 0.3448, Accuracy = 0.6552, Validation Loss = 0.2118, Validation Accuracy = 0.6568\n",
            "Timestep 6.00%(Calibrated): Training Loss = 0.3247, Accuracy = 0.6753, Validation Loss = 0.2025, Validation Accuracy = 0.6863\n",
            "Timestep 6.50%(Calibrated): Training Loss = 0.3428, Accuracy = 0.6572, Validation Loss = 0.2093, Validation Accuracy = 0.6696\n",
            "Timestep 7.00%(Calibrated): Training Loss = 0.3340, Accuracy = 0.6660, Validation Loss = 0.2020, Validation Accuracy = 0.6760\n",
            "Timestep 7.50%(Calibrated): Training Loss = 0.3287, Accuracy = 0.6713, Validation Loss = 0.2053, Validation Accuracy = 0.6645\n",
            "Timestep 8.00%(Calibrated): Training Loss = 0.3135, Accuracy = 0.6865, Validation Loss = 0.1934, Validation Accuracy = 0.7128\n",
            "Timestep 8.50%(Calibrated): Training Loss = 0.3289, Accuracy = 0.6711, Validation Loss = 0.2039, Validation Accuracy = 0.6681\n",
            "Timestep 9.00%(Calibrated): Training Loss = 0.3286, Accuracy = 0.6714, Validation Loss = 0.2074, Validation Accuracy = 0.6822\n",
            "Timestep 9.50%(Calibrated): Training Loss = 0.3234, Accuracy = 0.6766, Validation Loss = 0.2074, Validation Accuracy = 0.6688\n",
            "Timestep 10.00%(Calibrated): Training Loss = 0.2908, Accuracy = 0.7092, Validation Loss = 0.2049, Validation Accuracy = 0.6775\n",
            "Timestep 10.50%(Calibrated): Training Loss = 0.3023, Accuracy = 0.6977, Validation Loss = 0.2050, Validation Accuracy = 0.6681\n",
            "Timestep 11.00%(Calibrated): Training Loss = 0.3291, Accuracy = 0.6709, Validation Loss = 0.2009, Validation Accuracy = 0.6850\n",
            "Timestep 11.50%(Calibrated): Training Loss = 0.3109, Accuracy = 0.6891, Validation Loss = 0.1915, Validation Accuracy = 0.6967\n",
            "Timestep 12.00%(Calibrated): Training Loss = 0.3355, Accuracy = 0.6645, Validation Loss = 0.2014, Validation Accuracy = 0.6780\n",
            "Timestep 12.50%(Calibrated): Training Loss = 0.2914, Accuracy = 0.7086, Validation Loss = 0.1957, Validation Accuracy = 0.6926\n",
            "Timestep 13.00%(Calibrated): Training Loss = 0.2893, Accuracy = 0.7107, Validation Loss = 0.2021, Validation Accuracy = 0.6780\n",
            "Timestep 13.50%(Calibrated): Training Loss = 0.3030, Accuracy = 0.6970, Validation Loss = 0.1912, Validation Accuracy = 0.6991\n",
            "Timestep 14.00%(Calibrated): Training Loss = 0.2893, Accuracy = 0.7107, Validation Loss = 0.1991, Validation Accuracy = 0.6763\n",
            "Timestep 14.50%(Calibrated): Training Loss = 0.3055, Accuracy = 0.6945, Validation Loss = 0.1891, Validation Accuracy = 0.6913\n",
            "Timestep 15.00%(Calibrated): Training Loss = 0.2820, Accuracy = 0.7180, Validation Loss = 0.1983, Validation Accuracy = 0.7002\n",
            "Timestep 15.50%(Calibrated): Training Loss = 0.3135, Accuracy = 0.6865, Validation Loss = 0.1985, Validation Accuracy = 0.6826\n",
            "Timestep 16.00%(Calibrated): Training Loss = 0.3490, Accuracy = 0.6510, Validation Loss = 0.1959, Validation Accuracy = 0.6810\n",
            "Timestep 16.50%(Calibrated): Training Loss = 0.3363, Accuracy = 0.6637, Validation Loss = 0.2099, Validation Accuracy = 0.6592\n",
            "Timestep 17.00%(Calibrated): Training Loss = 0.2979, Accuracy = 0.7021, Validation Loss = 0.1947, Validation Accuracy = 0.6833\n",
            "Timestep 17.50%(Calibrated): Training Loss = 0.2981, Accuracy = 0.7019, Validation Loss = 0.2018, Validation Accuracy = 0.6618\n",
            "Timestep 18.00%(Calibrated): Training Loss = 0.2892, Accuracy = 0.7108, Validation Loss = 0.1920, Validation Accuracy = 0.7038\n",
            "Timestep 18.50%(Calibrated): Training Loss = 0.3027, Accuracy = 0.6973, Validation Loss = 0.1914, Validation Accuracy = 0.7069\n",
            "Timestep 19.00%(Calibrated): Training Loss = 0.2897, Accuracy = 0.7103, Validation Loss = 0.1834, Validation Accuracy = 0.7171\n",
            "Timestep 19.50%(Calibrated): Training Loss = 0.2912, Accuracy = 0.7088, Validation Loss = 0.1877, Validation Accuracy = 0.6874\n",
            "Timestep 20.00%(Calibrated): Training Loss = 0.2991, Accuracy = 0.7009, Validation Loss = 0.1827, Validation Accuracy = 0.7011\n",
            "Timestep 20.50%(Calibrated): Training Loss = 0.2869, Accuracy = 0.7131, Validation Loss = 0.1845, Validation Accuracy = 0.7217\n",
            "Timestep 21.00%(Calibrated): Training Loss = 0.3189, Accuracy = 0.6811, Validation Loss = 0.1852, Validation Accuracy = 0.6975\n",
            "Timestep 21.50%(Calibrated): Training Loss = 0.2897, Accuracy = 0.7103, Validation Loss = 0.1864, Validation Accuracy = 0.7107\n",
            "Timestep 22.00%(Calibrated): Training Loss = 0.2814, Accuracy = 0.7186, Validation Loss = 0.1781, Validation Accuracy = 0.7340\n",
            "Timestep 22.50%(Calibrated): Training Loss = 0.2797, Accuracy = 0.7203, Validation Loss = 0.1760, Validation Accuracy = 0.7495\n",
            "Timestep 23.00%(Calibrated): Training Loss = 0.2900, Accuracy = 0.7100, Validation Loss = 0.1821, Validation Accuracy = 0.7095\n",
            "Timestep 23.50%(Calibrated): Training Loss = 0.2708, Accuracy = 0.7292, Validation Loss = 0.1707, Validation Accuracy = 0.7317\n",
            "Timestep 24.00%(Calibrated): Training Loss = 0.3074, Accuracy = 0.6926, Validation Loss = 0.1820, Validation Accuracy = 0.7044\n",
            "Timestep 24.50%(Calibrated): Training Loss = 0.2828, Accuracy = 0.7172, Validation Loss = 0.1802, Validation Accuracy = 0.7346\n",
            "Completed 50/201 timesteps\n",
            "Timestep 25.00%(Calibrated): Training Loss = 0.2616, Accuracy = 0.7384, Validation Loss = 0.1770, Validation Accuracy = 0.7318\n",
            "Timestep 25.50%(Calibrated): Training Loss = 0.3468, Accuracy = 0.6532, Validation Loss = 0.1730, Validation Accuracy = 0.7190\n",
            "Timestep 26.00%(Calibrated): Training Loss = 0.3046, Accuracy = 0.6954, Validation Loss = 0.1781, Validation Accuracy = 0.7139\n",
            "Timestep 26.50%(Calibrated): Training Loss = 0.2868, Accuracy = 0.7132, Validation Loss = 0.1619, Validation Accuracy = 0.7567\n",
            "Timestep 27.00%(Calibrated): Training Loss = 0.2702, Accuracy = 0.7298, Validation Loss = 0.1763, Validation Accuracy = 0.7281\n",
            "Timestep 27.50%(Calibrated): Training Loss = 0.2907, Accuracy = 0.7093, Validation Loss = 0.1711, Validation Accuracy = 0.7302\n",
            "Timestep 28.00%(Calibrated): Training Loss = 0.2808, Accuracy = 0.7192, Validation Loss = 0.1796, Validation Accuracy = 0.7220\n",
            "Timestep 28.50%(Calibrated): Training Loss = 0.2673, Accuracy = 0.7327, Validation Loss = 0.1585, Validation Accuracy = 0.7399\n",
            "Timestep 29.00%(Calibrated): Training Loss = 0.2775, Accuracy = 0.7225, Validation Loss = 0.1737, Validation Accuracy = 0.7345\n",
            "Timestep 29.50%(Calibrated): Training Loss = 0.2762, Accuracy = 0.7238, Validation Loss = 0.1721, Validation Accuracy = 0.7388\n",
            "Timestep 30.00%(Calibrated): Training Loss = 0.2627, Accuracy = 0.7373, Validation Loss = 0.1833, Validation Accuracy = 0.7125\n",
            "Timestep 30.50%(Calibrated): Training Loss = 0.2695, Accuracy = 0.7305, Validation Loss = 0.1854, Validation Accuracy = 0.7052\n",
            "Timestep 31.00%(Calibrated): Training Loss = 0.2544, Accuracy = 0.7456, Validation Loss = 0.1766, Validation Accuracy = 0.7284\n",
            "Timestep 31.50%(Calibrated): Training Loss = 0.2849, Accuracy = 0.7151, Validation Loss = 0.1867, Validation Accuracy = 0.6867\n",
            "Timestep 32.00%(Calibrated): Training Loss = 0.2511, Accuracy = 0.7489, Validation Loss = 0.1718, Validation Accuracy = 0.7304\n",
            "Timestep 32.50%(Calibrated): Training Loss = 0.2576, Accuracy = 0.7424, Validation Loss = 0.1701, Validation Accuracy = 0.7472\n",
            "Timestep 33.00%(Calibrated): Training Loss = 0.2639, Accuracy = 0.7361, Validation Loss = 0.1649, Validation Accuracy = 0.7366\n",
            "Timestep 33.50%(Calibrated): Training Loss = 0.2481, Accuracy = 0.7519, Validation Loss = 0.1672, Validation Accuracy = 0.7347\n",
            "Timestep 34.00%(Calibrated): Training Loss = 0.2698, Accuracy = 0.7302, Validation Loss = 0.1755, Validation Accuracy = 0.7146\n",
            "Timestep 34.50%(Calibrated): Training Loss = 0.2401, Accuracy = 0.7599, Validation Loss = 0.1661, Validation Accuracy = 0.7448\n",
            "Timestep 35.00%(Calibrated): Training Loss = 0.2500, Accuracy = 0.7500, Validation Loss = 0.1752, Validation Accuracy = 0.7288\n",
            "Timestep 35.50%(Calibrated): Training Loss = 0.2502, Accuracy = 0.7498, Validation Loss = 0.1692, Validation Accuracy = 0.7335\n",
            "Timestep 36.00%(Calibrated): Training Loss = 0.2636, Accuracy = 0.7364, Validation Loss = 0.1639, Validation Accuracy = 0.7500\n",
            "Timestep 36.50%(Calibrated): Training Loss = 0.2214, Accuracy = 0.7786, Validation Loss = 0.1771, Validation Accuracy = 0.7238\n",
            "Timestep 37.00%(Calibrated): Training Loss = 0.2480, Accuracy = 0.7520, Validation Loss = 0.1738, Validation Accuracy = 0.7401\n",
            "Timestep 37.50%(Calibrated): Training Loss = 0.2442, Accuracy = 0.7558, Validation Loss = 0.1688, Validation Accuracy = 0.7479\n",
            "Timestep 38.00%(Calibrated): Training Loss = 0.2288, Accuracy = 0.7712, Validation Loss = 0.1731, Validation Accuracy = 0.7320\n",
            "Timestep 38.50%(Calibrated): Training Loss = 0.2473, Accuracy = 0.7527, Validation Loss = 0.1678, Validation Accuracy = 0.7403\n",
            "Timestep 39.00%(Calibrated): Training Loss = 0.2482, Accuracy = 0.7518, Validation Loss = 0.1701, Validation Accuracy = 0.7279\n",
            "Timestep 39.50%(Calibrated): Training Loss = 0.2372, Accuracy = 0.7628, Validation Loss = 0.1666, Validation Accuracy = 0.7516\n",
            "Timestep 40.00%(Calibrated): Training Loss = 0.2529, Accuracy = 0.7471, Validation Loss = 0.1749, Validation Accuracy = 0.7241\n",
            "Timestep 40.50%(Calibrated): Training Loss = 0.2237, Accuracy = 0.7763, Validation Loss = 0.1553, Validation Accuracy = 0.7642\n",
            "Timestep 41.00%(Calibrated): Training Loss = 0.2467, Accuracy = 0.7533, Validation Loss = 0.1611, Validation Accuracy = 0.7635\n",
            "Timestep 41.50%(Calibrated): Training Loss = 0.2279, Accuracy = 0.7721, Validation Loss = 0.1624, Validation Accuracy = 0.7522\n",
            "Timestep 42.00%(Calibrated): Training Loss = 0.2420, Accuracy = 0.7580, Validation Loss = 0.1766, Validation Accuracy = 0.7092\n",
            "Timestep 42.50%(Calibrated): Training Loss = 0.2411, Accuracy = 0.7589, Validation Loss = 0.1674, Validation Accuracy = 0.7559\n",
            "Timestep 43.00%(Calibrated): Training Loss = 0.2234, Accuracy = 0.7766, Validation Loss = 0.1609, Validation Accuracy = 0.7505\n",
            "Timestep 43.50%(Calibrated): Training Loss = 0.2176, Accuracy = 0.7824, Validation Loss = 0.1584, Validation Accuracy = 0.7630\n",
            "Timestep 44.00%(Calibrated): Training Loss = 0.2317, Accuracy = 0.7683, Validation Loss = 0.1707, Validation Accuracy = 0.7385\n",
            "Timestep 44.50%(Calibrated): Training Loss = 0.2128, Accuracy = 0.7872, Validation Loss = 0.1617, Validation Accuracy = 0.7579\n",
            "Timestep 45.00%(Calibrated): Training Loss = 0.2656, Accuracy = 0.7344, Validation Loss = 0.1645, Validation Accuracy = 0.7489\n",
            "Timestep 45.50%(Calibrated): Training Loss = 0.2314, Accuracy = 0.7686, Validation Loss = 0.1664, Validation Accuracy = 0.7383\n",
            "Timestep 46.00%(Calibrated): Training Loss = 0.2201, Accuracy = 0.7799, Validation Loss = 0.1426, Validation Accuracy = 0.7829\n",
            "Timestep 46.50%(Calibrated): Training Loss = 0.2034, Accuracy = 0.7966, Validation Loss = 0.1553, Validation Accuracy = 0.7728\n",
            "Timestep 47.00%(Calibrated): Training Loss = 0.2038, Accuracy = 0.7962, Validation Loss = 0.1574, Validation Accuracy = 0.7670\n",
            "Timestep 47.50%(Calibrated): Training Loss = 0.2072, Accuracy = 0.7928, Validation Loss = 0.1489, Validation Accuracy = 0.7800\n",
            "Timestep 48.00%(Calibrated): Training Loss = 0.2030, Accuracy = 0.7970, Validation Loss = 0.1522, Validation Accuracy = 0.7811\n",
            "Timestep 48.50%(Calibrated): Training Loss = 0.2078, Accuracy = 0.7922, Validation Loss = 0.1565, Validation Accuracy = 0.7625\n",
            "Timestep 49.00%(Calibrated): Training Loss = 0.1905, Accuracy = 0.8095, Validation Loss = 0.1632, Validation Accuracy = 0.7637\n",
            "Timestep 49.50%(Calibrated): Training Loss = 0.2204, Accuracy = 0.7796, Validation Loss = 0.1394, Validation Accuracy = 0.7990\n",
            "Completed 100/201 timesteps\n",
            "Timestep 50.00%(Calibrated): Training Loss = 0.1862, Accuracy = 0.8138, Validation Loss = 0.1387, Validation Accuracy = 0.8069\n",
            "Timestep 50.50%(Calibrated): Training Loss = 0.1856, Accuracy = 0.8144, Validation Loss = 0.1573, Validation Accuracy = 0.7664\n",
            "Timestep 51.00%(Calibrated): Training Loss = 0.2059, Accuracy = 0.7941, Validation Loss = 0.1446, Validation Accuracy = 0.7964\n",
            "Timestep 51.50%(Calibrated): Training Loss = 0.1758, Accuracy = 0.8242, Validation Loss = 0.1427, Validation Accuracy = 0.7995\n",
            "Timestep 52.00%(Calibrated): Training Loss = 0.2063, Accuracy = 0.7937, Validation Loss = 0.1336, Validation Accuracy = 0.8203\n",
            "Timestep 52.50%(Calibrated): Training Loss = 0.1908, Accuracy = 0.8092, Validation Loss = 0.1334, Validation Accuracy = 0.8210\n",
            "Timestep 53.00%(Calibrated): Training Loss = 0.2045, Accuracy = 0.7955, Validation Loss = 0.1567, Validation Accuracy = 0.7732\n",
            "Timestep 53.50%(Calibrated): Training Loss = 0.1801, Accuracy = 0.8199, Validation Loss = 0.1363, Validation Accuracy = 0.8121\n",
            "Timestep 54.00%(Calibrated): Training Loss = 0.1877, Accuracy = 0.8123, Validation Loss = 0.1613, Validation Accuracy = 0.7663\n",
            "Timestep 54.50%(Calibrated): Training Loss = 0.1791, Accuracy = 0.8209, Validation Loss = 0.1463, Validation Accuracy = 0.7883\n",
            "Timestep 55.00%(Calibrated): Training Loss = 0.1726, Accuracy = 0.8274, Validation Loss = 0.1442, Validation Accuracy = 0.7982\n",
            "Timestep 55.50%(Calibrated): Training Loss = 0.2006, Accuracy = 0.7994, Validation Loss = 0.1411, Validation Accuracy = 0.8004\n",
            "Timestep 56.00%(Calibrated): Training Loss = 0.1786, Accuracy = 0.8214, Validation Loss = 0.1423, Validation Accuracy = 0.7982\n",
            "Timestep 56.50%(Calibrated): Training Loss = 0.2096, Accuracy = 0.7904, Validation Loss = 0.1453, Validation Accuracy = 0.7854\n",
            "Timestep 57.00%(Calibrated): Training Loss = 0.2006, Accuracy = 0.7994, Validation Loss = 0.1369, Validation Accuracy = 0.8122\n",
            "Timestep 57.50%(Calibrated): Training Loss = 0.2362, Accuracy = 0.7638, Validation Loss = 0.1539, Validation Accuracy = 0.7590\n",
            "Timestep 58.00%(Calibrated): Training Loss = 0.1961, Accuracy = 0.8039, Validation Loss = 0.1364, Validation Accuracy = 0.8040\n",
            "Timestep 58.50%(Calibrated): Training Loss = 0.1905, Accuracy = 0.8095, Validation Loss = 0.1302, Validation Accuracy = 0.8198\n",
            "Timestep 59.00%(Calibrated): Training Loss = 0.1889, Accuracy = 0.8111, Validation Loss = 0.1446, Validation Accuracy = 0.8008\n",
            "Timestep 59.50%(Calibrated): Training Loss = 0.1963, Accuracy = 0.8037, Validation Loss = 0.1360, Validation Accuracy = 0.8143\n",
            "Timestep 60.00%(Calibrated): Training Loss = 0.1980, Accuracy = 0.8020, Validation Loss = 0.1407, Validation Accuracy = 0.8039\n",
            "Timestep 60.50%(Calibrated): Training Loss = 0.1860, Accuracy = 0.8140, Validation Loss = 0.1327, Validation Accuracy = 0.8025\n",
            "Timestep 61.00%(Calibrated): Training Loss = 0.1784, Accuracy = 0.8216, Validation Loss = 0.1303, Validation Accuracy = 0.8205\n",
            "Timestep 61.50%(Calibrated): Training Loss = 0.1726, Accuracy = 0.8274, Validation Loss = 0.1300, Validation Accuracy = 0.8184\n",
            "Timestep 62.00%(Calibrated): Training Loss = 0.1875, Accuracy = 0.8125, Validation Loss = 0.1318, Validation Accuracy = 0.8103\n",
            "Timestep 62.50%(Calibrated): Training Loss = 0.1744, Accuracy = 0.8256, Validation Loss = 0.1272, Validation Accuracy = 0.8320\n",
            "Timestep 63.00%(Calibrated): Training Loss = 0.1744, Accuracy = 0.8256, Validation Loss = 0.1374, Validation Accuracy = 0.8073\n",
            "Timestep 63.50%(Calibrated): Training Loss = 0.1897, Accuracy = 0.8103, Validation Loss = 0.1344, Validation Accuracy = 0.8108\n",
            "Timestep 64.00%(Calibrated): Training Loss = 0.1680, Accuracy = 0.8320, Validation Loss = 0.1432, Validation Accuracy = 0.7865\n",
            "Timestep 64.50%(Calibrated): Training Loss = 0.2174, Accuracy = 0.7826, Validation Loss = 0.1313, Validation Accuracy = 0.8095\n",
            "Timestep 65.00%(Calibrated): Training Loss = 0.1856, Accuracy = 0.8144, Validation Loss = 0.1555, Validation Accuracy = 0.7602\n",
            "Timestep 65.50%(Calibrated): Training Loss = 0.1646, Accuracy = 0.8354, Validation Loss = 0.1488, Validation Accuracy = 0.7710\n",
            "Timestep 66.00%(Calibrated): Training Loss = 0.1810, Accuracy = 0.8190, Validation Loss = 0.1298, Validation Accuracy = 0.8071\n",
            "Timestep 66.50%(Calibrated): Training Loss = 0.1658, Accuracy = 0.8342, Validation Loss = 0.1327, Validation Accuracy = 0.8051\n",
            "Timestep 67.00%(Calibrated): Training Loss = 0.1592, Accuracy = 0.8408, Validation Loss = 0.1344, Validation Accuracy = 0.8191\n",
            "Timestep 67.50%(Calibrated): Training Loss = 0.1603, Accuracy = 0.8397, Validation Loss = 0.1395, Validation Accuracy = 0.7939\n",
            "Timestep 68.00%(Calibrated): Training Loss = 0.1759, Accuracy = 0.8241, Validation Loss = 0.1277, Validation Accuracy = 0.8164\n",
            "Timestep 68.50%(Calibrated): Training Loss = 0.1731, Accuracy = 0.8269, Validation Loss = 0.1398, Validation Accuracy = 0.7946\n",
            "Timestep 69.00%(Calibrated): Training Loss = 0.1636, Accuracy = 0.8364, Validation Loss = 0.1278, Validation Accuracy = 0.7996\n",
            "Timestep 69.50%(Calibrated): Training Loss = 0.1609, Accuracy = 0.8391, Validation Loss = 0.1280, Validation Accuracy = 0.8143\n",
            "Timestep 70.00%(Calibrated): Training Loss = 0.1935, Accuracy = 0.8065, Validation Loss = 0.1235, Validation Accuracy = 0.8109\n",
            "Timestep 70.50%(Calibrated): Training Loss = 0.1597, Accuracy = 0.8403, Validation Loss = 0.1224, Validation Accuracy = 0.8286\n",
            "Timestep 71.00%(Calibrated): Training Loss = 0.1728, Accuracy = 0.8272, Validation Loss = 0.1259, Validation Accuracy = 0.8092\n",
            "Timestep 71.50%(Calibrated): Training Loss = 0.1505, Accuracy = 0.8495, Validation Loss = 0.1347, Validation Accuracy = 0.7932\n",
            "Timestep 72.00%(Calibrated): Training Loss = 0.1564, Accuracy = 0.8436, Validation Loss = 0.1114, Validation Accuracy = 0.8529\n",
            "Timestep 72.50%(Calibrated): Training Loss = 0.1604, Accuracy = 0.8396, Validation Loss = 0.1258, Validation Accuracy = 0.8154\n",
            "Timestep 73.00%(Calibrated): Training Loss = 0.1381, Accuracy = 0.8619, Validation Loss = 0.1302, Validation Accuracy = 0.8184\n",
            "Timestep 73.50%(Calibrated): Training Loss = 0.1526, Accuracy = 0.8474, Validation Loss = 0.1245, Validation Accuracy = 0.8229\n",
            "Timestep 74.00%(Calibrated): Training Loss = 0.1485, Accuracy = 0.8515, Validation Loss = 0.1173, Validation Accuracy = 0.8213\n",
            "Timestep 74.50%(Calibrated): Training Loss = 0.1463, Accuracy = 0.8537, Validation Loss = 0.1245, Validation Accuracy = 0.8193\n",
            "Completed 150/201 timesteps\n",
            "Timestep 75.00%(Calibrated): Training Loss = 0.1507, Accuracy = 0.8493, Validation Loss = 0.1185, Validation Accuracy = 0.8322\n",
            "Timestep 75.50%(Calibrated): Training Loss = 0.1208, Accuracy = 0.8792, Validation Loss = 0.1167, Validation Accuracy = 0.8333\n",
            "Timestep 76.00%(Calibrated): Training Loss = 0.1286, Accuracy = 0.8714, Validation Loss = 0.1137, Validation Accuracy = 0.8293\n",
            "Timestep 76.50%(Calibrated): Training Loss = 0.1333, Accuracy = 0.8667, Validation Loss = 0.1196, Validation Accuracy = 0.8330\n",
            "Timestep 77.00%(Calibrated): Training Loss = 0.1493, Accuracy = 0.8507, Validation Loss = 0.1304, Validation Accuracy = 0.8071\n",
            "Timestep 77.50%(Calibrated): Training Loss = 0.1375, Accuracy = 0.8625, Validation Loss = 0.1116, Validation Accuracy = 0.8433\n",
            "Timestep 78.00%(Calibrated): Training Loss = 0.1538, Accuracy = 0.8462, Validation Loss = 0.1345, Validation Accuracy = 0.8014\n",
            "Timestep 78.50%(Calibrated): Training Loss = 0.1451, Accuracy = 0.8549, Validation Loss = 0.1260, Validation Accuracy = 0.8261\n",
            "Timestep 79.00%(Calibrated): Training Loss = 0.1251, Accuracy = 0.8749, Validation Loss = 0.1030, Validation Accuracy = 0.8609\n",
            "Timestep 79.50%(Calibrated): Training Loss = 0.1550, Accuracy = 0.8450, Validation Loss = 0.1175, Validation Accuracy = 0.8304\n",
            "Timestep 80.00%(Calibrated): Training Loss = 0.1253, Accuracy = 0.8747, Validation Loss = 0.1040, Validation Accuracy = 0.8580\n",
            "Timestep 80.50%(Calibrated): Training Loss = 0.1340, Accuracy = 0.8660, Validation Loss = 0.1152, Validation Accuracy = 0.8358\n",
            "Timestep 81.00%(Calibrated): Training Loss = 0.1385, Accuracy = 0.8615, Validation Loss = 0.1172, Validation Accuracy = 0.8291\n",
            "Timestep 81.50%(Calibrated): Training Loss = 0.1235, Accuracy = 0.8765, Validation Loss = 0.1157, Validation Accuracy = 0.8223\n",
            "Timestep 82.00%(Calibrated): Training Loss = 0.1601, Accuracy = 0.8399, Validation Loss = 0.1044, Validation Accuracy = 0.8320\n",
            "Timestep 82.50%(Calibrated): Training Loss = 0.1342, Accuracy = 0.8658, Validation Loss = 0.1119, Validation Accuracy = 0.8489\n",
            "Timestep 83.00%(Calibrated): Training Loss = 0.1529, Accuracy = 0.8471, Validation Loss = 0.1040, Validation Accuracy = 0.8401\n",
            "Timestep 83.50%(Calibrated): Training Loss = 0.1316, Accuracy = 0.8684, Validation Loss = 0.0895, Validation Accuracy = 0.8747\n",
            "Timestep 84.00%(Calibrated): Training Loss = 0.1351, Accuracy = 0.8649, Validation Loss = 0.0946, Validation Accuracy = 0.8593\n",
            "Timestep 84.50%(Calibrated): Training Loss = 0.1621, Accuracy = 0.8379, Validation Loss = 0.1095, Validation Accuracy = 0.8386\n",
            "Timestep 85.00%(Calibrated): Training Loss = 0.1278, Accuracy = 0.8722, Validation Loss = 0.1044, Validation Accuracy = 0.8547\n",
            "Timestep 85.50%(Calibrated): Training Loss = 0.1210, Accuracy = 0.8790, Validation Loss = 0.1172, Validation Accuracy = 0.8337\n",
            "Timestep 86.00%(Calibrated): Training Loss = 0.1376, Accuracy = 0.8624, Validation Loss = 0.0980, Validation Accuracy = 0.8589\n",
            "Timestep 86.50%(Calibrated): Training Loss = 0.1294, Accuracy = 0.8706, Validation Loss = 0.0829, Validation Accuracy = 0.8844\n",
            "Timestep 87.00%(Calibrated): Training Loss = 0.1310, Accuracy = 0.8690, Validation Loss = 0.1127, Validation Accuracy = 0.8380\n",
            "Timestep 87.50%(Calibrated): Training Loss = 0.1270, Accuracy = 0.8730, Validation Loss = 0.0748, Validation Accuracy = 0.9050\n",
            "Timestep 88.00%(Calibrated): Training Loss = 0.1232, Accuracy = 0.8768, Validation Loss = 0.1018, Validation Accuracy = 0.8544\n",
            "Timestep 88.50%(Calibrated): Training Loss = 0.1332, Accuracy = 0.8668, Validation Loss = 0.1015, Validation Accuracy = 0.8529\n",
            "Timestep 89.00%(Calibrated): Training Loss = 0.1335, Accuracy = 0.8665, Validation Loss = 0.1067, Validation Accuracy = 0.8406\n",
            "Timestep 89.50%(Calibrated): Training Loss = 0.1061, Accuracy = 0.8939, Validation Loss = 0.0835, Validation Accuracy = 0.8912\n",
            "Timestep 90.00%(Calibrated): Training Loss = 0.1272, Accuracy = 0.8728, Validation Loss = 0.1010, Validation Accuracy = 0.8517\n",
            "Timestep 90.50%(Calibrated): Training Loss = 0.1227, Accuracy = 0.8773, Validation Loss = 0.0882, Validation Accuracy = 0.8740\n",
            "Timestep 91.00%(Calibrated): Training Loss = 0.1275, Accuracy = 0.8725, Validation Loss = 0.0844, Validation Accuracy = 0.8801\n",
            "Timestep 91.50%(Calibrated): Training Loss = 0.1076, Accuracy = 0.8924, Validation Loss = 0.0889, Validation Accuracy = 0.8837\n",
            "Timestep 92.00%(Calibrated): Training Loss = 0.1269, Accuracy = 0.8731, Validation Loss = 0.0862, Validation Accuracy = 0.8827\n",
            "Timestep 92.50%(Calibrated): Training Loss = 0.1147, Accuracy = 0.8853, Validation Loss = 0.0744, Validation Accuracy = 0.8946\n",
            "Timestep 93.00%(Calibrated): Training Loss = 0.1056, Accuracy = 0.8944, Validation Loss = 0.0725, Validation Accuracy = 0.8989\n",
            "Timestep 93.50%(Calibrated): Training Loss = 0.1111, Accuracy = 0.8889, Validation Loss = 0.0866, Validation Accuracy = 0.8860\n",
            "Timestep 94.00%(Calibrated): Training Loss = 0.0905, Accuracy = 0.9095, Validation Loss = 0.0761, Validation Accuracy = 0.8922\n",
            "Timestep 94.50%(Calibrated): Training Loss = 0.0901, Accuracy = 0.9099, Validation Loss = 0.0742, Validation Accuracy = 0.8854\n",
            "Timestep 95.00%(Calibrated): Training Loss = 0.1026, Accuracy = 0.8974, Validation Loss = 0.0923, Validation Accuracy = 0.8686\n",
            "Timestep 95.50%(Calibrated): Training Loss = 0.1085, Accuracy = 0.8915, Validation Loss = 0.0774, Validation Accuracy = 0.8847\n",
            "Timestep 96.00%(Calibrated): Training Loss = 0.1053, Accuracy = 0.8947, Validation Loss = 0.0888, Validation Accuracy = 0.8742\n",
            "Timestep 96.50%(Calibrated): Training Loss = 0.1016, Accuracy = 0.8984, Validation Loss = 0.0776, Validation Accuracy = 0.8897\n",
            "Timestep 97.00%(Calibrated): Training Loss = 0.0891, Accuracy = 0.9109, Validation Loss = 0.0793, Validation Accuracy = 0.8801\n",
            "Timestep 97.50%(Calibrated): Training Loss = 0.0932, Accuracy = 0.9068, Validation Loss = 0.0839, Validation Accuracy = 0.8782\n",
            "Timestep 98.00%(Calibrated): Training Loss = 0.0961, Accuracy = 0.9039, Validation Loss = 0.0750, Validation Accuracy = 0.8942\n",
            "Timestep 98.50%(Calibrated): Training Loss = 0.0908, Accuracy = 0.9092, Validation Loss = 0.0630, Validation Accuracy = 0.9098\n",
            "Timestep 99.00%(Calibrated): Training Loss = 0.0999, Accuracy = 0.9001, Validation Loss = 0.0589, Validation Accuracy = 0.9231\n",
            "Timestep 99.50%(Calibrated): Training Loss = 0.0979, Accuracy = 0.9021, Validation Loss = 0.0667, Validation Accuracy = 0.9048\n",
            "Completed 200/201 timesteps\n",
            "Timestep 100.00%(Calibrated): Training Loss = 0.0776, Accuracy = 0.9224, Validation Loss = 0.0336, Validation Accuracy = 0.9576\n",
            "Completed 201/201 timesteps\n"
          ]
        }
      ],
      "source": [
        "all_models[\"xgboost\"] = setup_xgboost_models(training_data, None, numeric_features, other_features, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['lstm', 'nn', 'logistic', 'xgboost'])\n",
            "Generating predictions for timestep 0.0\n",
            "Generating predictions for timestep 0.005\n",
            "Generating predictions for timestep 0.01\n",
            "Generating predictions for timestep 0.015\n",
            "Generating predictions for timestep 0.02\n",
            "Generating predictions for timestep 0.025\n",
            "Generating predictions for timestep 0.03\n",
            "Generating predictions for timestep 0.035\n",
            "Generating predictions for timestep 0.04\n",
            "Generating predictions for timestep 0.045\n",
            "Generating predictions for timestep 0.05\n",
            "Generating predictions for timestep 0.055\n",
            "Generating predictions for timestep 0.06\n",
            "Generating predictions for timestep 0.065\n",
            "Generating predictions for timestep 0.07\n",
            "Generating predictions for timestep 0.075\n",
            "Generating predictions for timestep 0.08\n",
            "Generating predictions for timestep 0.085\n",
            "Generating predictions for timestep 0.09\n",
            "Generating predictions for timestep 0.095\n",
            "Generating predictions for timestep 0.1\n",
            "Generating predictions for timestep 0.105\n",
            "Generating predictions for timestep 0.11\n",
            "Generating predictions for timestep 0.115\n",
            "Generating predictions for timestep 0.12\n",
            "Generating predictions for timestep 0.125\n",
            "Generating predictions for timestep 0.13\n",
            "Generating predictions for timestep 0.135\n",
            "Generating predictions for timestep 0.14\n",
            "Generating predictions for timestep 0.145\n",
            "Generating predictions for timestep 0.15\n",
            "Generating predictions for timestep 0.155\n",
            "Generating predictions for timestep 0.16\n",
            "Generating predictions for timestep 0.165\n",
            "Generating predictions for timestep 0.17\n",
            "Generating predictions for timestep 0.175\n",
            "Generating predictions for timestep 0.18\n",
            "Generating predictions for timestep 0.185\n",
            "Generating predictions for timestep 0.19\n",
            "Generating predictions for timestep 0.195\n",
            "Generating predictions for timestep 0.2\n",
            "Generating predictions for timestep 0.205\n",
            "Generating predictions for timestep 0.21\n",
            "Generating predictions for timestep 0.215\n",
            "Generating predictions for timestep 0.22\n",
            "Generating predictions for timestep 0.225\n",
            "Generating predictions for timestep 0.23\n",
            "Generating predictions for timestep 0.235\n",
            "Generating predictions for timestep 0.24\n",
            "Generating predictions for timestep 0.245\n",
            "Generating predictions for timestep 0.25\n",
            "Generating predictions for timestep 0.255\n",
            "Generating predictions for timestep 0.26\n",
            "Generating predictions for timestep 0.265\n",
            "Generating predictions for timestep 0.27\n",
            "Generating predictions for timestep 0.275\n",
            "Generating predictions for timestep 0.28\n",
            "Generating predictions for timestep 0.285\n",
            "Generating predictions for timestep 0.29\n",
            "Generating predictions for timestep 0.295\n",
            "Generating predictions for timestep 0.3\n",
            "Generating predictions for timestep 0.305\n",
            "Generating predictions for timestep 0.31\n",
            "Generating predictions for timestep 0.315\n",
            "Generating predictions for timestep 0.32\n",
            "Generating predictions for timestep 0.325\n",
            "Generating predictions for timestep 0.33\n",
            "Generating predictions for timestep 0.335\n",
            "Generating predictions for timestep 0.34\n",
            "Generating predictions for timestep 0.345\n",
            "Generating predictions for timestep 0.35\n",
            "Generating predictions for timestep 0.355\n",
            "Generating predictions for timestep 0.36\n",
            "Generating predictions for timestep 0.365\n",
            "Generating predictions for timestep 0.37\n",
            "Generating predictions for timestep 0.375\n",
            "Generating predictions for timestep 0.38\n",
            "Generating predictions for timestep 0.385\n",
            "Generating predictions for timestep 0.39\n",
            "Generating predictions for timestep 0.395\n",
            "Generating predictions for timestep 0.4\n",
            "Generating predictions for timestep 0.405\n",
            "Generating predictions for timestep 0.41\n",
            "Generating predictions for timestep 0.415\n",
            "Generating predictions for timestep 0.42\n",
            "Generating predictions for timestep 0.425\n",
            "Generating predictions for timestep 0.43\n",
            "Generating predictions for timestep 0.435\n",
            "Generating predictions for timestep 0.44\n",
            "Generating predictions for timestep 0.445\n",
            "Generating predictions for timestep 0.45\n",
            "Generating predictions for timestep 0.455\n",
            "Generating predictions for timestep 0.46\n",
            "Generating predictions for timestep 0.465\n",
            "Generating predictions for timestep 0.47\n",
            "Generating predictions for timestep 0.475\n",
            "Generating predictions for timestep 0.48\n",
            "Generating predictions for timestep 0.485\n",
            "Generating predictions for timestep 0.49\n",
            "Generating predictions for timestep 0.495\n",
            "Generating predictions for timestep 0.5\n",
            "Generating predictions for timestep 0.505\n",
            "Generating predictions for timestep 0.51\n",
            "Generating predictions for timestep 0.515\n",
            "Generating predictions for timestep 0.52\n",
            "Generating predictions for timestep 0.525\n",
            "Generating predictions for timestep 0.53\n",
            "Generating predictions for timestep 0.535\n",
            "Generating predictions for timestep 0.54\n",
            "Generating predictions for timestep 0.545\n",
            "Generating predictions for timestep 0.55\n",
            "Generating predictions for timestep 0.555\n",
            "Generating predictions for timestep 0.56\n",
            "Generating predictions for timestep 0.565\n",
            "Generating predictions for timestep 0.57\n",
            "Generating predictions for timestep 0.575\n",
            "Generating predictions for timestep 0.58\n",
            "Generating predictions for timestep 0.585\n",
            "Generating predictions for timestep 0.59\n",
            "Generating predictions for timestep 0.595\n",
            "Generating predictions for timestep 0.6\n",
            "Generating predictions for timestep 0.605\n",
            "Generating predictions for timestep 0.61\n",
            "Generating predictions for timestep 0.615\n",
            "Generating predictions for timestep 0.62\n",
            "Generating predictions for timestep 0.625\n",
            "Generating predictions for timestep 0.63\n",
            "Generating predictions for timestep 0.635\n",
            "Generating predictions for timestep 0.64\n",
            "Generating predictions for timestep 0.645\n",
            "Generating predictions for timestep 0.65\n",
            "Generating predictions for timestep 0.655\n",
            "Generating predictions for timestep 0.66\n",
            "Generating predictions for timestep 0.665\n",
            "Generating predictions for timestep 0.67\n",
            "Generating predictions for timestep 0.675\n",
            "Generating predictions for timestep 0.68\n",
            "Generating predictions for timestep 0.685\n",
            "Generating predictions for timestep 0.69\n",
            "Generating predictions for timestep 0.695\n",
            "Generating predictions for timestep 0.7\n",
            "Generating predictions for timestep 0.705\n",
            "Generating predictions for timestep 0.71\n",
            "Generating predictions for timestep 0.715\n",
            "Generating predictions for timestep 0.72\n",
            "Generating predictions for timestep 0.725\n",
            "Generating predictions for timestep 0.73\n",
            "Generating predictions for timestep 0.735\n",
            "Generating predictions for timestep 0.74\n",
            "Generating predictions for timestep 0.745\n",
            "Generating predictions for timestep 0.75\n",
            "Generating predictions for timestep 0.755\n",
            "Generating predictions for timestep 0.76\n",
            "Generating predictions for timestep 0.765\n",
            "Generating predictions for timestep 0.77\n",
            "Generating predictions for timestep 0.775\n",
            "Generating predictions for timestep 0.78\n",
            "Generating predictions for timestep 0.785\n",
            "Generating predictions for timestep 0.79\n",
            "Generating predictions for timestep 0.795\n",
            "Generating predictions for timestep 0.8\n",
            "Generating predictions for timestep 0.805\n",
            "Generating predictions for timestep 0.81\n",
            "Generating predictions for timestep 0.815\n",
            "Generating predictions for timestep 0.82\n",
            "Generating predictions for timestep 0.825\n",
            "Generating predictions for timestep 0.83\n",
            "Generating predictions for timestep 0.835\n",
            "Generating predictions for timestep 0.84\n",
            "Generating predictions for timestep 0.845\n",
            "Generating predictions for timestep 0.85\n",
            "Generating predictions for timestep 0.855\n",
            "Generating predictions for timestep 0.86\n",
            "Generating predictions for timestep 0.865\n",
            "Generating predictions for timestep 0.87\n",
            "Generating predictions for timestep 0.875\n",
            "Generating predictions for timestep 0.88\n",
            "Generating predictions for timestep 0.885\n",
            "Generating predictions for timestep 0.89\n",
            "Generating predictions for timestep 0.895\n",
            "Generating predictions for timestep 0.9\n",
            "Generating predictions for timestep 0.905\n",
            "Generating predictions for timestep 0.91\n",
            "Generating predictions for timestep 0.915\n",
            "Generating predictions for timestep 0.92\n",
            "Generating predictions for timestep 0.925\n",
            "Generating predictions for timestep 0.93\n",
            "Generating predictions for timestep 0.935\n",
            "Generating predictions for timestep 0.94\n",
            "Generating predictions for timestep 0.945\n",
            "Generating predictions for timestep 0.95\n",
            "Generating predictions for timestep 0.955\n",
            "Generating predictions for timestep 0.96\n",
            "Generating predictions for timestep 0.965\n",
            "Generating predictions for timestep 0.97\n",
            "Generating predictions for timestep 0.975\n",
            "Generating predictions for timestep 0.98\n",
            "Generating predictions for timestep 0.985\n",
            "Generating predictions for timestep 0.99\n",
            "Generating predictions for timestep 0.995\n",
            "Generating predictions for timestep 1.0\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "print(all_models.keys())\n",
        "all_models_order = [\"xgboost\", \"nn\", \"logistic\", \"lstm\"] # Strict ordering of models\n",
        "# all_models_order = [\"xgboost\", \"nn\", \"logistic\"] # Strict ordering of models\n",
        "\n",
        "def generate_ensemble_matrix(models, all_models_order, data_dict_seq):\n",
        "    \"\"\"Generate predictions from a specific model type on given data\"\"\"\n",
        "    predictions = {}\n",
        "    # predictions:\n",
        "        # timestep:\n",
        "            # \"predictions\": [model_1_predictions, model_2_predictions, ..., model_n_predictions, \n",
        "            # model_1_predictions_seq, model_2_predictions_seq, ..., model_n_predictions_seq],\n",
        "            # \"y_true\": y_true\n",
        "    for timestep in data_dict_seq:\n",
        "        print(f\"Generating predictions for timestep {timestep}\")\n",
        "        # For each entry, take the last array from the \"rows\" list and pair with its label\n",
        "        non_sequential_data_for_timestep = [{\"rows\": entry[\"rows\"][-1], \"label\": entry[\"label\"]} for entry in data_dict_seq[timestep]]\n",
        "        X = np.array([row[\"rows\"] for row in non_sequential_data_for_timestep])\n",
        "        y = np.array([row[\"label\"] for row in non_sequential_data_for_timestep])\n",
        "        X_seq = np.array([row[\"rows\"] for row in data_dict_seq[timestep]])\n",
        "        predictions[timestep] = {\"predictions\": [], \"y_true\": []}\n",
        "        for i in range(len(X)):\n",
        "            predictions[timestep][\"predictions\"].append(np.array([\n",
        "                models[model][timestep].predict_proba(np.expand_dims(X_seq[i], axis=0))[:, 1].item() if model == \"lstm\" else models[model][timestep].predict_proba(np.expand_dims(X[i], axis=0))[:, 1].item()\n",
        "                for model in all_models_order\n",
        "            ]))\n",
        "            predictions[timestep][\"y_true\"].append(y[i])\n",
        "        predictions[timestep][\"y_true\"] = np.array(predictions[timestep][\"y_true\"])\n",
        "        predictions[timestep][\"predictions\"] = np.array(predictions[timestep][\"predictions\"])\n",
        "    return predictions\n",
        "\n",
        "ensemble_matrices = generate_ensemble_matrix(all_models, all_models_order, ensemble_data_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LogisticRegressionMetaModel:\n",
        "    def __init__(self):\n",
        "        self.meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.meta_model.fit(X, y)\n",
        "        if X_val is not None and y_val is not None:\n",
        "            self.meta_model.fit(X_val, y_val)\n",
        "    def predict(self, X):\n",
        "        return 1 if self.meta_model.predict_proba(X)[:, 1] > 0.5 else 0\n",
        "    def predict_proba(self, X):\n",
        "        return self.meta_model.predict_proba(X)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class SimpleMetaNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleMetaNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class NeuralNetworkMetaModel(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, input_dim=None, lr=0.01, epochs=30, batch_size=32, device=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        if self.input_dim is None:\n",
        "            self.input_dim = X.shape[1]\n",
        "        self.model = SimpleMetaNN(self.input_dim).to(self.device)\n",
        "        criterion = nn.BCELoss()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(self.device)\n",
        "        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        self.model.train()\n",
        "        for epoch in range(self.epochs):\n",
        "            for xb, yb in loader:\n",
        "                optimizer.zero_grad()\n",
        "                preds = self.model(xb)\n",
        "                loss = criterion(preds, yb)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).cpu().numpy().flatten()\n",
        "        return (probs > 0.5).astype(int)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).cpu().numpy().flatten()\n",
        "        return np.column_stack([1 - probs, probs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training meta-model for timestep 0.0\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1679, 'logistic': 0.4389, 'lstm': 0.3932} (score: 0.230969)\n",
            "Training meta-model for timestep 0.005\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.3008, 'logistic': 0.6992, 'lstm': 0.0} (score: 0.238560)\n",
            "Training meta-model for timestep 0.01\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.3168, 'logistic': 0.6321, 'lstm': 0.0511} (score: 0.229674)\n",
            "Training meta-model for timestep 0.015\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0185, 'nn': 0.219, 'logistic': 0.5025, 'lstm': 0.2599} (score: 0.225935)\n",
            "Training meta-model for timestep 0.02\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.53, 'logistic': 0.0344, 'lstm': 0.4356} (score: 0.230743)\n",
            "Training meta-model for timestep 0.025\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5434, 'nn': 0.0478, 'logistic': 0.4088, 'lstm': 0.0} (score: 0.228836)\n",
            "Training meta-model for timestep 0.03\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0458, 'nn': 0.1589, 'logistic': 0.7655, 'lstm': 0.0299} (score: 0.223415)\n",
            "Training meta-model for timestep 0.035\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.405, 'nn': 0.2819, 'logistic': 0.313, 'lstm': 0.0} (score: 0.226435)\n",
            "Training meta-model for timestep 0.04\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3408, 'nn': 0.2629, 'logistic': 0.1909, 'lstm': 0.2053} (score: 0.233876)\n",
            "Training meta-model for timestep 0.045\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1464, 'logistic': 0.329, 'lstm': 0.5246} (score: 0.234837)\n",
            "Training meta-model for timestep 0.05\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.502, 'lstm': 0.498} (score: 0.228261)\n",
            "Training meta-model for timestep 0.055\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5161, 'nn': 0.0, 'logistic': 0.2571, 'lstm': 0.2268} (score: 0.216471)\n",
            "Training meta-model for timestep 0.06\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2924, 'nn': 0.0381, 'logistic': 0.3544, 'lstm': 0.3152} (score: 0.231293)\n",
            "Training meta-model for timestep 0.065\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.4342, 'lstm': 0.5658} (score: 0.229280)\n",
            "Training meta-model for timestep 0.07\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0608, 'nn': 0.1121, 'logistic': 0.8271, 'lstm': 0.0} (score: 0.228339)\n",
            "Training meta-model for timestep 0.075\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0618, 'nn': 0.6621, 'logistic': 0.2761, 'lstm': 0.0} (score: 0.224784)\n",
            "Training meta-model for timestep 0.08\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2898, 'logistic': 0.7102, 'lstm': 0.0} (score: 0.221387)\n",
            "Training meta-model for timestep 0.085\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.6712, 'lstm': 0.3288} (score: 0.213915)\n",
            "Training meta-model for timestep 0.09\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3072, 'nn': 0.446, 'logistic': 0.2468, 'lstm': 0.0} (score: 0.220551)\n",
            "Training meta-model for timestep 0.095\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0474, 'nn': 0.1926, 'logistic': 0.7599, 'lstm': 0.0} (score: 0.205991)\n",
            "Training meta-model for timestep 0.1\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2474, 'logistic': 0.2082, 'lstm': 0.5444} (score: 0.217125)\n",
            "Training meta-model for timestep 0.105\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2185, 'nn': 0.0, 'logistic': 0.3136, 'lstm': 0.4679} (score: 0.210646)\n",
            "Training meta-model for timestep 0.11\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3305, 'nn': 0.0815, 'logistic': 0.3196, 'lstm': 0.2684} (score: 0.222380)\n",
            "Training meta-model for timestep 0.115\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1058, 'nn': 0.1423, 'logistic': 0.1132, 'lstm': 0.6388} (score: 0.216221)\n",
            "Training meta-model for timestep 0.12\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0128, 'nn': 0.3611, 'logistic': 0.6261, 'lstm': 0.0} (score: 0.214642)\n",
            "Training meta-model for timestep 0.125\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0181, 'nn': 0.0, 'logistic': 0.4522, 'lstm': 0.5297} (score: 0.231469)\n",
            "Training meta-model for timestep 0.13\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1408, 'nn': 0.1491, 'logistic': 0.3396, 'lstm': 0.3705} (score: 0.213271)\n",
            "Training meta-model for timestep 0.135\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.3593, 'logistic': 0.4046, 'lstm': 0.2361} (score: 0.222532)\n",
            "Training meta-model for timestep 0.14\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2356, 'logistic': 0.3586, 'lstm': 0.4059} (score: 0.217544)\n",
            "Training meta-model for timestep 0.145\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0149, 'logistic': 0.7335, 'lstm': 0.2516} (score: 0.221872)\n",
            "Training meta-model for timestep 0.15\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.8018, 'lstm': 0.1982} (score: 0.211592)\n",
            "Training meta-model for timestep 0.155\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.5815, 'lstm': 0.4185} (score: 0.197051)\n",
            "Training meta-model for timestep 0.16\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2248, 'logistic': 0.6928, 'lstm': 0.0825} (score: 0.212947)\n",
            "Training meta-model for timestep 0.165\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1448, 'nn': 0.0, 'logistic': 0.6093, 'lstm': 0.2459} (score: 0.217629)\n",
            "Training meta-model for timestep 0.17\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.3854, 'logistic': 0.2682, 'lstm': 0.3463} (score: 0.218813)\n",
            "Training meta-model for timestep 0.175\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.4511, 'logistic': 0.4844, 'lstm': 0.0645} (score: 0.220142)\n",
            "Training meta-model for timestep 0.18\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0298, 'logistic': 0.5749, 'lstm': 0.3953} (score: 0.206840)\n",
            "Training meta-model for timestep 0.185\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.153, 'nn': 0.2111, 'logistic': 0.1756, 'lstm': 0.4604} (score: 0.211788)\n",
            "Training meta-model for timestep 0.19\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0573, 'nn': 0.0832, 'logistic': 0.4251, 'lstm': 0.4343} (score: 0.221530)\n",
            "Training meta-model for timestep 0.195\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0698, 'nn': 0.0, 'logistic': 0.4897, 'lstm': 0.4405} (score: 0.201833)\n",
            "Training meta-model for timestep 0.2\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0066, 'logistic': 0.7443, 'lstm': 0.2491} (score: 0.210796)\n",
            "Training meta-model for timestep 0.205\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0185, 'logistic': 0.7208, 'lstm': 0.2608} (score: 0.216613)\n",
            "Training meta-model for timestep 0.21\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.210376)\n",
            "Training meta-model for timestep 0.215\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.7553, 'lstm': 0.2447} (score: 0.212879)\n",
            "Training meta-model for timestep 0.22\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0072, 'nn': 0.1433, 'logistic': 0.4901, 'lstm': 0.3594} (score: 0.205479)\n",
            "Training meta-model for timestep 0.225\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0911, 'logistic': 0.6952, 'lstm': 0.2137} (score: 0.199914)\n",
            "Training meta-model for timestep 0.23\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.136, 'nn': 0.1883, 'logistic': 0.2768, 'lstm': 0.3989} (score: 0.222774)\n",
            "Training meta-model for timestep 0.235\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.4986, 'lstm': 0.5014} (score: 0.198762)\n",
            "Training meta-model for timestep 0.24\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0864, 'nn': 0.0, 'logistic': 0.6765, 'lstm': 0.2371} (score: 0.204755)\n",
            "Training meta-model for timestep 0.245\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.211848)\n",
            "Training meta-model for timestep 0.25\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.210448)\n",
            "Training meta-model for timestep 0.255\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2171, 'nn': 0.0, 'logistic': 0.0, 'lstm': 0.7829} (score: 0.204035)\n",
            "Training meta-model for timestep 0.26\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1806, 'logistic': 0.8194, 'lstm': 0.0} (score: 0.203619)\n",
            "Training meta-model for timestep 0.265\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.7953, 'lstm': 0.2047} (score: 0.213999)\n",
            "Training meta-model for timestep 0.27\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.7082, 'lstm': 0.2918} (score: 0.209203)\n",
            "Training meta-model for timestep 0.275\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0902, 'nn': 0.0, 'logistic': 0.3506, 'lstm': 0.5591} (score: 0.199499)\n",
            "Training meta-model for timestep 0.28\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.9199, 'lstm': 0.0801} (score: 0.201932)\n",
            "Training meta-model for timestep 0.285\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2627, 'nn': 0.0, 'logistic': 0.65, 'lstm': 0.0873} (score: 0.196474)\n",
            "Training meta-model for timestep 0.29\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2089, 'logistic': 0.7144, 'lstm': 0.0767} (score: 0.215342)\n",
            "Training meta-model for timestep 0.295\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2299, 'logistic': 0.7155, 'lstm': 0.0546} (score: 0.213714)\n",
            "Training meta-model for timestep 0.3\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2183, 'nn': 0.0, 'logistic': 0.484, 'lstm': 0.2977} (score: 0.197575)\n",
            "Training meta-model for timestep 0.305\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5016, 'nn': 0.3555, 'logistic': 0.143, 'lstm': 0.0} (score: 0.208747)\n",
            "Training meta-model for timestep 0.31\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2939, 'nn': 0.2128, 'logistic': 0.2706, 'lstm': 0.2227} (score: 0.191036)\n",
            "Training meta-model for timestep 0.315\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.7946, 'lstm': 0.2054} (score: 0.197441)\n",
            "Training meta-model for timestep 0.32\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1687, 'nn': 0.0163, 'logistic': 0.7457, 'lstm': 0.0693} (score: 0.214356)\n",
            "Training meta-model for timestep 0.325\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2741, 'logistic': 0.7259, 'lstm': 0.0} (score: 0.209805)\n",
            "Training meta-model for timestep 0.33\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.209252)\n",
            "Training meta-model for timestep 0.335\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1771, 'nn': 0.0, 'logistic': 0.7051, 'lstm': 0.1177} (score: 0.191549)\n",
            "Training meta-model for timestep 0.34\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1742, 'nn': 0.0271, 'logistic': 0.5102, 'lstm': 0.2886} (score: 0.187561)\n",
            "Training meta-model for timestep 0.345\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1637, 'nn': 0.0, 'logistic': 0.4684, 'lstm': 0.368} (score: 0.203351)\n",
            "Training meta-model for timestep 0.35\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.316, 'nn': 0.2359, 'logistic': 0.3034, 'lstm': 0.1448} (score: 0.206907)\n",
            "Training meta-model for timestep 0.355\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1213, 'nn': 0.0, 'logistic': 0.8787, 'lstm': 0.0} (score: 0.200401)\n",
            "Training meta-model for timestep 0.36\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1675, 'logistic': 0.8325, 'lstm': 0.0} (score: 0.193520)\n",
            "Training meta-model for timestep 0.365\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4266, 'nn': 0.4709, 'logistic': 0.1025, 'lstm': 0.0} (score: 0.203080)\n",
            "Training meta-model for timestep 0.37\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0021, 'logistic': 0.9349, 'lstm': 0.0629} (score: 0.202243)\n",
            "Training meta-model for timestep 0.375\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1051, 'logistic': 0.4085, 'lstm': 0.4864} (score: 0.193714)\n",
            "Training meta-model for timestep 0.38\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.190720)\n",
            "Training meta-model for timestep 0.385\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.6932, 'lstm': 0.3068} (score: 0.203411)\n",
            "Training meta-model for timestep 0.39\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0105, 'nn': 0.0, 'logistic': 0.9895, 'lstm': 0.0} (score: 0.193787)\n",
            "Training meta-model for timestep 0.395\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1996, 'nn': 0.0, 'logistic': 0.5728, 'lstm': 0.2277} (score: 0.204000)\n",
            "Training meta-model for timestep 0.4\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.2064, 'lstm': 0.7936} (score: 0.190646)\n",
            "Training meta-model for timestep 0.405\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2136, 'nn': 0.0, 'logistic': 0.7442, 'lstm': 0.0422} (score: 0.192730)\n",
            "Training meta-model for timestep 0.41\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.5798, 'logistic': 0.2551, 'lstm': 0.1651} (score: 0.209546)\n",
            "Training meta-model for timestep 0.415\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1204, 'logistic': 0.784, 'lstm': 0.0956} (score: 0.199903)\n",
            "Training meta-model for timestep 0.42\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.4391, 'logistic': 0.4232, 'lstm': 0.1376} (score: 0.204887)\n",
            "Training meta-model for timestep 0.425\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.8021, 'lstm': 0.1979} (score: 0.192849)\n",
            "Training meta-model for timestep 0.43\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0291, 'nn': 0.0, 'logistic': 0.9709, 'lstm': 0.0} (score: 0.194728)\n",
            "Training meta-model for timestep 0.435\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1597, 'logistic': 0.4825, 'lstm': 0.3578} (score: 0.190500)\n",
            "Training meta-model for timestep 0.44\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.9351, 'lstm': 0.0649} (score: 0.183447)\n",
            "Training meta-model for timestep 0.445\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2056, 'nn': 0.0442, 'logistic': 0.7502, 'lstm': 0.0} (score: 0.203892)\n",
            "Training meta-model for timestep 0.45\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.283, 'logistic': 0.4693, 'lstm': 0.2477} (score: 0.183102)\n",
            "Training meta-model for timestep 0.455\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2183, 'logistic': 0.3728, 'lstm': 0.4089} (score: 0.192593)\n",
            "Training meta-model for timestep 0.46\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1321, 'nn': 0.5028, 'logistic': 0.2864, 'lstm': 0.0788} (score: 0.179886)\n",
            "Training meta-model for timestep 0.465\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2232, 'nn': 0.1635, 'logistic': 0.3465, 'lstm': 0.2668} (score: 0.183146)\n",
            "Training meta-model for timestep 0.47\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0528, 'nn': 0.0, 'logistic': 0.5741, 'lstm': 0.373} (score: 0.188179)\n",
            "Training meta-model for timestep 0.475\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0691, 'nn': 0.0529, 'logistic': 0.6535, 'lstm': 0.2246} (score: 0.199355)\n",
            "Training meta-model for timestep 0.48\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0653, 'logistic': 0.2415, 'lstm': 0.6931} (score: 0.174844)\n",
            "Training meta-model for timestep 0.485\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2834, 'nn': 0.0, 'logistic': 0.4916, 'lstm': 0.225} (score: 0.175543)\n",
            "Training meta-model for timestep 0.49\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3072, 'nn': 0.4419, 'logistic': 0.1761, 'lstm': 0.0749} (score: 0.172771)\n",
            "Training meta-model for timestep 0.495\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1565, 'nn': 0.0, 'logistic': 0.7408, 'lstm': 0.1027} (score: 0.175572)\n",
            "Training meta-model for timestep 0.5\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.9242, 'lstm': 0.0758} (score: 0.178237)\n",
            "Training meta-model for timestep 0.505\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1168, 'nn': 0.3842, 'logistic': 0.4991, 'lstm': 0.0} (score: 0.168894)\n",
            "Training meta-model for timestep 0.51\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1809, 'nn': 0.3246, 'logistic': 0.4945, 'lstm': 0.0} (score: 0.167037)\n",
            "Training meta-model for timestep 0.515\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5402, 'nn': 0.0, 'logistic': 0.1882, 'lstm': 0.2717} (score: 0.180969)\n",
            "Training meta-model for timestep 0.52\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.181549)\n",
            "Training meta-model for timestep 0.525\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.7254, 'nn': 0.0, 'logistic': 0.2746, 'lstm': 0.0} (score: 0.169835)\n",
            "Training meta-model for timestep 0.53\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0212, 'nn': 0.0, 'logistic': 0.9788, 'lstm': 0.0} (score: 0.174407)\n",
            "Training meta-model for timestep 0.535\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4589, 'nn': 0.0, 'logistic': 0.5411, 'lstm': 0.0} (score: 0.175289)\n",
            "Training meta-model for timestep 0.54\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2012, 'nn': 0.7044, 'logistic': 0.0944, 'lstm': 0.0} (score: 0.161693)\n",
            "Training meta-model for timestep 0.545\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1391, 'nn': 0.2197, 'logistic': 0.6412, 'lstm': 0.0} (score: 0.184176)\n",
            "Training meta-model for timestep 0.55\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4656, 'nn': 0.0, 'logistic': 0.5098, 'lstm': 0.0246} (score: 0.174221)\n",
            "Training meta-model for timestep 0.555\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.128, 'nn': 0.0, 'logistic': 0.872, 'lstm': 0.0} (score: 0.170945)\n",
            "Training meta-model for timestep 0.56\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4146, 'nn': 0.0, 'logistic': 0.5854, 'lstm': 0.0} (score: 0.154728)\n",
            "Training meta-model for timestep 0.565\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.325, 'nn': 0.0138, 'logistic': 0.6613, 'lstm': 0.0} (score: 0.166569)\n",
            "Training meta-model for timestep 0.57\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.7776, 'lstm': 0.2224} (score: 0.168880)\n",
            "Training meta-model for timestep 0.575\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0041, 'nn': 0.0, 'logistic': 0.9959, 'lstm': 0.0} (score: 0.178049)\n",
            "Training meta-model for timestep 0.58\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4553, 'nn': 0.0, 'logistic': 0.4435, 'lstm': 0.1012} (score: 0.165365)\n",
            "Training meta-model for timestep 0.585\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 1.0, 'lstm': 0.0} (score: 0.165094)\n",
            "Training meta-model for timestep 0.59\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.6209, 'nn': 0.0743, 'logistic': 0.3048, 'lstm': 0.0} (score: 0.178590)\n",
            "Training meta-model for timestep 0.595\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.078, 'nn': 0.0746, 'logistic': 0.8475, 'lstm': 0.0} (score: 0.159589)\n",
            "Training meta-model for timestep 0.6\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1206, 'logistic': 0.628, 'lstm': 0.2514} (score: 0.175513)\n",
            "Training meta-model for timestep 0.605\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4524, 'nn': 0.265, 'logistic': 0.2826, 'lstm': 0.0} (score: 0.168134)\n",
            "Training meta-model for timestep 0.61\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0174, 'nn': 0.0, 'logistic': 0.8422, 'lstm': 0.1404} (score: 0.166177)\n",
            "Training meta-model for timestep 0.615\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0585, 'nn': 0.0824, 'logistic': 0.5991, 'lstm': 0.26} (score: 0.166897)\n",
            "Training meta-model for timestep 0.62\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1314, 'logistic': 0.5131, 'lstm': 0.3555} (score: 0.170674)\n",
            "Training meta-model for timestep 0.625\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2688, 'nn': 0.0, 'logistic': 0.6662, 'lstm': 0.065} (score: 0.158797)\n",
            "Training meta-model for timestep 0.63\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1652, 'nn': 0.0, 'logistic': 0.3217, 'lstm': 0.5131} (score: 0.155063)\n",
            "Training meta-model for timestep 0.635\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2965, 'nn': 0.0, 'logistic': 0.7035, 'lstm': 0.0} (score: 0.161345)\n",
            "Training meta-model for timestep 0.64\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0565, 'nn': 0.2713, 'logistic': 0.2329, 'lstm': 0.4393} (score: 0.156538)\n",
            "Training meta-model for timestep 0.645\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.6993, 'lstm': 0.3007} (score: 0.166014)\n",
            "Training meta-model for timestep 0.65\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2697, 'nn': 0.1136, 'logistic': 0.4402, 'lstm': 0.1765} (score: 0.159520)\n",
            "Training meta-model for timestep 0.655\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2068, 'nn': 0.1006, 'logistic': 0.5559, 'lstm': 0.1368} (score: 0.152518)\n",
            "Training meta-model for timestep 0.66\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4961, 'nn': 0.0, 'logistic': 0.338, 'lstm': 0.1658} (score: 0.163937)\n",
            "Training meta-model for timestep 0.665\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.508, 'nn': 0.0183, 'logistic': 0.4153, 'lstm': 0.0584} (score: 0.142752)\n",
            "Training meta-model for timestep 0.67\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1773, 'nn': 0.1456, 'logistic': 0.1156, 'lstm': 0.5616} (score: 0.153795)\n",
            "Training meta-model for timestep 0.675\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5809, 'nn': 0.1883, 'logistic': 0.0, 'lstm': 0.2308} (score: 0.168693)\n",
            "Training meta-model for timestep 0.68\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3153, 'nn': 0.0721, 'logistic': 0.0, 'lstm': 0.6125} (score: 0.162409)\n",
            "Training meta-model for timestep 0.685\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.7531, 'nn': 0.0, 'logistic': 0.2469, 'lstm': 0.0} (score: 0.149559)\n",
            "Training meta-model for timestep 0.69\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5588, 'nn': 0.4412, 'logistic': 0.0, 'lstm': 0.0} (score: 0.146633)\n",
            "Training meta-model for timestep 0.695\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5966, 'nn': 0.2841, 'logistic': 0.0, 'lstm': 0.1193} (score: 0.145985)\n",
            "Training meta-model for timestep 0.7\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5139, 'nn': 0.4861, 'logistic': 0.0, 'lstm': 0.0} (score: 0.150693)\n",
            "Training meta-model for timestep 0.705\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1398, 'nn': 0.2053, 'logistic': 0.3783, 'lstm': 0.2766} (score: 0.154188)\n",
            "Training meta-model for timestep 0.71\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.6439, 'nn': 0.0649, 'logistic': 0.2739, 'lstm': 0.0172} (score: 0.150237)\n",
            "Training meta-model for timestep 0.715\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.7142, 'nn': 0.0, 'logistic': 0.2858, 'lstm': 0.0} (score: 0.162521)\n",
            "Training meta-model for timestep 0.72\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1835, 'nn': 0.2928, 'logistic': 0.1399, 'lstm': 0.3838} (score: 0.150164)\n",
            "Training meta-model for timestep 0.725\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5326, 'nn': 0.3704, 'logistic': 0.0971, 'lstm': 0.0} (score: 0.147540)\n",
            "Training meta-model for timestep 0.73\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.064, 'nn': 0.0, 'logistic': 0.3687, 'lstm': 0.5673} (score: 0.147586)\n",
            "Training meta-model for timestep 0.735\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4667, 'nn': 0.1195, 'logistic': 0.2653, 'lstm': 0.1484} (score: 0.151909)\n",
            "Training meta-model for timestep 0.74\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3748, 'nn': 0.3021, 'logistic': 0.2319, 'lstm': 0.0913} (score: 0.138883)\n",
            "Training meta-model for timestep 0.745\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5105, 'nn': 0.3505, 'logistic': 0.1113, 'lstm': 0.0277} (score: 0.154992)\n",
            "Training meta-model for timestep 0.75\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2598, 'nn': 0.1213, 'logistic': 0.4116, 'lstm': 0.2073} (score: 0.153506)\n",
            "Training meta-model for timestep 0.755\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5857, 'nn': 0.2314, 'logistic': 0.1829, 'lstm': 0.0} (score: 0.144680)\n",
            "Training meta-model for timestep 0.76\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4255, 'nn': 0.0068, 'logistic': 0.0, 'lstm': 0.5677} (score: 0.145691)\n",
            "Training meta-model for timestep 0.765\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4604, 'nn': 0.0, 'logistic': 0.0572, 'lstm': 0.4825} (score: 0.123668)\n",
            "Training meta-model for timestep 0.77\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2443, 'nn': 0.0, 'logistic': 0.3696, 'lstm': 0.3861} (score: 0.151894)\n",
            "Training meta-model for timestep 0.775\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0946, 'nn': 0.6278, 'logistic': 0.2065, 'lstm': 0.0711} (score: 0.146642)\n",
            "Training meta-model for timestep 0.78\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3611, 'nn': 0.184, 'logistic': 0.4549, 'lstm': 0.0} (score: 0.141043)\n",
            "Training meta-model for timestep 0.785\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.1881, 'logistic': 0.7724, 'lstm': 0.0395} (score: 0.130898)\n",
            "Training meta-model for timestep 0.79\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0222, 'nn': 0.2234, 'logistic': 0.3855, 'lstm': 0.3689} (score: 0.128457)\n",
            "Training meta-model for timestep 0.795\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5927, 'nn': 0.0682, 'logistic': 0.1691, 'lstm': 0.17} (score: 0.142440)\n",
            "Training meta-model for timestep 0.8\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0773, 'logistic': 0.4534, 'lstm': 0.4693} (score: 0.130815)\n",
            "Training meta-model for timestep 0.805\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0325, 'logistic': 0.3575, 'lstm': 0.61} (score: 0.131160)\n",
            "Training meta-model for timestep 0.81\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.25, 'nn': 0.25, 'logistic': 0.25, 'lstm': 0.25} (score: 0.135428)\n",
            "Training meta-model for timestep 0.815\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2992, 'nn': 0.0, 'logistic': 0.1618, 'lstm': 0.539} (score: 0.128455)\n",
            "Training meta-model for timestep 0.82\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.099, 'nn': 0.0, 'logistic': 0.2466, 'lstm': 0.6544} (score: 0.148185)\n",
            "Training meta-model for timestep 0.825\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3578, 'nn': 0.0754, 'logistic': 0.5668, 'lstm': 0.0} (score: 0.133953)\n",
            "Training meta-model for timestep 0.83\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0104, 'nn': 0.4368, 'logistic': 0.4446, 'lstm': 0.1082} (score: 0.129655)\n",
            "Training meta-model for timestep 0.835\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3539, 'nn': 0.144, 'logistic': 0.0, 'lstm': 0.5021} (score: 0.134556)\n",
            "Training meta-model for timestep 0.84\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0514, 'nn': 0.1059, 'logistic': 0.8427, 'lstm': 0.0} (score: 0.129432)\n",
            "Training meta-model for timestep 0.845\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.4094, 'lstm': 0.5906} (score: 0.111909)\n",
            "Training meta-model for timestep 0.85\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0286, 'nn': 0.0, 'logistic': 0.7288, 'lstm': 0.2425} (score: 0.133221)\n",
            "Training meta-model for timestep 0.855\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1107, 'nn': 0.0, 'logistic': 0.8893, 'lstm': 0.0} (score: 0.134434)\n",
            "Training meta-model for timestep 0.86\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.061, 'nn': 0.1542, 'logistic': 0.4359, 'lstm': 0.3489} (score: 0.121355)\n",
            "Training meta-model for timestep 0.865\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.9953, 'lstm': 0.0047} (score: 0.126251)\n",
            "Training meta-model for timestep 0.87\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1025, 'nn': 0.0, 'logistic': 0.8975, 'lstm': 0.0} (score: 0.124550)\n",
            "Training meta-model for timestep 0.875\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0262, 'logistic': 0.9738, 'lstm': 0.0} (score: 0.127415)\n",
            "Training meta-model for timestep 0.88\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.324, 'nn': 0.268, 'logistic': 0.408, 'lstm': 0.0} (score: 0.110665)\n",
            "Training meta-model for timestep 0.885\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.401, 'nn': 0.0, 'logistic': 0.599, 'lstm': 0.0} (score: 0.127390)\n",
            "Training meta-model for timestep 0.89\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.5878, 'nn': 0.0, 'logistic': 0.4122, 'lstm': 0.0} (score: 0.102208)\n",
            "Training meta-model for timestep 0.895\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.336, 'nn': 0.3079, 'logistic': 0.3561, 'lstm': 0.0} (score: 0.092166)\n",
            "Training meta-model for timestep 0.9\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3977, 'nn': 0.2253, 'logistic': 0.3771, 'lstm': 0.0} (score: 0.108974)\n",
            "Training meta-model for timestep 0.905\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.25, 'nn': 0.25, 'logistic': 0.25, 'lstm': 0.25} (score: 0.112770)\n",
            "Training meta-model for timestep 0.91\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3159, 'nn': 0.0, 'logistic': 0.3585, 'lstm': 0.3256} (score: 0.117678)\n",
            "Training meta-model for timestep 0.915\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0618, 'nn': 0.0, 'logistic': 0.8456, 'lstm': 0.0926} (score: 0.087445)\n",
            "Training meta-model for timestep 0.92\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.4218, 'nn': 0.1048, 'logistic': 0.3767, 'lstm': 0.0967} (score: 0.098203)\n",
            "Training meta-model for timestep 0.925\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.9363, 'lstm': 0.0637} (score: 0.106128)\n",
            "Training meta-model for timestep 0.93\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2008, 'nn': 0.2608, 'logistic': 0.2029, 'lstm': 0.3355} (score: 0.094854)\n",
            "Training meta-model for timestep 0.935\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2321, 'nn': 0.0967, 'logistic': 0.6712, 'lstm': 0.0} (score: 0.094519)\n",
            "Training meta-model for timestep 0.94\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0956, 'nn': 0.1063, 'logistic': 0.63, 'lstm': 0.1681} (score: 0.097244)\n",
            "Training meta-model for timestep 0.945\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.3064, 'nn': 0.0193, 'logistic': 0.2175, 'lstm': 0.4568} (score: 0.102612)\n",
            "Training meta-model for timestep 0.95\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.25, 'nn': 0.25, 'logistic': 0.25, 'lstm': 0.25} (score: 0.101232)\n",
            "Training meta-model for timestep 0.955\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.0, 'logistic': 0.8411, 'lstm': 0.1589} (score: 0.097704)\n",
            "Training meta-model for timestep 0.96\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2254, 'nn': 0.4898, 'logistic': 0.2848, 'lstm': 0.0} (score: 0.105458)\n",
            "Training meta-model for timestep 0.965\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.178, 'logistic': 0.822, 'lstm': 0.0} (score: 0.104135)\n",
            "Training meta-model for timestep 0.97\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.207, 'nn': 0.213, 'logistic': 0.2628, 'lstm': 0.3171} (score: 0.092220)\n",
            "Training meta-model for timestep 0.975\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.2516, 'nn': 0.1337, 'logistic': 0.2294, 'lstm': 0.3853} (score: 0.090597)\n",
            "Training meta-model for timestep 0.98\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.1414, 'nn': 0.407, 'logistic': 0.1907, 'lstm': 0.2609} (score: 0.095674)\n",
            "Training meta-model for timestep 0.985\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.6092, 'logistic': 0.2695, 'lstm': 0.1213} (score: 0.074598)\n",
            "Training meta-model for timestep 0.99\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.9236, 'logistic': 0.0, 'lstm': 0.0764} (score: 0.074763)\n",
            "Training meta-model for timestep 0.995\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.0, 'nn': 0.2856, 'logistic': 0.3159, 'lstm': 0.3985} (score: 0.081839)\n",
            "Training meta-model for timestep 1.0\n",
            "Training ensemble for this timestep...\n",
            "Optimizing ensemble weights for this timestep...\n",
            "  Optimized weights: {'xgboost': 0.448, 'nn': 0.368, 'logistic': 0.0, 'lstm': 0.1839} (score: 0.051763)\n"
          ]
        }
      ],
      "source": [
        "def setup_meta_models(ensemble_matrices, all_models, all_models_order, strategy='meta_model', meta_model=None):\n",
        "    models = {}\n",
        "    for timestep in ensemble_matrices:\n",
        "        print(f\"Training meta-model for timestep {timestep}\")\n",
        "        ensemble_matrix = ensemble_matrices[timestep]\n",
        "        x_train = ensemble_matrix[\"predictions\"]\n",
        "        y_train = ensemble_matrix[\"y_true\"]\n",
        "        all_models_for_timestep = {model_name: all_models[model_name][timestep] for model_name in all_models_order}\n",
        "        models[timestep] = EnsemblePredictor(all_models_for_timestep, all_models_order, features, strategy, meta_model)\n",
        "        models[timestep].train_ensemble(x_train, y_train, objective='brier')\n",
        "    return models\n",
        "\n",
        "ensemble_models = setup_meta_models(ensemble_matrices, all_models, all_models_order, strategy='weighted_average', meta_model=LogisticRegressionMetaModel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestep 0.00%: Accuracy = 0.6848, Brier Score = 0.2159\n",
            "Timestep 0.50%: Accuracy = 0.6867, Brier Score = 0.2138\n",
            "Timestep 1.00%: Accuracy = 0.6762, Brier Score = 0.2105\n",
            "Timestep 1.50%: Accuracy = 0.6928, Brier Score = 0.2163\n",
            "Timestep 2.00%: Accuracy = 0.6574, Brier Score = 0.2180\n",
            "Timestep 2.50%: Accuracy = 0.7143, Brier Score = 0.2077\n",
            "Timestep 3.00%: Accuracy = 0.6984, Brier Score = 0.2090\n",
            "Timestep 3.50%: Accuracy = 0.7138, Brier Score = 0.2153\n",
            "Timestep 4.00%: Accuracy = 0.6667, Brier Score = 0.2162\n",
            "Timestep 4.50%: Accuracy = 0.6817, Brier Score = 0.2097\n",
            "Timestep 5.00%: Accuracy = 0.7194, Brier Score = 0.1987\n",
            "Timestep 5.50%: Accuracy = 0.7088, Brier Score = 0.2202\n",
            "Timestep 6.00%: Accuracy = 0.7147, Brier Score = 0.2112\n",
            "Timestep 6.50%: Accuracy = 0.6856, Brier Score = 0.2171\n",
            "Timestep 7.00%: Accuracy = 0.6834, Brier Score = 0.2166\n",
            "Timestep 7.50%: Accuracy = 0.7076, Brier Score = 0.2067\n",
            "Timestep 8.00%: Accuracy = 0.7164, Brier Score = 0.1981\n",
            "Timestep 8.50%: Accuracy = 0.7425, Brier Score = 0.1944\n",
            "Timestep 9.00%: Accuracy = 0.7019, Brier Score = 0.2111\n",
            "Timestep 9.50%: Accuracy = 0.6835, Brier Score = 0.2083\n",
            "Timestep 10.00%: Accuracy = 0.6884, Brier Score = 0.2135\n",
            "Timestep 10.50%: Accuracy = 0.7018, Brier Score = 0.2085\n",
            "Timestep 11.00%: Accuracy = 0.6705, Brier Score = 0.2054\n",
            "Timestep 11.50%: Accuracy = 0.7185, Brier Score = 0.1994\n",
            "Timestep 12.00%: Accuracy = 0.7227, Brier Score = 0.1994\n",
            "Timestep 12.50%: Accuracy = 0.6809, Brier Score = 0.2114\n",
            "Timestep 13.00%: Accuracy = 0.6981, Brier Score = 0.2044\n",
            "Timestep 13.50%: Accuracy = 0.6497, Brier Score = 0.2149\n",
            "Timestep 14.00%: Accuracy = 0.6960, Brier Score = 0.1914\n",
            "Timestep 14.50%: Accuracy = 0.6667, Brier Score = 0.1991\n",
            "Timestep 15.00%: Accuracy = 0.6821, Brier Score = 0.1982\n",
            "Timestep 15.50%: Accuracy = 0.6759, Brier Score = 0.1976\n",
            "Timestep 16.00%: Accuracy = 0.6982, Brier Score = 0.1980\n",
            "Timestep 16.50%: Accuracy = 0.6771, Brier Score = 0.2066\n",
            "Timestep 17.00%: Accuracy = 0.6714, Brier Score = 0.1997\n",
            "Timestep 17.50%: Accuracy = 0.6178, Brier Score = 0.2147\n",
            "Timestep 18.00%: Accuracy = 0.6588, Brier Score = 0.2019\n",
            "Timestep 18.50%: Accuracy = 0.6369, Brier Score = 0.2071\n",
            "Timestep 19.00%: Accuracy = 0.6629, Brier Score = 0.2162\n",
            "Timestep 19.50%: Accuracy = 0.6896, Brier Score = 0.1970\n",
            "Timestep 20.00%: Accuracy = 0.6797, Brier Score = 0.2029\n",
            "Timestep 20.50%: Accuracy = 0.6793, Brier Score = 0.1985\n",
            "Timestep 21.00%: Accuracy = 0.6773, Brier Score = 0.1938\n",
            "Timestep 21.50%: Accuracy = 0.6446, Brier Score = 0.2094\n",
            "Timestep 22.00%: Accuracy = 0.6494, Brier Score = 0.2031\n",
            "Timestep 22.50%: Accuracy = 0.6771, Brier Score = 0.2119\n",
            "Timestep 23.00%: Accuracy = 0.6328, Brier Score = 0.2034\n",
            "Timestep 23.50%: Accuracy = 0.6334, Brier Score = 0.2097\n",
            "Timestep 24.00%: Accuracy = 0.6348, Brier Score = 0.2112\n",
            "Timestep 24.50%: Accuracy = 0.6392, Brier Score = 0.2030\n",
            "Timestep 25.00%: Accuracy = 0.6348, Brier Score = 0.2046\n",
            "Timestep 25.50%: Accuracy = 0.6440, Brier Score = 0.2152\n",
            "Timestep 26.00%: Accuracy = 0.6471, Brier Score = 0.2039\n",
            "Timestep 26.50%: Accuracy = 0.6364, Brier Score = 0.2021\n",
            "Timestep 27.00%: Accuracy = 0.6614, Brier Score = 0.1913\n",
            "Timestep 27.50%: Accuracy = 0.6461, Brier Score = 0.2008\n",
            "Timestep 28.00%: Accuracy = 0.6718, Brier Score = 0.1951\n",
            "Timestep 28.50%: Accuracy = 0.6528, Brier Score = 0.1967\n",
            "Timestep 29.00%: Accuracy = 0.6891, Brier Score = 0.1892\n",
            "Timestep 29.50%: Accuracy = 0.6991, Brier Score = 0.1837\n",
            "Timestep 30.00%: Accuracy = 0.6817, Brier Score = 0.1942\n",
            "Timestep 30.50%: Accuracy = 0.6667, Brier Score = 0.1967\n",
            "Timestep 31.00%: Accuracy = 0.6778, Brier Score = 0.1977\n",
            "Timestep 31.50%: Accuracy = 0.6885, Brier Score = 0.1929\n",
            "Timestep 32.00%: Accuracy = 0.6930, Brier Score = 0.1892\n",
            "Timestep 32.50%: Accuracy = 0.6707, Brier Score = 0.1994\n",
            "Timestep 33.00%: Accuracy = 0.6807, Brier Score = 0.1947\n",
            "Timestep 33.50%: Accuracy = 0.6618, Brier Score = 0.1952\n",
            "Timestep 34.00%: Accuracy = 0.6842, Brier Score = 0.1939\n",
            "Timestep 34.50%: Accuracy = 0.6796, Brier Score = 0.1838\n",
            "Timestep 35.00%: Accuracy = 0.7135, Brier Score = 0.1802\n",
            "Timestep 35.50%: Accuracy = 0.6986, Brier Score = 0.1843\n",
            "Timestep 36.00%: Accuracy = 0.7381, Brier Score = 0.1705\n",
            "Timestep 36.50%: Accuracy = 0.7257, Brier Score = 0.1735\n",
            "Timestep 37.00%: Accuracy = 0.7104, Brier Score = 0.1691\n",
            "Timestep 37.50%: Accuracy = 0.7289, Brier Score = 0.1762\n",
            "Timestep 38.00%: Accuracy = 0.7584, Brier Score = 0.1617\n",
            "Timestep 38.50%: Accuracy = 0.7321, Brier Score = 0.1668\n",
            "Timestep 39.00%: Accuracy = 0.7515, Brier Score = 0.1675\n",
            "Timestep 39.50%: Accuracy = 0.7214, Brier Score = 0.1695\n",
            "Timestep 40.00%: Accuracy = 0.7306, Brier Score = 0.1728\n",
            "Timestep 40.50%: Accuracy = 0.7528, Brier Score = 0.1616\n",
            "Timestep 41.00%: Accuracy = 0.7346, Brier Score = 0.1718\n",
            "Timestep 41.50%: Accuracy = 0.7485, Brier Score = 0.1637\n",
            "Timestep 42.00%: Accuracy = 0.7333, Brier Score = 0.1765\n",
            "Timestep 42.50%: Accuracy = 0.7588, Brier Score = 0.1620\n",
            "Timestep 43.00%: Accuracy = 0.7205, Brier Score = 0.1703\n",
            "Timestep 43.50%: Accuracy = 0.7625, Brier Score = 0.1564\n",
            "Timestep 44.00%: Accuracy = 0.7654, Brier Score = 0.1571\n",
            "Timestep 44.50%: Accuracy = 0.7644, Brier Score = 0.1505\n",
            "Timestep 45.00%: Accuracy = 0.8022, Brier Score = 0.1487\n",
            "Timestep 45.50%: Accuracy = 0.7714, Brier Score = 0.1594\n",
            "Timestep 46.00%: Accuracy = 0.7628, Brier Score = 0.1638\n",
            "Timestep 46.50%: Accuracy = 0.8012, Brier Score = 0.1388\n",
            "Timestep 47.00%: Accuracy = 0.7761, Brier Score = 0.1487\n",
            "Timestep 47.50%: Accuracy = 0.7739, Brier Score = 0.1496\n",
            "Timestep 48.00%: Accuracy = 0.7732, Brier Score = 0.1516\n",
            "Timestep 48.50%: Accuracy = 0.7657, Brier Score = 0.1449\n",
            "Timestep 49.00%: Accuracy = 0.7942, Brier Score = 0.1447\n",
            "Timestep 49.50%: Accuracy = 0.7744, Brier Score = 0.1452\n",
            "Timestep 50.00%: Accuracy = 0.7683, Brier Score = 0.1495\n",
            "Timestep 50.50%: Accuracy = 0.7902, Brier Score = 0.1472\n",
            "Timestep 51.00%: Accuracy = 0.7670, Brier Score = 0.1525\n",
            "Timestep 51.50%: Accuracy = 0.7629, Brier Score = 0.1581\n",
            "Timestep 52.00%: Accuracy = 0.7923, Brier Score = 0.1349\n",
            "Timestep 52.50%: Accuracy = 0.7588, Brier Score = 0.1622\n",
            "Timestep 53.00%: Accuracy = 0.7434, Brier Score = 0.1666\n",
            "Timestep 53.50%: Accuracy = 0.7446, Brier Score = 0.1635\n",
            "Timestep 54.00%: Accuracy = 0.7560, Brier Score = 0.1528\n",
            "Timestep 54.50%: Accuracy = 0.7848, Brier Score = 0.1423\n",
            "Timestep 55.00%: Accuracy = 0.7605, Brier Score = 0.1444\n",
            "Timestep 55.50%: Accuracy = 0.7595, Brier Score = 0.1549\n",
            "Timestep 56.00%: Accuracy = 0.7604, Brier Score = 0.1601\n",
            "Timestep 56.50%: Accuracy = 0.7568, Brier Score = 0.1450\n",
            "Timestep 57.00%: Accuracy = 0.7561, Brier Score = 0.1585\n",
            "Timestep 57.50%: Accuracy = 0.7994, Brier Score = 0.1360\n",
            "Timestep 58.00%: Accuracy = 0.8056, Brier Score = 0.1336\n",
            "Timestep 58.50%: Accuracy = 0.8011, Brier Score = 0.1392\n",
            "Timestep 59.00%: Accuracy = 0.8012, Brier Score = 0.1397\n",
            "Timestep 59.50%: Accuracy = 0.8105, Brier Score = 0.1380\n",
            "Timestep 60.00%: Accuracy = 0.8208, Brier Score = 0.1273\n",
            "Timestep 60.50%: Accuracy = 0.7571, Brier Score = 0.1510\n",
            "Timestep 61.00%: Accuracy = 0.8017, Brier Score = 0.1432\n",
            "Timestep 61.50%: Accuracy = 0.7915, Brier Score = 0.1353\n",
            "Timestep 62.00%: Accuracy = 0.8021, Brier Score = 0.1414\n",
            "Timestep 62.50%: Accuracy = 0.8097, Brier Score = 0.1327\n",
            "Timestep 63.00%: Accuracy = 0.8118, Brier Score = 0.1342\n",
            "Timestep 63.50%: Accuracy = 0.8266, Brier Score = 0.1259\n",
            "Timestep 64.00%: Accuracy = 0.8209, Brier Score = 0.1279\n",
            "Timestep 64.50%: Accuracy = 0.8102, Brier Score = 0.1323\n",
            "Timestep 65.00%: Accuracy = 0.7812, Brier Score = 0.1383\n",
            "Timestep 65.50%: Accuracy = 0.8148, Brier Score = 0.1207\n",
            "Timestep 66.00%: Accuracy = 0.7807, Brier Score = 0.1335\n",
            "Timestep 66.50%: Accuracy = 0.8047, Brier Score = 0.1301\n",
            "Timestep 67.00%: Accuracy = 0.8359, Brier Score = 0.1200\n",
            "Timestep 67.50%: Accuracy = 0.7994, Brier Score = 0.1353\n",
            "Timestep 68.00%: Accuracy = 0.8301, Brier Score = 0.1162\n",
            "Timestep 68.50%: Accuracy = 0.7982, Brier Score = 0.1336\n",
            "Timestep 69.00%: Accuracy = 0.8218, Brier Score = 0.1266\n",
            "Timestep 69.50%: Accuracy = 0.8314, Brier Score = 0.1147\n",
            "Timestep 70.00%: Accuracy = 0.8112, Brier Score = 0.1271\n",
            "Timestep 70.50%: Accuracy = 0.8515, Brier Score = 0.1081\n",
            "Timestep 71.00%: Accuracy = 0.8313, Brier Score = 0.1125\n",
            "Timestep 71.50%: Accuracy = 0.8318, Brier Score = 0.1101\n",
            "Timestep 72.00%: Accuracy = 0.8266, Brier Score = 0.1146\n",
            "Timestep 72.50%: Accuracy = 0.8262, Brier Score = 0.1073\n",
            "Timestep 73.00%: Accuracy = 0.8503, Brier Score = 0.1106\n",
            "Timestep 73.50%: Accuracy = 0.8246, Brier Score = 0.1174\n",
            "Timestep 74.00%: Accuracy = 0.8269, Brier Score = 0.1173\n",
            "Timestep 74.50%: Accuracy = 0.8160, Brier Score = 0.1224\n",
            "Timestep 75.00%: Accuracy = 0.8402, Brier Score = 0.1055\n",
            "Timestep 75.50%: Accuracy = 0.8338, Brier Score = 0.1087\n",
            "Timestep 76.00%: Accuracy = 0.8350, Brier Score = 0.1048\n",
            "Timestep 76.50%: Accuracy = 0.8672, Brier Score = 0.0996\n",
            "Timestep 77.00%: Accuracy = 0.8594, Brier Score = 0.1044\n",
            "Timestep 77.50%: Accuracy = 0.8515, Brier Score = 0.1035\n",
            "Timestep 78.00%: Accuracy = 0.8522, Brier Score = 0.1038\n",
            "Timestep 78.50%: Accuracy = 0.8515, Brier Score = 0.1020\n",
            "Timestep 79.00%: Accuracy = 0.8544, Brier Score = 0.0992\n",
            "Timestep 79.50%: Accuracy = 0.8358, Brier Score = 0.1093\n",
            "Timestep 80.00%: Accuracy = 0.8583, Brier Score = 0.1023\n",
            "Timestep 80.50%: Accuracy = 0.8696, Brier Score = 0.1076\n",
            "Timestep 81.00%: Accuracy = 0.8506, Brier Score = 0.0994\n",
            "Timestep 81.50%: Accuracy = 0.8615, Brier Score = 0.1008\n",
            "Timestep 82.00%: Accuracy = 0.8713, Brier Score = 0.0883\n",
            "Timestep 82.50%: Accuracy = 0.8886, Brier Score = 0.0839\n",
            "Timestep 83.00%: Accuracy = 0.8757, Brier Score = 0.0913\n",
            "Timestep 83.50%: Accuracy = 0.8876, Brier Score = 0.0869\n",
            "Timestep 84.00%: Accuracy = 0.8601, Brier Score = 0.0969\n",
            "Timestep 84.50%: Accuracy = 0.8521, Brier Score = 0.0949\n",
            "Timestep 85.00%: Accuracy = 0.8710, Brier Score = 0.0877\n",
            "Timestep 85.50%: Accuracy = 0.8571, Brier Score = 0.1025\n",
            "Timestep 86.00%: Accuracy = 0.8929, Brier Score = 0.0768\n",
            "Timestep 86.50%: Accuracy = 0.8952, Brier Score = 0.0786\n",
            "Timestep 87.00%: Accuracy = 0.8782, Brier Score = 0.0846\n",
            "Timestep 87.50%: Accuracy = 0.8819, Brier Score = 0.0861\n",
            "Timestep 88.00%: Accuracy = 0.8947, Brier Score = 0.0823\n",
            "Timestep 88.50%: Accuracy = 0.9045, Brier Score = 0.0810\n",
            "Timestep 89.00%: Accuracy = 0.8892, Brier Score = 0.0872\n",
            "Timestep 89.50%: Accuracy = 0.9009, Brier Score = 0.0811\n",
            "Timestep 90.00%: Accuracy = 0.8901, Brier Score = 0.0844\n",
            "Timestep 90.50%: Accuracy = 0.8784, Brier Score = 0.0866\n",
            "Timestep 91.00%: Accuracy = 0.8927, Brier Score = 0.0803\n",
            "Timestep 91.50%: Accuracy = 0.9096, Brier Score = 0.0694\n",
            "Timestep 92.00%: Accuracy = 0.9000, Brier Score = 0.0753\n",
            "Timestep 92.50%: Accuracy = 0.8895, Brier Score = 0.0785\n",
            "Timestep 93.00%: Accuracy = 0.8597, Brier Score = 0.0925\n",
            "Timestep 93.50%: Accuracy = 0.8869, Brier Score = 0.0768\n",
            "Timestep 94.00%: Accuracy = 0.8897, Brier Score = 0.0751\n",
            "Timestep 94.50%: Accuracy = 0.8782, Brier Score = 0.0860\n",
            "Timestep 95.00%: Accuracy = 0.8792, Brier Score = 0.0836\n",
            "Timestep 95.50%: Accuracy = 0.8816, Brier Score = 0.0809\n",
            "Timestep 96.00%: Accuracy = 0.8739, Brier Score = 0.0839\n",
            "Timestep 96.50%: Accuracy = 0.9123, Brier Score = 0.0660\n",
            "Timestep 97.00%: Accuracy = 0.8920, Brier Score = 0.0773\n",
            "Timestep 97.50%: Accuracy = 0.8783, Brier Score = 0.0849\n",
            "Timestep 98.00%: Accuracy = 0.9120, Brier Score = 0.0771\n",
            "Timestep 98.50%: Accuracy = 0.9022, Brier Score = 0.0729\n",
            "Timestep 99.00%: Accuracy = 0.8957, Brier Score = 0.0760\n",
            "Timestep 99.50%: Accuracy = 0.8778, Brier Score = 0.0882\n",
            "Timestep 100.00%: Accuracy = 0.8915, Brier Score = 0.0774\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary Statistics:\n",
            "Average Accuracy: 0.7691  0.0822\n",
            "Average Brier Score: 0.1512  0.0467\n",
            "Best Accuracy: 0.9123 at timestep 96.50%\n",
            "Best Brier Score: 0.0660 at timestep 96.50%\n"
          ]
        }
      ],
      "source": [
        "# Test accuracy and Brier score of model for each timestep on test data and plot\n",
        "accuracies = []\n",
        "brier_scores = []\n",
        "timesteps = []\n",
        "def brier_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "for timestep, i in zip(ensemble_models, test_data.keys()):\n",
        "    model = ensemble_models[timestep]\n",
        "    # Convert test data to array\n",
        "    y_test = np.array([row[\"label\"] for row in test_data_seq[i]])\n",
        "    X_test = np.array([row[\"rows\"] for row in test_data_seq[i]])\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    \n",
        "    # Calculate Brier score\n",
        "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probability predictions\n",
        "    brier_score = brier_loss(y_test, y_test_pred_proba)\n",
        "    \n",
        "    print(f\"Timestep {timestep:.2%}: Accuracy = {accuracy:.4f}, Brier Score = {brier_score:.4f}\")\n",
        "    accuracies.append(accuracy)\n",
        "    brier_scores.append(brier_score)\n",
        "    timesteps.append(timestep)\n",
        "\n",
        "# Create subplots for both metrics\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot accuracy\n",
        "ax1.plot(timesteps, accuracies, 'b-', linewidth=2, marker='o', markersize=3)\n",
        "ax1.set_xlabel(\"Timestep\")\n",
        "ax1.set_ylabel(\"Accuracy\")\n",
        "ax1.set_title(\"Test Accuracy vs Timestep\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([min(accuracies) * 0.95, max(accuracies) * 1.05])\n",
        "\n",
        "# Plot Brier score\n",
        "ax2.plot(timesteps, brier_scores, 'r-', linewidth=2, marker='s', markersize=3)\n",
        "ax2.set_xlabel(\"Timestep\")\n",
        "ax2.set_ylabel(\"Brier Score\")\n",
        "ax2.set_title(\"Test Brier Score vs Timestep\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim([min(brier_scores) * 0.95, max(brier_scores) * 1.05])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\nSummary Statistics:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}  {np.std(accuracies):.4f}\")\n",
        "print(f\"Average Brier Score: {np.mean(brier_scores):.4f}  {np.std(brier_scores):.4f}\")\n",
        "print(f\"Best Accuracy: {max(accuracies):.4f} at timestep {timesteps[np.argmax(accuracies)]:.2%}\")\n",
        "print(f\"Best Brier Score: {min(brier_scores):.4f} at timestep {timesteps[np.argmin(brier_scores)]:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.56514468, 0.43485532]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ensemble_models[0.995]\n",
        "features = [\"relative_strength\", \"score_difference\", \"home_has_possession\", \"end.down\", \"end.distance\", \"end.yardsToEndzone\",  \"home_timeouts_left\", \"away_timeouts_left\"]\n",
        "data_point = [[0.5, -4, 1, 1, 1, 1, 1, 1], [0.5, -4, 1, 1, 1, 1, 1, 1], [0.5, -4, 1, 1, 1, 1, 1, 1], [0.5, -4, 1, 1, 1, 1, 1, 1], [0.5, -4, 1, 1, 1, 1, 1, 1]]\n",
        "model.predict_proba(np.array([data_point]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name:  xgboost\n",
            "(2, 5, 11)\n",
            "(2, 11)\n",
            "[[0.         1.        ]\n",
            " [0.19230769 0.80769231]]\n",
            "Model name:  nn\n",
            "(2, 5, 11)\n",
            "(2, 11)\n",
            "[[1. 0.]\n",
            " [1. 0.]]\n",
            "Model name:  logistic\n",
            "(2, 5, 11)\n",
            "(2, 11)\n",
            "[[0. 1.]\n",
            " [0. 1.]]\n",
            "Model name:  lstm\n",
            "(2, 5, 11)\n",
            "[[0.79934996 0.20065005]\n",
            " [0.7205218  0.27947822]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.48275698, 0.51724302],\n",
              "       [0.44681822, 0.55318178]])"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ensemble_models[0]\n",
        "model.predict_proba(np.arange(110).reshape(2, 5, 11))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data for 2024\n",
            "Processed file:  game_401671629.csv\n",
            "Processed file:  game_401671601.csv\n",
            "Processed file:  game_401671826.csv\n",
            "Processed file:  game_401671832.csv\n",
            "Processed file:  game_401671749.csv\n",
            "Processed file:  game_401671775.csv\n",
            "Processed file:  game_401671761.csv\n",
            "Processed file:  game_401671760.csv\n",
            "Processed file:  game_401671774.csv\n",
            "Processed file:  game_401671748.csv\n",
            "Processed file:  game_401671833.csv\n",
            "Processed file:  game_401671827.csv\n",
            "Processed file:  game_401671600.csv\n",
            "Processed file:  game_401671628.csv\n",
            "Processed file:  game_401671616.csv\n",
            "Processed file:  game_401671831.csv\n",
            "Processed file:  game_401671825.csv\n",
            "Processed file:  game_401671819.csv\n",
            "Processed file:  game_401671762.csv\n",
            "Processed file:  game_401671776.csv\n",
            "Processed file:  game_401671789.csv\n",
            "Processed file:  game_401671788.csv\n",
            "Processed file:  game_401671777.csv\n",
            "Processed file:  game_401671763.csv\n",
            "Processed file:  game_401671818.csv\n",
            "Processed file:  game_401671824.csv\n",
            "Processed file:  game_401671830.csv\n",
            "Processed file:  game_401671617.csv\n",
            "Processed file:  game_401671808.csv\n",
            "Processed file:  game_401671834.csv\n",
            "Processed file:  game_401671820.csv\n",
            "Processed file:  game_401671767.csv\n",
            "Processed file:  game_401671773.csv\n",
            "Processed file:  game_401671798.csv\n",
            "Processed file:  game_401671799.csv\n",
            "Processed file:  game_401671772.csv\n",
            "Processed file:  game_401671766.csv\n",
            "Processed file:  game_401671821.csv\n",
            "Processed file:  game_401671835.csv\n",
            "Processed file:  game_401671809.csv\n",
            "Processed file:  game_401671638.csv\n",
            "Processed file:  game_401671823.csv\n",
            "Processed file:  game_401671837.csv\n",
            "Processed file:  game_401671599.csv\n",
            "Processed file:  game_401671770.csv\n",
            "Processed file:  game_401671764.csv\n",
            "Processed file:  game_401671758.csv\n",
            "Processed file:  game_401671759.csv\n",
            "Processed file:  game_401671765.csv\n",
            "Processed file:  game_401671771.csv\n",
            "Processed file:  game_401671836.csv\n",
            "Processed file:  game_401671822.csv\n",
            "Processed file:  game_401671639.csv\n",
            "Processed file:  game_401671662.csv\n",
            "Processed file:  game_401671676.csv\n",
            "Processed file:  game_401671845.csv\n",
            "Processed file:  game_401671851.csv\n",
            "Processed file:  game_401671689.csv\n",
            "Processed file:  game_401671716.csv\n",
            "Processed file:  game_401671702.csv\n",
            "Processed file:  game_401671703.csv\n",
            "Processed file:  game_401671717.csv\n",
            "Processed file:  game_401671688.csv\n",
            "Processed file:  game_401671850.csv\n",
            "Processed file:  game_401671844.csv\n",
            "Processed file:  game_401671677.csv\n",
            "Processed file:  game_401671663.csv\n",
            "Processed file:  game_401671649.csv\n",
            "Processed file:  game_401671675.csv\n",
            "Processed file:  game_401671661.csv\n",
            "Processed file:  game_401671852.csv\n",
            "Processed file:  game_401671846.csv\n",
            "Processed file:  game_401671729.csv\n",
            "Processed file:  game_401671701.csv\n",
            "Processed file:  game_401671715.csv\n",
            "Processed file:  game_401671714.csv\n",
            "Processed file:  game_401671700.csv\n",
            "Processed file:  game_401671728.csv\n",
            "Processed file:  game_401671489.csv\n",
            "Processed file:  game_401671847.csv\n",
            "Processed file:  game_401671853.csv\n",
            "Processed file:  game_401671660.csv\n",
            "Processed file:  game_401671674.csv\n",
            "Processed file:  game_401671648.csv\n",
            "Processed file:  game_401671670.csv\n",
            "Processed file:  game_401671664.csv\n",
            "Processed file:  game_401671658.csv\n",
            "Processed file:  game_401671857.csv\n",
            "Processed file:  game_401671843.csv\n",
            "Processed file:  game_401671704.csv\n",
            "Processed file:  game_401671710.csv\n",
            "Processed file:  game_401671738.csv\n",
            "Processed file:  game_401671739.csv\n",
            "Processed file:  game_401671711.csv\n",
            "Processed file:  game_401671705.csv\n",
            "Processed file:  game_401671842.csv\n",
            "Processed file:  game_401671856.csv\n",
            "Processed file:  game_401671659.csv\n",
            "Processed file:  game_401671665.csv\n",
            "Processed file:  game_401671671.csv\n",
            "Processed file:  game_401671667.csv\n",
            "Processed file:  game_401671673.csv\n",
            "Processed file:  game_401671868.csv\n",
            "Processed file:  game_401671840.csv\n",
            "Processed file:  game_401671698.csv\n",
            "Processed file:  game_401671854.csv\n",
            "Processed file:  game_401671713.csv\n",
            "Processed file:  game_401671707.csv\n",
            "Processed file:  game_401671706.csv\n",
            "Processed file:  game_401671712.csv\n",
            "Processed file:  game_401671855.csv\n",
            "Processed file:  game_401671699.csv\n",
            "Processed file:  game_401671841.csv\n",
            "Processed file:  game_401671869.csv\n",
            "Processed file:  game_401671672.csv\n",
            "Processed file:  game_401671666.csv\n",
            "Processed file:  game_401671643.csv\n",
            "Processed file:  game_401671657.csv\n",
            "Processed file:  game_401671864.csv\n",
            "Processed file:  game_401671870.csv\n",
            "Processed file:  game_401671858.csv\n",
            "Processed file:  game_401671680.csv\n",
            "Processed file:  game_401671694.csv\n",
            "Processed file:  game_401671737.csv\n",
            "Processed file:  game_401671723.csv\n",
            "Processed file:  game_401671722.csv\n",
            "Processed file:  game_401671736.csv\n",
            "Processed file:  game_401671695.csv\n",
            "Processed file:  game_401671681.csv\n",
            "Processed file:  game_401671859.csv\n",
            "Processed file:  game_401671871.csv\n",
            "Processed file:  game_401671865.csv\n",
            "Processed file:  game_401671656.csv\n",
            "Processed file:  game_401671642.csv\n",
            "Processed file:  game_401671668.csv\n",
            "Processed file:  game_401671654.csv\n",
            "Processed file:  game_401671640.csv\n",
            "Processed file:  game_401671873.csv\n",
            "Processed file:  game_401671867.csv\n",
            "Processed file:  game_401671697.csv\n",
            "Processed file:  game_401671683.csv\n",
            "Processed file:  game_401671495.csv\n",
            "Processed file:  game_401671708.csv\n",
            "Processed file:  game_401671720.csv\n",
            "Processed file:  game_401671734.csv\n",
            "Processed file:  game_401671735.csv\n",
            "Processed file:  game_401671721.csv\n",
            "Processed file:  game_401671709.csv\n",
            "Processed file:  game_401671494.csv\n",
            "Processed file:  game_401671682.csv\n",
            "Processed file:  game_401671696.csv\n",
            "Processed file:  game_401671866.csv\n",
            "Processed file:  game_401671872.csv\n",
            "Processed file:  game_401671641.csv\n",
            "Processed file:  game_401671655.csv\n",
            "Processed file:  game_401671669.csv\n",
            "Processed file:  game_401671651.csv\n",
            "Processed file:  game_401671645.csv\n",
            "Processed file:  game_401671679.csv\n",
            "Processed file:  game_401671692.csv\n",
            "Processed file:  game_401671686.csv\n",
            "Processed file:  game_401671876.csv\n",
            "Processed file:  game_401671862.csv\n",
            "Processed file:  game_401671490.csv\n",
            "Processed file:  game_401671725.csv\n",
            "Processed file:  game_401671731.csv\n",
            "Processed file:  game_401671719.csv\n",
            "Processed file:  game_401671718.csv\n",
            "Processed file:  game_401671730.csv\n",
            "Processed file:  game_401671724.csv\n",
            "Processed file:  game_401671491.csv\n",
            "Processed file:  game_401671863.csv\n",
            "Processed file:  game_401671877.csv\n",
            "Processed file:  game_401671687.csv\n",
            "Processed file:  game_401671693.csv\n",
            "Processed file:  game_401671678.csv\n",
            "Processed file:  game_401671644.csv\n",
            "Processed file:  game_401671650.csv\n",
            "Processed file:  game_401671646.csv\n",
            "Processed file:  game_401671652.csv\n",
            "Processed file:  game_401671685.csv\n",
            "Processed file:  game_401671849.csv\n",
            "Processed file:  game_401671691.csv\n",
            "Processed file:  game_401671861.csv\n",
            "Processed file:  game_401671875.csv\n",
            "Processed file:  game_401671493.csv\n",
            "Processed file:  game_401671732.csv\n",
            "Processed file:  game_401671726.csv\n",
            "Processed file:  game_401671727.csv\n",
            "Processed file:  game_401671733.csv\n",
            "Processed file:  game_401671492.csv\n",
            "Processed file:  game_401671874.csv\n",
            "Processed file:  game_401671860.csv\n",
            "Processed file:  game_401671690.csv\n",
            "Processed file:  game_401671848.csv\n",
            "Processed file:  game_401671684.csv\n",
            "Processed file:  game_401671653.csv\n",
            "Processed file:  game_401671647.csv\n",
            "Processed file:  game_401671620.csv\n",
            "Processed file:  game_401671634.csv\n",
            "Processed file:  game_401671807.csv\n",
            "Processed file:  game_401671813.csv\n",
            "Processed file:  game_401671768.csv\n",
            "Processed file:  game_401671754.csv\n",
            "Processed file:  game_401671740.csv\n",
            "Processed file:  game_401671797.csv\n",
            "Processed file:  game_401671783.csv\n",
            "Processed file:  game_401671782.csv\n",
            "Processed file:  game_401671796.csv\n",
            "Processed file:  game_401671741.csv\n",
            "Processed file:  game_401671755.csv\n",
            "Processed file:  game_401671769.csv\n",
            "Processed file:  game_401671812.csv\n",
            "Processed file:  game_401671806.csv\n",
            "Processed file:  game_401671635.csv\n",
            "Processed file:  game_401671621.csv\n",
            "Processed file:  game_401671637.csv\n",
            "Processed file:  game_401671623.csv\n",
            "Processed file:  game_401671810.csv\n",
            "Processed file:  game_401671804.csv\n",
            "Processed file:  game_401671838.csv\n",
            "Processed file:  game_401671743.csv\n",
            "Processed file:  game_401671757.csv\n",
            "Processed file:  game_401671780.csv\n",
            "Processed file:  game_401671794.csv\n",
            "Processed file:  game_401671795.csv\n",
            "Processed file:  game_401671781.csv\n",
            "Processed file:  game_401671756.csv\n",
            "Processed file:  game_401671742.csv\n",
            "Processed file:  game_401671839.csv\n",
            "Processed file:  game_401671805.csv\n",
            "Processed file:  game_401671811.csv\n",
            "Processed file:  game_401671622.csv\n",
            "Processed file:  game_401671636.csv\n",
            "Processed file:  game_401671632.csv\n",
            "Processed file:  game_401671626.csv\n",
            "Processed file:  game_401671829.csv\n",
            "Processed file:  game_401671815.csv\n",
            "Processed file:  game_401671801.csv\n",
            "Processed file:  game_401671746.csv\n",
            "Processed file:  game_401671752.csv\n",
            "Processed file:  game_401671785.csv\n",
            "Processed file:  game_401671791.csv\n",
            "Processed file:  game_401671790.csv\n",
            "Processed file:  game_401671784.csv\n",
            "Processed file:  game_401671753.csv\n",
            "Processed file:  game_401671747.csv\n",
            "Processed file:  game_401671800.csv\n",
            "Processed file:  game_401671814.csv\n",
            "Processed file:  game_401671828.csv\n",
            "Processed file:  game_401671627.csv\n",
            "Processed file:  game_401671633.csv\n",
            "Processed file:  game_401671625.csv\n",
            "Processed file:  game_401671631.csv\n",
            "Processed file:  game_401671619.csv\n",
            "Processed file:  game_401671802.csv\n",
            "Processed file:  game_401671816.csv\n",
            "Processed file:  game_401671751.csv\n",
            "Processed file:  game_401671745.csv\n",
            "Processed file:  game_401671779.csv\n",
            "Processed file:  game_401671792.csv\n",
            "Processed file:  game_401671786.csv\n",
            "Processed file:  game_401671787.csv\n",
            "Processed file:  game_401671793.csv\n",
            "Processed file:  game_401671778.csv\n",
            "Processed file:  game_401671744.csv\n",
            "Processed file:  game_401671750.csv\n",
            "Processed file:  game_401671817.csv\n",
            "Processed file:  game_401671803.csv\n",
            "Processed file:  game_401671618.csv\n",
            "Processed file:  game_401671630.csv\n",
            "Processed file:  game_401671624.csv\n"
          ]
        }
      ],
      "source": [
        "# Write predictions to csv file\n",
        "from process_data import write_predictions\n",
        "write_predictions(ensemble_models, interpolated_dir, [2024], 4, features, replace_nan_val = 0, phat_b = \"ensemble_phat_b_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied '/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024' to '/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/test_7/ensemble_model_testing_2'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the ancestor directory and the parent directory\n",
        "src_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Adjust the number of \"../\" as needed\n",
        "dest_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
        "\n",
        "# Specify the file or directory to copy from the ancestor directory\n",
        "source = os.path.join(src_dir, \"dataset_interpolated_fixed\", \"2024\")  # Replace with the actual name\n",
        "destination = os.path.join(dest_dir, \"test_7\", \"ensemble_model_testing_2\")  # Replace with the desired name\n",
        "\n",
        "# Perform the copy operation\n",
        "if os.path.exists(source):\n",
        "    if os.path.isdir(source):\n",
        "        shutil.copytree(source, destination)\n",
        "    else:\n",
        "        shutil.copy2(source, destination)\n",
        "    print(f\"Copied '{source}' to '{destination}'\")\n",
        "else:\n",
        "    print(f\"Source '{source}' does not exist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NFL_env (3.9.13)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
