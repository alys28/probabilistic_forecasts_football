{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "print(parent_dir)\n",
    "interpolated_dir = os.path.join(parent_dir, \"dataset_interpolated_fixed\")\n",
    "# features = [\"game_completed\", \"relative_strength\", \"score_difference\", \"type.id\", \"home_has_possession\", \"end.down\", \"end.yardsToEndzone\", \"end.distance\", \"field_position_shift\", \"home_timeouts_left\", \"away_timeouts_left\"]\n",
    "features = [\"game_completed\", \"relative_strength\", \"score_difference\", \"home_has_possession\", \"end.down\", \"end.distance\", \"end.yardsToEndzone\",  \"home_timeouts_left\", \"away_timeouts_left\"]\n",
    "# features = [\"relative_strength\", \"score_difference\", \"home_has_possession\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 2022\n",
      "  Processing 271 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2022\n",
      "Loading data for 2024\n",
      "skipping  2024\n",
      "Loading data for 2023\n",
      "  Processing 272 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2023\n",
      "Loading data for .DS_Store\n",
      "Loading data for 2017\n",
      "  Processing 254 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2017\n",
      "Loading data for 2019\n",
      "  Processing 256 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2019\n",
      "Loading data for 2021\n",
      "  Processing 272 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2021\n",
      "Loading data for 2020\n",
      "  Processing 255 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2020\n",
      "Loading data for 2018\n",
      "  Processing 255 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2018\n",
      "Loading data for 2016\n",
      "  Processing 254 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2016\n",
      "Loading data for 2022\n",
      "skipping  2022\n",
      "Loading data for 2024\n",
      "  Processing 272 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2024\n",
      "Loading data for 2023\n",
      "skipping  2023\n",
      "Loading data for .DS_Store\n",
      "Loading data for 2017\n",
      "skipping  2017\n",
      "Loading data for 2019\n",
      "skipping  2019\n",
      "Loading data for 2021\n",
      "skipping  2021\n",
      "Loading data for 2020\n",
      "skipping  2020\n",
      "Loading data for 2018\n",
      "skipping  2018\n",
      "Loading data for 2016\n",
      "skipping  2016\n"
     ]
    }
   ],
   "source": [
    "# Reset the modules\n",
    "modules_to_reload = [\n",
    "    'process_data',\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "import process_data\n",
    "training_data = process_data.load_data(interpolated_dir, \n",
    "                                       years = [2016, 2017,2018, 2019, 2020, 2021, 2022, 2023], \n",
    "                                       history_length = 0, \n",
    "                                       features = features, \n",
    "                                       label_feature = \"home_win\")\n",
    "\n",
    "# validation_data = process_data.load_data(interpolated_dir, \n",
    "#                                        years = [2023], \n",
    "#                                        history_length = 0, \n",
    "#                                        features = features, \n",
    "#                                        label_feature = \"home_win\",\n",
    "#                                        train = True\n",
    "#                                        )\n",
    "\n",
    "test_data = process_data.load_data(interpolated_dir, \n",
    "                                       years = [2024],\n",
    "                                       history_length = 0, \n",
    "                                       features = features, \n",
    "                                       label_feature = \"home_win\",\n",
    "                                       train = False\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 2022\n",
      "  Processing 271 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2022\n",
      "Loading data for 2024\n",
      "skipping  2024\n",
      "Loading data for 2023\n",
      "  Processing 272 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2023\n",
      "Loading data for .DS_Store\n",
      "Loading data for 2017\n",
      "skipping  2017\n",
      "Loading data for 2019\n",
      "skipping  2019\n",
      "Loading data for 2021\n",
      "  Processing 272 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2021\n",
      "Loading data for 2020\n",
      "  Processing 255 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2020\n",
      "Loading data for 2018\n",
      "skipping  2018\n",
      "Loading data for 2016\n",
      "skipping  2016\n",
      "Loading data for 2022\n",
      "skipping  2022\n",
      "Loading data for 2024\n",
      "  Processing 272 CSV files in parallel with 8 workers...\n",
      "  Completed processing 2024\n",
      "Loading data for 2023\n",
      "skipping  2023\n",
      "Loading data for .DS_Store\n",
      "Loading data for 2017\n",
      "skipping  2017\n",
      "Loading data for 2019\n",
      "skipping  2019\n",
      "Loading data for 2021\n",
      "skipping  2021\n",
      "Loading data for 2020\n",
      "skipping  2020\n",
      "Loading data for 2018\n",
      "skipping  2018\n",
      "Loading data for 2016\n",
      "skipping  2016\n",
      "Num train entries: 8549\n",
      "Num test entries: 2371\n"
     ]
    }
   ],
   "source": [
    "# Load edge-case datasets (filter by timestep threshold and score_difference)\n",
    "# Reload module to pick up the new function\n",
    "modules_to_reload = [\n",
    "    'process_data',\n",
    "]\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "import process_data\n",
    "# edge_featues = [\"game_completed\", \"relative_strength\", \"score_difference\", \"home_has_possession\", \"end.down\",  \"end.distance\", \"end.yardsToEndzone\", \"home_timeouts_left\", \"away_timeouts_left\"]\n",
    "edge_threshold = 0.96  # minimum timestep to include (adjust as needed)\n",
    "edge_training_data = process_data.load_edge_case_data(\n",
    "    interpolated_dir,\n",
    "    years=[2020, 2021, 2022, 2023],\n",
    "    history_length=0,\n",
    "    features=features,\n",
    "    label_feature='home_win',\n",
    "    threshold=edge_threshold,\n",
    "    train=True\n",
    ")\n",
    "edge_test_data = process_data.load_edge_case_data(\n",
    "    interpolated_dir,\n",
    "    years=[2024],\n",
    "    history_length=0,\n",
    "    features=features,\n",
    "    label_feature='home_win',\n",
    "    threshold=edge_threshold,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "print('Num train entries:', len(edge_training_data))\n",
    "print('Num test entries:', len(edge_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": Training Loss = 0.4658, Accuracy = 0.7737, Test Loss = 0.4665, Test Accuracy = 0.8223\n",
      "[ 0.9961111   0.5851     -2.          1.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.00388889 -0.00777778  1.          0.\n",
      "  0.          0.          0.          1.          1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.56730726, 0.43269274]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a single LogisticRegressionModel on one timestep from the edge-case data\n",
    "modules_to_reload = [\n",
    "    'models.logistic_regression',\n",
    "    'models.Model'\n",
    "]\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "from models.logistic_regression import LogisticRegressionModel\n",
    "from models.xg_boost import LightGBM\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define numeric/other features here so this cell is self-contained\n",
    "edge_numeric_features = [\"score_difference\", \"relative_strength\", \"end.yardsToEndzone\", \"end.distance\"]\n",
    "edge_other_features = [\"home_has_possession\", \"end.down\", \"home_timeouts_left\", \"away_timeouts_left\"]\n",
    "# Define numeric/other features here so this cell is self-contained\n",
    "edge_numeric_features = [\n",
    "    \"score_difference\", \n",
    "    \"relative_strength\", \n",
    "    \"end.yardsToEndzone\", \n",
    "    \"end.distance\",\n",
    "    \"time_remaining_pct\",\n",
    "    \"score_diff_x_time\",\n",
    "    \"timeout_diff\",\n",
    "    \"yards_to_fg_range\"\n",
    "]\n",
    "\n",
    "edge_other_features = [\n",
    "    \"game_completed\",\n",
    "    \"home_has_possession\", \n",
    "    \"end.down\", \n",
    "    \"home_timeouts_left\", \n",
    "    \"away_timeouts_left\",\n",
    "    \"home_winning_with_ball\",\n",
    "    \"home_winning_no_ball\",\n",
    "    \"away_winning_with_ball\",\n",
    "    \"away_winning_no_ball\",\n",
    "    \"tied\",\n",
    "    \"needs_fg_only\",\n",
    "    \"needs_td_only\",\n",
    "    \"needs_multiple_scores\",\n",
    "    \"in_fg_range\",     # Binary (0/1) - moved from numeric\n",
    "    \"in_red_zone\"      # Binary (0/1) - moved from numeric\n",
    "]\n",
    "\n",
    "derived_features = [\n",
    "    \"home_winning_with_ball\", \"home_winning_no_ball\",\n",
    "    \"away_winning_with_ball\", \"away_winning_no_ball\",\n",
    "    \"tied\", \"time_remaining_pct\", \"score_diff_x_time\",\n",
    "    \"needs_fg_only\", \"needs_td_only\", \"needs_multiple_scores\",\n",
    "    \"timeout_diff\", \"yards_to_fg_range\", \"in_fg_range\", \"in_red_zone\"\n",
    "]\n",
    "\n",
    "all_features = features + derived_features\n",
    "# Choose timestep to train on (by default the largest available)\n",
    "if not edge_training_data:\n",
    "    raise ValueError(\"edge_training_data is empty\")\n",
    "\n",
    "# Prepare training data for selected timestep\n",
    "X = np.array([entry[\"rows\"].reshape(-1) for entry in edge_training_data])\n",
    "y = np.array([entry[\"label\"] for entry in edge_training_data])\n",
    "\n",
    "# Instantiate and train the model\n",
    "single_model = LogisticRegressionModel(\n",
    "    numeric_features=edge_numeric_features,\n",
    "    other_features=edge_other_features,\n",
    "    all_features=all_features,\n",
    "    use_calibration=False,\n",
    "    optimize_hyperparams=False\n",
    ")\n",
    "\n",
    "xgboost_model = LightGBM(\n",
    "    numeric_features=edge_numeric_features,\n",
    "    other_features=edge_other_features,\n",
    "    all_features=all_features,\n",
    "    use_calibration=False,\n",
    "    optimize_hyperparams=False \n",
    ")\n",
    "\n",
    "single_model.fit(X, y)\n",
    "print(X[1])\n",
    "# Keep model in notebook namespace\n",
    "edge_single_model = single_model\n",
    "edge_single_model.predict_proba([X[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared X_train shape: (7694, 23), X_val shape: (855, 23)\n",
      "Starting training on device: cpu\n",
      "Early stopping at epoch 36\n",
      "Best epoch: 26, Train Acc: 0.9014, Train Loss: 0.2273, Val Acc: 0.8620, Val Loss: 0.3153\n",
      "Restored model from best epoch 26 with val_loss: 0.315271\n",
      "Direct classifier training finished.\n",
      "Train loss: 0.22730973892468065\n",
      "Train accuracy: 0.9013517026254224\n",
      "Val loss: 0.31527079322508406\n",
      "Val accuracy: 0.8619883040935673\n"
     ]
    }
   ],
   "source": [
    "# Train a single DirectClassifier (neural network) on one timestep from the edge-case data\n",
    "modules_to_reload = [\n",
    "    'models.direct_prediction_network',\n",
    "    'models.Model'\n",
    "]\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "from models.direct_prediction_network import DirectPredictionNetwork, DirectClassifier\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare training data (flatten rows to 2D)\n",
    "X = np.array([np.asarray(entry['rows']).reshape(-1) for entry in edge_training_data], dtype=np.float32)\n",
    "y = np.array([entry['label'] for entry in edge_training_data], dtype=np.float32)\n",
    "# Train/validation split\n",
    "if len(X) < 10:\n",
    "    print(f\"Too few samples ({len(X)}) - using all for training\")\n",
    "    X_train, y_train, X_val, y_val = X, y, None, None\n",
    "else:\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    stratify = y if (len(unique) > 1 and counts.min() >= 2) else None\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=42, stratify=stratify)\n",
    "\n",
    "print(f\"Prepared X_train shape: {X_train.shape}, X_val shape: {None if X_val is None else X_val.shape}\")\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Build network\n",
    "input_dim = X.shape[1]\n",
    "direct_net = DirectPredictionNetwork(input_dim=input_dim, hidden_dims=[64, 32, 16, 8], dropout_rate=0).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(direct_net.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    " \n",
    "# Instantiate classifier\n",
    "direct_classifier = DirectClassifier(\n",
    "    model=direct_net,\n",
    "    epochs=50,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    features=all_features,  # uses same feature ordering as the dataset\n",
    "    scheduler=None,\n",
    "    use_scaler=True,\n",
    "    optimize_hyperparams=False\n",
    ")\n",
    "\n",
    "# Train (classifier handles internal scaling and uses provided val set)\n",
    "direct_classifier.fit(X_train, y_train, val_X=X_val, val_y=y_val, batch_size=64, verbose=True)\n",
    "\n",
    "print(\"Direct classifier training finished.\")\n",
    "print(\"Train loss:\", direct_classifier.final_train_loss)\n",
    "print(\"Train accuracy:\", direct_classifier.final_train_accuracy)\n",
    "print(\"Val loss:\", direct_classifier.final_val_loss)\n",
    "print(\"Val accuracy:\", direct_classifier.final_val_accuracy)\n",
    "\n",
    "# Keep classifier in notebook namespace\n",
    "edge_direct_classifier = direct_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other_features = [\n",
    "#             \"type.id\",             # Play type (categorical)\n",
    "#             \"home_has_possession\", # Binary indicator\n",
    "#             \"end.down\",            # Down number (1-4, discrete)\n",
    "#             \"home_timeouts_left\",  # Discrete count (0-3)\n",
    "#             \"away_timeouts_left\",  # Discrete count (0-3)\n",
    "#             \"game_completed\"\n",
    "#         ]\n",
    "# numeric_features = [\n",
    "#     \"score_difference\",\n",
    "#     \"relative_strength\", \n",
    "#     \"end.yardsToEndzone\", \n",
    "#     \"end.distance\", \n",
    "#     \"field_position_shift\"\n",
    "# ]\n",
    "other_features = [\n",
    "            \"home_has_possession\", # Binary indicator\n",
    "            # \"end.down\",            # Down number (1-4, discrete)\n",
    "            # \"home_timeouts_left\",  # Discrete count (0-3)\n",
    "            # \"away_timeouts_left\",  # Discrete count (0-3)\n",
    "        ]\n",
    "numeric_features = [\n",
    "    \"score_difference\",\n",
    "    \"relative_strength\", \n",
    "    # \"end.yardsToEndzone\", \n",
    "    # \"end.distance\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel:\n",
    "    def __init__(self, general_model, specialized_model, original_features, \n",
    "                 edge_numeric_features, edge_other_features, scaler=None, \n",
    "                 tight_threshold=7, late_game_threshold=0.95):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            general_model: Model trained on all game states\n",
    "            specialized_model: Model trained on late/tight games with derived features\n",
    "            original_features: List of original feature names\n",
    "            edge_numeric_features: List of numeric features for specialized model (for normalization)\n",
    "            edge_other_features: List of binary/categorical features for specialized model\n",
    "            scaler: Fitted StandardScaler for edge numeric features (optional)\n",
    "            tight_threshold: Score difference threshold for \"tight game\" (default 7)\n",
    "            late_game_threshold: game_completed threshold for \"late game\" (default 0.95)\n",
    "        \"\"\"\n",
    "        self.general_model = general_model\n",
    "        self.specialized_model = specialized_model\n",
    "        self.original_features = original_features\n",
    "        self.edge_numeric_features = edge_numeric_features\n",
    "        self.edge_other_features = edge_other_features\n",
    "        self.scaler = scaler\n",
    "        self.tight_threshold = tight_threshold\n",
    "        self.late_game_threshold = late_game_threshold\n",
    "        \n",
    "        # Get feature indices from original features\n",
    "        self.idx_score_diff = original_features.index(\"score_difference\")\n",
    "        self.idx_game_completed = original_features.index(\"game_completed\")\n",
    "        self.idx_home_poss = original_features.index(\"home_has_possession\")\n",
    "        self.idx_yards = original_features.index(\"end.yardsToEndzone\")\n",
    "        self.idx_home_to = original_features.index(\"home_timeouts_left\")\n",
    "        self.idx_away_to = original_features.index(\"away_timeouts_left\")\n",
    "        \n",
    "    def _is_tight_late_game(self, row):\n",
    "        \"\"\"Check if this is a tight late-game situation.\"\"\"\n",
    "        score_diff = abs(row[self.idx_score_diff])\n",
    "        game_completed = row[self.idx_game_completed]\n",
    "        return (score_diff <= self.tight_threshold and \n",
    "                game_completed >= self.late_game_threshold)\n",
    "    \n",
    "    def _derive_features(self, row):\n",
    "        \"\"\"Derive additional features for specialized model from original features.\"\"\"\n",
    "        score_diff = row[self.idx_score_diff]\n",
    "        game_completed = row[self.idx_game_completed]\n",
    "        home_poss = row[self.idx_home_poss]\n",
    "        yards = row[self.idx_yards]\n",
    "        home_to = row[self.idx_home_to]\n",
    "        away_to = row[self.idx_away_to]\n",
    "        \n",
    "        # Derived features\n",
    "        home_winning = 1 if score_diff > 0 else 0\n",
    "        away_winning = 1 if score_diff < 0 else 0\n",
    "        tied = 1 if score_diff == 0 else 0\n",
    "        \n",
    "        home_winning_with_ball = home_winning * home_poss\n",
    "        home_winning_no_ball = home_winning * (1 - home_poss)\n",
    "        away_winning_with_ball = away_winning * (1 - home_poss)\n",
    "        away_winning_no_ball = away_winning * home_poss\n",
    "        \n",
    "        time_remaining_pct = 1.0 - game_completed\n",
    "        score_diff_x_time = score_diff * time_remaining_pct\n",
    "        \n",
    "        abs_score_diff = abs(score_diff)\n",
    "        needs_fg_only = 1 if abs_score_diff <= 3 else 0\n",
    "        needs_td_only = 1 if 3 < abs_score_diff <= 7 else 0\n",
    "        needs_multiple_scores = 1 if abs_score_diff > 8 else 0\n",
    "        \n",
    "        timeout_diff = home_to - away_to\n",
    "        \n",
    "        yards_to_fg_range = max(0, yards - 37)\n",
    "        in_fg_range = 1 if yards <= 37 else 0\n",
    "        in_red_zone = 1 if yards <= 20 else 0\n",
    "        \n",
    "        derived = {\n",
    "            \"home_winning_with_ball\": home_winning_with_ball,\n",
    "            \"home_winning_no_ball\": home_winning_no_ball,\n",
    "            \"away_winning_with_ball\": away_winning_with_ball,\n",
    "            \"away_winning_no_ball\": away_winning_no_ball,\n",
    "            \"tied\": tied,\n",
    "            \"time_remaining_pct\": time_remaining_pct,\n",
    "            \"score_diff_x_time\": score_diff_x_time,\n",
    "            \"needs_fg_only\": needs_fg_only,\n",
    "            \"needs_td_only\": needs_td_only,\n",
    "            \"needs_multiple_scores\": needs_multiple_scores,\n",
    "            \"timeout_diff\": timeout_diff,\n",
    "            \"yards_to_fg_range\": yards_to_fg_range,\n",
    "            \"in_fg_range\": in_fg_range,\n",
    "            \"in_red_zone\": in_red_zone\n",
    "        }\n",
    "        return derived\n",
    "    \n",
    "    def _build_edge_features(self, row):\n",
    "        \"\"\"Build feature vector preserving all_edge_features order from training.\"\"\"\n",
    "        # Start with original features (already in row)\n",
    "        feature_dict = {feat: row[self.original_features.index(feat)] \n",
    "                    for feat in self.original_features}\n",
    "        \n",
    "        # Add derived features\n",
    "        derived = self._derive_features(row)\n",
    "        feature_dict.update(derived)\n",
    "        \n",
    "        # Build feature vector in EXACT order of all_edge_features (training order)\n",
    "        edge_features = []\n",
    "        for feat in feature_dict.keys():\n",
    "            edge_features.append(feature_dict[feat])\n",
    "        \n",
    "        edge_array = np.array(edge_features, dtype=np.float32).reshape(1, -1)\n",
    "        return edge_array \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probabilities, using specialized model for tight late games.\"\"\"\n",
    "        result = []\n",
    "        \n",
    "        for row in X:\n",
    "            if self._is_tight_late_game(row):\n",
    "                # Build edge features and use specialized model\n",
    "                edge_features = self._build_edge_features(row)\n",
    "                pred = self.specialized_model.predict_proba(edge_features)[0]\n",
    "            else:\n",
    "                # Use general model\n",
    "                pred = self.general_model.predict_proba(np.array([row]))[0]\n",
    "            \n",
    "            result.append(pred)\n",
    "        \n",
    "        return np.array(result)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels.\"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba[:, 1] >= 0.5).astype(int)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Calculate accuracy.\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing timestep: 0.0\n",
      "Timestep 0.00% : Training Loss = 0.6247, Accuracy = 0.6511, Test Loss = 0.6359, Test Accuracy = 0.6449\n",
      "Processing timestep: 0.005\n",
      "Timestep 0.50% : Training Loss = 0.6320, Accuracy = 0.6422, Test Loss = 0.6394, Test Accuracy = 0.6263\n",
      "Processing timestep: 0.01\n",
      "Timestep 1.00% : Training Loss = 0.6206, Accuracy = 0.6447, Test Loss = 0.6310, Test Accuracy = 0.6273\n",
      "Processing timestep: 0.015\n",
      "Timestep 1.50% : Training Loss = 0.6350, Accuracy = 0.6318, Test Loss = 0.6215, Test Accuracy = 0.6561\n",
      "Processing timestep: 0.02\n",
      "Timestep 2.00% : Training Loss = 0.6342, Accuracy = 0.6365, Test Loss = 0.6457, Test Accuracy = 0.6069\n",
      "Processing timestep: 0.025\n",
      "Timestep 2.50% : Training Loss = 0.6323, Accuracy = 0.6360, Test Loss = 0.6367, Test Accuracy = 0.6482\n",
      "Processing timestep: 0.03\n",
      "Timestep 3.00% : Training Loss = 0.6211, Accuracy = 0.6549, Test Loss = 0.6299, Test Accuracy = 0.6334\n",
      "Processing timestep: 0.035\n",
      "Timestep 3.50% : Training Loss = 0.6277, Accuracy = 0.6456, Test Loss = 0.6522, Test Accuracy = 0.6230\n",
      "Processing timestep: 0.04\n",
      "Timestep 4.00% : Training Loss = 0.6292, Accuracy = 0.6517, Test Loss = 0.6084, Test Accuracy = 0.6827\n",
      "Processing timestep: 0.045\n",
      "Timestep 4.50% : Training Loss = 0.6310, Accuracy = 0.6464, Test Loss = 0.6223, Test Accuracy = 0.6667\n",
      "Processing timestep: 0.05\n",
      "Timestep 5.00% : Training Loss = 0.6212, Accuracy = 0.6613, Test Loss = 0.6451, Test Accuracy = 0.6092\n",
      "Processing timestep: 0.055\n",
      "Timestep 5.50% : Training Loss = 0.6128, Accuracy = 0.6739, Test Loss = 0.6408, Test Accuracy = 0.6171\n",
      "Processing timestep: 0.06\n",
      "Timestep 6.00% : Training Loss = 0.6248, Accuracy = 0.6487, Test Loss = 0.6115, Test Accuracy = 0.6563\n",
      "Processing timestep: 0.065\n",
      "Timestep 6.50% : Training Loss = 0.6323, Accuracy = 0.6410, Test Loss = 0.6280, Test Accuracy = 0.6176\n",
      "Processing timestep: 0.07\n",
      "Timestep 7.00% : Training Loss = 0.6159, Accuracy = 0.6611, Test Loss = 0.6301, Test Accuracy = 0.6711\n",
      "Processing timestep: 0.075\n",
      "Timestep 7.50% : Training Loss = 0.6284, Accuracy = 0.6357, Test Loss = 0.5978, Test Accuracy = 0.6802\n",
      "Processing timestep: 0.08\n",
      "Timestep 8.00% : Training Loss = 0.6108, Accuracy = 0.6688, Test Loss = 0.5951, Test Accuracy = 0.7094\n",
      "Processing timestep: 0.085\n",
      "Timestep 8.50% : Training Loss = 0.6133, Accuracy = 0.6644, Test Loss = 0.6280, Test Accuracy = 0.6554\n",
      "Processing timestep: 0.09\n",
      "Timestep 9.00% : Training Loss = 0.6157, Accuracy = 0.6503, Test Loss = 0.6351, Test Accuracy = 0.6332\n",
      "Processing timestep: 0.095\n",
      "Timestep 9.50% : Training Loss = 0.6110, Accuracy = 0.6596, Test Loss = 0.6227, Test Accuracy = 0.6597\n",
      "Processing timestep: 0.1\n",
      "Timestep 10.00% : Training Loss = 0.6035, Accuracy = 0.6722, Test Loss = 0.6304, Test Accuracy = 0.6554\n",
      "Processing timestep: 0.105\n",
      "Timestep 10.50% : Training Loss = 0.5983, Accuracy = 0.6744, Test Loss = 0.6275, Test Accuracy = 0.6133\n",
      "Processing timestep: 0.11\n",
      "Timestep 11.00% : Training Loss = 0.6116, Accuracy = 0.6645, Test Loss = 0.6233, Test Accuracy = 0.6373\n",
      "Processing timestep: 0.115\n",
      "Timestep 11.50% : Training Loss = 0.5981, Accuracy = 0.6826, Test Loss = 0.5880, Test Accuracy = 0.6542\n",
      "Processing timestep: 0.12\n",
      "Timestep 12.00% : Training Loss = 0.6064, Accuracy = 0.6738, Test Loss = 0.6294, Test Accuracy = 0.6361\n",
      "Processing timestep: 0.125\n",
      "Timestep 12.50% : Training Loss = 0.5991, Accuracy = 0.6748, Test Loss = 0.5989, Test Accuracy = 0.6598\n",
      "Processing timestep: 0.13\n",
      "Timestep 13.00% : Training Loss = 0.5927, Accuracy = 0.6838, Test Loss = 0.6224, Test Accuracy = 0.6430\n",
      "Processing timestep: 0.135\n",
      "Timestep 13.50% : Training Loss = 0.6129, Accuracy = 0.6612, Test Loss = 0.5987, Test Accuracy = 0.6551\n",
      "Processing timestep: 0.14\n",
      "Timestep 14.00% : Training Loss = 0.5965, Accuracy = 0.6964, Test Loss = 0.6024, Test Accuracy = 0.6524\n",
      "Processing timestep: 0.145\n",
      "Timestep 14.50% : Training Loss = 0.5948, Accuracy = 0.6854, Test Loss = 0.5966, Test Accuracy = 0.6720\n",
      "Processing timestep: 0.15\n",
      "Timestep 15.00% : Training Loss = 0.5886, Accuracy = 0.6975, Test Loss = 0.6155, Test Accuracy = 0.6701\n",
      "Processing timestep: 0.155\n",
      "Timestep 15.50% : Training Loss = 0.5840, Accuracy = 0.6930, Test Loss = 0.6167, Test Accuracy = 0.6630\n",
      "Processing timestep: 0.16\n",
      "Timestep 16.00% : Training Loss = 0.5833, Accuracy = 0.6872, Test Loss = 0.6201, Test Accuracy = 0.6215\n",
      "Processing timestep: 0.165\n",
      "Timestep 16.50% : Training Loss = 0.6019, Accuracy = 0.6693, Test Loss = 0.6158, Test Accuracy = 0.6511\n",
      "Processing timestep: 0.17\n",
      "Timestep 17.00% : Training Loss = 0.5942, Accuracy = 0.6889, Test Loss = 0.5929, Test Accuracy = 0.6623\n",
      "Processing timestep: 0.175\n",
      "Timestep 17.50% : Training Loss = 0.6022, Accuracy = 0.6786, Test Loss = 0.6163, Test Accuracy = 0.6380\n",
      "Processing timestep: 0.18\n",
      "Timestep 18.00% : Training Loss = 0.5789, Accuracy = 0.6891, Test Loss = 0.5952, Test Accuracy = 0.6676\n",
      "Processing timestep: 0.185\n",
      "Timestep 18.50% : Training Loss = 0.5923, Accuracy = 0.6876, Test Loss = 0.5885, Test Accuracy = 0.6791\n",
      "Processing timestep: 0.19\n",
      "Timestep 19.00% : Training Loss = 0.5841, Accuracy = 0.6926, Test Loss = 0.5860, Test Accuracy = 0.6720\n",
      "Processing timestep: 0.195\n",
      "Timestep 19.50% : Training Loss = 0.5682, Accuracy = 0.7054, Test Loss = 0.6002, Test Accuracy = 0.6588\n",
      "Processing timestep: 0.2\n",
      "Timestep 20.00% : Training Loss = 0.5911, Accuracy = 0.6898, Test Loss = 0.5770, Test Accuracy = 0.6729\n",
      "Processing timestep: 0.205\n",
      "Timestep 20.50% : Training Loss = 0.5884, Accuracy = 0.6883, Test Loss = 0.5480, Test Accuracy = 0.6995\n",
      "Processing timestep: 0.21\n",
      "Timestep 21.00% : Training Loss = 0.5701, Accuracy = 0.7066, Test Loss = 0.5987, Test Accuracy = 0.6642\n",
      "Processing timestep: 0.215\n",
      "Timestep 21.50% : Training Loss = 0.5809, Accuracy = 0.6990, Test Loss = 0.5751, Test Accuracy = 0.6685\n",
      "Processing timestep: 0.22\n",
      "Timestep 22.00% : Training Loss = 0.5747, Accuracy = 0.7041, Test Loss = 0.5672, Test Accuracy = 0.6955\n",
      "Processing timestep: 0.225\n",
      "Timestep 22.50% : Training Loss = 0.5605, Accuracy = 0.7070, Test Loss = 0.5975, Test Accuracy = 0.6789\n",
      "Processing timestep: 0.23\n",
      "Timestep 23.00% : Training Loss = 0.5749, Accuracy = 0.6964, Test Loss = 0.5720, Test Accuracy = 0.6801\n",
      "Processing timestep: 0.235\n",
      "Timestep 23.50% : Training Loss = 0.5629, Accuracy = 0.7119, Test Loss = 0.5311, Test Accuracy = 0.7036\n",
      "Processing timestep: 0.24\n",
      "Timestep 24.00% : Training Loss = 0.5830, Accuracy = 0.6918, Test Loss = 0.5738, Test Accuracy = 0.6576\n",
      "Processing timestep: 0.245\n",
      "Timestep 24.50% : Training Loss = 0.5725, Accuracy = 0.6978, Test Loss = 0.5723, Test Accuracy = 0.6950\n",
      "Processing timestep: 0.25\n",
      "Timestep 25.00% : Training Loss = 0.5670, Accuracy = 0.7034, Test Loss = 0.5518, Test Accuracy = 0.7069\n",
      "Processing timestep: 0.255\n",
      "Timestep 25.50% : Training Loss = 0.5697, Accuracy = 0.6998, Test Loss = 0.5642, Test Accuracy = 0.6912\n",
      "Processing timestep: 0.26\n",
      "Timestep 26.00% : Training Loss = 0.5667, Accuracy = 0.7088, Test Loss = 0.5801, Test Accuracy = 0.6758\n",
      "Processing timestep: 0.265\n",
      "Timestep 26.50% : Training Loss = 0.5683, Accuracy = 0.6985, Test Loss = 0.5356, Test Accuracy = 0.7182\n",
      "Processing timestep: 0.27\n",
      "Timestep 27.00% : Training Loss = 0.5651, Accuracy = 0.7084, Test Loss = 0.5508, Test Accuracy = 0.6952\n",
      "Processing timestep: 0.275\n",
      "Timestep 27.50% : Training Loss = 0.5650, Accuracy = 0.6964, Test Loss = 0.5427, Test Accuracy = 0.7054\n",
      "Processing timestep: 0.28\n",
      "Timestep 28.00% : Training Loss = 0.5595, Accuracy = 0.7043, Test Loss = 0.5659, Test Accuracy = 0.7167\n",
      "Processing timestep: 0.285\n",
      "Timestep 28.50% : Training Loss = 0.5593, Accuracy = 0.7078, Test Loss = 0.5167, Test Accuracy = 0.7343\n",
      "Processing timestep: 0.29\n",
      "Timestep 29.00% : Training Loss = 0.5715, Accuracy = 0.6956, Test Loss = 0.5332, Test Accuracy = 0.7116\n",
      "Processing timestep: 0.295\n",
      "Timestep 29.50% : Training Loss = 0.5643, Accuracy = 0.6981, Test Loss = 0.5528, Test Accuracy = 0.7063\n",
      "Processing timestep: 0.3\n",
      "Timestep 30.00% : Training Loss = 0.5570, Accuracy = 0.7043, Test Loss = 0.5552, Test Accuracy = 0.6974\n",
      "Processing timestep: 0.305\n",
      "Timestep 30.50% : Training Loss = 0.5539, Accuracy = 0.7128, Test Loss = 0.5730, Test Accuracy = 0.6848\n",
      "Processing timestep: 0.31\n",
      "Timestep 31.00% : Training Loss = 0.5480, Accuracy = 0.7166, Test Loss = 0.5432, Test Accuracy = 0.7195\n",
      "Processing timestep: 0.315\n",
      "Timestep 31.50% : Training Loss = 0.5667, Accuracy = 0.6979, Test Loss = 0.5897, Test Accuracy = 0.6824\n",
      "Processing timestep: 0.32\n",
      "Timestep 32.00% : Training Loss = 0.5523, Accuracy = 0.7096, Test Loss = 0.5244, Test Accuracy = 0.7318\n",
      "Processing timestep: 0.325\n",
      "Timestep 32.50% : Training Loss = 0.5554, Accuracy = 0.7131, Test Loss = 0.5403, Test Accuracy = 0.7062\n",
      "Processing timestep: 0.33\n",
      "Timestep 33.00% : Training Loss = 0.5533, Accuracy = 0.7078, Test Loss = 0.5203, Test Accuracy = 0.7251\n",
      "Processing timestep: 0.335\n",
      "Timestep 33.50% : Training Loss = 0.5361, Accuracy = 0.7250, Test Loss = 0.5292, Test Accuracy = 0.7287\n",
      "Processing timestep: 0.34\n",
      "Timestep 34.00% : Training Loss = 0.5356, Accuracy = 0.7236, Test Loss = 0.5352, Test Accuracy = 0.7105\n",
      "Processing timestep: 0.345\n",
      "Timestep 34.50% : Training Loss = 0.5301, Accuracy = 0.7278, Test Loss = 0.5205, Test Accuracy = 0.7219\n",
      "Processing timestep: 0.35\n",
      "Timestep 35.00% : Training Loss = 0.5416, Accuracy = 0.7167, Test Loss = 0.5358, Test Accuracy = 0.7177\n",
      "Processing timestep: 0.355\n",
      "Timestep 35.50% : Training Loss = 0.5420, Accuracy = 0.7162, Test Loss = 0.5290, Test Accuracy = 0.7364\n",
      "Processing timestep: 0.36\n",
      "Timestep 36.00% : Training Loss = 0.5490, Accuracy = 0.7203, Test Loss = 0.5434, Test Accuracy = 0.7246\n",
      "Processing timestep: 0.365\n",
      "Timestep 36.50% : Training Loss = 0.5385, Accuracy = 0.7324, Test Loss = 0.5180, Test Accuracy = 0.7249\n",
      "Processing timestep: 0.37\n",
      "Timestep 37.00% : Training Loss = 0.5577, Accuracy = 0.7191, Test Loss = 0.5458, Test Accuracy = 0.7131\n",
      "Processing timestep: 0.375\n",
      "Timestep 37.50% : Training Loss = 0.5302, Accuracy = 0.7327, Test Loss = 0.5387, Test Accuracy = 0.7172\n",
      "Processing timestep: 0.38\n",
      "Timestep 38.00% : Training Loss = 0.5201, Accuracy = 0.7376, Test Loss = 0.5270, Test Accuracy = 0.7063\n",
      "Processing timestep: 0.385\n",
      "Timestep 38.50% : Training Loss = 0.5404, Accuracy = 0.7207, Test Loss = 0.5309, Test Accuracy = 0.7203\n",
      "Processing timestep: 0.39\n",
      "Timestep 39.00% : Training Loss = 0.5294, Accuracy = 0.7274, Test Loss = 0.5435, Test Accuracy = 0.7093\n",
      "Processing timestep: 0.395\n",
      "Timestep 39.50% : Training Loss = 0.5395, Accuracy = 0.7239, Test Loss = 0.5154, Test Accuracy = 0.7435\n",
      "Processing timestep: 0.4\n",
      "Timestep 40.00% : Training Loss = 0.5411, Accuracy = 0.7236, Test Loss = 0.5438, Test Accuracy = 0.7116\n",
      "Processing timestep: 0.405\n",
      "Timestep 40.50% : Training Loss = 0.5175, Accuracy = 0.7495, Test Loss = 0.4870, Test Accuracy = 0.7784\n",
      "Processing timestep: 0.41\n",
      "Timestep 41.00% : Training Loss = 0.5444, Accuracy = 0.7181, Test Loss = 0.5132, Test Accuracy = 0.7506\n",
      "Processing timestep: 0.415\n",
      "Timestep 41.50% : Training Loss = 0.5299, Accuracy = 0.7416, Test Loss = 0.5153, Test Accuracy = 0.7273\n",
      "Processing timestep: 0.42\n",
      "Timestep 42.00% : Training Loss = 0.5417, Accuracy = 0.7244, Test Loss = 0.5611, Test Accuracy = 0.6829\n",
      "Processing timestep: 0.425\n",
      "Timestep 42.50% : Training Loss = 0.5173, Accuracy = 0.7446, Test Loss = 0.5408, Test Accuracy = 0.7435\n",
      "Processing timestep: 0.43\n",
      "Timestep 43.00% : Training Loss = 0.5135, Accuracy = 0.7508, Test Loss = 0.5295, Test Accuracy = 0.7193\n",
      "Processing timestep: 0.435\n",
      "Timestep 43.50% : Training Loss = 0.5198, Accuracy = 0.7469, Test Loss = 0.5029, Test Accuracy = 0.7378\n",
      "Processing timestep: 0.44\n",
      "Timestep 44.00% : Training Loss = 0.5100, Accuracy = 0.7525, Test Loss = 0.5365, Test Accuracy = 0.7200\n",
      "Processing timestep: 0.445\n",
      "Timestep 44.50% : Training Loss = 0.5214, Accuracy = 0.7425, Test Loss = 0.5260, Test Accuracy = 0.7378\n",
      "Processing timestep: 0.45\n",
      "Timestep 45.00% : Training Loss = 0.5094, Accuracy = 0.7517, Test Loss = 0.5468, Test Accuracy = 0.7225\n",
      "Processing timestep: 0.455\n",
      "Timestep 45.50% : Training Loss = 0.5251, Accuracy = 0.7390, Test Loss = 0.5267, Test Accuracy = 0.7277\n",
      "Processing timestep: 0.46\n",
      "Timestep 46.00% : Training Loss = 0.5057, Accuracy = 0.7566, Test Loss = 0.4830, Test Accuracy = 0.7843\n",
      "Processing timestep: 0.465\n",
      "Timestep 46.50% : Training Loss = 0.4858, Accuracy = 0.7678, Test Loss = 0.5288, Test Accuracy = 0.7611\n",
      "Processing timestep: 0.47\n",
      "Timestep 47.00% : Training Loss = 0.5052, Accuracy = 0.7537, Test Loss = 0.5057, Test Accuracy = 0.7462\n",
      "Processing timestep: 0.475\n",
      "Timestep 47.50% : Training Loss = 0.4889, Accuracy = 0.7688, Test Loss = 0.4984, Test Accuracy = 0.7426\n",
      "Processing timestep: 0.48\n",
      "Timestep 48.00% : Training Loss = 0.4864, Accuracy = 0.7625, Test Loss = 0.4848, Test Accuracy = 0.7657\n",
      "Processing timestep: 0.485\n",
      "Timestep 48.50% : Training Loss = 0.4823, Accuracy = 0.7635, Test Loss = 0.4900, Test Accuracy = 0.7742\n",
      "Processing timestep: 0.49\n",
      "Timestep 49.00% : Training Loss = 0.4778, Accuracy = 0.7822, Test Loss = 0.5160, Test Accuracy = 0.7525\n",
      "Processing timestep: 0.495\n",
      "Timestep 49.50% : Training Loss = 0.4781, Accuracy = 0.7735, Test Loss = 0.4546, Test Accuracy = 0.7960\n",
      "Processing timestep: 0.5\n",
      "Timestep 50.00% : Training Loss = 0.4717, Accuracy = 0.7755, Test Loss = 0.4470, Test Accuracy = 0.8057\n",
      "Processing timestep: 0.505\n",
      "Timestep 50.50% : Training Loss = 0.4425, Accuracy = 0.7840, Test Loss = 0.5292, Test Accuracy = 0.7905\n",
      "Processing timestep: 0.51\n",
      "Timestep 51.00% : Training Loss = 0.4498, Accuracy = 0.7851, Test Loss = 0.4809, Test Accuracy = 0.7978\n",
      "Processing timestep: 0.515\n",
      "Timestep 51.50% : Training Loss = 0.4602, Accuracy = 0.7904, Test Loss = 0.4553, Test Accuracy = 0.7955\n",
      "Processing timestep: 0.52\n",
      "Timestep 52.00% : Training Loss = 0.4707, Accuracy = 0.7740, Test Loss = 0.4459, Test Accuracy = 0.8164\n",
      "Processing timestep: 0.525\n",
      "Timestep 52.50% : Training Loss = 0.4433, Accuracy = 0.7937, Test Loss = 0.4573, Test Accuracy = 0.8117\n",
      "Processing timestep: 0.53\n",
      "Timestep 53.00% : Training Loss = 0.4652, Accuracy = 0.7778, Test Loss = 0.4937, Test Accuracy = 0.7699\n",
      "Processing timestep: 0.535\n",
      "Timestep 53.50% : Training Loss = 0.4350, Accuracy = 0.7965, Test Loss = 0.4336, Test Accuracy = 0.8276\n",
      "Processing timestep: 0.54\n",
      "Timestep 54.00% : Training Loss = 0.4513, Accuracy = 0.7876, Test Loss = 0.5109, Test Accuracy = 0.7631\n",
      "Processing timestep: 0.545\n",
      "Timestep 54.50% : Training Loss = 0.4663, Accuracy = 0.7834, Test Loss = 0.4862, Test Accuracy = 0.7799\n",
      "Processing timestep: 0.55\n",
      "Timestep 55.00% : Training Loss = 0.4376, Accuracy = 0.7968, Test Loss = 0.4525, Test Accuracy = 0.8162\n",
      "Processing timestep: 0.555\n",
      "Timestep 55.50% : Training Loss = 0.4556, Accuracy = 0.7879, Test Loss = 0.4468, Test Accuracy = 0.8054\n",
      "Processing timestep: 0.56\n",
      "Timestep 56.00% : Training Loss = 0.4333, Accuracy = 0.8042, Test Loss = 0.4492, Test Accuracy = 0.8026\n",
      "Processing timestep: 0.565\n",
      "Timestep 56.50% : Training Loss = 0.4409, Accuracy = 0.7927, Test Loss = 0.4596, Test Accuracy = 0.7721\n",
      "Processing timestep: 0.57\n",
      "Timestep 57.00% : Training Loss = 0.4441, Accuracy = 0.7938, Test Loss = 0.4358, Test Accuracy = 0.8021\n",
      "Processing timestep: 0.575\n",
      "Timestep 57.50% : Training Loss = 0.4527, Accuracy = 0.7892, Test Loss = 0.4815, Test Accuracy = 0.7839\n",
      "Processing timestep: 0.58\n",
      "Timestep 58.00% : Training Loss = 0.4457, Accuracy = 0.7866, Test Loss = 0.4516, Test Accuracy = 0.7909\n",
      "Processing timestep: 0.585\n",
      "Timestep 58.50% : Training Loss = 0.4464, Accuracy = 0.7920, Test Loss = 0.4107, Test Accuracy = 0.8241\n",
      "Processing timestep: 0.59\n",
      "Timestep 59.00% : Training Loss = 0.4573, Accuracy = 0.7816, Test Loss = 0.4622, Test Accuracy = 0.7975\n",
      "Processing timestep: 0.595\n",
      "Timestep 59.50% : Training Loss = 0.4352, Accuracy = 0.7909, Test Loss = 0.4705, Test Accuracy = 0.7723\n",
      "Processing timestep: 0.6\n",
      "Timestep 60.00% : Training Loss = 0.4446, Accuracy = 0.7847, Test Loss = 0.4578, Test Accuracy = 0.7953\n",
      "Processing timestep: 0.605\n",
      "Timestep 60.50% : Training Loss = 0.4484, Accuracy = 0.7900, Test Loss = 0.4457, Test Accuracy = 0.7850\n",
      "Processing timestep: 0.61\n",
      "Timestep 61.00% : Training Loss = 0.4359, Accuracy = 0.7925, Test Loss = 0.4502, Test Accuracy = 0.7918\n",
      "Processing timestep: 0.615\n",
      "Timestep 61.50% : Training Loss = 0.4229, Accuracy = 0.7946, Test Loss = 0.4360, Test Accuracy = 0.7947\n",
      "Processing timestep: 0.62\n",
      "Timestep 62.00% : Training Loss = 0.4431, Accuracy = 0.7962, Test Loss = 0.4527, Test Accuracy = 0.7834\n",
      "Processing timestep: 0.625\n",
      "Timestep 62.50% : Training Loss = 0.4335, Accuracy = 0.8027, Test Loss = 0.4499, Test Accuracy = 0.7918\n",
      "Processing timestep: 0.63\n",
      "Timestep 63.00% : Training Loss = 0.4229, Accuracy = 0.8013, Test Loss = 0.4313, Test Accuracy = 0.8031\n",
      "Processing timestep: 0.635\n",
      "Timestep 63.50% : Training Loss = 0.4297, Accuracy = 0.8003, Test Loss = 0.4462, Test Accuracy = 0.7812\n",
      "Processing timestep: 0.64\n",
      "Timestep 64.00% : Training Loss = 0.4193, Accuracy = 0.8095, Test Loss = 0.4715, Test Accuracy = 0.7722\n",
      "Processing timestep: 0.645\n",
      "Timestep 64.50% : Training Loss = 0.4453, Accuracy = 0.7916, Test Loss = 0.4233, Test Accuracy = 0.8112\n",
      "Processing timestep: 0.65\n",
      "Timestep 65.00% : Training Loss = 0.4247, Accuracy = 0.7989, Test Loss = 0.5006, Test Accuracy = 0.7632\n",
      "Processing timestep: 0.655\n",
      "Timestep 65.50% : Training Loss = 0.4046, Accuracy = 0.8123, Test Loss = 0.4547, Test Accuracy = 0.7784\n",
      "Processing timestep: 0.66\n",
      "Timestep 66.00% : Training Loss = 0.4182, Accuracy = 0.8101, Test Loss = 0.4219, Test Accuracy = 0.8031\n",
      "Processing timestep: 0.665\n",
      "Timestep 66.50% : Training Loss = 0.3911, Accuracy = 0.8164, Test Loss = 0.4505, Test Accuracy = 0.7769\n",
      "Processing timestep: 0.67\n",
      "Timestep 67.00% : Training Loss = 0.4100, Accuracy = 0.8184, Test Loss = 0.4352, Test Accuracy = 0.8145\n",
      "Processing timestep: 0.675\n",
      "Timestep 67.50% : Training Loss = 0.4214, Accuracy = 0.8040, Test Loss = 0.4403, Test Accuracy = 0.7775\n",
      "Processing timestep: 0.68\n",
      "Timestep 68.00% : Training Loss = 0.4163, Accuracy = 0.8132, Test Loss = 0.4251, Test Accuracy = 0.7813\n",
      "Processing timestep: 0.685\n",
      "Timestep 68.50% : Training Loss = 0.4033, Accuracy = 0.8152, Test Loss = 0.4554, Test Accuracy = 0.7747\n",
      "Processing timestep: 0.69\n",
      "Timestep 69.00% : Training Loss = 0.4038, Accuracy = 0.8110, Test Loss = 0.4114, Test Accuracy = 0.7848\n",
      "Processing timestep: 0.695\n",
      "Timestep 69.50% : Training Loss = 0.3941, Accuracy = 0.8194, Test Loss = 0.3937, Test Accuracy = 0.7979\n",
      "Processing timestep: 0.7\n",
      "Timestep 70.00% : Training Loss = 0.4065, Accuracy = 0.8060, Test Loss = 0.3919, Test Accuracy = 0.8222\n",
      "Processing timestep: 0.705\n",
      "Timestep 70.50% : Training Loss = 0.3997, Accuracy = 0.8137, Test Loss = 0.3904, Test Accuracy = 0.8070\n",
      "Processing timestep: 0.71\n",
      "Timestep 71.00% : Training Loss = 0.3961, Accuracy = 0.8264, Test Loss = 0.4030, Test Accuracy = 0.8086\n",
      "Processing timestep: 0.715\n",
      "Timestep 71.50% : Training Loss = 0.3991, Accuracy = 0.8152, Test Loss = 0.4554, Test Accuracy = 0.7623\n",
      "Processing timestep: 0.72\n",
      "Timestep 72.00% : Training Loss = 0.3885, Accuracy = 0.8226, Test Loss = 0.3742, Test Accuracy = 0.8368\n",
      "Processing timestep: 0.725\n",
      "Timestep 72.50% : Training Loss = 0.3876, Accuracy = 0.8183, Test Loss = 0.3971, Test Accuracy = 0.8130\n",
      "Processing timestep: 0.73\n",
      "Timestep 73.00% : Training Loss = 0.3789, Accuracy = 0.8252, Test Loss = 0.4291, Test Accuracy = 0.8083\n",
      "Processing timestep: 0.735\n",
      "Timestep 73.50% : Training Loss = 0.3841, Accuracy = 0.8283, Test Loss = 0.4151, Test Accuracy = 0.8127\n",
      "Processing timestep: 0.74\n",
      "Timestep 74.00% : Training Loss = 0.3689, Accuracy = 0.8356, Test Loss = 0.4158, Test Accuracy = 0.8282\n",
      "Processing timestep: 0.745\n",
      "Timestep 74.50% : Training Loss = 0.3873, Accuracy = 0.8324, Test Loss = 0.4080, Test Accuracy = 0.8142\n",
      "Processing timestep: 0.75\n",
      "Timestep 75.00% : Training Loss = 0.3837, Accuracy = 0.8260, Test Loss = 0.3790, Test Accuracy = 0.8184\n",
      "Processing timestep: 0.755\n",
      "Timestep 75.50% : Training Loss = 0.3486, Accuracy = 0.8462, Test Loss = 0.3743, Test Accuracy = 0.8371\n",
      "Processing timestep: 0.76\n",
      "Timestep 76.00% : Training Loss = 0.3632, Accuracy = 0.8382, Test Loss = 0.3487, Test Accuracy = 0.8430\n",
      "Processing timestep: 0.765\n",
      "Timestep 76.50% : Training Loss = 0.3429, Accuracy = 0.8509, Test Loss = 0.3861, Test Accuracy = 0.8204\n",
      "Processing timestep: 0.77\n",
      "Timestep 77.00% : Training Loss = 0.3782, Accuracy = 0.8309, Test Loss = 0.3993, Test Accuracy = 0.8052\n",
      "Processing timestep: 0.775\n",
      "Timestep 77.50% : Training Loss = 0.3670, Accuracy = 0.8306, Test Loss = 0.3449, Test Accuracy = 0.8518\n",
      "Processing timestep: 0.78\n",
      "Timestep 78.00% : Training Loss = 0.3583, Accuracy = 0.8410, Test Loss = 0.4167, Test Accuracy = 0.8134\n",
      "Processing timestep: 0.785\n",
      "Timestep 78.50% : Training Loss = 0.3519, Accuracy = 0.8461, Test Loss = 0.4022, Test Accuracy = 0.8223\n",
      "Processing timestep: 0.79\n",
      "Timestep 79.00% : Training Loss = 0.3367, Accuracy = 0.8557, Test Loss = 0.3287, Test Accuracy = 0.8710\n",
      "Processing timestep: 0.795\n",
      "Timestep 79.50% : Training Loss = 0.3693, Accuracy = 0.8351, Test Loss = 0.3927, Test Accuracy = 0.8320\n",
      "Processing timestep: 0.8\n",
      "Timestep 80.00% : Training Loss = 0.3430, Accuracy = 0.8529, Test Loss = 0.3550, Test Accuracy = 0.8617\n",
      "Processing timestep: 0.805\n",
      "Timestep 80.50% : Training Loss = 0.3437, Accuracy = 0.8494, Test Loss = 0.3494, Test Accuracy = 0.8505\n",
      "Processing timestep: 0.81\n",
      "Timestep 81.00% : Training Loss = 0.3440, Accuracy = 0.8521, Test Loss = 0.3891, Test Accuracy = 0.8175\n",
      "Processing timestep: 0.815\n",
      "Timestep 81.50% : Training Loss = 0.3398, Accuracy = 0.8481, Test Loss = 0.3782, Test Accuracy = 0.8290\n",
      "Processing timestep: 0.82\n",
      "Timestep 82.00% : Training Loss = 0.3451, Accuracy = 0.8429, Test Loss = 0.3803, Test Accuracy = 0.8173\n",
      "Processing timestep: 0.825\n",
      "Timestep 82.50% : Training Loss = 0.3447, Accuracy = 0.8456, Test Loss = 0.3780, Test Accuracy = 0.8347\n",
      "Processing timestep: 0.83\n",
      "Timestep 83.00% : Training Loss = 0.3269, Accuracy = 0.8561, Test Loss = 0.3473, Test Accuracy = 0.8329\n",
      "Processing timestep: 0.835\n",
      "Timestep 83.50% : Training Loss = 0.3218, Accuracy = 0.8596, Test Loss = 0.3083, Test Accuracy = 0.8793\n",
      "Processing timestep: 0.84\n",
      "Timestep 84.00% : Training Loss = 0.3110, Accuracy = 0.8598, Test Loss = 0.3261, Test Accuracy = 0.8446\n",
      "Processing timestep: 0.845\n",
      "Timestep 84.50% : Training Loss = 0.3251, Accuracy = 0.8523, Test Loss = 0.3571, Test Accuracy = 0.8398\n",
      "Processing timestep: 0.85\n",
      "Timestep 85.00% : Training Loss = 0.3180, Accuracy = 0.8581, Test Loss = 0.3506, Test Accuracy = 0.8385\n",
      "Processing timestep: 0.855\n",
      "Timestep 85.50% : Training Loss = 0.3097, Accuracy = 0.8673, Test Loss = 0.4255, Test Accuracy = 0.7984\n",
      "Processing timestep: 0.86\n",
      "Timestep 86.00% : Training Loss = 0.3092, Accuracy = 0.8594, Test Loss = 0.3212, Test Accuracy = 0.8571\n",
      "Processing timestep: 0.865\n",
      "Timestep 86.50% : Training Loss = 0.3187, Accuracy = 0.8618, Test Loss = 0.3042, Test Accuracy = 0.8627\n",
      "Processing timestep: 0.87\n",
      "Timestep 87.00% : Training Loss = 0.3145, Accuracy = 0.8553, Test Loss = 0.3875, Test Accuracy = 0.7979\n",
      "Processing timestep: 0.875\n",
      "Timestep 87.50% : Training Loss = 0.3164, Accuracy = 0.8509, Test Loss = 0.2791, Test Accuracy = 0.8855\n",
      "Processing timestep: 0.88\n",
      "Timestep 88.00% : Training Loss = 0.2938, Accuracy = 0.8621, Test Loss = 0.3355, Test Accuracy = 0.8557\n",
      "Processing timestep: 0.885\n",
      "Timestep 88.50% : Training Loss = 0.3171, Accuracy = 0.8497, Test Loss = 0.3468, Test Accuracy = 0.8291\n",
      "Processing timestep: 0.89\n",
      "Timestep 89.00% : Training Loss = 0.2952, Accuracy = 0.8661, Test Loss = 0.3741, Test Accuracy = 0.8295\n",
      "Processing timestep: 0.895\n",
      "Timestep 89.50% : Training Loss = 0.2670, Accuracy = 0.8802, Test Loss = 0.2807, Test Accuracy = 0.8769\n",
      "Processing timestep: 0.9\n",
      "Timestep 90.00% : Training Loss = 0.3139, Accuracy = 0.8545, Test Loss = 0.3411, Test Accuracy = 0.8440\n",
      "Processing timestep: 0.905\n",
      "Timestep 90.50% : Training Loss = 0.2784, Accuracy = 0.8686, Test Loss = 0.3140, Test Accuracy = 0.8590\n",
      "Processing timestep: 0.91\n",
      "Timestep 91.00% : Training Loss = 0.2890, Accuracy = 0.8698, Test Loss = 0.2976, Test Accuracy = 0.8639\n",
      "Processing timestep: 0.915\n",
      "Timestep 91.50% : Training Loss = 0.2506, Accuracy = 0.8882, Test Loss = 0.3142, Test Accuracy = 0.8643\n",
      "Processing timestep: 0.92\n",
      "Timestep 92.00% : Training Loss = 0.2804, Accuracy = 0.8710, Test Loss = 0.3140, Test Accuracy = 0.8451\n",
      "Processing timestep: 0.925\n",
      "Timestep 92.50% : Training Loss = 0.2737, Accuracy = 0.8748, Test Loss = 0.2532, Test Accuracy = 0.8787\n",
      "Processing timestep: 0.93\n",
      "Timestep 93.00% : Training Loss = 0.2673, Accuracy = 0.8853, Test Loss = 0.2544, Test Accuracy = 0.8871\n",
      "Processing timestep: 0.935\n",
      "Timestep 93.50% : Training Loss = 0.2578, Accuracy = 0.8852, Test Loss = 0.3258, Test Accuracy = 0.8543\n",
      "Processing timestep: 0.94\n",
      "Timestep 94.00% : Training Loss = 0.2436, Accuracy = 0.8916, Test Loss = 0.2616, Test Accuracy = 0.8889\n",
      "Processing timestep: 0.945\n",
      "Timestep 94.50% : Training Loss = 0.2516, Accuracy = 0.8929, Test Loss = 0.2877, Test Accuracy = 0.8571\n",
      "Processing timestep: 0.95\n",
      "Timestep 95.00% : Training Loss = 0.2627, Accuracy = 0.8801, Test Loss = 0.3176, Test Accuracy = 0.8560\n",
      "Processing timestep: 0.955\n",
      "Timestep 95.50% : Training Loss = 0.2567, Accuracy = 0.8831, Test Loss = 0.2682, Test Accuracy = 0.8845\n",
      "Processing timestep: 0.96\n",
      "Timestep 96.00% : Training Loss = 0.2748, Accuracy = 0.8808, Test Loss = 0.2964, Test Accuracy = 0.8647\n",
      "Processing timestep: 0.965\n",
      "Timestep 96.50% : Training Loss = 0.2561, Accuracy = 0.8811, Test Loss = 0.2525, Test Accuracy = 0.8801\n",
      "Processing timestep: 0.97\n",
      "Timestep 97.00% : Training Loss = 0.2560, Accuracy = 0.8870, Test Loss = 0.2583, Test Accuracy = 0.8751\n",
      "Processing timestep: 0.975\n",
      "Timestep 97.50% : Training Loss = 0.2619, Accuracy = 0.8908, Test Loss = 0.2461, Test Accuracy = 0.8869\n",
      "Processing timestep: 0.98\n",
      "Timestep 98.00% : Training Loss = 0.2302, Accuracy = 0.9048, Test Loss = 0.2614, Test Accuracy = 0.8582\n",
      "Processing timestep: 0.985\n",
      "Timestep 98.50% : Training Loss = 0.2322, Accuracy = 0.9005, Test Loss = 0.2432, Test Accuracy = 0.8750\n",
      "Processing timestep: 0.99\n",
      "Timestep 99.00% : Training Loss = 0.2624, Accuracy = 0.8843, Test Loss = 0.2339, Test Accuracy = 0.8887\n",
      "Processing timestep: 0.995\n",
      "Timestep 99.50% : Training Loss = 0.2543, Accuracy = 0.8885, Test Loss = 0.2323, Test Accuracy = 0.8973\n",
      "Processing timestep: 1.0\n",
      "Timestep 100.00% : Training Loss = 0.1919, Accuracy = 0.9274, Test Loss = 0.1527, Test Accuracy = 0.9460\n"
     ]
    }
   ],
   "source": [
    "# Setup model for each timestep\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create an array of logistic regression models\n",
    "\n",
    "modules_to_reload = [\n",
    "    'models.logistic_regression',\n",
    "    'models.Model'\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "from models.Model import Model\n",
    "from models.logistic_regression import setup_logistic_regression_models\n",
    "\n",
    "models = setup_logistic_regression_models(training_data, None, numeric_features, other_features, features, optimize_hyperparams=False, use_calibration=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_model(models, specialized_model, original_features, \n",
    "                 edge_numeric_features, edge_other_features, edge_scaler,\n",
    "                 threshold=0.95, tight_threshold=7):\n",
    "    \"\"\"\n",
    "    Replace models after a certain threshold with CombinedModel that uses specialized model for edge cases.\n",
    "    \n",
    "    Args:\n",
    "        models: Dict of {timestep: model} \n",
    "        specialized_model: The edge-case specialized model\n",
    "        original_features: List of original feature names\n",
    "        edge_numeric_features: List of numeric features for specialized model\n",
    "        edge_other_features: List of binary/categorical features for specialized model\n",
    "        edge_scaler: Fitted StandardScaler for edge numeric features\n",
    "        threshold: Timestep threshold above which to use CombinedModel (default 0.95)\n",
    "        tight_threshold: Score difference threshold for \"tight game\" (default 7)\n",
    "    \n",
    "    Returns:\n",
    "        new_models: Dict with CombinedModel for timesteps >= threshold\n",
    "    \"\"\"\n",
    "    new_models = {}\n",
    "    \n",
    "    for key, general_model in models.items():\n",
    "        if key >= threshold:\n",
    "            # Wrap with CombinedModel that can route to specialized model\n",
    "            new_models[key] = CombinedModel(\n",
    "                general_model=general_model,\n",
    "                specialized_model=specialized_model,\n",
    "                original_features=original_features,\n",
    "                edge_numeric_features=edge_numeric_features,\n",
    "                edge_other_features=edge_other_features,\n",
    "                scaler=edge_scaler,\n",
    "                tight_threshold=tight_threshold,\n",
    "                late_game_threshold=threshold  # Use same threshold for consistency\n",
    "            )\n",
    "        else:\n",
    "            # Keep original model for early/mid-game\n",
    "            new_models[key] = general_model\n",
    "    \n",
    "    return new_models\n",
    "# Usage:\n",
    "new_models = replace_model(\n",
    "    models=models,\n",
    "    specialized_model=edge_single_model,\n",
    "    original_features=features,\n",
    "    edge_numeric_features=edge_numeric_features,\n",
    "    edge_other_features=edge_other_features,\n",
    "    edge_scaler=None,\n",
    "    threshold=0.95,\n",
    "    tight_threshold=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<models.logistic_regression.LogisticRegressionModel object at 0x37d39bdd0>\n",
      "<__main__.CombinedModel object at 0x37c7eea50>\n"
     ]
    }
   ],
   "source": [
    "print(models[0.99])\n",
    "print(new_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Test accuracy of model for each timestep on test data and plot\n",
    "# accuracies = []\n",
    "# timesteps = []\n",
    "import process_data\n",
    "modules_to_reload = [\n",
    "    'process_data',\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "x = process_data.plot_loss(models, test_data, \"Logistic Regression\")\n",
    "# process_data.plot_accuracy(models, test_data, \"Logistic Regression\")\n",
    "# process_data.plot_loss(new_models, test_data, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78621684, 0.21378316]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = new_models[0.99]\n",
    "# features = [\"relative_strength\", \"score_difference\", \"home_has_possession\", \"end.down\", \"end.distance\", \"end.yardsToEndzone\",  \"home_timeouts_left\", \"away_timeouts_left\"]\n",
    "data_point = [0.99, 0.5, -4, 1, 1, 1, 1, 1, 1]\n",
    "model.predict_proba(np.array([data_point]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "filename = 'logistic_regression_model.pickle'\n",
    "pickle.dump(models, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from models.utils import SHAP_analysis\n",
    "# model = models[0.99]\n",
    "# # Health Check:\n",
    "# if hasattr(model.model, \"coef_\"):\n",
    "#     feature_names = model.all_features if hasattr(model, \"all_features\") else None\n",
    "#     coefs = model.model.coef_[0]  # shape (n_features,)\n",
    "#     if feature_names is not None and len(feature_names) == len(coefs):\n",
    "#         for name, coef in zip(feature_names, coefs):\n",
    "#             print(f\"{name}: {coef}\")\n",
    "\n",
    "SHAP_analysis(models, training_data, test_data, \"logistic_regression\", \"shap_values/LR\", num_threads = 1)\n",
    "# x = np.array([[0.1, 0.9, 20, 1, 0, 1, 50, 20, 2, 2, 2]])\n",
    "# model.predict_proba(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeuristicNFLModel:\n",
    "    \"\"\"\n",
    "    Heuristic-based NFL win probability model using domain knowledge and situational logic.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: List of feature names in order\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.idx = {feat: i for i, feat in enumerate(features)}\n",
    "        \n",
    "    def _sigmoid(self, x, scale=1.0):\n",
    "        \"\"\"Smooth sigmoid function.\"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(-x / scale))\n",
    "    \n",
    "    def _expected_points_from_position(self, yards_to_endzone, down, distance):\n",
    "        \"\"\"\n",
    "        Estimate expected points for the possessing team from current position.\n",
    "        Based on historical NFL analytics.\n",
    "        \"\"\"\n",
    "        # Field position value (closer to opponent endzone = better)\n",
    "        if yards_to_endzone <= 10:  # Inside 10\n",
    "            base_ep = 6.0\n",
    "        elif yards_to_endzone <= 20:  # Red zone\n",
    "            base_ep = 4.5\n",
    "        elif yards_to_endzone <= 40:  # Good field position\n",
    "            base_ep = 3.0\n",
    "        elif yards_to_endzone <= 60:  # Midfield area\n",
    "            base_ep = 2.0\n",
    "        elif yards_to_endzone <= 80:  # Own territory\n",
    "            base_ep = 1.0\n",
    "        else:  # Backed up\n",
    "            base_ep = 0.3\n",
    "        \n",
    "        # Down and distance penalty\n",
    "        if down == 1:\n",
    "            down_multiplier = 1.0\n",
    "        elif down == 2:\n",
    "            down_multiplier = 0.9 if distance <= 7 else 0.7\n",
    "        elif down == 3:\n",
    "            down_multiplier = 0.7 if distance <= 5 else 0.4\n",
    "        else:  # 4th down\n",
    "            down_multiplier = 0.2 if distance <= 3 else 0.05\n",
    "        \n",
    "        return base_ep * down_multiplier\n",
    "    \n",
    "    def _time_value(self, game_completed, score_diff, has_possession):\n",
    "        \"\"\"\n",
    "        Adjust for time remaining and possession.\n",
    "        Returns multiplier for score difference impact.\n",
    "        \"\"\"\n",
    "        time_remaining = 1.0 - game_completed\n",
    "        \n",
    "        # Late game: time becomes critical\n",
    "        if game_completed > 0.95:  # Final ~3 minutes\n",
    "            if has_possession and score_diff > 0:\n",
    "                # Leading with ball late = can run clock\n",
    "                return 1.5\n",
    "            elif not has_possession and score_diff < 0:\n",
    "                # Trailing without ball late = desperate\n",
    "                return 0.6\n",
    "        \n",
    "        return 1.0\n",
    "    \n",
    "    def _calculate_win_prob(self, row):\n",
    "        \"\"\"Calculate win probability for a single game state.\"\"\"\n",
    "        # Extract features\n",
    "        game_completed = row[self.idx['game_completed']]\n",
    "        relative_strength = row[self.idx['relative_strength']]\n",
    "        score_diff = row[self.idx['score_difference']]\n",
    "        home_has_poss = row[self.idx['home_has_possession']]\n",
    "        down = row[self.idx['end.down']]\n",
    "        distance = row[self.idx['end.distance']]\n",
    "        yards = row[self.idx['end.yardsToEndzone']]\n",
    "        home_to = row[self.idx['home_timeouts_left']]\n",
    "        away_to = row[self.idx['away_timeouts_left']]\n",
    "        \n",
    "        time_remaining = 1.0 - game_completed\n",
    "        \n",
    "        # === Early Game (first 40%) ===\n",
    "        if game_completed < 0.40:\n",
    "            # Mostly rely on pre-game strength with small score adjustment\n",
    "            base_prob = relative_strength\n",
    "            score_adjustment = self._sigmoid(score_diff, scale=14.0) - 0.5\n",
    "            return np.clip(base_prob + 0.2 * score_adjustment, 0.01, 0.99)\n",
    "        \n",
    "        # === Mid Game (40-85%) ===\n",
    "        if game_completed < 0.85:\n",
    "            # Balance pre-game strength and current score\n",
    "            strength_weight = 0.3\n",
    "            score_weight = 0.7\n",
    "            \n",
    "            base_prob = strength_weight * relative_strength + \\\n",
    "                       score_weight * self._sigmoid(score_diff, scale=10.0)\n",
    "            \n",
    "            return np.clip(base_prob, 0.01, 0.99)\n",
    "        \n",
    "        # === Late Game (85-95%) ===\n",
    "        if game_completed < 0.95:\n",
    "            # Score difference dominates, with possession mattering more\n",
    "            base_prob = self._sigmoid(score_diff, scale=7.0)\n",
    "            \n",
    "            # Possession adjustment based on field position\n",
    "            if home_has_poss:\n",
    "                ep = self._expected_points_from_position(yards, down, distance)\n",
    "                poss_adjustment = ep / 40.0  # Scale to reasonable range\n",
    "            else:\n",
    "                ep = self._expected_points_from_position(yards, down, distance)\n",
    "                poss_adjustment = -ep / 40.0\n",
    "            \n",
    "            return np.clip(base_prob + poss_adjustment, 0.01, 0.99)\n",
    "        \n",
    "        # === Critical Final Minutes (95%+) ===\n",
    "        # This is where heuristics really matter\n",
    "        \n",
    "        # 1. Check if game is essentially over\n",
    "        seconds_left = time_remaining * 3600  # Approximate seconds\n",
    "        \n",
    "        # Leading team can kneel out clock?\n",
    "        if score_diff > 0 and home_has_poss:\n",
    "            # Home leading with ball\n",
    "            kneels_possible = home_to + away_to + 3  # Timeouts + 3 kneels\n",
    "            time_to_kneel = kneels_possible * 40\n",
    "            if seconds_left < time_to_kneel and down < 4:\n",
    "                return 0.995  # Game essentially over\n",
    "        \n",
    "        if score_diff < 0 and not home_has_poss:\n",
    "            # Away leading with ball\n",
    "            kneels_possible = home_to + away_to + 3\n",
    "            time_to_kneel = kneels_possible * 40\n",
    "            if seconds_left < time_to_kneel and down < 4:\n",
    "                return 0.005  # Home has essentially lost\n",
    "        \n",
    "        # 2. Score difference analysis\n",
    "        abs_score_diff = abs(score_diff)\n",
    "        \n",
    "        # Multiple score game (>8 points)\n",
    "        if abs_score_diff > 8:\n",
    "            if score_diff > 0:\n",
    "                return 0.98 if home_has_poss else 0.95\n",
    "            else:\n",
    "                return 0.02 if not home_has_poss else 0.05\n",
    "        \n",
    "        # 3. Single-score game analysis (most complex)\n",
    "        # This is where possession + field position + timeouts matter most\n",
    "        \n",
    "        # Calculate expected points for possessing team\n",
    "        if home_has_poss:\n",
    "            home_ep = self._expected_points_from_position(yards, down, distance)\n",
    "            away_ep = 0  # Don't have ball\n",
    "        else:\n",
    "            home_ep = 0\n",
    "            away_ep = self._expected_points_from_position(yards, down, distance)\n",
    "        \n",
    "        # Estimate possessions remaining (very rough)\n",
    "        possessions_left = max(1, time_remaining * 8)  # ~8 possessions per game\n",
    "        \n",
    "        # Timeout advantage\n",
    "        timeout_advantage = (home_to - away_to) * 0.02\n",
    "        \n",
    "        # Build probability from components\n",
    "        if abs_score_diff <= 3:  # Field goal game\n",
    "            # Need to reach FG range (approximately 35 yards from endzone)\n",
    "            if home_has_poss:\n",
    "                can_kick_fg = 1.0 if yards <= 35 else 0.5\n",
    "                home_scoring_prob = can_kick_fg * 0.7  # ~70% FG success\n",
    "            else:\n",
    "                home_scoring_prob = 0.3  # Need to get ball back and score\n",
    "            \n",
    "            if score_diff == 0:  # Tied\n",
    "                base_prob = 0.5 + (home_scoring_prob - 0.35)\n",
    "            elif score_diff > 0:  # Home leading by FG\n",
    "                base_prob = 0.65 if home_has_poss else 0.55\n",
    "            else:  # Home trailing by FG\n",
    "                base_prob = 0.35 if home_has_poss else 0.45\n",
    "        \n",
    "        elif abs_score_diff <= 7:  # Touchdown game\n",
    "            if score_diff > 0:  # Home leading by TD\n",
    "                if home_has_poss:\n",
    "                    # Can run clock, away needs stop + TD drive\n",
    "                    base_prob = 0.75\n",
    "                else:\n",
    "                    # Away has ball, needs TD to tie\n",
    "                    if yards <= 50:  # Good field position\n",
    "                        base_prob = 0.60\n",
    "                    elif yards <= 80:  # Decent position\n",
    "                        base_prob = 0.70\n",
    "                    else:  # Backed up\n",
    "                        base_prob = 0.80\n",
    "            else:  # Home trailing by TD\n",
    "                if home_has_poss:\n",
    "                    # Home needs TD to tie\n",
    "                    if yards <= 50:\n",
    "                        base_prob = 0.40\n",
    "                    elif yards <= 80:\n",
    "                        base_prob = 0.30\n",
    "                    else:\n",
    "                        base_prob = 0.20\n",
    "                else:\n",
    "                    # Away has ball, can run clock\n",
    "                    base_prob = 0.25\n",
    "        else:\n",
    "            # Shouldn't hit this, but fallback\n",
    "            base_prob = self._sigmoid(score_diff, scale=7.0)\n",
    "        \n",
    "        # Apply timeout adjustment\n",
    "        base_prob += timeout_advantage\n",
    "        \n",
    "        # Apply pre-game strength (small influence)\n",
    "        base_prob = 0.9 * base_prob + 0.1 * relative_strength\n",
    "        \n",
    "        return np.clip(base_prob, 0.01, 0.99)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict win probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: Array of shape (n_samples, n_features)\n",
    "            \n",
    "        Returns:\n",
    "            Array of shape (n_samples, 2) with [P(away_win), P(home_win)]\n",
    "        \"\"\"\n",
    "        n_samples = len(X)\n",
    "        probs = np.zeros((n_samples, 2))\n",
    "        \n",
    "        for i, row in enumerate(X):\n",
    "            home_win_prob = self._calculate_win_prob(row)\n",
    "            probs[i, 0] = 1 - home_win_prob  # Away win\n",
    "            probs[i, 1] = home_win_prob      # Home win\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels (0 = away win, 1 = home win).\"\"\"\n",
    "        probs = self.predict_proba(X)\n",
    "        return (probs[:, 1] >= 0.5).astype(int)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Calculate accuracy.\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n",
      "-0.018992848529760534\n",
      "-0.012637426715417514\n",
      "     game_completed  relative_strength  score_difference  home_has_possession  end.down  end.distance  end.yardsToEndzone  home_timeouts_left  away_timeouts_left  label  predicted  alt_predicted    ESPN      diff\n",
      "0          0.968333             0.5147              -1.0                  0.0       1.0          10.0                70.0                 3.0                 2.0    1.0   0.104827       0.242624  0.4577 -0.507246\n",
      "1          0.968333             0.5147              -1.0                  0.0      -1.0          10.0                65.0                 3.0                 2.0    1.0   0.096606       0.242624  0.4082 -0.465893\n",
      "2          0.968889             0.5220               0.0                  0.0       1.0          10.0                67.0                 1.0                 2.0    1.0   0.329978       0.320918  0.6831 -0.348505\n",
      "3          0.968056             0.4433              -1.0                  1.0       1.0           9.0                 9.0                 2.0                 1.0    1.0   0.357389       0.598437   0.689 -0.316228\n",
      "4          0.967500             0.3480              -1.0                  1.0       1.0          10.0                43.0                 3.0                 3.0    1.0   0.304988       0.558669  0.5743 -0.301822\n",
      "5          0.965556             0.5960               0.0                  0.0       1.0          10.0                78.0                 3.0                 3.0    1.0   0.332591       0.349137  0.5984 -0.284152\n",
      "6          0.966667             0.6107              -1.0                  1.0       1.0          10.0                11.0                 2.0                 0.0    1.0   0.417824       0.664992  0.7254 -0.263524\n",
      "7          0.967222             0.4073              -5.0                  0.0       1.0          10.0                57.0                 1.0                 2.0    1.0   0.087993       0.055861  0.2413 -0.256131\n",
      "8          0.966111             0.4147               7.0                  0.0      -1.0          10.0                 0.0                 3.0                 3.0    1.0   0.502408       0.845627  0.9559 -0.245653\n",
      "9          0.968056             0.6087              -3.0                  1.0       1.0           2.0                15.0                 3.0                 2.0    1.0   0.354201       0.482412  0.5847 -0.244582\n",
      "10         0.965278             0.4433              -1.0                  1.0       3.0           2.0                25.0                 2.0                 2.0    1.0   0.371600       0.598437   0.612 -0.244343\n",
      "11         0.966667             0.3480              -1.0                  1.0       1.0          10.0                54.0                 3.0                 3.0    1.0   0.321176       0.558669   0.527 -0.237072\n",
      "12         0.968056             0.6087              -3.0                  1.0       2.0           4.0                21.0                 3.0                 2.0    1.0   0.358427       0.482412  0.5568 -0.215190\n",
      "13         0.966667             0.6027               3.0                  0.0       1.0           8.0                62.0                 3.0                 2.0    1.0   0.544541       0.626563  0.9235 -0.201590\n",
      "14         0.966389             0.5213               5.0                  0.0      -1.0          13.0                15.0                 3.0                 1.0    1.0   0.554164       0.755965  0.9438 -0.195611\n",
      "15         0.967778             0.3687               0.0                  1.0       1.0          10.0                52.0                 3.0                 3.0    0.0   0.526999       0.656446   0.296 -0.190112\n",
      "16         0.966667             0.4600               5.0                  0.0       1.0          10.0                62.0                 2.0                 3.0    1.0   0.562842       0.736083   0.941 -0.187626\n",
      "17         0.969167             0.3800               0.0                  1.0       1.0          10.0                70.0                 3.0                 3.0    0.0   0.559449       0.660797  0.3597 -0.183599\n",
      "18         0.966111             0.4147               7.0                  0.0       1.0          10.0                69.0                 3.0                 3.0    1.0   0.573623       0.845627  0.9645 -0.180537\n",
      "19         0.966667             0.7120              -3.0                  1.0       3.0           9.0                90.0                 3.0                 3.0    0.0   0.450765       0.526604  0.1514 -0.180267\n",
      "20         0.969167             0.5147              -1.0                  1.0       1.0          11.0                55.0                 3.0                 2.0    1.0   0.373429       0.627434  0.5386 -0.179701\n",
      "21         0.970000             0.3360               0.0                  1.0       1.0           6.0                70.0                 2.0                 3.0    0.0   0.559823       0.643709  0.3668 -0.178859\n",
      "22         0.966667             0.4433              -1.0                  1.0       3.0           6.0                29.0                 2.0                 2.0    1.0   0.366671       0.598437  0.5264 -0.176809\n",
      "23         0.966111             0.4147               7.0                  0.0       1.0          10.0                65.0                 3.0                 3.0    1.0   0.567388       0.845627  0.8759 -0.171752\n",
      "24         0.965556             0.3407               3.0                  0.0       1.0          10.0                66.0                 3.0                 0.0    1.0   0.513614       0.517203  0.7406 -0.169283\n",
      "25         0.968889             0.3407               3.0                  0.0       3.0          10.0                59.0                 3.0                 0.0    1.0   0.545173       0.517203   0.798 -0.166063\n",
      "26         0.966944             0.3407               3.0                  0.0       1.0          10.0                66.0                 3.0                 0.0    1.0   0.525289       0.517203  0.7494 -0.162550\n",
      "27         0.967778             0.7120              -3.0                  1.0       1.0          10.0                90.0                 3.0                 3.0    0.0   0.427634       0.526604  0.1441 -0.162106\n",
      "28         0.966944             0.3407               3.0                  0.0       1.0          10.0                65.0                 3.0                 0.0    1.0   0.523702       0.517203  0.7451 -0.161885\n",
      "29         0.966667             0.6027               3.0                  0.0       4.0          23.0                95.0                 3.0                 2.0    1.0   0.597000       0.626563  0.9688 -0.161435\n",
      "30         0.969167             0.5673               0.0                  1.0       1.0           6.0                 6.0                 1.0                 3.0    1.0   0.566709       0.728611  0.8106 -0.151869\n",
      "31         0.969444             0.6980               2.0                  0.0       3.0           4.0                23.0                 3.0                 3.0    0.0   0.536844       0.575520  0.3717 -0.150040\n",
      "32         0.969167             0.3693               0.0                  0.0       2.0           8.0                66.0                 1.0                 1.0    1.0   0.321904       0.266775  0.4432 -0.149788\n",
      "33         0.967500             0.5873              -6.0                  1.0       2.0           2.0                 5.0                 0.0                 3.0    1.0   0.348800       0.225153  0.4761 -0.149590\n",
      "34         0.966667             0.3573              -6.0                  1.0       3.0          13.0                75.0                 1.0                 1.0    0.0   0.390574       0.163864  0.0716 -0.147422\n",
      "35         0.966389             0.5213               5.0                  0.0       1.0          14.0                70.0                 3.0                 1.0    1.0   0.614766       0.755965  0.9604 -0.146837\n",
      "36         0.968333             0.4920              -7.0                  1.0       2.0          10.0                87.0                 0.0                 2.0    0.0   0.384475       0.144876  0.0348 -0.146610\n",
      "37         0.967222             0.4073              -5.0                  0.0      -1.0          10.0                 0.0                 1.0                 2.0    1.0   0.072489       0.055861  0.1551 -0.146420\n",
      "38         0.966667             0.7633               3.0                  0.0       2.0          17.0                57.0                 3.0                 2.0    1.0   0.570975       0.688372  0.8046 -0.145881\n",
      "39         0.970000             0.4800               2.0                  0.0       1.0          10.0                20.0                 1.0                 3.0    0.0   0.474583       0.482781  0.2911 -0.140489\n",
      "40         0.967778             0.6293               3.0                  0.0       4.0           3.0                35.0                 3.0                 3.0    1.0   0.542151       0.637158  0.7356 -0.139718\n",
      "41         0.966667             0.4647               3.0                  0.0       1.0          11.0                59.0                 3.0                 1.0    1.0   0.521305       0.569836  0.7004 -0.139389\n",
      "42         0.966667             0.6060              -3.0                  1.0       1.0          10.0                31.0                 2.0                 3.0    1.0   0.343848       0.481258  0.4572 -0.135904\n",
      "43         0.968056             0.3573              -6.0                  1.0       3.0          13.0                75.0                 1.0                 1.0    0.0   0.372087       0.163864  0.0538 -0.135554\n",
      "44         0.967778             0.6980               2.0                  0.0       1.0          10.0                23.0                 3.0                 3.0    0.0   0.503893       0.575520  0.3449 -0.134952\n",
      "45         0.966667             0.7367              -7.0                  1.0       1.0          10.0                75.0                 3.0                 2.0    0.0   0.430054       0.204836  0.2244 -0.134591\n",
      "46         0.966667             0.3480              -1.0                  1.0       2.0          10.0                54.0                 3.0                 3.0    1.0   0.327641       0.558669  0.4365 -0.134534\n",
      "47         0.966667             0.5220               0.0                  0.0       2.0           8.0                67.0                 1.0                 2.0    1.0   0.337229       0.320918  0.4474 -0.133899\n",
      "48         0.968889             0.4340               0.0                  1.0       1.0          10.0                44.0                 3.0                 1.0    1.0   0.571078       0.681206  0.7751 -0.133394\n",
      "49         0.965833             0.4367              -5.0                  1.0       4.0           5.0                46.0                 1.0                 1.0    0.0   0.405018       0.246476  0.1843 -0.130073\n",
      "50         0.966667             0.7120              -3.0                  1.0       4.0           9.0                10.0                 3.0                 3.0    0.0   0.376499       0.526604  0.1144 -0.128664\n",
      "51         0.966667             0.3727              -1.0                  1.0       3.0          20.0                80.0                 2.0                 2.0    0.0   0.388038       0.569070  0.1502 -0.128014\n",
      "52         0.967778             0.5220               0.0                  0.0       4.0           8.0                33.0                 1.0                 2.0    1.0   0.318738       0.320918  0.4193 -0.126906\n",
      "53         0.966667             0.5900               7.0                  0.0       3.0          13.0                13.0                 1.0                 2.0    1.0   0.617498       0.880892  0.8575 -0.126001\n",
      "54         0.967222             0.5960               0.0                  1.0       1.0          10.0                43.0                 3.0                 3.0    1.0   0.568372       0.738220  0.7516 -0.124601\n",
      "55         0.966389             0.5607               4.0                  0.0       2.0          10.0                64.0                 3.0                 2.0    1.0   0.596403       0.694632   0.804 -0.124475\n",
      "56         0.966667             0.6293               3.0                  0.0       3.0           8.0                40.0                 3.0                 3.0    1.0   0.511046       0.637158  0.6614 -0.124426\n",
      "57         0.966667             0.6633              -2.0                  1.0       1.0          10.0                59.0                 3.0                 2.0    1.0   0.407277       0.598545  0.5227 -0.123506\n",
      "58         0.968611             0.6060              -3.0                  1.0       2.0          10.0                23.0                 2.0                 3.0    1.0   0.334427       0.481258  0.4347 -0.123423\n",
      "59         0.966667             0.5673               0.0                  1.0       2.0           6.0                17.0                 1.0                 3.0    1.0   0.578500       0.728611  0.7671 -0.123420\n",
      "60         0.966667             0.6513              -4.0                  1.0       4.0          10.0                36.0                 3.0                 3.0    0.0   0.403624       0.407643  0.1988 -0.123391\n",
      "61         0.969167             0.5337              -2.0                  1.0       2.0          12.0                78.0                 1.0                 1.0    0.0   0.428894       0.544253  0.2482 -0.122346\n",
      "62         0.966389             0.4447              -3.0                  1.0       1.0          10.0                82.0                 3.0                 2.0    0.0   0.379425       0.413086  0.1499 -0.121493\n",
      "63         0.966667             0.2493               1.0                  0.0       2.0           6.0                76.0                 2.0                 0.0    1.0   0.507726       0.301481  0.6507 -0.120323\n",
      "64         0.966667             0.4600               5.0                  0.0       1.0          10.0                53.0                 2.0                 3.0    1.0   0.548707       0.736083  0.7101 -0.119623\n",
      "65         0.966667             0.4827              -4.0                  1.0       4.0           3.0                60.0                 3.0                 3.0    0.0   0.395505       0.340193  0.1932 -0.119098\n",
      "66         0.966667             0.3573              -6.0                  1.0       2.0           6.0                68.0                 1.0                 1.0    0.0   0.382326       0.163864   0.166 -0.118617\n",
      "67         0.965833             0.5253               5.0                  1.0      -1.0          16.0                69.0                 1.0                 3.0    0.0   0.848591       0.942519  0.7756 -0.118551\n",
      "68         0.966111             0.6980               2.0                  0.0       1.0          10.0                23.0                 3.0                 3.0    0.0   0.494033       0.575520  0.3571 -0.116548\n",
      "69         0.966667             0.5900               7.0                  0.0       2.0          26.0                74.0                 1.0                 2.0    1.0   0.646470       0.880892  0.9073 -0.116390\n",
      "70         0.966667             0.7367              -7.0                  1.0       2.0          10.0                25.0                 3.0                 2.0    0.0   0.384572       0.204836  0.1804 -0.115351\n",
      "71         0.966389             0.6053               0.0                  1.0       1.0          10.0                30.0                 3.0                 1.0    1.0   0.608152       0.741286   0.801 -0.113944\n",
      "72         0.966389             0.5607               4.0                  0.0       1.0          10.0                64.0                 3.0                 2.0    1.0   0.589283       0.694632  0.7653 -0.113605\n",
      "73         0.968056             0.5607               4.0                  0.0       2.0          10.0                64.0                 3.0                 2.0    1.0   0.613800       0.694632  0.8097 -0.112937\n",
      "74         0.968056             0.7367              -7.0                  1.0       3.0          10.0                25.0                 3.0                 2.0    0.0   0.369824       0.204836  0.1556 -0.112559\n",
      "75         0.966667             0.5340              -7.0                  1.0       2.0           7.0                87.0                 2.0                 2.0    0.0   0.415572       0.154015   0.247 -0.111691\n",
      "76         0.967500             0.3219              -5.0                  1.0       1.0           9.0                80.0                 1.0                 3.0    0.0   0.347312       0.211804  0.1012 -0.110384\n",
      "77         0.968056             0.4433              -1.0                  1.0       4.0           1.0                76.0                 2.0                 2.0    1.0   0.429587       0.598437  0.5353 -0.109425\n",
      "78         0.966111             0.5853               5.0                  0.0       1.0          10.0                81.0                 2.0                 2.0    1.0   0.633792       0.775612  0.8396 -0.108380\n",
      "79         0.969444             0.6980               2.0                  0.0       2.0          11.0                24.0                 2.0                 3.0    0.0   0.525307       0.575520  0.4134 -0.105048\n",
      "80         0.968333             0.4220              -7.0                  1.0       1.0           4.0                70.0                 1.0                 3.0    0.0   0.322089       0.130648  0.0138 -0.103551\n",
      "81         0.965278             0.6840               5.0                  0.0       3.0          12.0                53.0                 3.0                 0.0    1.0   0.648353       0.803655  0.8573 -0.103292\n",
      "82         0.968056             0.3573              -6.0                  1.0       1.0          10.0                43.0                 0.0                 1.0    0.0   0.321008       0.163864   0.001 -0.103045\n",
      "83         0.966667             0.4207              -3.0                  1.0       1.0          10.0                58.0                 1.0                 3.0    0.0   0.328248       0.403159  0.0708 -0.102734\n",
      "84         0.966667             0.4340               0.0                  1.0       1.0          10.0                55.0                 3.0                 2.0    1.0   0.566641       0.681206  0.7076 -0.102302\n",
      "85         0.968056             0.5673               0.0                  1.0       3.0           6.0                17.0                 1.0                 3.0    1.0   0.586902       0.728611  0.7383 -0.102163\n",
      "86         0.966667             0.7113               0.0                  1.0       2.0           5.0                 5.0                 2.0                 1.0    1.0   0.640010       0.774549  0.8319 -0.101335\n",
      "87         0.970000             0.4800               2.0                  0.0       3.0           4.0                27.0                 2.0                 3.0    0.0   0.493414       0.482781  0.3788 -0.099968\n",
      "88         0.969444             0.6980               2.0                  0.0       2.0          11.0                24.0                 3.0                 3.0    0.0   0.520347       0.575520  0.4134 -0.099861\n",
      "89         0.966667             0.7347               7.0                  0.0       2.0          10.0                24.0                 3.0                 2.0    1.0   0.641846       0.904538  0.8309 -0.099680\n",
      "90         0.966667             0.6433               7.0                  0.0       2.0           8.0                58.0                 3.0                 1.0    1.0   0.667295       0.890140  0.8906 -0.098725\n",
      "91         0.967500             0.5853               5.0                  0.0       1.0          10.0                81.0                 2.0                 2.0    1.0   0.650924       0.775612  0.8454 -0.097953\n",
      "92         0.966667             0.6433               7.0                  0.0       3.0           8.0                58.0                 3.0                 1.0    1.0   0.673811       0.890140  0.9049 -0.097355\n",
      "93         0.967500             0.4367              -5.0                  1.0       4.0           1.0                46.0                 1.0                 1.0    0.0   0.391851       0.246476  0.2388 -0.096522\n",
      "94         0.966667             0.5367               6.0                  0.0       1.0          10.0                41.0                 3.0                 2.0    1.0   0.576466       0.822495  0.7121 -0.096495\n",
      "95         0.966667             0.6520               7.0                  0.0       1.0           1.0                49.0                 3.0                 1.0    1.0   0.658615       0.891589  0.8568 -0.096038\n",
      "96         0.969444             0.4280              -6.0                  1.0       2.0           3.0                73.0                 0.0                 3.0    0.0   0.341307       0.181134  0.1487 -0.094379\n",
      "97         0.966667             0.5880               0.0                  1.0       1.0          10.0                49.0                 2.0                 3.0    1.0   0.580122       0.735564   0.713 -0.093929\n",
      "98         0.965833             0.6087              -3.0                  1.0       2.0          10.0                21.0                 3.0                 2.0    1.0   0.364201       0.482412  0.4429 -0.093880\n",
      "99         0.966667             0.5673               0.0                  1.0       1.0          10.0                79.0                 1.0                 3.0    1.0   0.625601       0.728611  0.7845 -0.093735\n",
      "100        0.966667             0.4647               3.0                  0.0       2.0           1.0                62.0                 3.0                 1.0    1.0   0.547335       0.569836  0.6628 -0.091201\n",
      "101        0.965833             0.2540              -7.0                  1.0       1.0          10.0                45.0                 0.0                 2.0    0.0   0.301909       0.101293   0.001 -0.091148\n",
      "102        0.968333             0.4220              -7.0                  1.0      -1.0           4.0                65.0                 1.0                 3.0    0.0   0.302590       0.130648  0.0205 -0.091141\n",
      "103        0.967778             0.6433               7.0                  0.0       4.0          12.0                60.0                 3.0                 1.0    1.0   0.695760       0.890140  0.9539 -0.090437\n",
      "104        0.966667             0.6520               7.0                  0.0       2.0           6.0                67.0                 3.0                 1.0    1.0   0.684192       0.891589  0.9011 -0.089953\n",
      "105        0.966667             0.4887              -3.0                  1.0       3.0          14.0                55.0                 2.0                 2.0    0.0   0.361050       0.431466  0.2018 -0.089634\n",
      "106        0.966667             0.4287              -7.0                  1.0       2.0          10.0                23.0                 3.0                 0.0    0.0   0.349317       0.131956  0.1824 -0.088753\n",
      "107        0.966667             0.4713              -3.0                  1.0       4.0           7.0                63.0                 3.0                 3.0    0.0   0.361613       0.424172  0.2057 -0.088452\n",
      "108        0.967500             0.5853               5.0                  0.0       1.0          10.0                61.0                 2.0                 2.0    1.0   0.621488       0.775612  0.7646 -0.087858\n",
      "109        0.968333             0.4800               2.0                  0.0       2.0           5.0                28.0                 3.0                 3.0    0.0   0.470472       0.482781  0.3655 -0.087754\n",
      "110        0.966667             0.4207              -3.0                  1.0       4.0          15.0                58.0                 1.0                 3.0    0.0   0.341717       0.403159  0.1705 -0.087700\n",
      "111        0.968611             0.7080              -1.0                  1.0       4.0          10.0                55.0                 3.0                 3.0    0.0   0.423761       0.701037   0.306 -0.085938\n",
      "112        0.968056             0.6053               0.0                  1.0       1.0          10.0                70.0                 3.0                 1.0    1.0   0.650044       0.741286  0.8082 -0.085682\n",
      "113        0.968056             0.5607               4.0                  0.0       3.0           4.0                58.0                 3.0                 2.0    1.0   0.619700       0.694632  0.7567 -0.085433\n",
      "114        0.968889             0.3593              -3.0                  1.0       1.0          10.0                53.0                 3.0                 2.0    0.0   0.304169       0.378137   0.085 -0.085294\n",
      "115        0.966667             0.3593              -3.0                  1.0       4.0           9.0                62.0                 3.0                 2.0    0.0   0.350347       0.378137  0.1963 -0.084210\n",
      "116        0.966667             0.4960               0.0                  1.0       1.0          10.0                56.0                 2.0                 3.0    1.0   0.568608       0.703806  0.6805 -0.084019\n",
      "117        0.966667             0.5960               5.0                  0.0       1.0          10.0                10.0                 1.0                 3.0    0.0   0.562131       0.778785  0.4826 -0.083088\n",
      "118        0.966667             0.6840               5.0                  0.0       3.0          10.0                53.0                 3.0                 0.0    1.0   0.667655       0.803655  0.8328 -0.082497\n",
      "119        0.965278             0.4887              -3.0                  1.0       2.0          15.0                56.0                 2.0                 2.0    0.0   0.362879       0.431466  0.2264 -0.080424\n",
      "120        0.965833             0.2540              -7.0                  1.0      -1.0          10.0                15.0                 0.0                 2.0    0.0   0.281979       0.101293   0.001 -0.079511\n",
      "121        0.967500             0.7113               0.0                  0.0       3.0           2.0                22.0                 1.0                 3.0    0.0   0.337226       0.395228  0.1858 -0.079200\n",
      "122        0.966667             0.5367               6.0                  0.0       2.0           3.0                47.0                 3.0                 2.0    1.0   0.602331       0.822495  0.7187 -0.079011\n",
      "123        0.967778             0.6627               6.0                  0.0       2.0           7.0                60.0                 2.0                 3.0    1.0   0.648319       0.851840  0.7845 -0.077239\n",
      "124        0.966667             0.7113               0.0                  1.0       3.0          10.0                 5.0                 2.0                 1.0    1.0   0.640348       0.774549  0.7706 -0.076725\n",
      "125        0.970000             0.3360               0.0                  1.0      -1.0           4.0                15.0                 2.0                 3.0    0.0   0.499042       0.643709  0.4155 -0.076403\n",
      "126        0.966667             0.4887              -3.0                  1.0       2.0          15.0                56.0                 2.0                 2.0    0.0   0.354447       0.431466  0.2226 -0.076082\n",
      "127        0.966667             0.4287              -7.0                  1.0       1.0          10.0                29.0                 3.0                 0.0    0.0   0.346065       0.131956   0.211 -0.075240\n",
      "128        0.966667             0.7113               0.0                  0.0       2.0           2.0                26.0                 2.0                 3.0    0.0   0.327835       0.395228  0.1826 -0.074133\n",
      "129        0.967500             0.5580              -5.0                  1.0       3.0          10.0                29.0                 2.0                 2.0    0.0   0.372385       0.287046  0.2558 -0.073237\n",
      "130        0.966667             0.6293               3.0                  0.0       2.0           8.0                60.0                 3.0                 3.0    1.0   0.535422       0.637158  0.6217 -0.072722\n",
      "131        0.969167             0.3800               0.0                  1.0      -1.0          10.0                 0.0                 3.0                 3.0    0.0   0.486390       0.660797  0.4075 -0.070519\n",
      "132        0.966667             0.6513              -4.0                  1.0       3.0           7.0                42.0                 3.0                 3.0    0.0   0.395862       0.407643  0.2946 -0.069917\n",
      "133        0.967778             0.7693               2.0                  0.0       1.0          10.0                92.0                 2.0                 0.0    1.0   0.663216       0.605039   0.791 -0.069742\n",
      "134        0.966667             0.6107              -1.0                  1.0       3.0           7.0                80.0                 2.0                 0.0    1.0   0.503578       0.664992  0.5791 -0.069278\n",
      "135        0.966667             0.2493               1.0                  0.0       1.0           4.0                60.0                 2.0                 0.0    1.0   0.477723       0.301481  0.5483 -0.068740\n",
      "136        0.966667             0.7633               3.0                  0.0       1.0          10.0                50.0                 3.0                 2.0    1.0   0.562433       0.688372  0.6459 -0.066078\n",
      "137        0.966667             0.3687               0.0                  1.0       4.0           8.0                40.0                 3.0                 3.0    0.0   0.531812       0.656446  0.4672 -0.064548\n",
      "138        0.969444             0.4500               3.0                  0.0       2.0           3.0                24.0                 1.0                 2.0    0.0   0.519868       0.563655   0.454 -0.064147\n",
      "139        0.967778             0.3687               0.0                  1.0       4.0           4.0                40.0                 3.0                 3.0    0.0   0.538397       0.656446  0.4757 -0.063580\n",
      "140        0.969167             0.6913               6.0                  0.0       2.0          11.0                63.0                 3.0                 0.0    1.0   0.720179       0.857916  0.8762 -0.062973\n",
      "141        0.966667             0.7113               0.0                  0.0       1.0          10.0                27.0                 2.0                 3.0    0.0   0.312210       0.395228  0.1884 -0.061980\n",
      "142        0.968333             0.6840               5.0                  0.0       2.0          12.0                35.0                 3.0                 0.0    1.0   0.666758       0.803655  0.7767 -0.061188\n",
      "143        0.967778             0.6980               2.0                  0.0       2.0          13.0                24.0                 3.0                 3.0    0.0   0.507694       0.575520  0.4443 -0.060351\n",
      "144        0.969722             0.7113               7.0                  0.0       2.0          10.0                70.0                 2.0                 1.0    1.0   0.745353       0.901021  0.9311 -0.060098\n",
      "145        0.966667             0.4960               0.0                  1.0       2.0           1.0                61.0                 2.0                 3.0    1.0   0.595785       0.703806   0.677 -0.059061\n",
      "146        0.969167             0.6627               6.0                  0.0       3.0           5.0                55.0                 2.0                 3.0    1.0   0.670191       0.851840  0.7761 -0.058643\n",
      "147        0.967222             0.4800               2.0                  0.0       1.0          10.0                33.0                 3.0                 3.0    0.0   0.452782       0.482781  0.3828 -0.058476\n",
      "148        0.969444             0.5833               7.0                  0.0       2.0           2.0                79.0                 3.0                 0.0    1.0   0.748046       0.879683  0.9253 -0.057901\n",
      "149        0.968889             0.7347               7.0                  0.0       2.0          10.0                 7.0                 3.0                 2.0    1.0   0.672451       0.904538  0.7756 -0.056933\n",
      "150        0.966667             0.3593              -3.0                  1.0       3.0           9.0                62.0                 3.0                 2.0    0.0   0.343664       0.378137  0.2505 -0.055354\n",
      "151        0.966667             0.4713              -3.0                  1.0       3.0           7.0                63.0                 3.0                 3.0    0.0   0.354832       0.424172  0.2664 -0.054937\n",
      "152        0.966667             0.5873              -6.0                  1.0       1.0          10.0                13.0                 0.0                 3.0    1.0   0.347187       0.225153  0.3905 -0.054674\n",
      "153        0.968056             0.3107              -7.0                  1.0       1.0          10.0                44.0                 1.0                 2.0    0.0   0.277751       0.110481  0.1547 -0.053213\n",
      "154        0.966667             0.5580              -5.0                  1.0       2.0          10.0                29.0                 2.0                 2.0    0.0   0.374534       0.287046  0.2958 -0.052778\n",
      "155        0.965278             0.4447              -3.0                  1.0       3.0           5.0                60.0                 3.0                 2.0    0.0   0.373882       0.413086  0.3004 -0.049548\n",
      "156        0.967778             0.7693               2.0                  0.0       1.0           5.0                87.0                 2.0                 0.0    1.0   0.662372       0.605039  0.7444 -0.048662\n",
      "157        0.967222             0.5860              -5.0                  1.0       3.0           8.0                31.0                 3.0                 3.0    0.0   0.362434       0.296958  0.2905 -0.046968\n",
      "158        0.967500             0.7113               0.0                  0.0       2.0           9.0                26.0                 2.0                 3.0    0.0   0.319907       0.395228  0.2357 -0.046786\n",
      "159        0.966667             0.5340              -7.0                  1.0       3.0           4.0                10.0                 2.0                 2.0    0.0   0.351619       0.154015  0.2773 -0.046740\n",
      "160        0.966667             0.3727              -1.0                  1.0       4.0           3.0                63.0                 2.0                 2.0    0.0   0.391999       0.569070  0.3272 -0.046603\n",
      "161        0.966111             0.5147               2.0                  0.0       4.0          10.0                22.0                 3.0                 2.0    1.0   0.489880       0.497629   0.536 -0.044927\n",
      "162        0.966667             0.8520               6.0                  0.0       1.0          10.0                54.0                 3.0                 1.0    1.0   0.686756       0.888278   0.769 -0.044761\n",
      "163        0.969444             0.2880              -5.0                  1.0       1.0          10.0                43.0                 2.0                 2.0    1.0   0.281751       0.202275  0.3135 -0.044599\n",
      "164        0.966667             0.8520               6.0                  0.0       2.0           7.0                51.0                 3.0                 1.0    1.0   0.692583       0.888278  0.7756 -0.044150\n",
      "165        0.966667             0.4827              -4.0                  1.0       1.0          10.0                55.0                 3.0                 3.0    0.0   0.358065       0.340193  0.2907 -0.043704\n",
      "166        0.969167             0.7693               2.0                  0.0       1.0          10.0                80.0                 2.0                 0.0    1.0   0.653439       0.605039  0.7211 -0.042320\n",
      "167        0.970000             0.4847               6.0                  0.0       3.0          10.0                 1.0                 1.0                 2.0    1.0   0.627209       0.809119  0.6887 -0.042066\n",
      "168        0.966667             0.7347               7.0                  0.0       1.0          10.0                 5.0                 3.0                 2.0    1.0   0.627360       0.904538  0.6876 -0.041267\n",
      "169        0.966667             0.2260              -4.0                  1.0       3.0           3.0                53.0                 1.0                 3.0    0.0   0.328680       0.249361  0.2595 -0.040690\n",
      "170        0.966667             0.3360              -7.0                  1.0       2.0          10.0                14.0                 2.0                 3.0    0.0   0.280468       0.114811  0.1985 -0.039260\n",
      "171        0.966667             0.5020               5.0                  0.0       2.0           8.0                17.0                 1.0                 3.0    1.0   0.553441       0.749816  0.5979 -0.037730\n",
      "172        0.969167             0.7367              -7.0                  1.0       1.0          10.0                14.0                 3.0                 2.0    0.0   0.336582       0.204836   0.276 -0.037112\n",
      "173        0.969722             0.4447               2.0                  1.0       1.0          10.0                43.0                 2.0                 1.0    1.0   0.815701       0.822038  0.9764 -0.033409\n",
      "174        0.967500             0.4367              -5.0                  1.0       1.0           5.0                43.0                 1.0                 1.0    0.0   0.361343       0.246476  0.3128 -0.032725\n",
      "175        0.966667             0.5633               2.0                  1.0       1.0           6.0                 6.0                 1.0                 1.0    1.0   0.821736       0.849836   0.999 -0.031777\n",
      "176        0.966667             0.2613               3.0                  1.0       3.0           3.0                51.0                 3.0                 1.0    1.0   0.804467       0.830959  0.9144 -0.030906\n",
      "177        0.966667             0.5633               2.0                  1.0       2.0           3.0                 4.0                 1.0                 1.0    1.0   0.827700       0.849836   0.999 -0.029686\n",
      "178        0.967222             0.5147               2.0                  0.0       4.0           4.0                22.0                 3.0                 2.0    1.0   0.504860       0.497629  0.5352 -0.029124\n",
      "179        0.967500             0.5633               2.0                  1.0       2.0           4.0                 4.0                 1.0                 1.0    1.0   0.829704       0.849836   0.999 -0.029000\n",
      "180        0.966667             0.5580              -5.0                  1.0       1.0          10.0                71.0                 2.0                 2.0    0.0   0.411006       0.287046  0.3741 -0.028975\n",
      "181        0.966667             0.6840               5.0                  0.0       1.0          12.0                35.0                 3.0                 0.0    1.0   0.639814       0.803655  0.6815 -0.028291\n",
      "182        0.966667             0.5220               0.0                  0.0       3.0           8.0                33.0                 1.0                 2.0    1.0   0.311499       0.320918  0.3323 -0.028211\n",
      "183        0.966667             0.5200              -5.0                  1.0       2.0           4.0                57.0                 3.0                 3.0    0.0   0.372046       0.273915  0.3337 -0.027062\n",
      "184        0.968333             0.3693              -7.0                  1.0       2.0           4.0                 4.0                 1.0                 2.0    1.0   0.286698       0.120735  0.3054 -0.026331\n",
      "185        0.967500             0.5633               2.0                  1.0       3.0          10.0                 1.0                 1.0                 0.0    1.0   0.839133       0.849836  0.9918 -0.025811\n",
      "186        0.966944             0.4760               3.0                  1.0       1.0          10.0                62.0                 3.0                 3.0    1.0   0.809910       0.876544  0.8937 -0.024835\n",
      "187        0.968056             0.6053               0.0                  1.0       1.0          20.0                40.0                 3.0                 1.0    1.0   0.592020       0.741286  0.6224 -0.023866\n",
      "188        0.968611             0.4847               6.0                  0.0       2.0          10.0                 1.0                 1.0                 2.0    1.0   0.599234       0.809119  0.6289 -0.022898\n",
      "189        0.969722             0.4447               2.0                  1.0       3.0           2.0                51.0                 2.0                 2.0    1.0   0.826675       0.822038  0.9059 -0.021187\n",
      "190        0.965833             0.5253               5.0                  1.0      -1.0          16.0                15.0                 1.0                 3.0    0.0   0.822512       0.942519  0.8098 -0.020750\n",
      "191        0.967500             0.2613               3.0                  1.0       1.0          10.0                74.0                 3.0                 1.0    1.0   0.816168       0.830959  0.7671  0.020448\n",
      "192        0.969444             0.3219              -5.0                  0.0       2.0           9.0                98.0                 1.0                 3.0    0.0   0.090245       0.048630  0.1706  0.020960\n",
      "193        0.966944             0.5107               2.0                  0.0       1.0          10.0                58.0                 1.0                 3.0    1.0   0.491008       0.495917  0.4689  0.022994\n",
      "194        0.967778             0.5573              -3.0                  0.0       4.0          27.0                41.0                 2.0                 1.0    0.0   0.089660       0.139678  0.1787  0.023895\n",
      "195        0.966111             0.5573              -3.0                  0.0       4.0          10.0                41.0                 2.0                 1.0    0.0   0.101698       0.139678   0.186  0.024254\n",
      "196        0.966667             0.4847               6.0                  0.0       3.0           1.0                17.0                 2.0                 2.0    1.0   0.593601       0.809119  0.5633  0.025547\n",
      "197        0.966667             0.6340              -3.0                  0.0       3.0           4.0                72.0                 3.0                 3.0    0.0   0.109558       0.156220  0.1942  0.025711\n",
      "198        0.969444             0.3219              -5.0                  0.0       3.0           7.0                96.0                 0.0                 3.0    0.0   0.094253       0.048630  0.1893  0.026951\n",
      "199        0.966667             0.3413               0.0                  0.0       1.0          10.0                57.0                 3.0                 3.0    0.0   0.253560       0.257501  0.3021  0.026972\n",
      "200        0.968333             0.5147              -1.0                  1.0       2.0          10.0                70.0                 3.0                 2.0    1.0   0.405718       0.627434  0.3832  0.027272\n",
      "201        0.967778             0.4227              -5.0                  1.0       1.0          10.0                37.0                 3.0                 3.0    0.0   0.308254       0.242051  0.3509  0.028110\n",
      "202        0.965833             0.5573              -3.0                  0.0       3.0          36.0                50.0                 2.0                 2.0    0.0   0.085556       0.139678  0.1904  0.028932\n",
      "203        0.965278             0.5620               0.0                  0.0       1.0          10.0                45.0                 2.0                 1.0    1.0   0.318330       0.336025  0.2957  0.031365\n",
      "204        0.966667             0.7080              -1.0                  1.0       2.0          10.0                55.0                 3.0                 3.0    0.0   0.412423       0.701037  0.4489  0.031419\n",
      "205        0.968889             0.4447              -3.0                  0.0       2.0          10.0                77.0                 3.0                 2.0    0.0   0.091637       0.118074     0.2  0.031603\n",
      "206        0.967222             0.5860              -5.0                  1.0       3.0           1.0                31.0                 3.0                 3.0    0.0   0.371550       0.296958  0.4121  0.031777\n",
      "207        0.967778             0.7080              -1.0                  1.0       3.0           6.0                55.0                 3.0                 3.0    0.0   0.423330       0.701037  0.4602  0.032575\n",
      "208        0.966667             0.5200              -5.0                  1.0       1.0          10.0                29.0                 3.0                 3.0    0.0   0.336257       0.273915  0.3824  0.033161\n",
      "209        0.968889             0.3219              -5.0                  0.0       2.0          11.0                98.0                 1.0                 3.0    0.0   0.091449       0.048630   0.204  0.033253\n",
      "210        0.970000             0.5220               0.0                  1.0       2.0          10.0                59.0                 1.0                 2.0    1.0   0.613643       0.713003  0.5719  0.033998\n",
      "211        0.965833             0.7693               2.0                  1.0       1.0          10.0                92.0                 3.0                 0.0    1.0   0.889984       0.889543  0.7834  0.034812\n",
      "212        0.965833             0.7693               2.0                  1.0       4.0           2.0                56.0                 3.0                 0.0    1.0   0.880260       0.889543  0.7777  0.035080\n",
      "213        0.968889             0.4487              -2.0                  0.0       3.0          12.0                52.0                 1.0                 2.0    0.0   0.089817       0.164152  0.2078  0.035114\n",
      "214        0.966667             0.4700               4.0                  0.0       1.0          10.0                16.0                 0.0                 3.0    1.0   0.526644       0.660729  0.4909  0.035117\n",
      "215        0.966667             0.4447               2.0                  1.0       2.0          11.0                58.0                 2.0                 3.0    1.0   0.798113       0.822038  0.7231  0.035915\n",
      "216        0.970000             0.4447              -3.0                  0.0       3.0          13.0                76.0                 2.0                 2.0    0.0   0.091378       0.118074   0.217  0.038739\n",
      "217        0.966667             0.4500               3.0                  0.0       2.0           1.0                38.0                 1.0                 2.0    0.0   0.495594       0.563655  0.5335  0.039009\n",
      "218        0.968889             0.4340               0.0                  1.0       3.0          10.0                55.0                 3.0                 1.0    1.0   0.602340       0.681206  0.5556  0.039358\n",
      "219        0.967778             0.6627               6.0                  1.0       1.0          10.0                60.0                 2.0                 3.0    1.0   0.885356       0.967975  0.7708  0.039389\n",
      "220        0.967778             0.4487              -2.0                  0.0       2.0          12.0                55.0                 2.0                 2.0    0.0   0.088833       0.164152  0.2192  0.040157\n",
      "221        0.966389             0.4500               3.0                  0.0       2.0           1.0                38.0                 1.0                 2.0    0.0   0.493256       0.563655  0.5338  0.041641\n",
      "222        0.967778             0.4227              -5.0                  1.0       2.0           1.0                37.0                 3.0                 3.0    0.0   0.325558       0.242051  0.3878  0.044401\n",
      "223        0.968611             0.5200              -5.0                  1.0       2.0           6.0                25.0                 3.0                 3.0    0.0   0.325532       0.273915  0.3885  0.044961\n",
      "224        0.968889             0.2993               2.0                  1.0       4.0           2.0                62.0                 2.0                 1.0    1.0   0.828803       0.782659  0.7267  0.045384\n",
      "225        0.967778             0.4340               0.0                  1.0       3.0          10.0                55.0                 3.0                 1.0    1.0   0.601371       0.681206  0.5463  0.046938\n",
      "226        0.966667             0.7620               2.0                  0.0       3.0          10.0                30.0                 2.0                 1.0    1.0   0.576773       0.602048  0.5227  0.048694\n",
      "227        0.966667             0.4373               1.0                  0.0       2.0           6.0                66.0                 3.0                 0.0    0.0   0.533612       0.373247  0.5799  0.051542\n",
      "228        0.966667             0.5907              -4.0                  1.0       2.0           7.0                87.0                 3.0                 3.0    0.0   0.443661       0.382845  0.5002  0.053365\n",
      "229        0.968889             0.5793               2.0                  0.0       4.0          10.0                17.0                 1.0                 3.0    1.0   0.512938       0.525264  0.4604  0.053939\n",
      "230        0.966667             0.5020               5.0                  0.0       3.0           3.0                14.0                 1.0                 3.0    1.0   0.565750       0.749816  0.5058  0.055661\n",
      "231        0.968056             0.6340              -3.0                  0.0       4.0          10.0                72.0                 2.0                 3.0    0.0   0.107534       0.156220  0.2606  0.056349\n",
      "232        0.966944             0.4700               4.0                  0.0       2.0           3.0                22.0                 0.0                 3.0    1.0   0.546785       0.660729  0.4876  0.057150\n",
      "233        0.966667             0.4487              -2.0                  0.0       3.0           6.0                66.0                 2.0                 2.0    0.0   0.101866       0.164152  0.2666  0.060699\n",
      "234        0.966667             0.5620               0.0                  0.0       1.0          10.0                55.0                 2.0                 1.0    1.0   0.333414       0.336025  0.2889  0.061327\n",
      "235        0.968889             0.5793               2.0                  0.0       3.0          15.0                17.0                 2.0                 3.0    1.0   0.493589       0.525264  0.4348  0.062999\n",
      "236        0.966667             0.6633              -2.0                  1.0       2.0          16.0                58.0                 3.0                 2.0    1.0   0.404745       0.598545  0.3536  0.063504\n",
      "237        0.968889             0.4073              -5.0                  1.0       2.0           3.0                50.0                 1.0                 2.0    1.0   0.341182       0.237245  0.2946  0.063549\n",
      "238        0.966667             0.7453              -2.0                  0.0       1.0          20.0                53.0                 3.0                 0.0    0.0   0.123321       0.246059  0.2868  0.067046\n",
      "239        0.969167             0.6340              -3.0                  0.0       1.0          10.0                66.0                 2.0                 3.0    0.0   0.093454       0.156220   0.276  0.067442\n",
      "240        0.966667             0.5133               4.0                  0.0       1.0          10.0                33.0                 0.0                 3.0    0.0   0.544316       0.677148  0.6052  0.069987\n",
      "241        0.965556             0.5133               4.0                  0.0       1.0           4.0                33.0                 0.0                 3.0    0.0   0.540616       0.677148  0.6055  0.074365\n",
      "242        0.966667             0.3800              -3.0                  1.0       3.0           5.0                75.0                 3.0                 3.0    0.0   0.354058       0.386508  0.4506  0.077683\n",
      "243        0.966667             0.4487              -2.0                  0.0       3.0          13.0                71.0                 2.0                 2.0    0.0   0.101189       0.164152  0.2966  0.077732\n",
      "244        0.969167             0.3687               0.0                  0.0       2.0          10.0                48.0                 3.0                 2.0    0.0   0.270695       0.266574  0.3916  0.080075\n",
      "245        0.966667             0.5313              -1.0                  1.0       2.0           9.0                50.0                 3.0                 2.0    0.0   0.383157       0.634055  0.4764  0.080148\n",
      "246        0.966667             0.2993               2.0                  1.0       4.0           2.0                62.0                 2.0                 1.0    1.0   0.821211       0.782659  0.6647  0.080461\n",
      "247        0.966667             0.5873              -6.0                  1.0       1.0          10.0                79.0                 0.0                 3.0    1.0   0.407906       0.225153  0.3434  0.080548\n",
      "248        0.968889             0.2993               2.0                  1.0       1.0          10.0                74.0                 2.0                 0.0    1.0   0.832039       0.782659  0.6693  0.081152\n",
      "249        0.966667             0.6733               4.0                  0.0       2.0           3.0                49.0                 3.0                 1.0    0.0   0.631481       0.733936  0.6939  0.082729\n",
      "250        0.967222             0.4847               6.0                  0.0       1.0           1.0                 1.0                 2.0                 2.0    1.0   0.578070       0.809119  0.4886  0.083505\n",
      "251        0.966667             0.5337              -2.0                  0.0       4.0          14.0                60.0                 1.0                 1.0    0.0   0.114492       0.185111  0.3192  0.088780\n",
      "252        0.969167             0.4227              -5.0                  1.0       1.0           1.0                22.0                 3.0                 3.0    0.0   0.297296       0.242051   0.422  0.089699\n",
      "253        0.966944             0.3693              -7.0                  1.0       2.0          10.0                 4.0                 1.0                 2.0    1.0   0.298838       0.120735  0.2334  0.096048\n",
      "254        0.966667             0.4487              -2.0                  0.0       3.0          12.0                71.0                 2.0                 2.0    0.0   0.101699       0.164152  0.3378  0.103766\n",
      "255        0.968611             0.4847               6.0                  0.0       1.0           1.0                 1.0                 2.0                 2.0    1.0   0.599491       0.809119  0.4811  0.108850\n",
      "256        0.967778             0.5793               2.0                  0.0       2.0          12.0                14.0                 3.0                 3.0    1.0   0.476996       0.525264  0.3803  0.110495\n",
      "257        0.966944             0.5960               0.0                  1.0       2.0          10.0                77.0                 3.0                 3.0    1.0   0.627146       0.738220  0.4999  0.111080\n",
      "258        0.966667             0.7620               2.0                  0.0       2.0           7.0                31.0                 2.0                 1.0    1.0   0.574292       0.602048  0.4593  0.111129\n",
      "259        0.968611             0.7620               2.0                  0.0       3.0           6.0                30.0                 2.0                 1.0    1.0   0.593385       0.602048  0.4716  0.113871\n",
      "260        0.966667             0.6060              -3.0                  1.0       2.0           5.0                64.0                 2.0                 3.0    1.0   0.387994       0.481258  0.2994  0.116290\n",
      "261        0.966667             0.5907              -4.0                  1.0       3.0           5.0                11.0                 3.0                 3.0    0.0   0.377459       0.382845  0.5098  0.117421\n",
      "262        0.969167             0.3693               0.0                  1.0      -1.0          10.0                15.0                 1.0                 1.0    1.0   0.543020       0.656678  0.4251  0.121680\n",
      "263        0.967222             0.4073              -5.0                  0.0       1.0          10.0                65.0                 1.0                 2.0    1.0   0.092164       0.055861  0.0274  0.121784\n",
      "264        0.965833             0.7080              -1.0                  1.0       1.0          10.0                55.0                 3.0                 3.0    0.0   0.406574       0.701037  0.5378  0.123927\n",
      "265        0.966667             0.5337              -2.0                  0.0       1.0          10.0                24.0                 1.0                 1.0    0.0   0.096487       0.185111  0.3662  0.124793\n",
      "266        0.966667             0.7080              -1.0                  1.0       1.0          10.0                55.0                 3.0                 3.0    0.0   0.405294       0.701037  0.5391  0.126366\n",
      "267        0.967778             0.4433               3.0                  0.0       1.0          10.0                42.0                 3.0                 1.0    0.0   0.499708       0.560831  0.6138  0.127042\n",
      "268        0.966667             0.5620               0.0                  0.0       1.0          10.0                27.0                 2.0                 1.0    1.0   0.314632       0.336025  0.2269  0.127955\n",
      "269        0.969167             0.3800               0.0                  1.0       1.0          10.0                65.0                 3.0                 3.0    0.0   0.551595       0.660797  0.6615  0.133325\n",
      "270        0.970000             0.3360               0.0                  0.0       2.0          10.0                66.0                 2.0                 3.0    0.0   0.275635       0.255770  0.4575  0.133332\n",
      "271        0.970000             0.4847               6.0                  0.0       2.0           1.0                 1.0                 1.0                 2.0    1.0   0.632095       0.809119  0.4802  0.134838\n",
      "272        0.967778             0.4433               3.0                  0.0       2.0           6.0                42.0                 3.0                 1.0    0.0   0.512686       0.560831  0.6322  0.136830\n",
      "273        0.965278             0.4433               3.0                  0.0       1.0           6.0                42.0                 3.0                 1.0    0.0   0.484271       0.560831  0.6108  0.138558\n",
      "274        0.969167             0.3800               0.0                  0.0       2.0          10.0                70.0                 3.0                 3.0    0.0   0.284985       0.270374  0.4709  0.140530\n",
      "275        0.966667             0.3687               0.0                  1.0       3.0           4.0                40.0                 3.0                 3.0    0.0   0.530050       0.656446  0.6533  0.145848\n",
      "276        0.969444             0.5860              -5.0                  1.0       1.0           4.0                12.0                 3.0                 3.0    0.0   0.323547       0.296958  0.5071  0.152468\n",
      "277        0.966667             0.5133               4.0                  0.0       2.0          10.0                32.0                 0.0                 3.0    0.0   0.550997       0.677148  0.6778  0.155815\n",
      "278        0.966667             0.5313              -1.0                  1.0       1.0          10.0                51.0                 3.0                 2.0    0.0   0.376387       0.634055  0.5479  0.158527\n",
      "279        0.966667             0.6733               4.0                  0.0       1.0          10.0                56.0                 3.0                 1.0    0.0   0.625830       0.733936   0.749  0.169338\n",
      "280        0.966667             0.6320               3.0                  1.0       3.0           1.0                18.0                 3.0                 3.0    0.0   0.827337       0.902670  0.9338  0.187495\n",
      "281        0.969722             0.7453              -2.0                  1.0       2.0           4.0                37.0                 3.0                 0.0    0.0   0.448562       0.631773    0.63  0.195692\n",
      "282        0.966667             0.6320               3.0                  1.0       1.0           6.0                17.0                 3.0                 3.0    0.0   0.814168       0.902670  0.9314  0.204637\n",
      "283        0.966667             0.5793               2.0                  0.0       2.0           5.0                14.0                 3.0                 3.0    1.0   0.480226       0.525264  0.3055  0.212165\n",
      "284        0.966667             0.2880              -5.0                  1.0       3.0           9.0                57.0                 2.0                 2.0    1.0   0.342272       0.202275  0.1924  0.219612\n",
      "285        0.966667             0.6320               3.0                  1.0       0.0           1.0                 0.0                 3.0                 3.0    0.0   0.807354       0.902670  0.9338  0.220162\n",
      "286        0.966667             0.5793               2.0                  0.0       1.0          10.0                12.0                 3.0                 3.0    1.0   0.464630       0.525264  0.2821  0.228760\n",
      "287        0.969167             0.6320               3.0                  1.0       3.0           3.0                10.0                 3.0                 1.0    0.0   0.855648       0.902670  0.9813  0.230816\n",
      "288        0.969167             0.3693               0.0                  1.0       1.0          10.0                70.0                 1.0                 1.0    1.0   0.605394       0.656678  0.3773  0.232042\n",
      "289        0.966667             0.3400               3.0                  0.0       1.0          10.0                58.0                 3.0                 2.0    0.0   0.470120       0.516903  0.6753  0.235017\n",
      "290        0.967222             0.5253               5.0                  0.0       1.0          10.0                69.0                 1.0                 3.0    0.0   0.601565       0.757226  0.7796  0.245895\n",
      "291        0.968611             0.4433               3.0                  0.0       3.0          10.0                38.0                 3.0                 1.0    0.0   0.515107       0.560831  0.7168  0.248467\n",
      "292        0.967778             0.5793               2.0                  0.0       3.0           2.0                17.0                 2.0                 3.0    1.0   0.505233       0.525264  0.2972  0.249134\n",
      "293        0.966667             0.5960               5.0                  0.0       1.0          10.0                73.0                 1.0                 3.0    0.0   0.617280       0.778785  0.7944  0.250037\n",
      "294        0.969167             0.6320               3.0                  1.0       2.0           6.0                13.0                 3.0                 2.0    0.0   0.840357       0.902670  0.9824  0.258910\n",
      "295        0.966667             0.3400               3.0                  0.0       3.0           4.0                64.0                 3.0                 2.0    0.0   0.502784       0.516903  0.7174  0.261871\n",
      "296        0.967778             0.6320               3.0                  1.0       1.0          10.0                17.0                 3.0                 3.0    0.0   0.816426       0.902670  0.9644  0.263516\n",
      "297        0.967778             0.6320               3.0                  1.0       2.0           3.0                13.0                 3.0                 3.0    0.0   0.825051       0.902670  0.9761  0.272062\n",
      "298        0.968611             0.7620               2.0                  0.0       1.0           7.0                17.0                 1.0                 1.0    1.0   0.578212       0.602048  0.3271  0.274889\n",
      "299        0.966667             0.3413               0.0                  0.0       4.0          27.0                71.0                 3.0                 3.0    0.0   0.269442       0.257501  0.6402  0.337257\n",
      "300        0.967500             0.3820               7.0                  0.0       1.0          10.0                35.0                 3.0                 3.0    0.0   0.552766       0.838175   0.805  0.342475\n",
      "301        0.968056             0.7453              -2.0                  0.0       1.0          10.0                43.0                 3.0                 0.0    0.0   0.120081       0.246059  0.6097  0.357315\n",
      "302        0.967222             0.5253               5.0                  0.0       2.0          16.0                64.0                 1.0                 3.0    0.0   0.592919       0.757226  0.8465  0.365009\n",
      "303        0.968889             0.5413              -3.0                  1.0       1.0          25.0                28.0                 3.0                 2.0    1.0   0.309842       0.453684   0.082  0.366407\n",
      "304        0.968889             0.3820               7.0                  0.0       2.0          10.0                35.0                 3.0                 3.0    0.0   0.585100       0.838175  0.8453  0.372190\n",
      "305        0.967500             0.3820               7.0                  0.0       4.0           2.0                59.0                 3.0                 3.0    0.0   0.607352       0.838175  0.8623  0.374685\n",
      "306        0.968889             0.5413              -3.0                  1.0       4.0          15.0                80.0                 3.0                 2.0    1.0   0.397948       0.453684  0.1166  0.417929\n",
      "307        0.965833             0.5413              -3.0                  1.0       4.0          25.0                80.0                 3.0                 2.0    1.0   0.403855       0.453684  0.1141  0.429429\n",
      "308        0.966111             0.3820               7.0                  0.0       4.0           2.0                41.0                 3.0                 3.0    0.0   0.554604       0.838175  0.8607  0.433218\n"
     ]
    }
   ],
   "source": [
    "modules_to_reload = [\n",
    "    \"process_data\"\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "import process_data\n",
    "features = [\"game_completed\", \"relative_strength\", \"score_difference\", \"home_has_possession\", \"end.down\", \"end.distance\", \"end.yardsToEndzone\",  \"home_timeouts_left\", \"away_timeouts_left\"]\n",
    "class myModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def predict_proba(self, X):\n",
    "        return np.array([[0.5, 0.5] for _ in X])\n",
    "t = 0.97\n",
    "process_data.assess_differences(new_models, test_data, t, features, threshold=0.02, alt_model=models[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 2024\n",
      "Processed file:  game_401671629.csv\n",
      "Processed file:  game_401671601.csv\n",
      "Processed file:  game_401671826.csv\n",
      "Processed file:  game_401671832.csv\n",
      "Processed file:  game_401671749.csv\n",
      "Processed file:  game_401671775.csv\n",
      "Processed file:  game_401671761.csv\n",
      "Processed file:  game_401671760.csv\n",
      "Processed file:  game_401671774.csv\n",
      "Processed file:  game_401671748.csv\n",
      "Processed file:  game_401671833.csv\n",
      "Processed file:  game_401671827.csv\n",
      "Processed file:  game_401671600.csv\n",
      "Processed file:  game_401671628.csv\n",
      "Processed file:  game_401671616.csv\n",
      "Processed file:  game_401671831.csv\n",
      "Processed file:  game_401671825.csv\n",
      "Processed file:  game_401671819.csv\n",
      "Processed file:  game_401671762.csv\n",
      "Processed file:  game_401671776.csv\n",
      "Processed file:  game_401671789.csv\n",
      "Processed file:  game_401671788.csv\n",
      "Processed file:  game_401671777.csv\n",
      "Processed file:  game_401671763.csv\n",
      "Processed file:  game_401671818.csv\n",
      "Processed file:  game_401671824.csv\n",
      "Processed file:  game_401671830.csv\n",
      "Processed file:  game_401671617.csv\n",
      "Processed file:  game_401671808.csv\n",
      "Processed file:  game_401671834.csv\n",
      "Processed file:  game_401671820.csv\n",
      "Processed file:  game_401671767.csv\n",
      "Processed file:  game_401671773.csv\n",
      "Processed file:  game_401671798.csv\n",
      "Processed file:  game_401671799.csv\n",
      "Processed file:  game_401671772.csv\n",
      "Processed file:  game_401671766.csv\n",
      "Processed file:  game_401671821.csv\n",
      "Processed file:  game_401671835.csv\n",
      "Processed file:  game_401671809.csv\n",
      "Processed file:  game_401671638.csv\n",
      "Processed file:  game_401671823.csv\n",
      "Processed file:  game_401671837.csv\n",
      "Processed file:  game_401671599.csv\n",
      "Processed file:  game_401671770.csv\n",
      "Processed file:  game_401671764.csv\n",
      "Processed file:  game_401671758.csv\n",
      "Processed file:  game_401671759.csv\n",
      "Processed file:  game_401671765.csv\n",
      "Processed file:  game_401671771.csv\n",
      "Processed file:  game_401671836.csv\n",
      "Processed file:  game_401671822.csv\n",
      "Processed file:  game_401671639.csv\n",
      "Processed file:  game_401671662.csv\n",
      "Processed file:  game_401671676.csv\n",
      "Processed file:  game_401671845.csv\n",
      "Processed file:  game_401671851.csv\n",
      "Processed file:  game_401671689.csv\n",
      "Processed file:  game_401671716.csv\n",
      "Processed file:  game_401671702.csv\n",
      "Processed file:  game_401671703.csv\n",
      "Processed file:  game_401671717.csv\n",
      "Processed file:  game_401671688.csv\n",
      "Processed file:  game_401671850.csv\n",
      "Processed file:  game_401671844.csv\n",
      "Processed file:  game_401671677.csv\n",
      "Processed file:  game_401671663.csv\n",
      "Processed file:  game_401671649.csv\n",
      "Processed file:  game_401671675.csv\n",
      "Processed file:  game_401671661.csv\n",
      "Processed file:  game_401671852.csv\n",
      "Processed file:  game_401671846.csv\n",
      "Processed file:  game_401671729.csv\n",
      "Processed file:  game_401671701.csv\n",
      "Processed file:  game_401671715.csv\n",
      "Processed file:  game_401671714.csv\n",
      "Processed file:  game_401671700.csv\n",
      "Processed file:  game_401671728.csv\n",
      "Processed file:  game_401671489.csv\n",
      "Processed file:  game_401671847.csv\n",
      "Processed file:  game_401671853.csv\n",
      "Processed file:  game_401671660.csv\n",
      "Processed file:  game_401671674.csv\n",
      "Processed file:  game_401671648.csv\n",
      "Processed file:  game_401671670.csv\n",
      "Processed file:  game_401671664.csv\n",
      "Processed file:  game_401671658.csv\n",
      "Processed file:  game_401671857.csv\n",
      "Processed file:  game_401671843.csv\n",
      "Processed file:  game_401671704.csv\n",
      "Processed file:  game_401671710.csv\n",
      "Processed file:  game_401671738.csv\n",
      "Processed file:  game_401671739.csv\n",
      "Processed file:  game_401671711.csv\n",
      "Processed file:  game_401671705.csv\n",
      "Processed file:  game_401671842.csv\n",
      "Processed file:  game_401671856.csv\n",
      "Processed file:  game_401671659.csv\n",
      "Processed file:  game_401671665.csv\n",
      "Processed file:  game_401671671.csv\n",
      "Processed file:  game_401671667.csv\n",
      "Processed file:  game_401671673.csv\n",
      "Processed file:  game_401671868.csv\n",
      "Processed file:  game_401671840.csv\n",
      "Processed file:  game_401671698.csv\n",
      "Processed file:  game_401671854.csv\n",
      "Processed file:  game_401671713.csv\n",
      "Processed file:  game_401671707.csv\n",
      "Processed file:  game_401671706.csv\n",
      "Processed file:  game_401671712.csv\n",
      "Processed file:  game_401671855.csv\n",
      "Processed file:  game_401671699.csv\n",
      "Processed file:  game_401671841.csv\n",
      "Processed file:  game_401671869.csv\n",
      "Processed file:  game_401671672.csv\n",
      "Processed file:  game_401671666.csv\n",
      "Processed file:  game_401671643.csv\n",
      "Processed file:  game_401671657.csv\n",
      "Processed file:  game_401671864.csv\n",
      "Processed file:  game_401671870.csv\n",
      "Processed file:  game_401671858.csv\n",
      "Processed file:  game_401671680.csv\n",
      "Processed file:  game_401671694.csv\n",
      "Processed file:  game_401671737.csv\n",
      "Processed file:  game_401671723.csv\n",
      "Processed file:  game_401671722.csv\n",
      "Processed file:  game_401671736.csv\n",
      "Processed file:  game_401671695.csv\n",
      "Processed file:  game_401671681.csv\n",
      "Processed file:  game_401671859.csv\n",
      "Processed file:  game_401671871.csv\n",
      "Processed file:  game_401671865.csv\n",
      "Processed file:  game_401671656.csv\n",
      "Processed file:  game_401671642.csv\n",
      "Processed file:  game_401671668.csv\n",
      "Processed file:  game_401671654.csv\n",
      "Processed file:  game_401671640.csv\n",
      "Processed file:  game_401671873.csv\n",
      "Processed file:  game_401671867.csv\n",
      "Processed file:  game_401671697.csv\n",
      "Processed file:  game_401671683.csv\n",
      "Processed file:  game_401671495.csv\n",
      "Processed file:  game_401671708.csv\n",
      "Processed file:  game_401671720.csv\n",
      "Processed file:  game_401671734.csv\n",
      "Processed file:  game_401671735.csv\n",
      "Processed file:  game_401671721.csv\n",
      "Processed file:  game_401671709.csv\n",
      "Processed file:  game_401671494.csv\n",
      "Processed file:  game_401671682.csv\n",
      "Processed file:  game_401671696.csv\n",
      "Processed file:  game_401671866.csv\n",
      "Processed file:  game_401671872.csv\n",
      "Processed file:  game_401671641.csv\n",
      "Processed file:  game_401671655.csv\n",
      "Processed file:  game_401671669.csv\n",
      "Processed file:  game_401671651.csv\n",
      "Processed file:  game_401671645.csv\n",
      "Processed file:  game_401671679.csv\n",
      "Processed file:  game_401671692.csv\n",
      "Processed file:  game_401671686.csv\n",
      "Processed file:  game_401671876.csv\n",
      "Processed file:  game_401671862.csv\n",
      "Processed file:  game_401671490.csv\n",
      "Processed file:  game_401671725.csv\n",
      "Processed file:  game_401671731.csv\n",
      "Processed file:  game_401671719.csv\n",
      "Processed file:  game_401671718.csv\n",
      "Processed file:  game_401671730.csv\n",
      "Processed file:  game_401671724.csv\n",
      "Processed file:  game_401671491.csv\n",
      "Processed file:  game_401671863.csv\n",
      "Processed file:  game_401671877.csv\n",
      "Processed file:  game_401671687.csv\n",
      "Processed file:  game_401671693.csv\n",
      "Processed file:  game_401671678.csv\n",
      "Processed file:  game_401671644.csv\n",
      "Processed file:  game_401671650.csv\n",
      "Processed file:  game_401671646.csv\n",
      "Processed file:  game_401671652.csv\n",
      "Processed file:  game_401671685.csv\n",
      "Processed file:  game_401671849.csv\n",
      "Processed file:  game_401671691.csv\n",
      "Processed file:  game_401671861.csv\n",
      "Processed file:  game_401671875.csv\n",
      "Processed file:  game_401671493.csv\n",
      "Processed file:  game_401671732.csv\n",
      "Processed file:  game_401671726.csv\n",
      "Processed file:  game_401671727.csv\n",
      "Processed file:  game_401671733.csv\n",
      "Processed file:  game_401671492.csv\n",
      "Processed file:  game_401671874.csv\n",
      "Processed file:  game_401671860.csv\n",
      "Processed file:  game_401671690.csv\n",
      "Processed file:  game_401671848.csv\n",
      "Processed file:  game_401671684.csv\n",
      "Processed file:  game_401671653.csv\n",
      "Processed file:  game_401671647.csv\n",
      "Processed file:  game_401671620.csv\n",
      "Processed file:  game_401671634.csv\n",
      "Processed file:  game_401671807.csv\n",
      "Processed file:  game_401671813.csv\n",
      "Processed file:  game_401671768.csv\n",
      "Processed file:  game_401671754.csv\n",
      "Processed file:  game_401671740.csv\n",
      "Processed file:  game_401671797.csv\n",
      "Processed file:  game_401671783.csv\n",
      "Processed file:  game_401671782.csv\n",
      "Processed file:  game_401671796.csv\n",
      "Processed file:  game_401671741.csv\n",
      "Processed file:  game_401671755.csv\n",
      "Processed file:  game_401671769.csv\n",
      "Processed file:  game_401671812.csv\n",
      "Processed file:  game_401671806.csv\n",
      "Processed file:  game_401671635.csv\n",
      "Processed file:  game_401671621.csv\n",
      "Processed file:  game_401671637.csv\n",
      "Processed file:  game_401671623.csv\n",
      "Processed file:  game_401671810.csv\n",
      "Processed file:  game_401671804.csv\n",
      "Processed file:  game_401671838.csv\n",
      "Processed file:  game_401671743.csv\n",
      "Processed file:  game_401671757.csv\n",
      "Processed file:  game_401671780.csv\n",
      "Processed file:  game_401671794.csv\n",
      "Processed file:  game_401671795.csv\n",
      "Processed file:  game_401671781.csv\n",
      "Processed file:  game_401671756.csv\n",
      "Processed file:  game_401671742.csv\n",
      "Processed file:  game_401671839.csv\n",
      "Processed file:  game_401671805.csv\n",
      "Processed file:  game_401671811.csv\n",
      "Processed file:  game_401671622.csv\n",
      "Processed file:  game_401671636.csv\n",
      "Processed file:  game_401671632.csv\n",
      "Processed file:  game_401671626.csv\n",
      "Processed file:  game_401671829.csv\n",
      "Processed file:  game_401671815.csv\n",
      "Processed file:  game_401671801.csv\n",
      "Processed file:  game_401671746.csv\n",
      "Processed file:  game_401671752.csv\n",
      "Processed file:  game_401671785.csv\n",
      "Processed file:  game_401671791.csv\n",
      "Processed file:  game_401671790.csv\n",
      "Processed file:  game_401671784.csv\n",
      "Processed file:  game_401671753.csv\n",
      "Processed file:  game_401671747.csv\n",
      "Processed file:  game_401671800.csv\n",
      "Processed file:  game_401671814.csv\n",
      "Processed file:  game_401671828.csv\n",
      "Processed file:  game_401671627.csv\n",
      "Processed file:  game_401671633.csv\n",
      "Processed file:  game_401671625.csv\n",
      "Processed file:  game_401671631.csv\n",
      "Processed file:  game_401671619.csv\n",
      "Processed file:  game_401671802.csv\n",
      "Processed file:  game_401671816.csv\n",
      "Processed file:  game_401671751.csv\n",
      "Processed file:  game_401671745.csv\n",
      "Processed file:  game_401671779.csv\n",
      "Processed file:  game_401671792.csv\n",
      "Processed file:  game_401671786.csv\n",
      "Processed file:  game_401671787.csv\n",
      "Processed file:  game_401671793.csv\n",
      "Processed file:  game_401671778.csv\n",
      "Processed file:  game_401671744.csv\n",
      "Processed file:  game_401671750.csv\n",
      "Processed file:  game_401671817.csv\n",
      "Processed file:  game_401671803.csv\n",
      "Processed file:  game_401671618.csv\n",
      "Processed file:  game_401671630.csv\n",
      "Processed file:  game_401671624.csv\n"
     ]
    }
   ],
   "source": [
    "from process_data import write_predictions\n",
    "write_predictions(new_models, interpolated_dir, [2024], 0, features, replace_nan_val = 0, phat_b = \"LR_phat_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied '/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/ML/dataset_interpolated_fixed/2024' to '/Users/aly/Documents/University_of_Waterloo/Winter 2025/Research/code/NFL/test_7/LR_with_end_fix'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the ancestor directory and the parent directory\n",
    "src_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Adjust the number of \"../\" as needed\n",
    "dest_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "\n",
    "# Specify the file or directory to copy from the ancestor directory\n",
    "source = os.path.join(src_dir, \"dataset_interpolated_fixed\", \"2024\")  # Replace with the actual name\n",
    "destination = os.path.join(dest_dir, \"test_7\", \"LR_with_end_fix\")  # Replace with the desired name\n",
    "\n",
    "# Perform the copy operation\n",
    "if os.path.exists(source):\n",
    "    if os.path.isdir(source):\n",
    "        shutil.copytree(source, destination)\n",
    "    else:\n",
    "        shutil.copy2(source, destination)\n",
    "    print(f\"Copied '{source}' to '{destination}'\")\n",
    "else:\n",
    "    print(f\"Source '{source}' does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
